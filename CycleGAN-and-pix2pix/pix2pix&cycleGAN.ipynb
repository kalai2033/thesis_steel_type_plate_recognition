{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 4                             \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: jun23                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: data366                       \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 512                           \t[default: 286]\n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: data366                       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: crop                          \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 366\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.383 M\n",
      "DataParallel(\n",
      "  (module): ResnetGenerator(\n",
      "    (model): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (18): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (27): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory jun23/data366/web...\n",
      "(epoch: 1, iters: 100, time: 0.144, data: 0.123) G_GAN: 1.510 G_L1: 10.821 D_real: 0.519 D_fake: 0.330 \n",
      "(epoch: 1, iters: 200, time: 0.145, data: 0.001) G_GAN: 2.879 G_L1: 10.348 D_real: 0.217 D_fake: 0.057 \n",
      "(epoch: 1, iters: 300, time: 0.146, data: 0.001) G_GAN: 2.369 G_L1: 17.189 D_real: 0.149 D_fake: 0.326 \n",
      "End of epoch 1 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 32, time: 0.169, data: 0.001) G_GAN: 1.630 G_L1: 14.507 D_real: 0.541 D_fake: 0.151 \n",
      "(epoch: 2, iters: 132, time: 0.147, data: 0.001) G_GAN: 2.104 G_L1: 14.199 D_real: 0.237 D_fake: 0.155 \n",
      "(epoch: 2, iters: 232, time: 0.149, data: 0.001) G_GAN: 1.616 G_L1: 12.920 D_real: 0.186 D_fake: 0.361 \n",
      "(epoch: 2, iters: 332, time: 0.148, data: 0.001) G_GAN: 1.957 G_L1: 14.363 D_real: 0.337 D_fake: 0.460 \n",
      "End of epoch 2 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 64, time: 0.164, data: 0.001) G_GAN: 1.854 G_L1: 13.959 D_real: 0.091 D_fake: 0.370 \n",
      "(epoch: 3, iters: 164, time: 0.147, data: 0.001) G_GAN: 1.281 G_L1: 10.857 D_real: 1.240 D_fake: 0.237 \n",
      "(epoch: 3, iters: 264, time: 0.147, data: 0.002) G_GAN: 1.514 G_L1: 11.292 D_real: 0.261 D_fake: 0.280 \n",
      "(epoch: 3, iters: 364, time: 0.147, data: 0.001) G_GAN: 0.515 G_L1: 11.018 D_real: 0.633 D_fake: 0.238 \n",
      "End of epoch 3 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 96, time: 0.166, data: 0.001) G_GAN: 1.256 G_L1: 9.460 D_real: 0.043 D_fake: 0.634 \n",
      "(epoch: 4, iters: 196, time: 0.146, data: 0.001) G_GAN: 1.229 G_L1: 8.382 D_real: 2.310 D_fake: 0.209 \n",
      "(epoch: 4, iters: 296, time: 0.146, data: 0.001) G_GAN: 0.662 G_L1: 10.423 D_real: 1.148 D_fake: 0.190 \n",
      "End of epoch 4 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 28, time: 0.147, data: 0.002) G_GAN: 1.596 G_L1: 10.754 D_real: 0.088 D_fake: 0.742 \n",
      "(epoch: 5, iters: 128, time: 0.166, data: 0.001) G_GAN: 0.789 G_L1: 10.823 D_real: 0.797 D_fake: 0.240 \n",
      "(epoch: 5, iters: 228, time: 0.148, data: 0.002) G_GAN: 1.657 G_L1: 11.081 D_real: 0.354 D_fake: 0.190 \n",
      "(epoch: 5, iters: 328, time: 0.148, data: 0.001) G_GAN: 1.122 G_L1: 9.410 D_real: 0.950 D_fake: 0.282 \n",
      "saving the model at the end of epoch 5, iters 1840\n",
      "End of epoch 5 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 60, time: 0.148, data: 0.001) G_GAN: 0.767 G_L1: 7.888 D_real: 0.896 D_fake: 0.314 \n",
      "(epoch: 6, iters: 160, time: 0.162, data: 0.002) G_GAN: 1.090 G_L1: 10.543 D_real: 0.822 D_fake: 0.210 \n",
      "(epoch: 6, iters: 260, time: 0.147, data: 0.002) G_GAN: 1.698 G_L1: 9.055 D_real: 1.323 D_fake: 0.129 \n",
      "(epoch: 6, iters: 360, time: 0.147, data: 0.001) G_GAN: 0.853 G_L1: 10.777 D_real: 0.410 D_fake: 0.461 \n",
      "End of epoch 6 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 92, time: 0.147, data: 0.001) G_GAN: 0.897 G_L1: 10.025 D_real: 1.677 D_fake: 0.186 \n",
      "(epoch: 7, iters: 192, time: 0.167, data: 0.001) G_GAN: 0.431 G_L1: 5.926 D_real: 1.775 D_fake: 0.525 \n",
      "(epoch: 7, iters: 292, time: 0.148, data: 0.001) G_GAN: 1.974 G_L1: 12.362 D_real: 0.041 D_fake: 0.429 \n",
      "End of epoch 7 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 24, time: 0.148, data: 0.002) G_GAN: 1.567 G_L1: 12.059 D_real: 0.032 D_fake: 0.496 \n",
      "(epoch: 8, iters: 124, time: 0.148, data: 0.001) G_GAN: 1.447 G_L1: 12.682 D_real: 0.256 D_fake: 0.556 \n",
      "(epoch: 8, iters: 224, time: 0.167, data: 0.001) G_GAN: 0.847 G_L1: 8.429 D_real: 0.532 D_fake: 0.464 \n",
      "(epoch: 8, iters: 324, time: 0.148, data: 0.001) G_GAN: 1.387 G_L1: 10.954 D_real: 0.326 D_fake: 0.597 \n",
      "End of epoch 8 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 56, time: 0.148, data: 0.001) G_GAN: 1.471 G_L1: 9.469 D_real: 0.742 D_fake: 0.253 \n",
      "(epoch: 9, iters: 156, time: 0.148, data: 0.002) G_GAN: 1.187 G_L1: 8.758 D_real: 0.604 D_fake: 0.324 \n",
      "(epoch: 9, iters: 256, time: 0.168, data: 0.001) G_GAN: 1.357 G_L1: 7.907 D_real: 0.489 D_fake: 0.316 \n",
      "(epoch: 9, iters: 356, time: 0.149, data: 0.001) G_GAN: 0.939 G_L1: 10.449 D_real: 0.562 D_fake: 0.488 \n",
      "End of epoch 9 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 88, time: 0.149, data: 0.001) G_GAN: 0.504 G_L1: 8.564 D_real: 1.461 D_fake: 0.304 \n",
      "(epoch: 10, iters: 188, time: 0.149, data: 0.002) G_GAN: 0.957 G_L1: 8.002 D_real: 0.162 D_fake: 1.171 \n",
      "(epoch: 10, iters: 288, time: 0.169, data: 0.001) G_GAN: 1.488 G_L1: 10.912 D_real: 0.322 D_fake: 0.246 \n",
      "saving the model at the end of epoch 10, iters 3680\n",
      "End of epoch 10 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.176 G_L1: 8.443 D_real: 0.134 D_fake: 0.941 \n",
      "(epoch: 11, iters: 120, time: 0.149, data: 0.002) G_GAN: 1.279 G_L1: 10.223 D_real: 0.115 D_fake: 0.689 \n",
      "(epoch: 11, iters: 220, time: 0.149, data: 0.001) G_GAN: 1.369 G_L1: 8.584 D_real: 0.467 D_fake: 0.344 \n",
      "(epoch: 11, iters: 320, time: 0.168, data: 0.002) G_GAN: 0.654 G_L1: 8.593 D_real: 0.582 D_fake: 0.768 \n",
      "End of epoch 11 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 52, time: 0.149, data: 0.001) G_GAN: 1.243 G_L1: 7.853 D_real: 1.609 D_fake: 0.214 \n",
      "(epoch: 12, iters: 152, time: 0.149, data: 0.002) G_GAN: 0.860 G_L1: 8.967 D_real: 0.515 D_fake: 0.481 \n",
      "(epoch: 12, iters: 252, time: 0.148, data: 0.001) G_GAN: 1.112 G_L1: 8.768 D_real: 0.191 D_fake: 0.698 \n",
      "(epoch: 12, iters: 352, time: 0.169, data: 0.001) G_GAN: 0.903 G_L1: 9.400 D_real: 0.049 D_fake: 1.705 \n",
      "End of epoch 12 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 84, time: 0.148, data: 0.001) G_GAN: 1.039 G_L1: 8.351 D_real: 0.249 D_fake: 0.552 \n",
      "(epoch: 13, iters: 184, time: 0.149, data: 0.001) G_GAN: 1.060 G_L1: 9.420 D_real: 0.031 D_fake: 1.175 \n",
      "(epoch: 13, iters: 284, time: 0.149, data: 0.001) G_GAN: 1.030 G_L1: 9.279 D_real: 1.989 D_fake: 0.484 \n",
      "End of epoch 13 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 16, time: 0.172, data: 0.002) G_GAN: 1.284 G_L1: 9.024 D_real: 0.255 D_fake: 0.264 \n",
      "(epoch: 14, iters: 116, time: 0.149, data: 0.001) G_GAN: 1.529 G_L1: 12.228 D_real: 0.266 D_fake: 0.313 \n",
      "(epoch: 14, iters: 216, time: 0.150, data: 0.002) G_GAN: 1.028 G_L1: 9.980 D_real: 0.693 D_fake: 0.293 \n",
      "saving the latest model (epoch 14, total_iters 5000)\n",
      "(epoch: 14, iters: 316, time: 0.150, data: 0.001) G_GAN: 1.763 G_L1: 8.204 D_real: 1.926 D_fake: 0.159 \n",
      "End of epoch 14 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 48, time: 0.172, data: 0.001) G_GAN: 0.800 G_L1: 6.297 D_real: 0.349 D_fake: 0.699 \n",
      "(epoch: 15, iters: 148, time: 0.150, data: 0.001) G_GAN: 1.461 G_L1: 10.997 D_real: 0.298 D_fake: 0.359 \n",
      "(epoch: 15, iters: 248, time: 0.149, data: 0.001) G_GAN: 0.951 G_L1: 7.129 D_real: 0.892 D_fake: 0.367 \n",
      "(epoch: 15, iters: 348, time: 0.149, data: 0.001) G_GAN: 0.972 G_L1: 9.485 D_real: 0.313 D_fake: 0.451 \n",
      "saving the model at the end of epoch 15, iters 5520\n",
      "End of epoch 15 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 80, time: 0.171, data: 0.001) G_GAN: 0.874 G_L1: 9.912 D_real: 0.232 D_fake: 0.681 \n",
      "(epoch: 16, iters: 180, time: 0.149, data: 0.001) G_GAN: 1.506 G_L1: 12.035 D_real: 0.528 D_fake: 0.273 \n",
      "(epoch: 16, iters: 280, time: 0.149, data: 0.001) G_GAN: 1.112 G_L1: 5.447 D_real: 0.715 D_fake: 0.337 \n",
      "End of epoch 16 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 12, time: 0.151, data: 0.001) G_GAN: 1.674 G_L1: 12.979 D_real: 0.253 D_fake: 0.190 \n",
      "(epoch: 17, iters: 112, time: 0.172, data: 0.002) G_GAN: 0.870 G_L1: 7.934 D_real: 0.201 D_fake: 0.687 \n",
      "(epoch: 17, iters: 212, time: 0.150, data: 0.001) G_GAN: 1.729 G_L1: 14.296 D_real: 0.273 D_fake: 0.169 \n",
      "(epoch: 17, iters: 312, time: 0.150, data: 0.002) G_GAN: 1.902 G_L1: 6.793 D_real: 1.818 D_fake: 0.102 \n",
      "End of epoch 17 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 44, time: 0.150, data: 0.002) G_GAN: 0.805 G_L1: 8.182 D_real: 0.285 D_fake: 0.757 \n",
      "(epoch: 18, iters: 144, time: 0.175, data: 0.001) G_GAN: 0.830 G_L1: 5.798 D_real: 0.346 D_fake: 1.035 \n",
      "(epoch: 18, iters: 244, time: 0.149, data: 0.001) G_GAN: 1.042 G_L1: 7.420 D_real: 0.626 D_fake: 0.554 \n",
      "(epoch: 18, iters: 344, time: 0.149, data: 0.001) G_GAN: 0.925 G_L1: 7.830 D_real: 0.947 D_fake: 0.401 \n",
      "End of epoch 18 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 76, time: 0.149, data: 0.001) G_GAN: 1.160 G_L1: 3.706 D_real: 1.351 D_fake: 0.273 \n",
      "(epoch: 19, iters: 176, time: 0.174, data: 0.001) G_GAN: 0.837 G_L1: 7.895 D_real: 0.150 D_fake: 0.718 \n",
      "(epoch: 19, iters: 276, time: 0.150, data: 0.002) G_GAN: 1.240 G_L1: 8.915 D_real: 0.529 D_fake: 0.340 \n",
      "End of epoch 19 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 8, time: 0.150, data: 0.001) G_GAN: 1.168 G_L1: 6.846 D_real: 0.747 D_fake: 0.255 \n",
      "(epoch: 20, iters: 108, time: 0.150, data: 0.001) G_GAN: 1.000 G_L1: 7.920 D_real: 0.315 D_fake: 0.330 \n",
      "(epoch: 20, iters: 208, time: 0.174, data: 0.002) G_GAN: 1.374 G_L1: 8.064 D_real: 0.244 D_fake: 0.635 \n",
      "(epoch: 20, iters: 308, time: 0.149, data: 0.001) G_GAN: 0.824 G_L1: 7.180 D_real: 0.376 D_fake: 0.719 \n",
      "saving the model at the end of epoch 20, iters 7360\n",
      "End of epoch 20 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 40, time: 0.156, data: 0.002) G_GAN: 1.149 G_L1: 7.284 D_real: 0.477 D_fake: 0.349 \n",
      "(epoch: 21, iters: 140, time: 0.149, data: 0.001) G_GAN: 1.217 G_L1: 7.751 D_real: 0.995 D_fake: 0.233 \n",
      "(epoch: 21, iters: 240, time: 0.172, data: 0.002) G_GAN: 0.971 G_L1: 12.147 D_real: 0.969 D_fake: 0.459 \n",
      "(epoch: 21, iters: 340, time: 0.149, data: 0.002) G_GAN: 1.340 G_L1: 11.769 D_real: 0.046 D_fake: 0.502 \n",
      "End of epoch 21 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 72, time: 0.149, data: 0.001) G_GAN: 1.265 G_L1: 6.345 D_real: 2.022 D_fake: 0.221 \n",
      "(epoch: 22, iters: 172, time: 0.149, data: 0.002) G_GAN: 1.428 G_L1: 10.272 D_real: 0.177 D_fake: 0.631 \n",
      "(epoch: 22, iters: 272, time: 0.173, data: 0.001) G_GAN: 1.254 G_L1: 8.263 D_real: 0.068 D_fake: 0.960 \n",
      "End of epoch 22 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 4, time: 0.095, data: 0.001) G_GAN: 0.846 G_L1: 7.956 D_real: 0.056 D_fake: 0.949 \n",
      "(epoch: 23, iters: 104, time: 0.150, data: 0.001) G_GAN: 1.117 G_L1: 8.057 D_real: 0.455 D_fake: 0.504 \n",
      "(epoch: 23, iters: 204, time: 0.150, data: 0.002) G_GAN: 0.736 G_L1: 8.689 D_real: 0.431 D_fake: 0.577 \n",
      "(epoch: 23, iters: 304, time: 0.175, data: 0.001) G_GAN: 0.618 G_L1: 6.499 D_real: 0.978 D_fake: 0.288 \n",
      "End of epoch 23 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 36, time: 0.149, data: 0.001) G_GAN: 1.191 G_L1: 7.703 D_real: 1.151 D_fake: 0.171 \n",
      "(epoch: 24, iters: 136, time: 0.149, data: 0.001) G_GAN: 1.140 G_L1: 8.926 D_real: 0.146 D_fake: 0.642 \n",
      "(epoch: 24, iters: 236, time: 0.150, data: 0.001) G_GAN: 1.140 G_L1: 6.404 D_real: 1.411 D_fake: 0.200 \n",
      "(epoch: 24, iters: 336, time: 0.174, data: 0.001) G_GAN: 1.326 G_L1: 6.886 D_real: 0.217 D_fake: 0.572 \n",
      "End of epoch 24 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 68, time: 0.149, data: 0.001) G_GAN: 1.487 G_L1: 7.665 D_real: 1.433 D_fake: 0.167 \n",
      "(epoch: 25, iters: 168, time: 0.150, data: 0.001) G_GAN: 1.120 G_L1: 4.119 D_real: 1.768 D_fake: 0.236 \n",
      "(epoch: 25, iters: 268, time: 0.150, data: 0.002) G_GAN: 1.270 G_L1: 9.503 D_real: 0.309 D_fake: 0.297 \n",
      "(epoch: 25, iters: 368, time: 0.132, data: 0.001) G_GAN: 1.064 G_L1: 6.231 D_real: 0.343 D_fake: 0.487 \n",
      "saving the model at the end of epoch 25, iters 9200\n",
      "End of epoch 25 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.152, data: 0.089) G_GAN: 1.158 G_L1: 6.436 D_real: 0.964 D_fake: 0.283 \n",
      "(epoch: 26, iters: 200, time: 0.150, data: 0.001) G_GAN: 0.937 G_L1: 7.971 D_real: 0.257 D_fake: 0.864 \n",
      "(epoch: 26, iters: 300, time: 0.149, data: 0.002) G_GAN: 0.789 G_L1: 6.185 D_real: 0.841 D_fake: 0.333 \n",
      "End of epoch 26 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 32, time: 0.176, data: 0.001) G_GAN: 0.921 G_L1: 8.625 D_real: 0.196 D_fake: 1.297 \n",
      "(epoch: 27, iters: 132, time: 0.149, data: 0.001) G_GAN: 0.960 G_L1: 8.282 D_real: 0.079 D_fake: 0.863 \n",
      "(epoch: 27, iters: 232, time: 0.150, data: 0.002) G_GAN: 0.877 G_L1: 7.975 D_real: 0.166 D_fake: 0.959 \n",
      "(epoch: 27, iters: 332, time: 0.149, data: 0.001) G_GAN: 1.119 G_L1: 8.717 D_real: 1.018 D_fake: 0.427 \n",
      "End of epoch 27 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 64, time: 0.175, data: 0.002) G_GAN: 1.211 G_L1: 8.973 D_real: 0.228 D_fake: 0.724 \n",
      "saving the latest model (epoch 28, total_iters 10000)\n",
      "(epoch: 28, iters: 164, time: 0.151, data: 0.002) G_GAN: 0.868 G_L1: 6.901 D_real: 0.440 D_fake: 0.471 \n",
      "(epoch: 28, iters: 264, time: 0.150, data: 0.001) G_GAN: 0.944 G_L1: 5.990 D_real: 0.764 D_fake: 0.541 \n",
      "(epoch: 28, iters: 364, time: 0.150, data: 0.002) G_GAN: 0.906 G_L1: 5.683 D_real: 1.159 D_fake: 0.360 \n",
      "End of epoch 28 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 96, time: 0.176, data: 0.001) G_GAN: 1.015 G_L1: 7.768 D_real: 0.524 D_fake: 0.535 \n",
      "(epoch: 29, iters: 196, time: 0.149, data: 0.001) G_GAN: 1.039 G_L1: 9.975 D_real: 0.235 D_fake: 0.794 \n",
      "(epoch: 29, iters: 296, time: 0.149, data: 0.001) G_GAN: 0.897 G_L1: 7.010 D_real: 0.275 D_fake: 0.550 \n",
      "End of epoch 29 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 28, time: 0.150, data: 0.002) G_GAN: 1.282 G_L1: 7.311 D_real: 1.570 D_fake: 0.309 \n",
      "(epoch: 30, iters: 128, time: 0.172, data: 0.002) G_GAN: 0.937 G_L1: 6.298 D_real: 0.603 D_fake: 0.499 \n",
      "(epoch: 30, iters: 228, time: 0.150, data: 0.001) G_GAN: 0.896 G_L1: 7.859 D_real: 0.333 D_fake: 0.546 \n",
      "(epoch: 30, iters: 328, time: 0.150, data: 0.002) G_GAN: 1.746 G_L1: 10.737 D_real: 0.069 D_fake: 0.401 \n",
      "saving the model at the end of epoch 30, iters 11040\n",
      "End of epoch 30 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 60, time: 0.150, data: 0.001) G_GAN: 1.105 G_L1: 12.104 D_real: 0.068 D_fake: 0.648 \n",
      "(epoch: 31, iters: 160, time: 0.180, data: 0.001) G_GAN: 1.120 G_L1: 8.896 D_real: 0.287 D_fake: 1.343 \n",
      "(epoch: 31, iters: 260, time: 0.149, data: 0.001) G_GAN: 0.799 G_L1: 6.549 D_real: 0.927 D_fake: 0.441 \n",
      "(epoch: 31, iters: 360, time: 0.149, data: 0.001) G_GAN: 1.120 G_L1: 7.182 D_real: 0.383 D_fake: 1.133 \n",
      "End of epoch 31 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 92, time: 0.149, data: 0.001) G_GAN: 0.990 G_L1: 8.118 D_real: 0.313 D_fake: 0.890 \n",
      "(epoch: 32, iters: 192, time: 0.176, data: 0.002) G_GAN: 1.146 G_L1: 5.837 D_real: 1.349 D_fake: 0.312 \n",
      "(epoch: 32, iters: 292, time: 0.149, data: 0.001) G_GAN: 0.998 G_L1: 9.605 D_real: 0.212 D_fake: 0.528 \n",
      "End of epoch 32 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 24, time: 0.149, data: 0.001) G_GAN: 1.146 G_L1: 9.106 D_real: 0.179 D_fake: 0.749 \n",
      "(epoch: 33, iters: 124, time: 0.149, data: 0.002) G_GAN: 0.887 G_L1: 8.926 D_real: 0.116 D_fake: 0.926 \n",
      "(epoch: 33, iters: 224, time: 0.186, data: 0.001) G_GAN: 0.939 G_L1: 7.681 D_real: 0.161 D_fake: 1.133 \n",
      "(epoch: 33, iters: 324, time: 0.149, data: 0.001) G_GAN: 1.393 G_L1: 8.125 D_real: 0.199 D_fake: 0.468 \n",
      "End of epoch 33 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 56, time: 0.149, data: 0.001) G_GAN: 1.111 G_L1: 6.947 D_real: 0.568 D_fake: 0.466 \n",
      "(epoch: 34, iters: 156, time: 0.150, data: 0.001) G_GAN: 1.373 G_L1: 9.436 D_real: 0.246 D_fake: 0.623 \n",
      "(epoch: 34, iters: 256, time: 0.176, data: 0.001) G_GAN: 0.652 G_L1: 6.394 D_real: 1.263 D_fake: 0.361 \n",
      "(epoch: 34, iters: 356, time: 0.150, data: 0.001) G_GAN: 0.856 G_L1: 8.293 D_real: 0.354 D_fake: 0.916 \n",
      "End of epoch 34 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 88, time: 0.150, data: 0.002) G_GAN: 0.772 G_L1: 6.021 D_real: 0.247 D_fake: 1.047 \n",
      "(epoch: 35, iters: 188, time: 0.149, data: 0.001) G_GAN: 1.091 G_L1: 4.555 D_real: 1.318 D_fake: 0.275 \n",
      "(epoch: 35, iters: 288, time: 0.172, data: 0.002) G_GAN: 0.912 G_L1: 5.664 D_real: 0.361 D_fake: 0.663 \n",
      "saving the model at the end of epoch 35, iters 12880\n",
      "End of epoch 35 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 20, time: 0.149, data: 0.001) G_GAN: 1.113 G_L1: 6.604 D_real: 1.135 D_fake: 0.317 \n",
      "(epoch: 36, iters: 120, time: 0.150, data: 0.001) G_GAN: 0.941 G_L1: 8.161 D_real: 0.460 D_fake: 0.459 \n",
      "(epoch: 36, iters: 220, time: 0.149, data: 0.001) G_GAN: 0.843 G_L1: 8.560 D_real: 0.298 D_fake: 0.736 \n",
      "(epoch: 36, iters: 320, time: 0.173, data: 0.001) G_GAN: 0.854 G_L1: 6.670 D_real: 0.758 D_fake: 0.355 \n",
      "End of epoch 36 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 52, time: 0.149, data: 0.001) G_GAN: 1.088 G_L1: 5.740 D_real: 0.804 D_fake: 0.305 \n",
      "(epoch: 37, iters: 152, time: 0.149, data: 0.001) G_GAN: 1.509 G_L1: 9.288 D_real: 0.713 D_fake: 0.236 \n",
      "(epoch: 37, iters: 252, time: 0.149, data: 0.001) G_GAN: 0.809 G_L1: 7.119 D_real: 0.333 D_fake: 0.781 \n",
      "(epoch: 37, iters: 352, time: 0.180, data: 0.001) G_GAN: 1.500 G_L1: 8.326 D_real: 0.136 D_fake: 0.793 \n",
      "End of epoch 37 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 84, time: 0.149, data: 0.001) G_GAN: 1.081 G_L1: 8.875 D_real: 0.434 D_fake: 0.896 \n",
      "(epoch: 38, iters: 184, time: 0.150, data: 0.001) G_GAN: 0.955 G_L1: 8.527 D_real: 0.155 D_fake: 0.912 \n",
      "(epoch: 38, iters: 284, time: 0.150, data: 0.001) G_GAN: 0.805 G_L1: 6.380 D_real: 0.941 D_fake: 0.416 \n",
      "End of epoch 38 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 16, time: 0.179, data: 0.001) G_GAN: 0.668 G_L1: 7.684 D_real: 0.515 D_fake: 0.651 \n",
      "(epoch: 39, iters: 116, time: 0.149, data: 0.002) G_GAN: 1.244 G_L1: 6.246 D_real: 1.235 D_fake: 0.205 \n",
      "(epoch: 39, iters: 216, time: 0.149, data: 0.002) G_GAN: 1.134 G_L1: 6.294 D_real: 0.631 D_fake: 0.434 \n",
      "(epoch: 39, iters: 316, time: 0.149, data: 0.001) G_GAN: 1.264 G_L1: 7.840 D_real: 1.265 D_fake: 0.323 \n",
      "End of epoch 39 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 48, time: 0.182, data: 0.002) G_GAN: 1.069 G_L1: 5.999 D_real: 0.335 D_fake: 0.570 \n",
      "(epoch: 40, iters: 148, time: 0.150, data: 0.001) G_GAN: 0.998 G_L1: 9.154 D_real: 0.140 D_fake: 0.693 \n",
      "(epoch: 40, iters: 248, time: 0.149, data: 0.001) G_GAN: 0.712 G_L1: 8.534 D_real: 0.890 D_fake: 0.542 \n",
      "(epoch: 40, iters: 348, time: 0.149, data: 0.002) G_GAN: 0.697 G_L1: 6.248 D_real: 0.836 D_fake: 0.524 \n",
      "saving the model at the end of epoch 40, iters 14720\n",
      "End of epoch 40 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 80, time: 0.180, data: 0.001) G_GAN: 1.222 G_L1: 6.714 D_real: 1.710 D_fake: 0.248 \n",
      "(epoch: 41, iters: 180, time: 0.150, data: 0.001) G_GAN: 0.766 G_L1: 7.438 D_real: 1.066 D_fake: 0.299 \n",
      "(epoch: 41, iters: 280, time: 0.150, data: 0.002) G_GAN: 0.902 G_L1: 7.159 D_real: 1.104 D_fake: 0.353 \n",
      "saving the latest model (epoch 41, total_iters 15000)\n",
      "End of epoch 41 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 12, time: 0.150, data: 0.001) G_GAN: 1.166 G_L1: 5.895 D_real: 1.407 D_fake: 0.262 \n",
      "(epoch: 42, iters: 112, time: 0.176, data: 0.002) G_GAN: 0.796 G_L1: 4.432 D_real: 0.960 D_fake: 0.423 \n",
      "(epoch: 42, iters: 212, time: 0.149, data: 0.001) G_GAN: 1.498 G_L1: 10.083 D_real: 0.095 D_fake: 0.741 \n",
      "(epoch: 42, iters: 312, time: 0.149, data: 0.001) G_GAN: 0.737 G_L1: 5.034 D_real: 0.657 D_fake: 0.531 \n",
      "End of epoch 42 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 44, time: 0.149, data: 0.002) G_GAN: 0.863 G_L1: 7.532 D_real: 0.497 D_fake: 0.431 \n",
      "(epoch: 43, iters: 144, time: 0.181, data: 0.003) G_GAN: 0.811 G_L1: 5.144 D_real: 0.649 D_fake: 0.560 \n",
      "(epoch: 43, iters: 244, time: 0.150, data: 0.001) G_GAN: 0.587 G_L1: 4.873 D_real: 1.000 D_fake: 0.525 \n",
      "(epoch: 43, iters: 344, time: 0.149, data: 0.001) G_GAN: 1.391 G_L1: 10.783 D_real: 0.260 D_fake: 0.736 \n",
      "End of epoch 43 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 76, time: 0.149, data: 0.001) G_GAN: 0.993 G_L1: 7.072 D_real: 0.349 D_fake: 0.413 \n",
      "(epoch: 44, iters: 176, time: 0.180, data: 0.002) G_GAN: 0.797 G_L1: 8.769 D_real: 0.192 D_fake: 0.963 \n",
      "(epoch: 44, iters: 276, time: 0.149, data: 0.001) G_GAN: 0.728 G_L1: 6.940 D_real: 0.919 D_fake: 0.387 \n",
      "End of epoch 44 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 8, time: 0.150, data: 0.002) G_GAN: 0.918 G_L1: 9.257 D_real: 0.022 D_fake: 1.950 \n",
      "(epoch: 45, iters: 108, time: 0.150, data: 0.001) G_GAN: 1.022 G_L1: 5.078 D_real: 1.064 D_fake: 0.269 \n",
      "(epoch: 45, iters: 208, time: 0.181, data: 0.002) G_GAN: 0.834 G_L1: 9.572 D_real: 0.278 D_fake: 0.986 \n",
      "(epoch: 45, iters: 308, time: 0.151, data: 0.001) G_GAN: 0.800 G_L1: 6.402 D_real: 1.138 D_fake: 0.283 \n",
      "saving the model at the end of epoch 45, iters 16560\n",
      "End of epoch 45 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 40, time: 0.150, data: 0.002) G_GAN: 0.815 G_L1: 7.213 D_real: 0.249 D_fake: 1.068 \n",
      "(epoch: 46, iters: 140, time: 0.150, data: 0.001) G_GAN: 0.828 G_L1: 5.213 D_real: 1.202 D_fake: 0.313 \n",
      "(epoch: 46, iters: 240, time: 0.182, data: 0.001) G_GAN: 0.950 G_L1: 5.543 D_real: 0.601 D_fake: 0.765 \n",
      "(epoch: 46, iters: 340, time: 0.150, data: 0.001) G_GAN: 0.905 G_L1: 6.944 D_real: 0.340 D_fake: 0.793 \n",
      "End of epoch 46 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 72, time: 0.149, data: 0.001) G_GAN: 0.858 G_L1: 6.921 D_real: 0.372 D_fake: 0.639 \n",
      "(epoch: 47, iters: 172, time: 0.150, data: 0.001) G_GAN: 0.982 G_L1: 6.150 D_real: 0.587 D_fake: 0.758 \n",
      "(epoch: 47, iters: 272, time: 0.181, data: 0.001) G_GAN: 0.878 G_L1: 7.816 D_real: 0.856 D_fake: 0.344 \n",
      "End of epoch 47 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 4, time: 0.095, data: 0.002) G_GAN: 1.466 G_L1: 9.049 D_real: 0.530 D_fake: 0.186 \n",
      "(epoch: 48, iters: 104, time: 0.149, data: 0.001) G_GAN: 0.661 G_L1: 5.744 D_real: 0.726 D_fake: 0.510 \n",
      "(epoch: 48, iters: 204, time: 0.149, data: 0.002) G_GAN: 0.896 G_L1: 7.611 D_real: 0.260 D_fake: 0.463 \n",
      "(epoch: 48, iters: 304, time: 0.183, data: 0.001) G_GAN: 1.226 G_L1: 10.371 D_real: 0.307 D_fake: 0.822 \n",
      "End of epoch 48 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 36, time: 0.149, data: 0.002) G_GAN: 0.955 G_L1: 8.376 D_real: 0.743 D_fake: 0.689 \n",
      "(epoch: 49, iters: 136, time: 0.149, data: 0.002) G_GAN: 1.290 G_L1: 9.480 D_real: 0.037 D_fake: 1.327 \n",
      "(epoch: 49, iters: 236, time: 0.149, data: 0.001) G_GAN: 1.033 G_L1: 8.422 D_real: 0.181 D_fake: 0.783 \n",
      "(epoch: 49, iters: 336, time: 0.181, data: 0.002) G_GAN: 0.726 G_L1: 5.637 D_real: 0.808 D_fake: 0.400 \n",
      "End of epoch 49 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 68, time: 0.150, data: 0.001) G_GAN: 0.740 G_L1: 8.046 D_real: 0.659 D_fake: 0.797 \n",
      "(epoch: 50, iters: 168, time: 0.149, data: 0.001) G_GAN: 0.998 G_L1: 5.625 D_real: 1.272 D_fake: 0.195 \n",
      "(epoch: 50, iters: 268, time: 0.149, data: 0.001) G_GAN: 0.541 G_L1: 6.229 D_real: 0.654 D_fake: 0.836 \n",
      "(epoch: 50, iters: 368, time: 0.138, data: 0.002) G_GAN: 0.920 G_L1: 9.015 D_real: 0.220 D_fake: 0.530 \n",
      "saving the model at the end of epoch 50, iters 18400\n",
      "End of epoch 50 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.149, data: 0.098) G_GAN: 1.011 G_L1: 6.433 D_real: 1.018 D_fake: 0.363 \n",
      "(epoch: 51, iters: 200, time: 0.149, data: 0.002) G_GAN: 0.933 G_L1: 6.265 D_real: 0.918 D_fake: 0.337 \n",
      "(epoch: 51, iters: 300, time: 0.150, data: 0.001) G_GAN: 0.912 G_L1: 8.094 D_real: 0.358 D_fake: 0.675 \n",
      "End of epoch 51 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 32, time: 0.194, data: 0.001) G_GAN: 0.848 G_L1: 5.196 D_real: 0.316 D_fake: 1.126 \n",
      "(epoch: 52, iters: 132, time: 0.150, data: 0.001) G_GAN: 0.911 G_L1: 8.031 D_real: 0.255 D_fake: 0.705 \n",
      "(epoch: 52, iters: 232, time: 0.149, data: 0.002) G_GAN: 0.666 G_L1: 5.857 D_real: 0.522 D_fake: 0.686 \n",
      "(epoch: 52, iters: 332, time: 0.150, data: 0.001) G_GAN: 1.058 G_L1: 9.129 D_real: 0.439 D_fake: 0.376 \n",
      "End of epoch 52 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 64, time: 0.187, data: 0.001) G_GAN: 0.682 G_L1: 5.583 D_real: 0.527 D_fake: 0.631 \n",
      "(epoch: 53, iters: 164, time: 0.150, data: 0.001) G_GAN: 0.989 G_L1: 8.317 D_real: 0.252 D_fake: 0.446 \n",
      "(epoch: 53, iters: 264, time: 0.149, data: 0.002) G_GAN: 0.831 G_L1: 9.095 D_real: 0.420 D_fake: 0.822 \n",
      "(epoch: 53, iters: 364, time: 0.150, data: 0.001) G_GAN: 1.268 G_L1: 9.081 D_real: 0.263 D_fake: 0.461 \n",
      "End of epoch 53 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 96, time: 0.186, data: 0.001) G_GAN: 1.045 G_L1: 5.219 D_real: 1.302 D_fake: 0.310 \n",
      "(epoch: 54, iters: 196, time: 0.151, data: 0.002) G_GAN: 0.702 G_L1: 8.502 D_real: 0.359 D_fake: 1.073 \n",
      "(epoch: 54, iters: 296, time: 0.151, data: 0.002) G_GAN: 1.321 G_L1: 10.095 D_real: 0.103 D_fake: 1.473 \n",
      "End of epoch 54 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 28, time: 0.151, data: 0.001) G_GAN: 0.945 G_L1: 5.872 D_real: 0.732 D_fake: 0.503 \n",
      "(epoch: 55, iters: 128, time: 0.189, data: 0.001) G_GAN: 1.064 G_L1: 5.030 D_real: 0.497 D_fake: 0.476 \n",
      "saving the latest model (epoch 55, total_iters 20000)\n",
      "(epoch: 55, iters: 228, time: 0.150, data: 0.001) G_GAN: 0.870 G_L1: 6.905 D_real: 0.305 D_fake: 0.863 \n",
      "(epoch: 55, iters: 328, time: 0.150, data: 0.002) G_GAN: 1.280 G_L1: 8.685 D_real: 0.360 D_fake: 0.746 \n",
      "saving the model at the end of epoch 55, iters 20240\n",
      "End of epoch 55 / 200 \t Time Taken: 36 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 60, time: 0.149, data: 0.002) G_GAN: 0.893 G_L1: 6.831 D_real: 0.619 D_fake: 0.597 \n",
      "(epoch: 56, iters: 160, time: 0.184, data: 0.001) G_GAN: 0.867 G_L1: 7.239 D_real: 0.765 D_fake: 0.318 \n",
      "(epoch: 56, iters: 260, time: 0.150, data: 0.001) G_GAN: 1.052 G_L1: 7.465 D_real: 0.699 D_fake: 0.703 \n",
      "(epoch: 56, iters: 360, time: 0.175, data: 0.002) G_GAN: 0.844 G_L1: 6.585 D_real: 0.228 D_fake: 1.180 \n",
      "End of epoch 56 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 92, time: 0.150, data: 0.002) G_GAN: 0.806 G_L1: 5.831 D_real: 0.606 D_fake: 0.465 \n",
      "(epoch: 57, iters: 192, time: 0.185, data: 0.002) G_GAN: 0.897 G_L1: 8.240 D_real: 0.435 D_fake: 0.568 \n",
      "(epoch: 57, iters: 292, time: 0.162, data: 0.001) G_GAN: 0.849 G_L1: 8.377 D_real: 0.267 D_fake: 1.082 \n",
      "End of epoch 57 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 24, time: 0.150, data: 0.001) G_GAN: 0.894 G_L1: 7.670 D_real: 0.547 D_fake: 0.979 \n",
      "(epoch: 58, iters: 124, time: 0.151, data: 0.002) G_GAN: 1.305 G_L1: 8.124 D_real: 0.161 D_fake: 1.010 \n",
      "(epoch: 58, iters: 224, time: 0.188, data: 0.001) G_GAN: 0.684 G_L1: 7.574 D_real: 0.376 D_fake: 1.187 \n",
      "(epoch: 58, iters: 324, time: 0.150, data: 0.002) G_GAN: 1.263 G_L1: 8.904 D_real: 0.114 D_fake: 1.171 \n",
      "End of epoch 58 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 56, time: 0.149, data: 0.002) G_GAN: 1.200 G_L1: 9.942 D_real: 0.053 D_fake: 0.668 \n",
      "(epoch: 59, iters: 156, time: 0.150, data: 0.001) G_GAN: 0.901 G_L1: 7.257 D_real: 0.170 D_fake: 0.753 \n",
      "(epoch: 59, iters: 256, time: 0.191, data: 0.002) G_GAN: 0.617 G_L1: 7.163 D_real: 0.938 D_fake: 0.493 \n",
      "(epoch: 59, iters: 356, time: 0.150, data: 0.001) G_GAN: 0.688 G_L1: 6.323 D_real: 0.695 D_fake: 0.596 \n",
      "End of epoch 59 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 88, time: 0.150, data: 0.001) G_GAN: 0.953 G_L1: 7.285 D_real: 0.121 D_fake: 1.934 \n",
      "(epoch: 60, iters: 188, time: 0.150, data: 0.001) G_GAN: 1.002 G_L1: 7.947 D_real: 1.290 D_fake: 0.280 \n",
      "(epoch: 60, iters: 288, time: 0.187, data: 0.001) G_GAN: 0.651 G_L1: 7.258 D_real: 1.502 D_fake: 0.369 \n",
      "saving the model at the end of epoch 60, iters 22080\n",
      "End of epoch 60 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 20, time: 0.149, data: 0.001) G_GAN: 1.031 G_L1: 7.219 D_real: 1.682 D_fake: 0.312 \n",
      "(epoch: 61, iters: 120, time: 0.150, data: 0.002) G_GAN: 0.659 G_L1: 7.926 D_real: 0.409 D_fake: 0.834 \n",
      "(epoch: 61, iters: 220, time: 0.149, data: 0.001) G_GAN: 0.505 G_L1: 5.382 D_real: 1.029 D_fake: 0.485 \n",
      "(epoch: 61, iters: 320, time: 0.186, data: 0.001) G_GAN: 1.109 G_L1: 6.931 D_real: 0.099 D_fake: 1.128 \n",
      "End of epoch 61 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 52, time: 0.149, data: 0.001) G_GAN: 0.905 G_L1: 5.816 D_real: 1.390 D_fake: 0.315 \n",
      "(epoch: 62, iters: 152, time: 0.149, data: 0.001) G_GAN: 1.108 G_L1: 8.695 D_real: 1.019 D_fake: 0.359 \n",
      "(epoch: 62, iters: 252, time: 0.150, data: 0.001) G_GAN: 0.724 G_L1: 8.127 D_real: 0.533 D_fake: 0.501 \n",
      "(epoch: 62, iters: 352, time: 0.187, data: 0.002) G_GAN: 0.905 G_L1: 7.460 D_real: 0.184 D_fake: 0.609 \n",
      "End of epoch 62 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 84, time: 0.151, data: 0.001) G_GAN: 0.855 G_L1: 8.171 D_real: 0.298 D_fake: 0.902 \n",
      "(epoch: 63, iters: 184, time: 0.150, data: 0.002) G_GAN: 0.926 G_L1: 7.010 D_real: 1.001 D_fake: 0.549 \n",
      "(epoch: 63, iters: 284, time: 0.149, data: 0.002) G_GAN: 0.764 G_L1: 7.143 D_real: 1.023 D_fake: 0.339 \n",
      "End of epoch 63 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 16, time: 0.190, data: 0.001) G_GAN: 1.082 G_L1: 7.925 D_real: 0.306 D_fake: 0.599 \n",
      "(epoch: 64, iters: 116, time: 0.149, data: 0.004) G_GAN: 0.715 G_L1: 6.144 D_real: 0.643 D_fake: 0.599 \n",
      "(epoch: 64, iters: 216, time: 0.150, data: 0.002) G_GAN: 0.667 G_L1: 5.694 D_real: 0.394 D_fake: 0.955 \n",
      "(epoch: 64, iters: 316, time: 0.150, data: 0.002) G_GAN: 1.171 G_L1: 9.766 D_real: 0.355 D_fake: 0.349 \n",
      "End of epoch 64 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 48, time: 0.188, data: 0.001) G_GAN: 0.890 G_L1: 7.915 D_real: 0.502 D_fake: 0.495 \n",
      "(epoch: 65, iters: 148, time: 0.150, data: 0.002) G_GAN: 0.809 G_L1: 6.272 D_real: 0.409 D_fake: 0.744 \n",
      "(epoch: 65, iters: 248, time: 0.150, data: 0.001) G_GAN: 0.901 G_L1: 6.950 D_real: 0.722 D_fake: 0.587 \n",
      "(epoch: 65, iters: 348, time: 0.150, data: 0.002) G_GAN: 0.813 G_L1: 5.012 D_real: 0.524 D_fake: 0.656 \n",
      "saving the model at the end of epoch 65, iters 23920\n",
      "End of epoch 65 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 80, time: 0.202, data: 0.001) G_GAN: 1.142 G_L1: 7.829 D_real: 0.876 D_fake: 0.393 \n",
      "(epoch: 66, iters: 180, time: 0.150, data: 0.001) G_GAN: 0.895 G_L1: 7.973 D_real: 0.960 D_fake: 0.440 \n",
      "(epoch: 66, iters: 280, time: 0.149, data: 0.001) G_GAN: 1.154 G_L1: 6.400 D_real: 1.336 D_fake: 0.246 \n",
      "End of epoch 66 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 12, time: 0.149, data: 0.002) G_GAN: 0.567 G_L1: 4.828 D_real: 0.920 D_fake: 0.625 \n",
      "(epoch: 67, iters: 112, time: 0.190, data: 0.002) G_GAN: 0.835 G_L1: 9.577 D_real: 0.400 D_fake: 0.481 \n",
      "(epoch: 67, iters: 212, time: 0.150, data: 0.002) G_GAN: 0.862 G_L1: 7.510 D_real: 0.637 D_fake: 0.587 \n",
      "(epoch: 67, iters: 312, time: 0.150, data: 0.001) G_GAN: 0.848 G_L1: 9.333 D_real: 0.053 D_fake: 1.358 \n",
      "End of epoch 67 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 44, time: 0.150, data: 0.001) G_GAN: 0.778 G_L1: 7.256 D_real: 0.668 D_fake: 0.607 \n",
      "(epoch: 68, iters: 144, time: 0.193, data: 0.002) G_GAN: 0.665 G_L1: 5.966 D_real: 0.791 D_fake: 0.585 \n",
      "(epoch: 68, iters: 244, time: 0.169, data: 0.002) G_GAN: 0.836 G_L1: 7.917 D_real: 0.361 D_fake: 0.779 \n",
      "(epoch: 68, iters: 344, time: 0.150, data: 0.001) G_GAN: 0.995 G_L1: 5.504 D_real: 0.537 D_fake: 0.472 \n",
      "saving the latest model (epoch 68, total_iters 25000)\n",
      "End of epoch 68 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 76, time: 0.150, data: 0.002) G_GAN: 0.784 G_L1: 5.363 D_real: 0.566 D_fake: 0.550 \n",
      "(epoch: 69, iters: 176, time: 0.193, data: 0.002) G_GAN: 0.756 G_L1: 7.403 D_real: 0.380 D_fake: 0.707 \n",
      "(epoch: 69, iters: 276, time: 0.149, data: 0.002) G_GAN: 0.976 G_L1: 6.647 D_real: 0.678 D_fake: 0.790 \n",
      "End of epoch 69 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 8, time: 0.149, data: 0.002) G_GAN: 0.953 G_L1: 8.730 D_real: 0.359 D_fake: 0.530 \n",
      "(epoch: 70, iters: 108, time: 0.148, data: 0.001) G_GAN: 0.695 G_L1: 6.393 D_real: 0.607 D_fake: 0.739 \n",
      "(epoch: 70, iters: 208, time: 0.187, data: 0.002) G_GAN: 1.211 G_L1: 4.791 D_real: 1.225 D_fake: 0.213 \n",
      "(epoch: 70, iters: 308, time: 0.149, data: 0.001) G_GAN: 1.047 G_L1: 6.523 D_real: 0.626 D_fake: 0.359 \n",
      "saving the model at the end of epoch 70, iters 25760\n",
      "End of epoch 70 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 40, time: 0.149, data: 0.002) G_GAN: 0.997 G_L1: 5.266 D_real: 1.305 D_fake: 0.234 \n",
      "(epoch: 71, iters: 140, time: 0.148, data: 0.001) G_GAN: 1.468 G_L1: 8.851 D_real: 0.191 D_fake: 0.569 \n",
      "(epoch: 71, iters: 240, time: 0.191, data: 0.001) G_GAN: 1.257 G_L1: 6.224 D_real: 1.037 D_fake: 0.285 \n",
      "(epoch: 71, iters: 340, time: 0.148, data: 0.001) G_GAN: 1.149 G_L1: 7.076 D_real: 0.059 D_fake: 1.714 \n",
      "End of epoch 71 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 72, time: 0.151, data: 0.001) G_GAN: 1.387 G_L1: 7.718 D_real: 1.771 D_fake: 0.195 \n",
      "(epoch: 72, iters: 172, time: 0.148, data: 0.002) G_GAN: 1.106 G_L1: 10.005 D_real: 0.058 D_fake: 0.978 \n",
      "(epoch: 72, iters: 272, time: 0.194, data: 0.001) G_GAN: 0.767 G_L1: 4.129 D_real: 1.023 D_fake: 0.429 \n",
      "End of epoch 72 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 4, time: 0.097, data: 0.001) G_GAN: 0.657 G_L1: 7.112 D_real: 0.371 D_fake: 0.892 \n",
      "(epoch: 73, iters: 104, time: 0.149, data: 0.002) G_GAN: 0.878 G_L1: 2.512 D_real: 1.143 D_fake: 0.407 \n",
      "(epoch: 73, iters: 204, time: 0.149, data: 0.002) G_GAN: 1.087 G_L1: 5.966 D_real: 1.078 D_fake: 0.295 \n",
      "(epoch: 73, iters: 304, time: 0.188, data: 0.001) G_GAN: 1.128 G_L1: 5.975 D_real: 0.373 D_fake: 0.929 \n",
      "End of epoch 73 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 36, time: 0.147, data: 0.001) G_GAN: 0.674 G_L1: 6.090 D_real: 1.235 D_fake: 0.338 \n",
      "(epoch: 74, iters: 136, time: 0.148, data: 0.001) G_GAN: 0.711 G_L1: 5.751 D_real: 0.349 D_fake: 1.122 \n",
      "(epoch: 74, iters: 236, time: 0.149, data: 0.002) G_GAN: 0.734 G_L1: 6.437 D_real: 1.091 D_fake: 0.623 \n",
      "(epoch: 74, iters: 336, time: 0.192, data: 0.001) G_GAN: 1.319 G_L1: 7.273 D_real: 0.321 D_fake: 0.604 \n",
      "End of epoch 74 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 68, time: 0.151, data: 0.001) G_GAN: 0.758 G_L1: 6.202 D_real: 0.562 D_fake: 0.786 \n",
      "(epoch: 75, iters: 168, time: 0.162, data: 0.001) G_GAN: 0.729 G_L1: 6.663 D_real: 0.807 D_fake: 0.485 \n",
      "(epoch: 75, iters: 268, time: 0.165, data: 0.002) G_GAN: 1.045 G_L1: 7.550 D_real: 0.229 D_fake: 0.635 \n",
      "(epoch: 75, iters: 368, time: 0.151, data: 0.002) G_GAN: 1.156 G_L1: 6.998 D_real: 0.198 D_fake: 1.423 \n",
      "saving the model at the end of epoch 75, iters 27600\n",
      "End of epoch 75 / 200 \t Time Taken: 36 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 100, time: 0.148, data: 0.092) G_GAN: 0.994 G_L1: 7.712 D_real: 0.787 D_fake: 0.502 \n",
      "(epoch: 76, iters: 200, time: 0.148, data: 0.002) G_GAN: 0.869 G_L1: 6.704 D_real: 0.269 D_fake: 1.465 \n",
      "(epoch: 76, iters: 300, time: 0.159, data: 0.002) G_GAN: 0.875 G_L1: 4.765 D_real: 0.646 D_fake: 0.590 \n",
      "End of epoch 76 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 32, time: 0.204, data: 0.001) G_GAN: 1.090 G_L1: 5.703 D_real: 0.438 D_fake: 0.632 \n",
      "(epoch: 77, iters: 132, time: 0.147, data: 0.001) G_GAN: 0.729 G_L1: 6.520 D_real: 0.808 D_fake: 0.641 \n",
      "(epoch: 77, iters: 232, time: 1.138, data: 0.002) G_GAN: 1.033 G_L1: 6.927 D_real: 0.889 D_fake: 0.284 \n",
      "(epoch: 77, iters: 332, time: 0.144, data: 0.001) G_GAN: 1.194 G_L1: 9.767 D_real: 0.091 D_fake: 1.027 \n",
      "End of epoch 77 / 200 \t Time Taken: 88 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 64, time: 0.212, data: 0.001) G_GAN: 0.782 G_L1: 7.575 D_real: 0.305 D_fake: 1.054 \n",
      "(epoch: 78, iters: 164, time: 0.146, data: 0.002) G_GAN: 0.911 G_L1: 5.603 D_real: 0.699 D_fake: 0.693 \n",
      "(epoch: 78, iters: 264, time: 0.151, data: 0.001) G_GAN: 0.893 G_L1: 6.677 D_real: 0.425 D_fake: 0.914 \n",
      "(epoch: 78, iters: 364, time: 0.148, data: 0.001) G_GAN: 0.769 G_L1: 6.115 D_real: 0.542 D_fake: 0.476 \n",
      "End of epoch 78 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 96, time: 0.193, data: 0.002) G_GAN: 0.928 G_L1: 5.470 D_real: 0.688 D_fake: 0.695 \n",
      "(epoch: 79, iters: 196, time: 0.148, data: 0.001) G_GAN: 0.844 G_L1: 5.178 D_real: 0.601 D_fake: 0.537 \n",
      "(epoch: 79, iters: 296, time: 0.148, data: 0.001) G_GAN: 1.353 G_L1: 7.139 D_real: 1.440 D_fake: 0.259 \n",
      "End of epoch 79 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 28, time: 0.147, data: 0.002) G_GAN: 0.748 G_L1: 7.304 D_real: 0.382 D_fake: 0.844 \n",
      "(epoch: 80, iters: 128, time: 0.193, data: 0.001) G_GAN: 0.900 G_L1: 9.715 D_real: 0.178 D_fake: 0.757 \n",
      "(epoch: 80, iters: 228, time: 0.147, data: 0.001) G_GAN: 1.215 G_L1: 7.078 D_real: 0.134 D_fake: 1.019 \n",
      "(epoch: 80, iters: 328, time: 0.147, data: 0.001) G_GAN: 0.888 G_L1: 7.380 D_real: 0.491 D_fake: 0.892 \n",
      "saving the model at the end of epoch 80, iters 29440\n",
      "End of epoch 80 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 60, time: 0.147, data: 0.002) G_GAN: 1.431 G_L1: 9.306 D_real: 0.265 D_fake: 0.461 \n",
      "(epoch: 81, iters: 160, time: 0.192, data: 0.002) G_GAN: 0.795 G_L1: 5.051 D_real: 0.838 D_fake: 0.437 \n",
      "(epoch: 81, iters: 260, time: 0.147, data: 0.002) G_GAN: 0.623 G_L1: 6.218 D_real: 0.802 D_fake: 0.560 \n",
      "(epoch: 81, iters: 360, time: 0.147, data: 0.001) G_GAN: 0.938 G_L1: 5.596 D_real: 1.205 D_fake: 0.269 \n",
      "End of epoch 81 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 92, time: 0.147, data: 0.001) G_GAN: 0.885 G_L1: 4.516 D_real: 0.854 D_fake: 0.434 \n",
      "(epoch: 82, iters: 192, time: 0.195, data: 0.002) G_GAN: 0.545 G_L1: 7.137 D_real: 0.947 D_fake: 0.421 \n",
      "saving the latest model (epoch 82, total_iters 30000)\n",
      "(epoch: 82, iters: 292, time: 0.147, data: 0.001) G_GAN: 0.731 G_L1: 5.228 D_real: 0.334 D_fake: 1.034 \n",
      "End of epoch 82 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 24, time: 0.147, data: 0.001) G_GAN: 0.885 G_L1: 7.409 D_real: 0.803 D_fake: 0.359 \n",
      "(epoch: 83, iters: 124, time: 0.147, data: 0.002) G_GAN: 1.189 G_L1: 10.022 D_real: 0.247 D_fake: 0.415 \n",
      "(epoch: 83, iters: 224, time: 0.193, data: 0.001) G_GAN: 1.414 G_L1: 8.180 D_real: 0.370 D_fake: 0.450 \n",
      "(epoch: 83, iters: 324, time: 0.147, data: 0.002) G_GAN: 0.663 G_L1: 6.807 D_real: 1.526 D_fake: 0.346 \n",
      "End of epoch 83 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 56, time: 0.147, data: 0.001) G_GAN: 0.867 G_L1: 7.670 D_real: 0.597 D_fake: 1.204 \n",
      "(epoch: 84, iters: 156, time: 0.147, data: 0.001) G_GAN: 1.065 G_L1: 5.553 D_real: 0.651 D_fake: 0.313 \n",
      "(epoch: 84, iters: 256, time: 0.195, data: 0.002) G_GAN: 1.012 G_L1: 7.546 D_real: 0.880 D_fake: 0.352 \n",
      "(epoch: 84, iters: 356, time: 0.147, data: 0.001) G_GAN: 1.185 G_L1: 8.914 D_real: 0.476 D_fake: 0.319 \n",
      "End of epoch 84 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 88, time: 0.147, data: 0.002) G_GAN: 0.896 G_L1: 7.037 D_real: 0.913 D_fake: 0.376 \n",
      "(epoch: 85, iters: 188, time: 0.147, data: 0.002) G_GAN: 0.865 G_L1: 5.268 D_real: 0.473 D_fake: 0.753 \n",
      "(epoch: 85, iters: 288, time: 0.196, data: 0.001) G_GAN: 0.941 G_L1: 4.509 D_real: 0.903 D_fake: 0.390 \n",
      "saving the model at the end of epoch 85, iters 31280\n",
      "End of epoch 85 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 20, time: 0.147, data: 0.001) G_GAN: 1.006 G_L1: 8.500 D_real: 0.299 D_fake: 0.750 \n",
      "(epoch: 86, iters: 120, time: 0.146, data: 0.002) G_GAN: 1.320 G_L1: 6.451 D_real: 0.172 D_fake: 0.997 \n",
      "(epoch: 86, iters: 220, time: 0.147, data: 0.002) G_GAN: 1.319 G_L1: 8.160 D_real: 0.626 D_fake: 0.232 \n",
      "(epoch: 86, iters: 320, time: 0.203, data: 0.002) G_GAN: 0.717 G_L1: 4.533 D_real: 0.633 D_fake: 0.696 \n",
      "End of epoch 86 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 52, time: 0.147, data: 0.002) G_GAN: 1.225 G_L1: 5.523 D_real: 0.356 D_fake: 0.646 \n",
      "(epoch: 87, iters: 152, time: 0.147, data: 0.002) G_GAN: 0.827 G_L1: 5.866 D_real: 1.307 D_fake: 0.212 \n",
      "(epoch: 87, iters: 252, time: 0.147, data: 0.002) G_GAN: 0.642 G_L1: 7.852 D_real: 0.958 D_fake: 0.433 \n",
      "(epoch: 87, iters: 352, time: 0.193, data: 0.001) G_GAN: 0.724 G_L1: 6.102 D_real: 0.717 D_fake: 0.726 \n",
      "End of epoch 87 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 84, time: 0.147, data: 0.002) G_GAN: 0.980 G_L1: 8.325 D_real: 0.431 D_fake: 0.318 \n",
      "(epoch: 88, iters: 184, time: 0.147, data: 0.001) G_GAN: 0.820 G_L1: 6.866 D_real: 0.622 D_fake: 0.680 \n",
      "(epoch: 88, iters: 284, time: 0.147, data: 0.002) G_GAN: 1.109 G_L1: 5.643 D_real: 0.254 D_fake: 0.768 \n",
      "End of epoch 88 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 16, time: 0.196, data: 0.002) G_GAN: 1.071 G_L1: 7.971 D_real: 0.634 D_fake: 0.594 \n",
      "(epoch: 89, iters: 116, time: 0.147, data: 0.001) G_GAN: 0.775 G_L1: 6.904 D_real: 0.657 D_fake: 0.961 \n",
      "(epoch: 89, iters: 216, time: 0.147, data: 0.001) G_GAN: 1.158 G_L1: 7.684 D_real: 0.690 D_fake: 0.322 \n",
      "(epoch: 89, iters: 316, time: 0.146, data: 0.002) G_GAN: 1.021 G_L1: 6.642 D_real: 0.473 D_fake: 0.575 \n",
      "End of epoch 89 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 48, time: 0.198, data: 0.002) G_GAN: 1.406 G_L1: 7.666 D_real: 1.845 D_fake: 0.139 \n",
      "(epoch: 90, iters: 148, time: 0.147, data: 0.001) G_GAN: 1.006 G_L1: 6.268 D_real: 0.790 D_fake: 0.274 \n",
      "(epoch: 90, iters: 248, time: 0.147, data: 0.001) G_GAN: 0.919 G_L1: 7.661 D_real: 0.488 D_fake: 0.549 \n",
      "(epoch: 90, iters: 348, time: 0.146, data: 0.002) G_GAN: 1.598 G_L1: 8.533 D_real: 0.453 D_fake: 0.149 \n",
      "saving the model at the end of epoch 90, iters 33120\n",
      "End of epoch 90 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 80, time: 0.197, data: 0.001) G_GAN: 1.019 G_L1: 5.886 D_real: 0.843 D_fake: 0.584 \n",
      "(epoch: 91, iters: 180, time: 0.147, data: 0.002) G_GAN: 0.775 G_L1: 7.217 D_real: 1.013 D_fake: 0.404 \n",
      "(epoch: 91, iters: 280, time: 0.147, data: 0.002) G_GAN: 1.238 G_L1: 7.760 D_real: 0.923 D_fake: 0.217 \n",
      "End of epoch 91 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 12, time: 0.147, data: 0.002) G_GAN: 0.983 G_L1: 7.048 D_real: 0.440 D_fake: 0.590 \n",
      "(epoch: 92, iters: 112, time: 0.199, data: 0.002) G_GAN: 0.707 G_L1: 6.375 D_real: 1.118 D_fake: 0.230 \n",
      "(epoch: 92, iters: 212, time: 0.147, data: 0.001) G_GAN: 1.560 G_L1: 6.533 D_real: 1.879 D_fake: 0.141 \n",
      "(epoch: 92, iters: 312, time: 0.146, data: 0.002) G_GAN: 0.837 G_L1: 7.153 D_real: 0.457 D_fake: 1.021 \n",
      "End of epoch 92 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 44, time: 0.147, data: 0.001) G_GAN: 1.202 G_L1: 8.226 D_real: 0.571 D_fake: 0.446 \n",
      "(epoch: 93, iters: 144, time: 0.199, data: 0.001) G_GAN: 0.568 G_L1: 7.884 D_real: 0.464 D_fake: 0.909 \n",
      "(epoch: 93, iters: 244, time: 0.146, data: 0.001) G_GAN: 1.010 G_L1: 5.677 D_real: 0.758 D_fake: 0.540 \n",
      "(epoch: 93, iters: 344, time: 0.146, data: 0.002) G_GAN: 1.237 G_L1: 7.769 D_real: 0.475 D_fake: 0.665 \n",
      "End of epoch 93 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 76, time: 0.147, data: 0.001) G_GAN: 0.999 G_L1: 7.986 D_real: 0.500 D_fake: 0.571 \n",
      "(epoch: 94, iters: 176, time: 0.197, data: 0.002) G_GAN: 0.758 G_L1: 4.093 D_real: 0.595 D_fake: 0.674 \n",
      "(epoch: 94, iters: 276, time: 0.147, data: 0.002) G_GAN: 0.827 G_L1: 5.071 D_real: 0.812 D_fake: 0.363 \n",
      "End of epoch 94 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 8, time: 0.146, data: 0.002) G_GAN: 0.848 G_L1: 6.403 D_real: 1.433 D_fake: 0.181 \n",
      "(epoch: 95, iters: 108, time: 0.147, data: 0.001) G_GAN: 1.308 G_L1: 7.525 D_real: 0.776 D_fake: 0.344 \n",
      "(epoch: 95, iters: 208, time: 0.204, data: 0.002) G_GAN: 0.689 G_L1: 4.505 D_real: 0.590 D_fake: 0.641 \n",
      "(epoch: 95, iters: 308, time: 0.147, data: 0.001) G_GAN: 0.902 G_L1: 6.655 D_real: 0.465 D_fake: 0.465 \n",
      "saving the model at the end of epoch 95, iters 34960\n",
      "End of epoch 95 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 40, time: 0.146, data: 0.001) G_GAN: 0.896 G_L1: 4.267 D_real: 1.363 D_fake: 0.350 \n",
      "saving the latest model (epoch 96, total_iters 35000)\n",
      "(epoch: 96, iters: 140, time: 0.146, data: 0.001) G_GAN: 0.742 G_L1: 4.749 D_real: 0.940 D_fake: 0.517 \n",
      "(epoch: 96, iters: 240, time: 0.197, data: 0.002) G_GAN: 0.691 G_L1: 7.567 D_real: 0.116 D_fake: 1.857 \n",
      "(epoch: 96, iters: 340, time: 0.147, data: 0.001) G_GAN: 0.754 G_L1: 6.315 D_real: 0.699 D_fake: 0.762 \n",
      "End of epoch 96 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 72, time: 0.147, data: 0.002) G_GAN: 1.203 G_L1: 7.049 D_real: 0.458 D_fake: 1.281 \n",
      "(epoch: 97, iters: 172, time: 0.146, data: 0.002) G_GAN: 1.055 G_L1: 6.446 D_real: 0.468 D_fake: 0.576 \n",
      "(epoch: 97, iters: 272, time: 0.197, data: 0.002) G_GAN: 1.169 G_L1: 9.295 D_real: 1.082 D_fake: 0.365 \n",
      "End of epoch 97 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 4, time: 0.094, data: 0.002) G_GAN: 1.129 G_L1: 6.442 D_real: 0.553 D_fake: 0.440 \n",
      "(epoch: 98, iters: 104, time: 0.146, data: 0.002) G_GAN: 1.200 G_L1: 6.963 D_real: 0.306 D_fake: 0.644 \n",
      "(epoch: 98, iters: 204, time: 0.147, data: 0.001) G_GAN: 1.037 G_L1: 5.487 D_real: 0.859 D_fake: 0.380 \n",
      "(epoch: 98, iters: 304, time: 0.199, data: 0.001) G_GAN: 1.330 G_L1: 6.876 D_real: 0.534 D_fake: 0.378 \n",
      "End of epoch 98 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 36, time: 0.148, data: 0.002) G_GAN: 1.059 G_L1: 6.759 D_real: 0.502 D_fake: 0.502 \n",
      "(epoch: 99, iters: 136, time: 0.147, data: 0.001) G_GAN: 1.065 G_L1: 6.913 D_real: 0.544 D_fake: 0.447 \n",
      "(epoch: 99, iters: 236, time: 0.147, data: 0.001) G_GAN: 1.845 G_L1: 9.644 D_real: 0.154 D_fake: 0.419 \n",
      "(epoch: 99, iters: 336, time: 0.197, data: 0.002) G_GAN: 1.349 G_L1: 6.262 D_real: 0.594 D_fake: 0.458 \n",
      "End of epoch 99 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 68, time: 0.147, data: 0.001) G_GAN: 0.999 G_L1: 7.397 D_real: 0.825 D_fake: 0.179 \n",
      "(epoch: 100, iters: 168, time: 0.147, data: 0.001) G_GAN: 0.943 G_L1: 5.652 D_real: 0.215 D_fake: 1.217 \n",
      "(epoch: 100, iters: 268, time: 0.147, data: 0.001) G_GAN: 1.127 G_L1: 5.758 D_real: 0.867 D_fake: 0.371 \n",
      "(epoch: 100, iters: 368, time: 0.152, data: 0.001) G_GAN: 1.110 G_L1: 4.741 D_real: 0.413 D_fake: 0.797 \n",
      "saving the model at the end of epoch 100, iters 36800\n",
      "End of epoch 100 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.147, data: 0.094) G_GAN: 1.073 G_L1: 7.290 D_real: 0.411 D_fake: 0.636 \n",
      "(epoch: 101, iters: 200, time: 0.147, data: 0.002) G_GAN: 1.287 G_L1: 7.914 D_real: 0.204 D_fake: 0.744 \n",
      "(epoch: 101, iters: 300, time: 0.147, data: 0.001) G_GAN: 1.088 G_L1: 8.915 D_real: 0.457 D_fake: 0.355 \n",
      "End of epoch 101 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 32, time: 0.203, data: 0.002) G_GAN: 1.781 G_L1: 6.185 D_real: 1.806 D_fake: 0.093 \n",
      "(epoch: 102, iters: 132, time: 0.147, data: 0.002) G_GAN: 1.436 G_L1: 9.697 D_real: 0.262 D_fake: 0.508 \n",
      "(epoch: 102, iters: 232, time: 0.147, data: 0.002) G_GAN: 0.835 G_L1: 8.578 D_real: 1.142 D_fake: 0.191 \n",
      "(epoch: 102, iters: 332, time: 0.146, data: 0.001) G_GAN: 1.212 G_L1: 5.721 D_real: 0.619 D_fake: 0.534 \n",
      "End of epoch 102 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 64, time: 0.200, data: 0.002) G_GAN: 0.900 G_L1: 6.288 D_real: 0.266 D_fake: 0.888 \n",
      "(epoch: 103, iters: 164, time: 0.147, data: 0.002) G_GAN: 0.980 G_L1: 4.493 D_real: 1.121 D_fake: 0.324 \n",
      "(epoch: 103, iters: 264, time: 0.147, data: 0.001) G_GAN: 1.153 G_L1: 5.911 D_real: 0.906 D_fake: 0.289 \n",
      "(epoch: 103, iters: 364, time: 0.147, data: 0.001) G_GAN: 1.011 G_L1: 7.565 D_real: 0.336 D_fake: 0.533 \n",
      "End of epoch 103 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 96, time: 0.213, data: 0.001) G_GAN: 0.999 G_L1: 6.180 D_real: 0.373 D_fake: 0.738 \n",
      "(epoch: 104, iters: 196, time: 0.147, data: 0.001) G_GAN: 0.793 G_L1: 6.172 D_real: 0.241 D_fake: 1.253 \n",
      "(epoch: 104, iters: 296, time: 0.147, data: 0.002) G_GAN: 1.164 G_L1: 7.512 D_real: 0.637 D_fake: 0.584 \n",
      "End of epoch 104 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 28, time: 0.147, data: 0.002) G_GAN: 0.915 G_L1: 5.747 D_real: 0.623 D_fake: 0.323 \n",
      "(epoch: 105, iters: 128, time: 0.200, data: 0.001) G_GAN: 0.983 G_L1: 7.515 D_real: 0.655 D_fake: 0.621 \n",
      "(epoch: 105, iters: 228, time: 0.147, data: 0.002) G_GAN: 1.688 G_L1: 7.251 D_real: 0.193 D_fake: 0.266 \n",
      "(epoch: 105, iters: 328, time: 0.147, data: 0.002) G_GAN: 1.408 G_L1: 9.952 D_real: 0.330 D_fake: 0.422 \n",
      "saving the model at the end of epoch 105, iters 38640\n",
      "End of epoch 105 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 60, time: 0.147, data: 0.001) G_GAN: 1.000 G_L1: 7.916 D_real: 0.443 D_fake: 0.526 \n",
      "(epoch: 106, iters: 160, time: 0.201, data: 0.002) G_GAN: 0.642 G_L1: 5.525 D_real: 0.948 D_fake: 0.384 \n",
      "(epoch: 106, iters: 260, time: 0.147, data: 0.001) G_GAN: 0.902 G_L1: 5.449 D_real: 0.865 D_fake: 0.258 \n",
      "(epoch: 106, iters: 360, time: 0.147, data: 0.001) G_GAN: 1.326 G_L1: 9.745 D_real: 0.239 D_fake: 0.551 \n",
      "End of epoch 106 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 92, time: 0.147, data: 0.001) G_GAN: 0.978 G_L1: 7.629 D_real: 0.439 D_fake: 0.751 \n",
      "(epoch: 107, iters: 192, time: 0.203, data: 0.001) G_GAN: 0.813 G_L1: 7.858 D_real: 0.826 D_fake: 0.594 \n",
      "(epoch: 107, iters: 292, time: 0.147, data: 0.002) G_GAN: 1.509 G_L1: 6.510 D_real: 0.492 D_fake: 0.260 \n",
      "End of epoch 107 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 24, time: 0.147, data: 0.002) G_GAN: 1.370 G_L1: 3.922 D_real: 0.880 D_fake: 0.209 \n",
      "(epoch: 108, iters: 124, time: 0.147, data: 0.002) G_GAN: 0.549 G_L1: 7.818 D_real: 1.246 D_fake: 0.207 \n",
      "(epoch: 108, iters: 224, time: 0.201, data: 0.002) G_GAN: 2.285 G_L1: 10.039 D_real: 0.130 D_fake: 0.519 \n",
      "(epoch: 108, iters: 324, time: 0.147, data: 0.002) G_GAN: 0.920 G_L1: 6.697 D_real: 0.422 D_fake: 0.589 \n",
      "End of epoch 108 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 56, time: 0.148, data: 0.002) G_GAN: 1.826 G_L1: 9.327 D_real: 0.116 D_fake: 0.831 \n",
      "(epoch: 109, iters: 156, time: 0.147, data: 0.002) G_GAN: 1.228 G_L1: 7.832 D_real: 0.475 D_fake: 0.297 \n",
      "(epoch: 109, iters: 256, time: 0.204, data: 0.002) G_GAN: 1.391 G_L1: 9.414 D_real: 0.366 D_fake: 0.436 \n",
      "saving the latest model (epoch 109, total_iters 40000)\n",
      "(epoch: 109, iters: 356, time: 0.147, data: 0.002) G_GAN: 0.878 G_L1: 6.528 D_real: 0.816 D_fake: 0.435 \n",
      "End of epoch 109 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 88, time: 0.147, data: 0.001) G_GAN: 1.005 G_L1: 5.663 D_real: 0.247 D_fake: 1.056 \n",
      "(epoch: 110, iters: 188, time: 0.147, data: 0.002) G_GAN: 0.353 G_L1: 3.053 D_real: 1.447 D_fake: 0.295 \n",
      "(epoch: 110, iters: 288, time: 0.204, data: 0.002) G_GAN: 0.638 G_L1: 5.774 D_real: 0.561 D_fake: 0.772 \n",
      "saving the model at the end of epoch 110, iters 40480\n",
      "End of epoch 110 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 20, time: 0.147, data: 0.001) G_GAN: 1.717 G_L1: 8.697 D_real: 0.362 D_fake: 0.171 \n",
      "(epoch: 111, iters: 120, time: 0.147, data: 0.003) G_GAN: 0.964 G_L1: 5.432 D_real: 0.635 D_fake: 0.365 \n",
      "(epoch: 111, iters: 220, time: 0.147, data: 0.001) G_GAN: 1.087 G_L1: 7.476 D_real: 0.248 D_fake: 0.831 \n",
      "(epoch: 111, iters: 320, time: 0.215, data: 0.002) G_GAN: 1.657 G_L1: 8.344 D_real: 0.204 D_fake: 0.432 \n",
      "End of epoch 111 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 52, time: 0.147, data: 0.002) G_GAN: 1.267 G_L1: 5.741 D_real: 0.231 D_fake: 1.036 \n",
      "(epoch: 112, iters: 152, time: 0.147, data: 0.002) G_GAN: 0.848 G_L1: 5.967 D_real: 0.532 D_fake: 0.584 \n",
      "(epoch: 112, iters: 252, time: 0.147, data: 0.002) G_GAN: 0.983 G_L1: 8.117 D_real: 0.363 D_fake: 0.849 \n",
      "(epoch: 112, iters: 352, time: 0.204, data: 0.001) G_GAN: 0.788 G_L1: 6.283 D_real: 0.773 D_fake: 0.237 \n",
      "End of epoch 112 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 84, time: 0.147, data: 0.002) G_GAN: 1.186 G_L1: 7.439 D_real: 1.326 D_fake: 0.092 \n",
      "(epoch: 113, iters: 184, time: 0.147, data: 0.002) G_GAN: 1.450 G_L1: 8.825 D_real: 0.163 D_fake: 0.794 \n",
      "(epoch: 113, iters: 284, time: 0.146, data: 0.001) G_GAN: 0.753 G_L1: 7.204 D_real: 0.348 D_fake: 0.926 \n",
      "End of epoch 113 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 16, time: 0.201, data: 0.001) G_GAN: 0.946 G_L1: 5.230 D_real: 0.423 D_fake: 0.688 \n",
      "(epoch: 114, iters: 116, time: 0.147, data: 0.003) G_GAN: 1.147 G_L1: 8.269 D_real: 0.332 D_fake: 0.511 \n",
      "(epoch: 114, iters: 216, time: 0.147, data: 0.001) G_GAN: 1.040 G_L1: 8.397 D_real: 0.266 D_fake: 0.564 \n",
      "(epoch: 114, iters: 316, time: 0.147, data: 0.002) G_GAN: 1.633 G_L1: 5.717 D_real: 0.126 D_fake: 0.993 \n",
      "End of epoch 114 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 48, time: 0.204, data: 0.002) G_GAN: 0.961 G_L1: 6.671 D_real: 0.566 D_fake: 0.515 \n",
      "(epoch: 115, iters: 148, time: 0.147, data: 0.002) G_GAN: 0.963 G_L1: 4.464 D_real: 0.690 D_fake: 0.291 \n",
      "(epoch: 115, iters: 248, time: 0.147, data: 0.001) G_GAN: 0.854 G_L1: 6.195 D_real: 0.294 D_fake: 1.006 \n",
      "(epoch: 115, iters: 348, time: 0.146, data: 0.002) G_GAN: 0.994 G_L1: 6.089 D_real: 0.875 D_fake: 0.338 \n",
      "saving the model at the end of epoch 115, iters 42320\n",
      "End of epoch 115 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 80, time: 0.205, data: 0.001) G_GAN: 1.454 G_L1: 6.468 D_real: 0.451 D_fake: 0.519 \n",
      "(epoch: 116, iters: 180, time: 0.147, data: 0.001) G_GAN: 1.627 G_L1: 6.661 D_real: 0.448 D_fake: 0.437 \n",
      "(epoch: 116, iters: 280, time: 0.147, data: 0.002) G_GAN: 0.825 G_L1: 6.687 D_real: 1.018 D_fake: 0.368 \n",
      "End of epoch 116 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 12, time: 0.147, data: 0.002) G_GAN: 0.988 G_L1: 5.332 D_real: 0.836 D_fake: 0.391 \n",
      "(epoch: 117, iters: 112, time: 0.207, data: 0.001) G_GAN: 0.878 G_L1: 9.258 D_real: 0.118 D_fake: 0.829 \n",
      "(epoch: 117, iters: 212, time: 0.146, data: 0.001) G_GAN: 0.975 G_L1: 7.120 D_real: 0.387 D_fake: 0.482 \n",
      "(epoch: 117, iters: 312, time: 0.147, data: 0.001) G_GAN: 1.120 G_L1: 7.096 D_real: 1.460 D_fake: 0.138 \n",
      "End of epoch 117 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 44, time: 0.147, data: 0.002) G_GAN: 0.982 G_L1: 6.936 D_real: 0.894 D_fake: 0.325 \n",
      "(epoch: 118, iters: 144, time: 0.216, data: 0.002) G_GAN: 1.202 G_L1: 7.128 D_real: 0.609 D_fake: 0.346 \n",
      "(epoch: 118, iters: 244, time: 0.147, data: 0.001) G_GAN: 1.329 G_L1: 7.255 D_real: 0.148 D_fake: 0.389 \n",
      "(epoch: 118, iters: 344, time: 0.147, data: 0.002) G_GAN: 1.034 G_L1: 7.125 D_real: 0.209 D_fake: 0.880 \n",
      "End of epoch 118 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 76, time: 0.147, data: 0.002) G_GAN: 0.776 G_L1: 8.073 D_real: 0.484 D_fake: 1.030 \n",
      "(epoch: 119, iters: 176, time: 0.204, data: 0.001) G_GAN: 1.835 G_L1: 9.322 D_real: 0.078 D_fake: 0.955 \n",
      "(epoch: 119, iters: 276, time: 0.147, data: 0.001) G_GAN: 1.647 G_L1: 7.685 D_real: 0.369 D_fake: 0.237 \n",
      "End of epoch 119 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 8, time: 0.147, data: 0.001) G_GAN: 1.001 G_L1: 4.800 D_real: 1.001 D_fake: 0.237 \n",
      "(epoch: 120, iters: 108, time: 0.147, data: 0.001) G_GAN: 1.118 G_L1: 7.799 D_real: 0.290 D_fake: 0.906 \n",
      "(epoch: 120, iters: 208, time: 0.208, data: 0.002) G_GAN: 1.390 G_L1: 9.985 D_real: 0.389 D_fake: 0.418 \n",
      "(epoch: 120, iters: 308, time: 0.147, data: 0.002) G_GAN: 1.091 G_L1: 5.536 D_real: 0.819 D_fake: 0.266 \n",
      "saving the model at the end of epoch 120, iters 44160\n",
      "End of epoch 120 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 40, time: 0.147, data: 0.002) G_GAN: 1.005 G_L1: 4.944 D_real: 1.143 D_fake: 0.230 \n",
      "(epoch: 121, iters: 140, time: 0.147, data: 0.001) G_GAN: 1.013 G_L1: 6.096 D_real: 0.178 D_fake: 1.127 \n",
      "(epoch: 121, iters: 240, time: 0.208, data: 0.001) G_GAN: 1.014 G_L1: 7.072 D_real: 0.265 D_fake: 0.907 \n",
      "(epoch: 121, iters: 340, time: 0.147, data: 0.002) G_GAN: 0.769 G_L1: 5.555 D_real: 0.814 D_fake: 0.447 \n",
      "End of epoch 121 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 72, time: 0.147, data: 0.002) G_GAN: 0.830 G_L1: 5.623 D_real: 0.800 D_fake: 0.434 \n",
      "(epoch: 122, iters: 172, time: 0.150, data: 0.001) G_GAN: 0.662 G_L1: 5.218 D_real: 0.158 D_fake: 1.518 \n",
      "(epoch: 122, iters: 272, time: 0.207, data: 0.002) G_GAN: 1.694 G_L1: 7.047 D_real: 1.711 D_fake: 0.110 \n",
      "End of epoch 122 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 4, time: 0.094, data: 0.002) G_GAN: 1.417 G_L1: 7.900 D_real: 0.245 D_fake: 0.718 \n",
      "(epoch: 123, iters: 104, time: 0.147, data: 0.001) G_GAN: 0.622 G_L1: 5.477 D_real: 0.850 D_fake: 0.337 \n",
      "saving the latest model (epoch 123, total_iters 45000)\n",
      "(epoch: 123, iters: 204, time: 0.147, data: 0.001) G_GAN: 0.634 G_L1: 4.751 D_real: 0.856 D_fake: 0.434 \n",
      "(epoch: 123, iters: 304, time: 0.203, data: 0.002) G_GAN: 1.390 G_L1: 4.502 D_real: 0.614 D_fake: 0.402 \n",
      "End of epoch 123 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 36, time: 0.147, data: 0.001) G_GAN: 1.320 G_L1: 8.431 D_real: 0.732 D_fake: 0.421 \n",
      "(epoch: 124, iters: 136, time: 0.147, data: 0.001) G_GAN: 0.776 G_L1: 5.009 D_real: 0.780 D_fake: 0.421 \n",
      "(epoch: 124, iters: 236, time: 0.147, data: 0.002) G_GAN: 0.898 G_L1: 6.981 D_real: 0.253 D_fake: 0.853 \n",
      "(epoch: 124, iters: 336, time: 0.220, data: 0.002) G_GAN: 0.941 G_L1: 7.198 D_real: 0.745 D_fake: 0.369 \n",
      "End of epoch 124 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 68, time: 0.147, data: 0.001) G_GAN: 0.619 G_L1: 5.847 D_real: 0.229 D_fake: 1.185 \n",
      "(epoch: 125, iters: 168, time: 0.147, data: 0.002) G_GAN: 0.878 G_L1: 6.368 D_real: 0.392 D_fake: 0.688 \n",
      "(epoch: 125, iters: 268, time: 0.147, data: 0.002) G_GAN: 1.245 G_L1: 7.186 D_real: 0.311 D_fake: 0.537 \n",
      "(epoch: 125, iters: 368, time: 0.164, data: 0.002) G_GAN: 1.029 G_L1: 3.867 D_real: 0.644 D_fake: 0.450 \n",
      "saving the model at the end of epoch 125, iters 46000\n",
      "End of epoch 125 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 100, time: 0.148, data: 0.093) G_GAN: 1.356 G_L1: 6.158 D_real: 0.660 D_fake: 0.263 \n",
      "(epoch: 126, iters: 200, time: 0.147, data: 0.001) G_GAN: 0.631 G_L1: 6.950 D_real: 0.896 D_fake: 0.203 \n",
      "(epoch: 126, iters: 300, time: 0.147, data: 0.002) G_GAN: 0.567 G_L1: 9.416 D_real: 0.039 D_fake: 2.033 \n",
      "End of epoch 126 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 32, time: 0.211, data: 0.001) G_GAN: 1.703 G_L1: 7.964 D_real: 0.242 D_fake: 0.482 \n",
      "(epoch: 127, iters: 132, time: 0.147, data: 0.001) G_GAN: 1.159 G_L1: 8.893 D_real: 0.931 D_fake: 0.307 \n",
      "(epoch: 127, iters: 232, time: 0.148, data: 0.001) G_GAN: 0.994 G_L1: 5.477 D_real: 0.721 D_fake: 0.314 \n",
      "(epoch: 127, iters: 332, time: 0.147, data: 0.002) G_GAN: 1.709 G_L1: 8.421 D_real: 0.073 D_fake: 1.497 \n",
      "End of epoch 127 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 64, time: 0.208, data: 0.002) G_GAN: 1.163 G_L1: 7.492 D_real: 0.989 D_fake: 0.168 \n",
      "(epoch: 128, iters: 164, time: 0.147, data: 0.001) G_GAN: 0.573 G_L1: 5.761 D_real: 0.949 D_fake: 0.947 \n",
      "(epoch: 128, iters: 264, time: 0.147, data: 0.002) G_GAN: 0.933 G_L1: 6.589 D_real: 1.010 D_fake: 0.252 \n",
      "(epoch: 128, iters: 364, time: 0.147, data: 0.002) G_GAN: 0.729 G_L1: 2.840 D_real: 1.153 D_fake: 0.399 \n",
      "End of epoch 128 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 96, time: 0.210, data: 0.002) G_GAN: 1.668 G_L1: 7.066 D_real: 0.337 D_fake: 0.251 \n",
      "(epoch: 129, iters: 196, time: 0.147, data: 0.001) G_GAN: 1.060 G_L1: 7.394 D_real: 0.234 D_fake: 1.035 \n",
      "(epoch: 129, iters: 296, time: 0.147, data: 0.002) G_GAN: 0.853 G_L1: 5.936 D_real: 0.168 D_fake: 1.496 \n",
      "End of epoch 129 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 28, time: 0.148, data: 0.002) G_GAN: 1.342 G_L1: 8.239 D_real: 0.550 D_fake: 0.304 \n",
      "(epoch: 130, iters: 128, time: 0.210, data: 0.001) G_GAN: 1.407 G_L1: 5.228 D_real: 0.530 D_fake: 0.290 \n",
      "(epoch: 130, iters: 228, time: 0.147, data: 0.001) G_GAN: 1.095 G_L1: 5.170 D_real: 0.694 D_fake: 0.357 \n",
      "(epoch: 130, iters: 328, time: 0.147, data: 0.002) G_GAN: 1.206 G_L1: 3.678 D_real: 1.012 D_fake: 0.164 \n",
      "saving the model at the end of epoch 130, iters 47840\n",
      "End of epoch 130 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 60, time: 0.147, data: 0.002) G_GAN: 0.971 G_L1: 6.122 D_real: 0.772 D_fake: 0.287 \n",
      "(epoch: 131, iters: 160, time: 0.221, data: 0.002) G_GAN: 2.150 G_L1: 6.221 D_real: 0.397 D_fake: 0.149 \n",
      "(epoch: 131, iters: 260, time: 0.147, data: 0.001) G_GAN: 1.419 G_L1: 5.343 D_real: 0.577 D_fake: 0.309 \n",
      "(epoch: 131, iters: 360, time: 0.147, data: 0.002) G_GAN: 1.353 G_L1: 6.439 D_real: 0.224 D_fake: 1.515 \n",
      "End of epoch 131 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 92, time: 0.147, data: 0.002) G_GAN: 0.540 G_L1: 7.863 D_real: 0.650 D_fake: 0.515 \n",
      "(epoch: 132, iters: 192, time: 0.212, data: 0.001) G_GAN: 0.910 G_L1: 6.784 D_real: 0.314 D_fake: 0.683 \n",
      "(epoch: 132, iters: 292, time: 0.147, data: 0.001) G_GAN: 0.859 G_L1: 6.468 D_real: 0.594 D_fake: 0.262 \n",
      "End of epoch 132 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 24, time: 0.147, data: 0.002) G_GAN: 0.674 G_L1: 5.361 D_real: 2.220 D_fake: 0.152 \n",
      "(epoch: 133, iters: 124, time: 0.147, data: 0.001) G_GAN: 0.822 G_L1: 4.327 D_real: 0.494 D_fake: 0.599 \n",
      "(epoch: 133, iters: 224, time: 0.212, data: 0.002) G_GAN: 0.973 G_L1: 5.180 D_real: 0.330 D_fake: 0.652 \n",
      "(epoch: 133, iters: 324, time: 0.147, data: 0.002) G_GAN: 1.129 G_L1: 5.905 D_real: 0.134 D_fake: 0.648 \n",
      "End of epoch 133 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 56, time: 0.147, data: 0.002) G_GAN: 1.104 G_L1: 6.787 D_real: 0.187 D_fake: 1.082 \n",
      "(epoch: 134, iters: 156, time: 0.147, data: 0.002) G_GAN: 1.513 G_L1: 8.839 D_real: 0.221 D_fake: 0.410 \n",
      "(epoch: 134, iters: 256, time: 0.214, data: 0.002) G_GAN: 0.411 G_L1: 5.699 D_real: 0.076 D_fake: 2.207 \n",
      "(epoch: 134, iters: 356, time: 0.147, data: 0.002) G_GAN: 0.992 G_L1: 6.693 D_real: 0.461 D_fake: 0.498 \n",
      "End of epoch 134 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 88, time: 0.147, data: 0.001) G_GAN: 1.011 G_L1: 6.299 D_real: 1.270 D_fake: 0.317 \n",
      "(epoch: 135, iters: 188, time: 0.147, data: 0.002) G_GAN: 1.251 G_L1: 6.061 D_real: 0.942 D_fake: 0.140 \n",
      "(epoch: 135, iters: 288, time: 0.212, data: 0.001) G_GAN: 1.448 G_L1: 8.087 D_real: 0.188 D_fake: 0.653 \n",
      "saving the model at the end of epoch 135, iters 49680\n",
      "End of epoch 135 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 20, time: 0.147, data: 0.002) G_GAN: 0.797 G_L1: 5.836 D_real: 1.633 D_fake: 0.212 \n",
      "(epoch: 136, iters: 120, time: 0.148, data: 0.001) G_GAN: 0.872 G_L1: 5.425 D_real: 0.264 D_fake: 0.967 \n",
      "(epoch: 136, iters: 220, time: 0.147, data: 0.002) G_GAN: 1.125 G_L1: 6.321 D_real: 0.049 D_fake: 2.105 \n",
      "(epoch: 136, iters: 320, time: 0.213, data: 0.002) G_GAN: 0.829 G_L1: 6.887 D_real: 0.675 D_fake: 0.503 \n",
      "saving the latest model (epoch 136, total_iters 50000)\n",
      "End of epoch 136 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 52, time: 0.147, data: 0.003) G_GAN: 0.949 G_L1: 4.978 D_real: 1.378 D_fake: 0.216 \n",
      "(epoch: 137, iters: 152, time: 0.147, data: 0.002) G_GAN: 0.548 G_L1: 6.414 D_real: 0.084 D_fake: 2.699 \n",
      "(epoch: 137, iters: 252, time: 0.147, data: 0.002) G_GAN: 0.500 G_L1: 6.434 D_real: 0.326 D_fake: 1.759 \n",
      "(epoch: 137, iters: 352, time: 0.219, data: 0.002) G_GAN: 2.688 G_L1: 6.861 D_real: 0.182 D_fake: 0.086 \n",
      "End of epoch 137 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 84, time: 0.147, data: 0.001) G_GAN: 0.966 G_L1: 6.032 D_real: 1.247 D_fake: 0.290 \n",
      "(epoch: 138, iters: 184, time: 0.148, data: 0.002) G_GAN: 1.280 G_L1: 9.160 D_real: 0.239 D_fake: 0.314 \n",
      "(epoch: 138, iters: 284, time: 0.147, data: 0.002) G_GAN: 1.947 G_L1: 4.741 D_real: 0.384 D_fake: 0.131 \n",
      "End of epoch 138 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 16, time: 0.213, data: 0.002) G_GAN: 1.379 G_L1: 7.326 D_real: 0.863 D_fake: 0.128 \n",
      "(epoch: 139, iters: 116, time: 0.148, data: 0.002) G_GAN: 1.097 G_L1: 5.780 D_real: 0.658 D_fake: 0.245 \n",
      "(epoch: 139, iters: 216, time: 0.147, data: 0.002) G_GAN: 1.522 G_L1: 4.566 D_real: 0.327 D_fake: 0.484 \n",
      "(epoch: 139, iters: 316, time: 0.147, data: 0.002) G_GAN: 1.294 G_L1: 7.270 D_real: 0.075 D_fake: 1.189 \n",
      "End of epoch 139 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 48, time: 0.215, data: 0.001) G_GAN: 1.126 G_L1: 9.515 D_real: 0.009 D_fake: 1.354 \n",
      "(epoch: 140, iters: 148, time: 0.147, data: 0.002) G_GAN: 1.126 G_L1: 5.898 D_real: 0.195 D_fake: 1.097 \n",
      "(epoch: 140, iters: 248, time: 0.147, data: 0.002) G_GAN: 1.375 G_L1: 9.242 D_real: 0.167 D_fake: 0.347 \n",
      "(epoch: 140, iters: 348, time: 0.148, data: 0.002) G_GAN: 1.244 G_L1: 8.250 D_real: 0.088 D_fake: 1.086 \n",
      "saving the model at the end of epoch 140, iters 51520\n",
      "End of epoch 140 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 80, time: 0.215, data: 0.002) G_GAN: 0.810 G_L1: 6.136 D_real: 1.063 D_fake: 0.399 \n",
      "(epoch: 141, iters: 180, time: 0.147, data: 0.001) G_GAN: 0.963 G_L1: 4.325 D_real: 0.633 D_fake: 0.504 \n",
      "(epoch: 141, iters: 280, time: 0.147, data: 0.001) G_GAN: 1.179 G_L1: 3.767 D_real: 0.383 D_fake: 0.447 \n",
      "End of epoch 141 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 12, time: 0.148, data: 0.002) G_GAN: 0.768 G_L1: 6.309 D_real: 1.077 D_fake: 0.541 \n",
      "(epoch: 142, iters: 112, time: 0.215, data: 0.001) G_GAN: 1.200 G_L1: 5.946 D_real: 0.806 D_fake: 0.348 \n",
      "(epoch: 142, iters: 212, time: 0.147, data: 0.001) G_GAN: 0.970 G_L1: 8.643 D_real: 0.891 D_fake: 0.621 \n",
      "(epoch: 142, iters: 312, time: 0.148, data: 0.002) G_GAN: 1.364 G_L1: 5.631 D_real: 0.897 D_fake: 0.282 \n",
      "End of epoch 142 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 44, time: 0.148, data: 0.001) G_GAN: 1.207 G_L1: 3.348 D_real: 1.194 D_fake: 0.192 \n",
      "(epoch: 143, iters: 144, time: 0.224, data: 0.002) G_GAN: 0.944 G_L1: 4.649 D_real: 0.605 D_fake: 0.558 \n",
      "(epoch: 143, iters: 244, time: 0.147, data: 0.002) G_GAN: 1.585 G_L1: 12.649 D_real: 0.094 D_fake: 0.412 \n",
      "(epoch: 143, iters: 344, time: 0.147, data: 0.002) G_GAN: 1.447 G_L1: 4.799 D_real: 0.893 D_fake: 0.361 \n",
      "End of epoch 143 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 76, time: 0.147, data: 0.002) G_GAN: 1.077 G_L1: 3.684 D_real: 0.938 D_fake: 0.421 \n",
      "(epoch: 144, iters: 176, time: 0.215, data: 0.002) G_GAN: 1.268 G_L1: 4.693 D_real: 0.986 D_fake: 0.284 \n",
      "(epoch: 144, iters: 276, time: 0.147, data: 0.002) G_GAN: 1.090 G_L1: 5.328 D_real: 0.425 D_fake: 0.526 \n",
      "End of epoch 144 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 8, time: 0.147, data: 0.002) G_GAN: 0.938 G_L1: 7.814 D_real: 0.426 D_fake: 0.646 \n",
      "(epoch: 145, iters: 108, time: 0.147, data: 0.001) G_GAN: 0.978 G_L1: 5.244 D_real: 0.897 D_fake: 0.270 \n",
      "(epoch: 145, iters: 208, time: 0.213, data: 0.002) G_GAN: 0.966 G_L1: 6.368 D_real: 0.425 D_fake: 0.436 \n",
      "(epoch: 145, iters: 308, time: 0.147, data: 0.001) G_GAN: 0.987 G_L1: 6.621 D_real: 0.146 D_fake: 0.990 \n",
      "saving the model at the end of epoch 145, iters 53360\n",
      "End of epoch 145 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 40, time: 0.147, data: 0.002) G_GAN: 0.976 G_L1: 8.470 D_real: 0.783 D_fake: 0.348 \n",
      "(epoch: 146, iters: 140, time: 0.147, data: 0.001) G_GAN: 1.303 G_L1: 4.884 D_real: 0.186 D_fake: 0.688 \n",
      "(epoch: 146, iters: 240, time: 0.213, data: 0.002) G_GAN: 1.131 G_L1: 5.508 D_real: 0.941 D_fake: 0.350 \n",
      "(epoch: 146, iters: 340, time: 0.148, data: 0.002) G_GAN: 1.456 G_L1: 10.798 D_real: 0.309 D_fake: 0.435 \n",
      "End of epoch 146 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 72, time: 0.148, data: 0.002) G_GAN: 1.719 G_L1: 7.637 D_real: 0.385 D_fake: 0.181 \n",
      "(epoch: 147, iters: 172, time: 0.148, data: 0.002) G_GAN: 1.350 G_L1: 5.719 D_real: 0.214 D_fake: 0.669 \n",
      "(epoch: 147, iters: 272, time: 0.214, data: 0.001) G_GAN: 1.933 G_L1: 5.285 D_real: 1.087 D_fake: 0.084 \n",
      "End of epoch 147 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 4, time: 0.094, data: 0.001) G_GAN: 1.522 G_L1: 8.236 D_real: 0.068 D_fake: 1.081 \n",
      "(epoch: 148, iters: 104, time: 0.148, data: 0.003) G_GAN: 0.872 G_L1: 6.213 D_real: 1.029 D_fake: 0.321 \n",
      "(epoch: 148, iters: 204, time: 0.148, data: 0.002) G_GAN: 0.950 G_L1: 7.263 D_real: 0.086 D_fake: 0.752 \n",
      "(epoch: 148, iters: 304, time: 0.228, data: 0.001) G_GAN: 1.954 G_L1: 6.058 D_real: 0.965 D_fake: 0.129 \n",
      "End of epoch 148 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 36, time: 0.148, data: 0.001) G_GAN: 2.545 G_L1: 8.572 D_real: 0.175 D_fake: 0.124 \n",
      "(epoch: 149, iters: 136, time: 0.147, data: 0.002) G_GAN: 0.807 G_L1: 7.737 D_real: 0.220 D_fake: 1.313 \n",
      "(epoch: 149, iters: 236, time: 0.147, data: 0.001) G_GAN: 1.776 G_L1: 7.614 D_real: 0.169 D_fake: 0.529 \n",
      "(epoch: 149, iters: 336, time: 0.217, data: 0.001) G_GAN: 1.404 G_L1: 7.762 D_real: 0.225 D_fake: 0.744 \n",
      "End of epoch 149 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 68, time: 0.147, data: 0.001) G_GAN: 1.392 G_L1: 6.861 D_real: 0.529 D_fake: 0.456 \n",
      "(epoch: 150, iters: 168, time: 0.147, data: 0.001) G_GAN: 1.400 G_L1: 6.365 D_real: 0.375 D_fake: 0.293 \n",
      "saving the latest model (epoch 150, total_iters 55000)\n",
      "(epoch: 150, iters: 268, time: 0.148, data: 0.001) G_GAN: 1.481 G_L1: 6.424 D_real: 0.321 D_fake: 0.385 \n",
      "(epoch: 150, iters: 368, time: 0.172, data: 0.002) G_GAN: 1.181 G_L1: 4.754 D_real: 0.452 D_fake: 0.279 \n",
      "saving the model at the end of epoch 150, iters 55200\n",
      "End of epoch 150 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 100, time: 0.148, data: 0.090) G_GAN: 1.229 G_L1: 5.615 D_real: 0.528 D_fake: 0.277 \n",
      "(epoch: 151, iters: 200, time: 0.148, data: 0.002) G_GAN: 1.958 G_L1: 6.168 D_real: 0.174 D_fake: 0.215 \n",
      "(epoch: 151, iters: 300, time: 0.148, data: 0.001) G_GAN: 1.664 G_L1: 4.888 D_real: 1.595 D_fake: 0.251 \n",
      "End of epoch 151 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 32, time: 0.215, data: 0.002) G_GAN: 1.242 G_L1: 5.092 D_real: 0.383 D_fake: 0.566 \n",
      "(epoch: 152, iters: 132, time: 0.147, data: 0.001) G_GAN: 1.649 G_L1: 8.501 D_real: 0.056 D_fake: 0.337 \n",
      "(epoch: 152, iters: 232, time: 0.148, data: 0.002) G_GAN: 1.728 G_L1: 7.214 D_real: 0.191 D_fake: 0.576 \n",
      "(epoch: 152, iters: 332, time: 0.147, data: 0.002) G_GAN: 1.424 G_L1: 6.580 D_real: 1.007 D_fake: 0.217 \n",
      "End of epoch 152 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 64, time: 0.219, data: 0.002) G_GAN: 0.749 G_L1: 4.745 D_real: 1.568 D_fake: 0.153 \n",
      "(epoch: 153, iters: 164, time: 0.148, data: 0.001) G_GAN: 1.369 G_L1: 6.737 D_real: 0.153 D_fake: 0.635 \n",
      "(epoch: 153, iters: 264, time: 0.147, data: 0.002) G_GAN: 1.514 G_L1: 7.245 D_real: 0.294 D_fake: 0.523 \n",
      "(epoch: 153, iters: 364, time: 0.148, data: 0.001) G_GAN: 1.292 G_L1: 8.677 D_real: 0.142 D_fake: 0.853 \n",
      "End of epoch 153 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 96, time: 0.233, data: 0.002) G_GAN: 1.334 G_L1: 5.249 D_real: 0.667 D_fake: 0.305 \n",
      "(epoch: 154, iters: 196, time: 0.147, data: 0.001) G_GAN: 0.657 G_L1: 9.205 D_real: 0.050 D_fake: 1.643 \n",
      "(epoch: 154, iters: 296, time: 0.147, data: 0.002) G_GAN: 1.530 G_L1: 5.104 D_real: 0.228 D_fake: 0.206 \n",
      "End of epoch 154 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 28, time: 0.148, data: 0.002) G_GAN: 2.697 G_L1: 5.983 D_real: 0.212 D_fake: 0.075 \n",
      "(epoch: 155, iters: 128, time: 0.219, data: 0.001) G_GAN: 1.910 G_L1: 6.615 D_real: 0.299 D_fake: 0.193 \n",
      "(epoch: 155, iters: 228, time: 0.148, data: 0.002) G_GAN: 1.596 G_L1: 6.494 D_real: 0.149 D_fake: 0.969 \n",
      "(epoch: 155, iters: 328, time: 0.148, data: 0.001) G_GAN: 1.382 G_L1: 8.279 D_real: 0.207 D_fake: 0.536 \n",
      "saving the model at the end of epoch 155, iters 57040\n",
      "End of epoch 155 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 60, time: 0.148, data: 0.002) G_GAN: 1.171 G_L1: 5.465 D_real: 0.179 D_fake: 0.873 \n",
      "(epoch: 156, iters: 160, time: 0.220, data: 0.002) G_GAN: 0.976 G_L1: 6.344 D_real: 0.278 D_fake: 0.958 \n",
      "(epoch: 156, iters: 260, time: 0.147, data: 0.002) G_GAN: 1.095 G_L1: 6.761 D_real: 0.207 D_fake: 0.977 \n",
      "(epoch: 156, iters: 360, time: 0.147, data: 0.002) G_GAN: 0.956 G_L1: 6.523 D_real: 2.025 D_fake: 0.069 \n",
      "End of epoch 156 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 92, time: 0.148, data: 0.002) G_GAN: 1.196 G_L1: 6.739 D_real: 0.218 D_fake: 0.425 \n",
      "(epoch: 157, iters: 192, time: 0.223, data: 0.002) G_GAN: 1.464 G_L1: 8.438 D_real: 0.609 D_fake: 0.273 \n",
      "(epoch: 157, iters: 292, time: 0.148, data: 0.002) G_GAN: 1.234 G_L1: 5.729 D_real: 0.808 D_fake: 0.136 \n",
      "End of epoch 157 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 24, time: 0.147, data: 0.002) G_GAN: 1.454 G_L1: 4.779 D_real: 0.183 D_fake: 0.415 \n",
      "(epoch: 158, iters: 124, time: 0.148, data: 0.001) G_GAN: 1.597 G_L1: 5.540 D_real: 0.456 D_fake: 0.212 \n",
      "(epoch: 158, iters: 224, time: 0.221, data: 0.002) G_GAN: 1.569 G_L1: 9.050 D_real: 0.091 D_fake: 0.378 \n",
      "(epoch: 158, iters: 324, time: 0.148, data: 0.002) G_GAN: 1.922 G_L1: 7.764 D_real: 0.066 D_fake: 0.320 \n",
      "End of epoch 158 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 56, time: 0.147, data: 0.002) G_GAN: 1.113 G_L1: 6.816 D_real: 0.431 D_fake: 0.438 \n",
      "(epoch: 159, iters: 156, time: 0.147, data: 0.001) G_GAN: 1.334 G_L1: 5.794 D_real: 0.168 D_fake: 0.412 \n",
      "(epoch: 159, iters: 256, time: 0.234, data: 0.002) G_GAN: 1.143 G_L1: 7.589 D_real: 0.259 D_fake: 0.595 \n",
      "(epoch: 159, iters: 356, time: 0.148, data: 0.001) G_GAN: 1.525 G_L1: 8.257 D_real: 0.308 D_fake: 0.940 \n",
      "End of epoch 159 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 88, time: 0.147, data: 0.002) G_GAN: 1.718 G_L1: 6.602 D_real: 0.132 D_fake: 0.320 \n",
      "(epoch: 160, iters: 188, time: 0.148, data: 0.002) G_GAN: 2.033 G_L1: 7.519 D_real: 0.088 D_fake: 0.143 \n",
      "(epoch: 160, iters: 288, time: 0.222, data: 0.001) G_GAN: 0.972 G_L1: 7.082 D_real: 0.136 D_fake: 0.911 \n",
      "saving the model at the end of epoch 160, iters 58880\n",
      "End of epoch 160 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 20, time: 0.147, data: 0.001) G_GAN: 1.024 G_L1: 5.142 D_real: 0.284 D_fake: 0.973 \n",
      "(epoch: 161, iters: 120, time: 0.147, data: 0.001) G_GAN: 0.863 G_L1: 6.028 D_real: 0.262 D_fake: 0.638 \n",
      "(epoch: 161, iters: 220, time: 0.147, data: 0.002) G_GAN: 2.824 G_L1: 6.154 D_real: 2.471 D_fake: 0.039 \n",
      "(epoch: 161, iters: 320, time: 0.220, data: 0.002) G_GAN: 2.011 G_L1: 6.206 D_real: 0.223 D_fake: 0.141 \n",
      "End of epoch 161 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 52, time: 0.147, data: 0.001) G_GAN: 1.023 G_L1: 7.117 D_real: 0.751 D_fake: 0.610 \n",
      "(epoch: 162, iters: 152, time: 0.148, data: 0.002) G_GAN: 1.748 G_L1: 6.785 D_real: 0.086 D_fake: 0.317 \n",
      "(epoch: 162, iters: 252, time: 0.147, data: 0.002) G_GAN: 1.070 G_L1: 5.924 D_real: 0.362 D_fake: 0.768 \n",
      "(epoch: 162, iters: 352, time: 0.223, data: 0.002) G_GAN: 1.877 G_L1: 5.265 D_real: 0.149 D_fake: 0.358 \n",
      "End of epoch 162 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 84, time: 0.147, data: 0.002) G_GAN: 1.896 G_L1: 1.470 D_real: 1.353 D_fake: 0.087 \n",
      "(epoch: 163, iters: 184, time: 0.147, data: 0.002) G_GAN: 1.283 G_L1: 6.713 D_real: 0.206 D_fake: 0.597 \n",
      "(epoch: 163, iters: 284, time: 0.147, data: 0.002) G_GAN: 0.919 G_L1: 4.229 D_real: 0.952 D_fake: 0.388 \n",
      "End of epoch 163 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 16, time: 0.233, data: 0.002) G_GAN: 1.027 G_L1: 5.318 D_real: 0.259 D_fake: 0.868 \n",
      "saving the latest model (epoch 164, total_iters 60000)\n",
      "(epoch: 164, iters: 116, time: 0.147, data: 0.003) G_GAN: 1.320 G_L1: 6.972 D_real: 0.530 D_fake: 0.332 \n",
      "(epoch: 164, iters: 216, time: 0.148, data: 0.001) G_GAN: 1.813 G_L1: 9.260 D_real: 0.063 D_fake: 0.215 \n",
      "(epoch: 164, iters: 316, time: 0.147, data: 0.002) G_GAN: 1.270 G_L1: 7.775 D_real: 0.223 D_fake: 0.905 \n",
      "End of epoch 164 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 48, time: 0.227, data: 0.001) G_GAN: 1.349 G_L1: 6.481 D_real: 0.177 D_fake: 0.585 \n",
      "(epoch: 165, iters: 148, time: 0.147, data: 0.001) G_GAN: 2.558 G_L1: 5.688 D_real: 0.668 D_fake: 0.067 \n",
      "(epoch: 165, iters: 248, time: 0.147, data: 0.002) G_GAN: 1.187 G_L1: 7.389 D_real: 0.259 D_fake: 0.462 \n",
      "(epoch: 165, iters: 348, time: 0.147, data: 0.002) G_GAN: 2.389 G_L1: 6.846 D_real: 0.186 D_fake: 0.103 \n",
      "saving the model at the end of epoch 165, iters 60720\n",
      "End of epoch 165 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 80, time: 0.225, data: 0.002) G_GAN: 1.164 G_L1: 7.437 D_real: 0.536 D_fake: 0.550 \n",
      "(epoch: 166, iters: 180, time: 0.147, data: 0.001) G_GAN: 1.372 G_L1: 8.643 D_real: 0.043 D_fake: 0.406 \n",
      "(epoch: 166, iters: 280, time: 0.147, data: 0.002) G_GAN: 1.015 G_L1: 3.231 D_real: 1.033 D_fake: 0.423 \n",
      "End of epoch 166 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 12, time: 0.147, data: 0.001) G_GAN: 1.175 G_L1: 5.499 D_real: 1.532 D_fake: 0.374 \n",
      "(epoch: 167, iters: 112, time: 0.225, data: 0.001) G_GAN: 1.720 G_L1: 5.914 D_real: 0.872 D_fake: 0.145 \n",
      "(epoch: 167, iters: 212, time: 0.147, data: 0.001) G_GAN: 1.067 G_L1: 7.751 D_real: 0.877 D_fake: 0.156 \n",
      "(epoch: 167, iters: 312, time: 0.148, data: 0.002) G_GAN: 1.550 G_L1: 6.954 D_real: 0.183 D_fake: 0.312 \n",
      "End of epoch 167 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 44, time: 0.147, data: 0.001) G_GAN: 1.087 G_L1: 6.633 D_real: 0.305 D_fake: 0.430 \n",
      "(epoch: 168, iters: 144, time: 0.221, data: 0.001) G_GAN: 1.647 G_L1: 2.999 D_real: 0.501 D_fake: 0.411 \n",
      "(epoch: 168, iters: 244, time: 0.147, data: 0.001) G_GAN: 1.417 G_L1: 6.037 D_real: 0.208 D_fake: 0.379 \n",
      "(epoch: 168, iters: 344, time: 0.147, data: 0.001) G_GAN: 2.267 G_L1: 6.185 D_real: 0.290 D_fake: 0.109 \n",
      "End of epoch 168 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 76, time: 0.147, data: 0.002) G_GAN: 1.842 G_L1: 6.836 D_real: 1.111 D_fake: 0.150 \n",
      "(epoch: 169, iters: 176, time: 0.238, data: 0.002) G_GAN: 1.719 G_L1: 8.043 D_real: 0.379 D_fake: 0.192 \n",
      "(epoch: 169, iters: 276, time: 0.147, data: 0.001) G_GAN: 1.352 G_L1: 9.199 D_real: 0.010 D_fake: 0.691 \n",
      "End of epoch 169 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 8, time: 0.146, data: 0.002) G_GAN: 1.149 G_L1: 5.642 D_real: 0.867 D_fake: 0.336 \n",
      "(epoch: 170, iters: 108, time: 0.146, data: 0.001) G_GAN: 1.640 G_L1: 5.907 D_real: 0.302 D_fake: 0.270 \n",
      "(epoch: 170, iters: 208, time: 0.223, data: 0.001) G_GAN: 2.534 G_L1: 6.019 D_real: 0.151 D_fake: 0.064 \n",
      "(epoch: 170, iters: 308, time: 0.147, data: 0.002) G_GAN: 1.049 G_L1: 5.953 D_real: 0.205 D_fake: 0.643 \n",
      "saving the model at the end of epoch 170, iters 62560\n",
      "End of epoch 170 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 40, time: 0.147, data: 0.001) G_GAN: 3.660 G_L1: 4.784 D_real: 0.916 D_fake: 0.025 \n",
      "(epoch: 171, iters: 140, time: 0.148, data: 0.002) G_GAN: 1.740 G_L1: 8.581 D_real: 0.177 D_fake: 0.327 \n",
      "(epoch: 171, iters: 240, time: 0.227, data: 0.002) G_GAN: 1.817 G_L1: 8.390 D_real: 0.070 D_fake: 0.197 \n",
      "(epoch: 171, iters: 340, time: 0.148, data: 0.002) G_GAN: 1.173 G_L1: 5.309 D_real: 0.606 D_fake: 0.247 \n",
      "End of epoch 171 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 72, time: 0.147, data: 0.002) G_GAN: 2.488 G_L1: 4.503 D_real: 2.385 D_fake: 0.035 \n",
      "(epoch: 172, iters: 172, time: 0.147, data: 0.001) G_GAN: 1.313 G_L1: 3.004 D_real: 0.207 D_fake: 0.529 \n",
      "(epoch: 172, iters: 272, time: 0.225, data: 0.002) G_GAN: 1.129 G_L1: 5.012 D_real: 0.285 D_fake: 0.673 \n",
      "End of epoch 172 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 4, time: 0.094, data: 0.001) G_GAN: 1.473 G_L1: 5.938 D_real: 0.092 D_fake: 0.532 \n",
      "(epoch: 173, iters: 104, time: 0.147, data: 0.003) G_GAN: 2.204 G_L1: 7.066 D_real: 0.291 D_fake: 0.120 \n",
      "(epoch: 173, iters: 204, time: 0.147, data: 0.001) G_GAN: 2.015 G_L1: 5.269 D_real: 0.221 D_fake: 0.218 \n",
      "(epoch: 173, iters: 304, time: 0.237, data: 0.002) G_GAN: 1.601 G_L1: 5.437 D_real: 0.477 D_fake: 0.216 \n",
      "End of epoch 173 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 36, time: 0.147, data: 0.002) G_GAN: 1.077 G_L1: 8.244 D_real: 0.077 D_fake: 0.916 \n",
      "(epoch: 174, iters: 136, time: 0.147, data: 0.001) G_GAN: 1.194 G_L1: 5.506 D_real: 0.141 D_fake: 0.634 \n",
      "(epoch: 174, iters: 236, time: 0.147, data: 0.002) G_GAN: 2.147 G_L1: 5.390 D_real: 0.205 D_fake: 0.137 \n",
      "(epoch: 174, iters: 336, time: 0.227, data: 0.002) G_GAN: 0.705 G_L1: 6.968 D_real: 0.498 D_fake: 1.069 \n",
      "End of epoch 174 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 68, time: 0.147, data: 0.002) G_GAN: 1.102 G_L1: 8.092 D_real: 0.739 D_fake: 0.399 \n",
      "(epoch: 175, iters: 168, time: 0.148, data: 0.001) G_GAN: 2.076 G_L1: 8.355 D_real: 0.120 D_fake: 0.166 \n",
      "(epoch: 175, iters: 268, time: 0.147, data: 0.001) G_GAN: 0.856 G_L1: 8.014 D_real: 0.315 D_fake: 0.666 \n",
      "(epoch: 175, iters: 368, time: 0.181, data: 0.001) G_GAN: 1.401 G_L1: 6.901 D_real: 1.122 D_fake: 0.204 \n",
      "saving the model at the end of epoch 175, iters 64400\n",
      "End of epoch 175 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 100, time: 0.148, data: 0.091) G_GAN: 3.968 G_L1: 7.819 D_real: 0.043 D_fake: 0.022 \n",
      "(epoch: 176, iters: 200, time: 0.147, data: 0.002) G_GAN: 1.410 G_L1: 7.544 D_real: 0.119 D_fake: 0.341 \n",
      "(epoch: 176, iters: 300, time: 0.147, data: 0.001) G_GAN: 0.841 G_L1: 5.131 D_real: 0.371 D_fake: 0.898 \n",
      "End of epoch 176 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 32, time: 0.226, data: 0.002) G_GAN: 2.302 G_L1: 9.217 D_real: 0.419 D_fake: 0.106 \n",
      "(epoch: 177, iters: 132, time: 0.147, data: 0.001) G_GAN: 1.066 G_L1: 5.415 D_real: 0.273 D_fake: 0.774 \n",
      "(epoch: 177, iters: 232, time: 0.147, data: 0.002) G_GAN: 3.074 G_L1: 6.548 D_real: 0.305 D_fake: 0.051 \n",
      "saving the latest model (epoch 177, total_iters 65000)\n",
      "(epoch: 177, iters: 332, time: 0.148, data: 0.002) G_GAN: 1.638 G_L1: 7.685 D_real: 0.091 D_fake: 0.249 \n",
      "End of epoch 177 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 64, time: 0.228, data: 0.002) G_GAN: 1.810 G_L1: 4.817 D_real: 0.456 D_fake: 0.150 \n",
      "(epoch: 178, iters: 164, time: 0.148, data: 0.002) G_GAN: 2.264 G_L1: 7.287 D_real: 0.252 D_fake: 0.129 \n",
      "(epoch: 178, iters: 264, time: 0.148, data: 0.001) G_GAN: 1.451 G_L1: 6.905 D_real: 0.351 D_fake: 0.413 \n",
      "(epoch: 178, iters: 364, time: 0.148, data: 0.002) G_GAN: 1.460 G_L1: 5.267 D_real: 0.379 D_fake: 0.282 \n",
      "End of epoch 178 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 96, time: 0.239, data: 0.002) G_GAN: 2.320 G_L1: 4.042 D_real: 0.419 D_fake: 0.094 \n",
      "(epoch: 179, iters: 196, time: 0.148, data: 0.002) G_GAN: 1.027 G_L1: 9.510 D_real: 0.058 D_fake: 0.957 \n",
      "(epoch: 179, iters: 296, time: 0.148, data: 0.002) G_GAN: 2.194 G_L1: 6.486 D_real: 0.146 D_fake: 0.116 \n",
      "End of epoch 179 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000416\n",
      "(epoch: 180, iters: 28, time: 0.147, data: 0.001) G_GAN: 1.158 G_L1: 6.140 D_real: 0.236 D_fake: 0.481 \n",
      "(epoch: 180, iters: 128, time: 0.222, data: 0.001) G_GAN: 2.099 G_L1: 5.247 D_real: 0.219 D_fake: 0.140 \n",
      "(epoch: 180, iters: 228, time: 0.147, data: 0.001) G_GAN: 1.867 G_L1: 4.815 D_real: 0.117 D_fake: 0.392 \n",
      "(epoch: 180, iters: 328, time: 0.147, data: 0.001) G_GAN: 2.171 G_L1: 6.696 D_real: 0.190 D_fake: 0.136 \n",
      "saving the model at the end of epoch 180, iters 66240\n",
      "End of epoch 180 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 60, time: 0.148, data: 0.002) G_GAN: 1.498 G_L1: 5.162 D_real: 0.761 D_fake: 0.337 \n",
      "(epoch: 181, iters: 160, time: 0.229, data: 0.002) G_GAN: 1.742 G_L1: 5.692 D_real: 1.474 D_fake: 0.131 \n",
      "(epoch: 181, iters: 260, time: 0.148, data: 0.001) G_GAN: 0.916 G_L1: 6.728 D_real: 0.056 D_fake: 0.760 \n",
      "(epoch: 181, iters: 360, time: 0.147, data: 0.002) G_GAN: 4.223 G_L1: 6.918 D_real: 0.480 D_fake: 0.016 \n",
      "End of epoch 181 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 92, time: 0.148, data: 0.002) G_GAN: 1.091 G_L1: 6.381 D_real: 0.042 D_fake: 0.727 \n",
      "(epoch: 182, iters: 192, time: 0.230, data: 0.002) G_GAN: 0.820 G_L1: 7.078 D_real: 0.257 D_fake: 0.943 \n",
      "(epoch: 182, iters: 292, time: 0.148, data: 0.002) G_GAN: 1.122 G_L1: 6.580 D_real: 0.190 D_fake: 0.617 \n",
      "End of epoch 182 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 24, time: 0.147, data: 0.002) G_GAN: 3.484 G_L1: 5.563 D_real: 0.148 D_fake: 0.033 \n",
      "(epoch: 183, iters: 124, time: 0.147, data: 0.001) G_GAN: 1.456 G_L1: 6.849 D_real: 0.064 D_fake: 0.318 \n",
      "(epoch: 183, iters: 224, time: 0.241, data: 0.001) G_GAN: 1.413 G_L1: 6.185 D_real: 0.342 D_fake: 0.319 \n",
      "(epoch: 183, iters: 324, time: 0.147, data: 0.002) G_GAN: 1.280 G_L1: 8.424 D_real: 0.152 D_fake: 0.512 \n",
      "End of epoch 183 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 56, time: 0.148, data: 0.001) G_GAN: 1.585 G_L1: 8.329 D_real: 0.032 D_fake: 0.385 \n",
      "(epoch: 184, iters: 156, time: 0.147, data: 0.002) G_GAN: 2.430 G_L1: 7.283 D_real: 0.052 D_fake: 0.118 \n",
      "(epoch: 184, iters: 256, time: 0.231, data: 0.001) G_GAN: 1.212 G_L1: 6.260 D_real: 0.536 D_fake: 0.350 \n",
      "(epoch: 184, iters: 356, time: 0.147, data: 0.001) G_GAN: 1.434 G_L1: 4.604 D_real: 0.472 D_fake: 0.372 \n",
      "End of epoch 184 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 88, time: 0.147, data: 0.001) G_GAN: 2.548 G_L1: 5.723 D_real: 0.128 D_fake: 0.092 \n",
      "(epoch: 185, iters: 188, time: 0.147, data: 0.001) G_GAN: 2.613 G_L1: 6.957 D_real: 0.179 D_fake: 0.084 \n",
      "(epoch: 185, iters: 288, time: 0.229, data: 0.001) G_GAN: 1.408 G_L1: 6.472 D_real: 0.187 D_fake: 0.413 \n",
      "saving the model at the end of epoch 185, iters 68080\n",
      "End of epoch 185 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 20, time: 0.147, data: 0.002) G_GAN: 1.449 G_L1: 7.187 D_real: 0.146 D_fake: 0.471 \n",
      "(epoch: 186, iters: 120, time: 0.147, data: 0.001) G_GAN: 1.097 G_L1: 6.862 D_real: 0.100 D_fake: 0.648 \n",
      "(epoch: 186, iters: 220, time: 0.147, data: 0.002) G_GAN: 1.708 G_L1: 5.409 D_real: 0.189 D_fake: 0.258 \n",
      "(epoch: 186, iters: 320, time: 0.230, data: 0.002) G_GAN: 1.198 G_L1: 6.938 D_real: 0.292 D_fake: 0.583 \n",
      "End of epoch 186 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 52, time: 0.147, data: 0.002) G_GAN: 1.543 G_L1: 6.558 D_real: 0.452 D_fake: 0.193 \n",
      "(epoch: 187, iters: 152, time: 0.147, data: 0.002) G_GAN: 0.804 G_L1: 6.922 D_real: 0.264 D_fake: 0.762 \n",
      "(epoch: 187, iters: 252, time: 0.147, data: 0.001) G_GAN: 1.383 G_L1: 5.219 D_real: 0.786 D_fake: 0.281 \n",
      "(epoch: 187, iters: 352, time: 0.240, data: 0.002) G_GAN: 1.289 G_L1: 5.559 D_real: 0.586 D_fake: 0.312 \n",
      "End of epoch 187 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 84, time: 0.147, data: 0.002) G_GAN: 1.353 G_L1: 7.930 D_real: 0.144 D_fake: 0.446 \n",
      "(epoch: 188, iters: 184, time: 0.147, data: 0.002) G_GAN: 1.958 G_L1: 8.462 D_real: 0.010 D_fake: 0.194 \n",
      "(epoch: 188, iters: 284, time: 0.147, data: 0.001) G_GAN: 2.066 G_L1: 3.083 D_real: 0.086 D_fake: 0.169 \n",
      "End of epoch 188 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 16, time: 0.234, data: 0.002) G_GAN: 1.884 G_L1: 5.282 D_real: 0.299 D_fake: 0.161 \n",
      "(epoch: 189, iters: 116, time: 0.147, data: 0.002) G_GAN: 1.261 G_L1: 9.136 D_real: 0.006 D_fake: 0.658 \n",
      "(epoch: 189, iters: 216, time: 0.147, data: 0.002) G_GAN: 3.503 G_L1: 6.049 D_real: 0.532 D_fake: 0.028 \n",
      "(epoch: 189, iters: 316, time: 0.147, data: 0.001) G_GAN: 2.801 G_L1: 7.084 D_real: 0.768 D_fake: 0.050 \n",
      "End of epoch 189 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 48, time: 0.233, data: 0.002) G_GAN: 1.267 G_L1: 7.226 D_real: 0.344 D_fake: 0.445 \n",
      "(epoch: 190, iters: 148, time: 0.147, data: 0.002) G_GAN: 1.444 G_L1: 6.339 D_real: 0.012 D_fake: 0.419 \n",
      "(epoch: 190, iters: 248, time: 0.147, data: 0.001) G_GAN: 3.156 G_L1: 5.806 D_real: 0.147 D_fake: 0.045 \n",
      "(epoch: 190, iters: 348, time: 0.146, data: 0.001) G_GAN: 2.186 G_L1: 5.025 D_real: 0.165 D_fake: 0.136 \n",
      "saving the model at the end of epoch 190, iters 69920\n",
      "End of epoch 190 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 80, time: 0.231, data: 0.002) G_GAN: 1.171 G_L1: 5.728 D_real: 0.239 D_fake: 0.440 \n",
      "saving the latest model (epoch 191, total_iters 70000)\n",
      "(epoch: 191, iters: 180, time: 0.147, data: 0.001) G_GAN: 1.111 G_L1: 8.204 D_real: 0.163 D_fake: 0.443 \n",
      "(epoch: 191, iters: 280, time: 0.147, data: 0.002) G_GAN: 1.793 G_L1: 5.361 D_real: 0.849 D_fake: 0.178 \n",
      "End of epoch 191 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 12, time: 0.147, data: 0.002) G_GAN: 1.205 G_L1: 6.850 D_real: 0.151 D_fake: 0.585 \n",
      "(epoch: 192, iters: 112, time: 0.238, data: 0.001) G_GAN: 1.305 G_L1: 6.036 D_real: 0.046 D_fake: 0.491 \n",
      "(epoch: 192, iters: 212, time: 0.147, data: 0.001) G_GAN: 2.619 G_L1: 5.524 D_real: 0.242 D_fake: 0.080 \n",
      "(epoch: 192, iters: 312, time: 0.147, data: 0.002) G_GAN: 2.609 G_L1: 4.424 D_real: 1.161 D_fake: 0.066 \n",
      "End of epoch 192 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 44, time: 0.147, data: 0.002) G_GAN: 1.764 G_L1: 6.697 D_real: 0.266 D_fake: 0.195 \n",
      "(epoch: 193, iters: 144, time: 0.235, data: 0.002) G_GAN: 1.959 G_L1: 4.531 D_real: 0.492 D_fake: 0.140 \n",
      "(epoch: 193, iters: 244, time: 0.148, data: 0.002) G_GAN: 1.728 G_L1: 4.623 D_real: 0.160 D_fake: 0.238 \n",
      "(epoch: 193, iters: 344, time: 0.148, data: 0.002) G_GAN: 1.311 G_L1: 5.460 D_real: 0.345 D_fake: 0.358 \n",
      "End of epoch 193 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 76, time: 0.147, data: 0.001) G_GAN: 1.783 G_L1: 4.819 D_real: 0.232 D_fake: 0.202 \n",
      "(epoch: 194, iters: 176, time: 0.230, data: 0.002) G_GAN: 0.916 G_L1: 4.414 D_real: 0.148 D_fake: 0.664 \n",
      "(epoch: 194, iters: 276, time: 0.147, data: 0.002) G_GAN: 1.350 G_L1: 5.607 D_real: 0.503 D_fake: 0.308 \n",
      "End of epoch 194 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 8, time: 0.148, data: 0.002) G_GAN: 1.334 G_L1: 5.450 D_real: 1.946 D_fake: 0.220 \n",
      "(epoch: 195, iters: 108, time: 0.148, data: 0.002) G_GAN: 2.423 G_L1: 4.281 D_real: 0.237 D_fake: 0.097 \n",
      "(epoch: 195, iters: 208, time: 0.232, data: 0.002) G_GAN: 1.796 G_L1: 5.784 D_real: 1.143 D_fake: 0.175 \n",
      "(epoch: 195, iters: 308, time: 0.148, data: 0.001) G_GAN: 0.909 G_L1: 7.325 D_real: 0.356 D_fake: 0.673 \n",
      "saving the model at the end of epoch 195, iters 71760\n",
      "End of epoch 195 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 40, time: 0.148, data: 0.002) G_GAN: 0.804 G_L1: 6.222 D_real: 0.136 D_fake: 0.808 \n",
      "(epoch: 196, iters: 140, time: 0.147, data: 0.001) G_GAN: 2.346 G_L1: 7.602 D_real: 0.015 D_fake: 0.115 \n",
      "(epoch: 196, iters: 240, time: 0.244, data: 0.001) G_GAN: 1.433 G_L1: 7.068 D_real: 0.115 D_fake: 0.334 \n",
      "(epoch: 196, iters: 340, time: 0.148, data: 0.002) G_GAN: 1.596 G_L1: 8.192 D_real: 0.148 D_fake: 0.263 \n",
      "End of epoch 196 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 72, time: 0.148, data: 0.002) G_GAN: 2.133 G_L1: 9.679 D_real: 0.028 D_fake: 0.140 \n",
      "(epoch: 197, iters: 172, time: 0.148, data: 0.001) G_GAN: 1.876 G_L1: 7.768 D_real: 0.389 D_fake: 0.183 \n",
      "(epoch: 197, iters: 272, time: 0.235, data: 0.002) G_GAN: 1.738 G_L1: 6.550 D_real: 0.118 D_fake: 0.228 \n",
      "End of epoch 197 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 4, time: 0.096, data: 0.002) G_GAN: 2.403 G_L1: 5.523 D_real: 1.182 D_fake: 0.102 \n",
      "(epoch: 198, iters: 104, time: 0.148, data: 0.003) G_GAN: 1.385 G_L1: 6.154 D_real: 0.583 D_fake: 0.306 \n",
      "(epoch: 198, iters: 204, time: 0.148, data: 0.001) G_GAN: 1.671 G_L1: 6.328 D_real: 0.473 D_fake: 0.239 \n",
      "(epoch: 198, iters: 304, time: 0.238, data: 0.001) G_GAN: 1.547 G_L1: 8.444 D_real: 0.025 D_fake: 0.277 \n",
      "End of epoch 198 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 36, time: 0.148, data: 0.002) G_GAN: 1.267 G_L1: 4.914 D_real: 0.199 D_fake: 0.365 \n",
      "(epoch: 199, iters: 136, time: 0.148, data: 0.002) G_GAN: 3.908 G_L1: 4.605 D_real: 0.487 D_fake: 0.023 \n",
      "(epoch: 199, iters: 236, time: 0.148, data: 0.002) G_GAN: 0.738 G_L1: 3.550 D_real: 0.203 D_fake: 0.716 \n",
      "(epoch: 199, iters: 336, time: 0.245, data: 0.001) G_GAN: 0.465 G_L1: 6.375 D_real: 0.491 D_fake: 1.148 \n",
      "End of epoch 199 / 200 \t Time Taken: 34 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 68, time: 0.148, data: 0.001) G_GAN: 1.801 G_L1: 5.257 D_real: 0.367 D_fake: 0.193 \n",
      "(epoch: 200, iters: 168, time: 0.147, data: 0.001) G_GAN: 1.398 G_L1: 5.131 D_real: 0.847 D_fake: 0.310 \n",
      "(epoch: 200, iters: 268, time: 0.148, data: 0.002) G_GAN: 1.340 G_L1: 7.014 D_real: 0.760 D_fake: 0.339 \n",
      "(epoch: 200, iters: 368, time: 0.190, data: 0.002) G_GAN: 1.815 G_L1: 7.766 D_real: 0.039 D_fake: 0.200 \n",
      "saving the model at the end of epoch 200, iters 73600\n",
      "End of epoch 200 / 200 \t Time Taken: 35 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot data366 --model pix2pix --checkpoints_dir jun23  --no_flip --batch_size 4  --netG resnet_9blocks --preprocess crop --load_size 512 --name data366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: jun23                         \t[default: ./checkpoints]\n",
      "                crop_size: 128                           \t[default: 256]\n",
      "                 dataroot: testA                         \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: data366                       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \t[default: False]\n",
      "                     norm: batch                         \t[default: instance]\n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: crop                          \t[default: resize_and_crop]\n",
      "              results_dir: results_demojun_crop128       \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from jun23/data366/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.383 M\n",
      "DataParallel(\n",
      "  (module): ResnetGenerator(\n",
      "    (model): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (18): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (27): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['testA/251.jpg']\n",
      "processing (0005)-th image... ['testA/256.jpg']\n",
      "processing (0010)-th image... ['testA/261.jpg']\n",
      "processing (0015)-th image... ['testA/266.jpg']\n",
      "processing (0020)-th image... ['testA/271.jpg']\n",
      "processing (0025)-th image... ['testA/276.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot testA --results_dir results_demojun_crop128 --model test --dataset_mode single --netG resnet_9blocks --norm batch --preprocess crop  --crop_size 128 --no_flip --checkpoints_dir jun23 --name data366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 4                             \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: jun23                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: syndata                       \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 512                           \t[default: 286]\n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: synth                         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: crop                          \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 868\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.383 M\n",
      "DataParallel(\n",
      "  (module): ResnetGenerator(\n",
      "    (model): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (18): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (27): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory jun23/synth/web...\n",
      "(epoch: 1, iters: 100, time: 0.146, data: 0.126) G_GAN: 1.422 G_L1: 14.317 D_real: 0.453 D_fake: 0.482 \n",
      "(epoch: 1, iters: 200, time: 0.147, data: 0.002) G_GAN: 1.972 G_L1: 14.285 D_real: 0.168 D_fake: 0.572 \n",
      "(epoch: 1, iters: 300, time: 0.147, data: 0.001) G_GAN: 0.753 G_L1: 10.161 D_real: 2.263 D_fake: 0.218 \n",
      "(epoch: 1, iters: 400, time: 0.166, data: 0.001) G_GAN: 1.467 G_L1: 12.160 D_real: 0.247 D_fake: 0.569 \n",
      "(epoch: 1, iters: 500, time: 0.147, data: 0.001) G_GAN: 1.819 G_L1: 10.750 D_real: 0.033 D_fake: 2.189 \n",
      "(epoch: 1, iters: 600, time: 0.148, data: 0.001) G_GAN: 1.474 G_L1: 13.250 D_real: 0.056 D_fake: 0.492 \n",
      "(epoch: 1, iters: 700, time: 0.148, data: 0.001) G_GAN: 0.714 G_L1: 10.495 D_real: 2.692 D_fake: 0.159 \n",
      "(epoch: 1, iters: 800, time: 0.169, data: 0.001) G_GAN: 0.691 G_L1: 12.031 D_real: 0.613 D_fake: 0.355 \n",
      "End of epoch 1 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 32, time: 0.148, data: 0.002) G_GAN: 1.316 G_L1: 11.908 D_real: 0.371 D_fake: 0.325 \n",
      "(epoch: 2, iters: 132, time: 0.147, data: 0.001) G_GAN: 1.550 G_L1: 13.650 D_real: 0.101 D_fake: 0.662 \n",
      "(epoch: 2, iters: 232, time: 0.148, data: 0.001) G_GAN: 1.362 G_L1: 12.106 D_real: 0.550 D_fake: 0.201 \n",
      "(epoch: 2, iters: 332, time: 0.167, data: 0.001) G_GAN: 1.405 G_L1: 11.092 D_real: 0.250 D_fake: 1.015 \n",
      "(epoch: 2, iters: 432, time: 0.148, data: 0.002) G_GAN: 1.670 G_L1: 11.574 D_real: 0.475 D_fake: 0.505 \n",
      "(epoch: 2, iters: 532, time: 0.148, data: 0.001) G_GAN: 1.088 G_L1: 11.278 D_real: 0.100 D_fake: 0.523 \n",
      "(epoch: 2, iters: 632, time: 0.147, data: 0.001) G_GAN: 1.950 G_L1: 12.914 D_real: 0.052 D_fake: 0.837 \n",
      "(epoch: 2, iters: 732, time: 0.163, data: 0.001) G_GAN: 0.735 G_L1: 10.383 D_real: 0.797 D_fake: 0.340 \n",
      "(epoch: 2, iters: 832, time: 0.147, data: 0.001) G_GAN: 1.483 G_L1: 12.944 D_real: 0.318 D_fake: 0.312 \n",
      "End of epoch 2 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 64, time: 0.148, data: 0.001) G_GAN: 0.650 G_L1: 9.740 D_real: 0.805 D_fake: 0.179 \n",
      "(epoch: 3, iters: 164, time: 0.148, data: 0.001) G_GAN: 1.072 G_L1: 10.841 D_real: 1.772 D_fake: 0.223 \n",
      "(epoch: 3, iters: 264, time: 0.166, data: 0.001) G_GAN: 0.766 G_L1: 10.126 D_real: 1.473 D_fake: 0.657 \n",
      "(epoch: 3, iters: 364, time: 0.148, data: 0.001) G_GAN: 1.634 G_L1: 10.949 D_real: 0.113 D_fake: 1.468 \n",
      "(epoch: 3, iters: 464, time: 0.148, data: 0.001) G_GAN: 0.744 G_L1: 9.475 D_real: 1.699 D_fake: 0.496 \n",
      "(epoch: 3, iters: 564, time: 0.148, data: 0.001) G_GAN: 0.702 G_L1: 10.886 D_real: 0.364 D_fake: 0.383 \n",
      "(epoch: 3, iters: 664, time: 0.165, data: 0.001) G_GAN: 1.077 G_L1: 11.039 D_real: 0.071 D_fake: 1.582 \n",
      "(epoch: 3, iters: 764, time: 0.148, data: 0.001) G_GAN: 1.563 G_L1: 10.027 D_real: 0.916 D_fake: 0.185 \n",
      "(epoch: 3, iters: 864, time: 0.147, data: 0.001) G_GAN: 1.517 G_L1: 10.855 D_real: 0.124 D_fake: 0.868 \n",
      "End of epoch 3 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 96, time: 0.147, data: 0.001) G_GAN: 1.060 G_L1: 11.533 D_real: 1.088 D_fake: 0.255 \n",
      "(epoch: 4, iters: 196, time: 0.166, data: 0.001) G_GAN: 1.370 G_L1: 12.491 D_real: 0.044 D_fake: 0.416 \n",
      "(epoch: 4, iters: 296, time: 0.147, data: 0.001) G_GAN: 1.220 G_L1: 10.057 D_real: 0.530 D_fake: 0.697 \n",
      "(epoch: 4, iters: 396, time: 0.148, data: 0.001) G_GAN: 0.882 G_L1: 7.627 D_real: 0.338 D_fake: 0.873 \n",
      "(epoch: 4, iters: 496, time: 0.147, data: 0.001) G_GAN: 0.949 G_L1: 10.946 D_real: 0.610 D_fake: 0.402 \n",
      "(epoch: 4, iters: 596, time: 0.165, data: 0.001) G_GAN: 1.132 G_L1: 12.147 D_real: 0.482 D_fake: 0.354 \n",
      "(epoch: 4, iters: 696, time: 0.148, data: 0.001) G_GAN: 1.140 G_L1: 8.144 D_real: 1.536 D_fake: 0.254 \n",
      "(epoch: 4, iters: 796, time: 0.147, data: 0.001) G_GAN: 1.132 G_L1: 7.984 D_real: 0.719 D_fake: 0.375 \n",
      "End of epoch 4 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 28, time: 0.148, data: 0.002) G_GAN: 0.647 G_L1: 9.300 D_real: 1.048 D_fake: 0.377 \n",
      "(epoch: 5, iters: 128, time: 0.166, data: 0.001) G_GAN: 1.186 G_L1: 13.428 D_real: 0.097 D_fake: 0.975 \n",
      "(epoch: 5, iters: 228, time: 0.148, data: 0.001) G_GAN: 1.033 G_L1: 8.229 D_real: 0.412 D_fake: 0.302 \n",
      "(epoch: 5, iters: 328, time: 0.148, data: 0.001) G_GAN: 1.044 G_L1: 10.651 D_real: 1.091 D_fake: 0.345 \n",
      "(epoch: 5, iters: 428, time: 0.148, data: 0.001) G_GAN: 0.902 G_L1: 7.745 D_real: 2.077 D_fake: 0.219 \n",
      "(epoch: 5, iters: 528, time: 0.164, data: 0.001) G_GAN: 1.982 G_L1: 12.559 D_real: 0.156 D_fake: 0.194 \n",
      "(epoch: 5, iters: 628, time: 0.147, data: 0.002) G_GAN: 1.277 G_L1: 8.252 D_real: 0.353 D_fake: 0.384 \n",
      "(epoch: 5, iters: 728, time: 0.148, data: 0.001) G_GAN: 1.559 G_L1: 8.762 D_real: 0.155 D_fake: 0.729 \n",
      "(epoch: 5, iters: 828, time: 0.147, data: 0.001) G_GAN: 1.292 G_L1: 11.297 D_real: 0.145 D_fake: 0.612 \n",
      "saving the model at the end of epoch 5, iters 4340\n",
      "End of epoch 5 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 60, time: 0.168, data: 0.001) G_GAN: 1.323 G_L1: 9.560 D_real: 0.924 D_fake: 0.275 \n",
      "(epoch: 6, iters: 160, time: 0.147, data: 0.001) G_GAN: 0.978 G_L1: 12.047 D_real: 0.837 D_fake: 0.235 \n",
      "(epoch: 6, iters: 260, time: 0.147, data: 0.001) G_GAN: 0.978 G_L1: 8.174 D_real: 0.057 D_fake: 1.189 \n",
      "(epoch: 6, iters: 360, time: 0.148, data: 0.001) G_GAN: 1.060 G_L1: 9.972 D_real: 1.999 D_fake: 0.207 \n",
      "(epoch: 6, iters: 460, time: 0.166, data: 0.001) G_GAN: 0.909 G_L1: 10.976 D_real: 0.841 D_fake: 0.366 \n",
      "(epoch: 6, iters: 560, time: 0.148, data: 0.001) G_GAN: 1.485 G_L1: 12.682 D_real: 0.176 D_fake: 0.335 \n",
      "(epoch: 6, iters: 660, time: 0.147, data: 0.001) G_GAN: 1.085 G_L1: 11.177 D_real: 0.710 D_fake: 0.465 \n",
      "saving the latest model (epoch 6, total_iters 5000)\n",
      "(epoch: 6, iters: 760, time: 0.148, data: 0.001) G_GAN: 0.574 G_L1: 8.595 D_real: 0.743 D_fake: 0.533 \n",
      "(epoch: 6, iters: 860, time: 0.167, data: 0.001) G_GAN: 0.708 G_L1: 9.802 D_real: 0.880 D_fake: 0.408 \n",
      "End of epoch 6 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 92, time: 0.148, data: 0.001) G_GAN: 0.911 G_L1: 7.766 D_real: 1.400 D_fake: 0.229 \n",
      "(epoch: 7, iters: 192, time: 0.147, data: 0.001) G_GAN: 1.194 G_L1: 9.481 D_real: 0.459 D_fake: 0.327 \n",
      "(epoch: 7, iters: 292, time: 0.147, data: 0.002) G_GAN: 0.835 G_L1: 7.607 D_real: 0.886 D_fake: 0.323 \n",
      "(epoch: 7, iters: 392, time: 0.163, data: 0.001) G_GAN: 0.518 G_L1: 8.255 D_real: 0.800 D_fake: 0.614 \n",
      "(epoch: 7, iters: 492, time: 0.147, data: 0.001) G_GAN: 0.873 G_L1: 10.709 D_real: 0.803 D_fake: 0.379 \n",
      "(epoch: 7, iters: 592, time: 0.147, data: 0.002) G_GAN: 1.287 G_L1: 8.797 D_real: 0.124 D_fake: 1.011 \n",
      "(epoch: 7, iters: 692, time: 0.147, data: 0.001) G_GAN: 0.918 G_L1: 9.609 D_real: 0.497 D_fake: 0.617 \n",
      "(epoch: 7, iters: 792, time: 0.166, data: 0.001) G_GAN: 1.098 G_L1: 7.788 D_real: 1.012 D_fake: 0.473 \n",
      "End of epoch 7 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 24, time: 0.148, data: 0.001) G_GAN: 0.846 G_L1: 8.786 D_real: 0.530 D_fake: 0.603 \n",
      "(epoch: 8, iters: 124, time: 0.147, data: 0.002) G_GAN: 0.902 G_L1: 9.206 D_real: 0.393 D_fake: 0.394 \n",
      "(epoch: 8, iters: 224, time: 0.148, data: 0.001) G_GAN: 0.811 G_L1: 9.057 D_real: 0.347 D_fake: 0.689 \n",
      "(epoch: 8, iters: 324, time: 0.170, data: 0.001) G_GAN: 0.747 G_L1: 6.853 D_real: 0.822 D_fake: 0.424 \n",
      "(epoch: 8, iters: 424, time: 0.147, data: 0.001) G_GAN: 0.657 G_L1: 11.220 D_real: 0.706 D_fake: 0.546 \n",
      "(epoch: 8, iters: 524, time: 0.147, data: 0.002) G_GAN: 1.296 G_L1: 9.928 D_real: 0.125 D_fake: 0.649 \n",
      "(epoch: 8, iters: 624, time: 0.148, data: 0.001) G_GAN: 0.939 G_L1: 8.454 D_real: 0.311 D_fake: 1.098 \n",
      "(epoch: 8, iters: 724, time: 0.169, data: 0.001) G_GAN: 1.095 G_L1: 7.949 D_real: 0.540 D_fake: 0.370 \n",
      "(epoch: 8, iters: 824, time: 0.148, data: 0.001) G_GAN: 1.216 G_L1: 10.889 D_real: 0.049 D_fake: 0.886 \n",
      "End of epoch 8 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 56, time: 0.148, data: 0.001) G_GAN: 1.050 G_L1: 10.060 D_real: 0.659 D_fake: 0.500 \n",
      "(epoch: 9, iters: 156, time: 0.147, data: 0.002) G_GAN: 1.232 G_L1: 8.171 D_real: 1.201 D_fake: 0.172 \n",
      "(epoch: 9, iters: 256, time: 0.167, data: 0.001) G_GAN: 1.252 G_L1: 10.618 D_real: 0.169 D_fake: 0.804 \n",
      "(epoch: 9, iters: 356, time: 0.147, data: 0.001) G_GAN: 0.835 G_L1: 7.942 D_real: 0.325 D_fake: 0.711 \n",
      "(epoch: 9, iters: 456, time: 0.148, data: 0.001) G_GAN: 0.576 G_L1: 9.381 D_real: 0.863 D_fake: 0.390 \n",
      "(epoch: 9, iters: 556, time: 0.148, data: 0.002) G_GAN: 1.106 G_L1: 8.852 D_real: 1.393 D_fake: 0.231 \n",
      "(epoch: 9, iters: 656, time: 0.168, data: 0.002) G_GAN: 1.258 G_L1: 11.206 D_real: 0.022 D_fake: 1.562 \n",
      "(epoch: 9, iters: 756, time: 0.148, data: 0.001) G_GAN: 0.926 G_L1: 7.176 D_real: 1.268 D_fake: 0.261 \n",
      "(epoch: 9, iters: 856, time: 0.148, data: 0.001) G_GAN: 1.182 G_L1: 8.845 D_real: 0.784 D_fake: 0.298 \n",
      "End of epoch 9 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 88, time: 0.148, data: 0.001) G_GAN: 1.124 G_L1: 9.343 D_real: 0.093 D_fake: 1.128 \n",
      "(epoch: 10, iters: 188, time: 0.168, data: 0.001) G_GAN: 1.198 G_L1: 6.086 D_real: 1.688 D_fake: 0.212 \n",
      "(epoch: 10, iters: 288, time: 0.148, data: 0.001) G_GAN: 1.036 G_L1: 8.136 D_real: 0.973 D_fake: 0.347 \n",
      "(epoch: 10, iters: 388, time: 0.147, data: 0.001) G_GAN: 0.951 G_L1: 7.989 D_real: 0.308 D_fake: 0.495 \n",
      "(epoch: 10, iters: 488, time: 0.148, data: 0.001) G_GAN: 0.737 G_L1: 8.746 D_real: 0.681 D_fake: 0.443 \n",
      "(epoch: 10, iters: 588, time: 0.167, data: 0.001) G_GAN: 0.651 G_L1: 6.154 D_real: 0.489 D_fake: 0.861 \n",
      "(epoch: 10, iters: 688, time: 0.148, data: 0.001) G_GAN: 1.148 G_L1: 7.497 D_real: 0.772 D_fake: 0.254 \n",
      "(epoch: 10, iters: 788, time: 0.148, data: 0.001) G_GAN: 1.211 G_L1: 7.505 D_real: 0.684 D_fake: 0.380 \n",
      "saving the model at the end of epoch 10, iters 8680\n",
      "End of epoch 10 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 20, time: 0.147, data: 0.001) G_GAN: 1.108 G_L1: 9.112 D_real: 0.927 D_fake: 0.214 \n",
      "(epoch: 11, iters: 120, time: 0.171, data: 0.001) G_GAN: 1.233 G_L1: 13.050 D_real: 0.053 D_fake: 0.700 \n",
      "(epoch: 11, iters: 220, time: 0.148, data: 0.001) G_GAN: 1.085 G_L1: 8.303 D_real: 0.124 D_fake: 0.923 \n",
      "(epoch: 11, iters: 320, time: 0.147, data: 0.002) G_GAN: 0.916 G_L1: 7.024 D_real: 0.229 D_fake: 0.865 \n",
      "(epoch: 11, iters: 420, time: 0.149, data: 0.002) G_GAN: 0.936 G_L1: 8.108 D_real: 0.386 D_fake: 0.384 \n",
      "(epoch: 11, iters: 520, time: 0.167, data: 0.001) G_GAN: 1.051 G_L1: 8.523 D_real: 0.264 D_fake: 0.600 \n",
      "(epoch: 11, iters: 620, time: 0.148, data: 0.001) G_GAN: 1.154 G_L1: 8.308 D_real: 1.007 D_fake: 0.292 \n",
      "(epoch: 11, iters: 720, time: 0.148, data: 0.001) G_GAN: 1.316 G_L1: 9.188 D_real: 0.210 D_fake: 0.632 \n",
      "(epoch: 11, iters: 820, time: 0.147, data: 0.001) G_GAN: 1.248 G_L1: 9.128 D_real: 0.069 D_fake: 0.852 \n",
      "End of epoch 11 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 52, time: 0.171, data: 0.001) G_GAN: 1.195 G_L1: 10.825 D_real: 0.240 D_fake: 0.599 \n",
      "(epoch: 12, iters: 152, time: 0.148, data: 0.001) G_GAN: 1.087 G_L1: 10.865 D_real: 0.576 D_fake: 0.337 \n",
      "(epoch: 12, iters: 252, time: 0.148, data: 0.001) G_GAN: 0.583 G_L1: 6.617 D_real: 1.598 D_fake: 0.179 \n",
      "(epoch: 12, iters: 352, time: 0.148, data: 0.002) G_GAN: 0.805 G_L1: 7.946 D_real: 0.446 D_fake: 0.716 \n",
      "(epoch: 12, iters: 452, time: 0.166, data: 0.001) G_GAN: 0.913 G_L1: 9.165 D_real: 0.317 D_fake: 0.911 \n",
      "saving the latest model (epoch 12, total_iters 10000)\n",
      "(epoch: 12, iters: 552, time: 0.148, data: 0.002) G_GAN: 0.625 G_L1: 5.371 D_real: 1.473 D_fake: 0.286 \n",
      "(epoch: 12, iters: 652, time: 0.148, data: 0.001) G_GAN: 0.937 G_L1: 8.953 D_real: 0.243 D_fake: 1.357 \n",
      "(epoch: 12, iters: 752, time: 0.147, data: 0.001) G_GAN: 0.953 G_L1: 8.683 D_real: 1.325 D_fake: 0.379 \n",
      "(epoch: 12, iters: 852, time: 0.171, data: 0.002) G_GAN: 0.989 G_L1: 8.209 D_real: 0.354 D_fake: 0.653 \n",
      "End of epoch 12 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 84, time: 0.148, data: 0.001) G_GAN: 1.012 G_L1: 8.919 D_real: 0.371 D_fake: 0.955 \n",
      "(epoch: 13, iters: 184, time: 0.148, data: 0.001) G_GAN: 0.703 G_L1: 9.013 D_real: 0.784 D_fake: 0.486 \n",
      "(epoch: 13, iters: 284, time: 0.147, data: 0.001) G_GAN: 0.961 G_L1: 10.950 D_real: 0.079 D_fake: 1.230 \n",
      "(epoch: 13, iters: 384, time: 0.172, data: 0.001) G_GAN: 1.100 G_L1: 7.710 D_real: 0.321 D_fake: 0.455 \n",
      "(epoch: 13, iters: 484, time: 0.148, data: 0.001) G_GAN: 1.369 G_L1: 10.326 D_real: 0.157 D_fake: 0.838 \n",
      "(epoch: 13, iters: 584, time: 0.148, data: 0.001) G_GAN: 1.162 G_L1: 10.620 D_real: 0.053 D_fake: 1.358 \n",
      "(epoch: 13, iters: 684, time: 0.148, data: 0.001) G_GAN: 1.091 G_L1: 6.312 D_real: 1.507 D_fake: 0.201 \n",
      "(epoch: 13, iters: 784, time: 0.170, data: 0.001) G_GAN: 1.309 G_L1: 6.734 D_real: 0.141 D_fake: 0.731 \n",
      "End of epoch 13 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 16, time: 0.148, data: 0.002) G_GAN: 0.868 G_L1: 9.080 D_real: 0.333 D_fake: 0.705 \n",
      "(epoch: 14, iters: 116, time: 0.148, data: 0.003) G_GAN: 0.906 G_L1: 8.230 D_real: 0.343 D_fake: 0.589 \n",
      "(epoch: 14, iters: 216, time: 0.148, data: 0.001) G_GAN: 1.183 G_L1: 8.848 D_real: 0.191 D_fake: 1.586 \n",
      "(epoch: 14, iters: 316, time: 0.171, data: 0.001) G_GAN: 0.936 G_L1: 7.629 D_real: 0.557 D_fake: 0.692 \n",
      "(epoch: 14, iters: 416, time: 0.148, data: 0.001) G_GAN: 0.852 G_L1: 8.964 D_real: 0.518 D_fake: 0.596 \n",
      "(epoch: 14, iters: 516, time: 0.148, data: 0.001) G_GAN: 1.547 G_L1: 8.009 D_real: 0.674 D_fake: 0.310 \n",
      "(epoch: 14, iters: 616, time: 0.147, data: 0.002) G_GAN: 0.815 G_L1: 7.428 D_real: 0.622 D_fake: 0.457 \n",
      "(epoch: 14, iters: 716, time: 0.172, data: 0.001) G_GAN: 1.036 G_L1: 8.499 D_real: 0.566 D_fake: 0.374 \n",
      "(epoch: 14, iters: 816, time: 0.148, data: 0.001) G_GAN: 0.742 G_L1: 5.983 D_real: 1.103 D_fake: 0.416 \n",
      "End of epoch 14 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 48, time: 0.148, data: 0.001) G_GAN: 1.079 G_L1: 11.238 D_real: 0.105 D_fake: 0.735 \n",
      "(epoch: 15, iters: 148, time: 0.148, data: 0.002) G_GAN: 1.038 G_L1: 6.695 D_real: 1.531 D_fake: 0.241 \n",
      "(epoch: 15, iters: 248, time: 0.168, data: 0.001) G_GAN: 0.933 G_L1: 7.368 D_real: 0.347 D_fake: 0.464 \n",
      "(epoch: 15, iters: 348, time: 0.147, data: 0.001) G_GAN: 1.045 G_L1: 8.771 D_real: 0.418 D_fake: 0.481 \n",
      "(epoch: 15, iters: 448, time: 0.147, data: 0.002) G_GAN: 0.750 G_L1: 8.637 D_real: 0.788 D_fake: 0.543 \n",
      "(epoch: 15, iters: 548, time: 0.148, data: 0.001) G_GAN: 1.046 G_L1: 6.081 D_real: 1.426 D_fake: 0.242 \n",
      "(epoch: 15, iters: 648, time: 0.168, data: 0.001) G_GAN: 1.194 G_L1: 7.906 D_real: 1.545 D_fake: 0.214 \n",
      "(epoch: 15, iters: 748, time: 0.147, data: 0.001) G_GAN: 1.193 G_L1: 9.936 D_real: 0.964 D_fake: 0.273 \n",
      "(epoch: 15, iters: 848, time: 0.147, data: 0.001) G_GAN: 0.919 G_L1: 6.856 D_real: 0.857 D_fake: 0.484 \n",
      "saving the model at the end of epoch 15, iters 13020\n",
      "End of epoch 15 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 80, time: 0.147, data: 0.001) G_GAN: 0.959 G_L1: 8.052 D_real: 0.087 D_fake: 1.338 \n",
      "(epoch: 16, iters: 180, time: 0.171, data: 0.002) G_GAN: 0.970 G_L1: 7.593 D_real: 0.850 D_fake: 0.465 \n",
      "(epoch: 16, iters: 280, time: 0.148, data: 0.001) G_GAN: 1.194 G_L1: 9.642 D_real: 0.538 D_fake: 0.380 \n",
      "(epoch: 16, iters: 380, time: 0.148, data: 0.001) G_GAN: 0.876 G_L1: 7.993 D_real: 0.143 D_fake: 1.145 \n",
      "(epoch: 16, iters: 480, time: 0.148, data: 0.001) G_GAN: 0.835 G_L1: 7.695 D_real: 1.194 D_fake: 0.315 \n",
      "(epoch: 16, iters: 580, time: 0.165, data: 0.001) G_GAN: 0.769 G_L1: 6.615 D_real: 1.169 D_fake: 0.387 \n",
      "(epoch: 16, iters: 680, time: 0.147, data: 0.001) G_GAN: 1.484 G_L1: 8.334 D_real: 2.220 D_fake: 0.199 \n",
      "(epoch: 16, iters: 780, time: 0.148, data: 0.001) G_GAN: 0.878 G_L1: 8.224 D_real: 0.327 D_fake: 0.578 \n",
      "End of epoch 16 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 12, time: 0.147, data: 0.001) G_GAN: 1.340 G_L1: 7.557 D_real: 0.686 D_fake: 0.363 \n",
      "(epoch: 17, iters: 112, time: 0.170, data: 0.001) G_GAN: 1.098 G_L1: 10.543 D_real: 0.221 D_fake: 0.502 \n",
      "(epoch: 17, iters: 212, time: 0.148, data: 0.001) G_GAN: 1.116 G_L1: 7.193 D_real: 0.559 D_fake: 0.316 \n",
      "(epoch: 17, iters: 312, time: 0.147, data: 0.001) G_GAN: 0.769 G_L1: 5.845 D_real: 0.466 D_fake: 0.678 \n",
      "(epoch: 17, iters: 412, time: 0.148, data: 0.001) G_GAN: 1.064 G_L1: 8.895 D_real: 0.494 D_fake: 0.685 \n",
      "(epoch: 17, iters: 512, time: 0.176, data: 0.001) G_GAN: 0.907 G_L1: 8.332 D_real: 0.338 D_fake: 1.103 \n",
      "(epoch: 17, iters: 612, time: 0.147, data: 0.002) G_GAN: 1.057 G_L1: 5.712 D_real: 1.771 D_fake: 0.213 \n",
      "(epoch: 17, iters: 712, time: 0.148, data: 0.002) G_GAN: 0.823 G_L1: 5.587 D_real: 0.631 D_fake: 0.601 \n",
      "(epoch: 17, iters: 812, time: 0.148, data: 0.001) G_GAN: 0.894 G_L1: 7.867 D_real: 1.227 D_fake: 0.417 \n",
      "End of epoch 17 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 44, time: 0.173, data: 0.001) G_GAN: 0.862 G_L1: 7.758 D_real: 0.552 D_fake: 0.599 \n",
      "(epoch: 18, iters: 144, time: 0.148, data: 0.001) G_GAN: 0.678 G_L1: 7.836 D_real: 0.540 D_fake: 0.531 \n",
      "(epoch: 18, iters: 244, time: 0.148, data: 0.002) G_GAN: 0.907 G_L1: 9.840 D_real: 0.388 D_fake: 1.243 \n",
      "saving the latest model (epoch 18, total_iters 15000)\n",
      "(epoch: 18, iters: 344, time: 0.147, data: 0.001) G_GAN: 1.048 G_L1: 8.430 D_real: 0.462 D_fake: 0.444 \n",
      "(epoch: 18, iters: 444, time: 0.172, data: 0.001) G_GAN: 1.058 G_L1: 8.479 D_real: 0.101 D_fake: 0.885 \n",
      "(epoch: 18, iters: 544, time: 0.147, data: 0.001) G_GAN: 0.908 G_L1: 8.151 D_real: 0.250 D_fake: 0.805 \n",
      "(epoch: 18, iters: 644, time: 0.148, data: 0.001) G_GAN: 0.747 G_L1: 8.111 D_real: 0.561 D_fake: 0.420 \n",
      "(epoch: 18, iters: 744, time: 0.148, data: 0.002) G_GAN: 1.143 G_L1: 11.360 D_real: 0.039 D_fake: 1.058 \n",
      "(epoch: 18, iters: 844, time: 0.171, data: 0.001) G_GAN: 0.982 G_L1: 7.613 D_real: 1.453 D_fake: 0.175 \n",
      "End of epoch 18 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 76, time: 0.147, data: 0.002) G_GAN: 0.727 G_L1: 8.429 D_real: 0.678 D_fake: 0.425 \n",
      "(epoch: 19, iters: 176, time: 0.148, data: 0.001) G_GAN: 0.915 G_L1: 8.378 D_real: 0.646 D_fake: 0.638 \n",
      "(epoch: 19, iters: 276, time: 0.147, data: 0.001) G_GAN: 1.075 G_L1: 8.932 D_real: 0.948 D_fake: 0.172 \n",
      "(epoch: 19, iters: 376, time: 0.171, data: 0.001) G_GAN: 0.782 G_L1: 6.680 D_real: 0.603 D_fake: 0.457 \n",
      "(epoch: 19, iters: 476, time: 0.148, data: 0.001) G_GAN: 0.840 G_L1: 8.610 D_real: 0.254 D_fake: 0.659 \n",
      "(epoch: 19, iters: 576, time: 0.148, data: 0.001) G_GAN: 0.835 G_L1: 9.003 D_real: 0.180 D_fake: 1.194 \n",
      "(epoch: 19, iters: 676, time: 0.147, data: 0.001) G_GAN: 0.946 G_L1: 8.539 D_real: 0.577 D_fake: 0.497 \n",
      "(epoch: 19, iters: 776, time: 0.173, data: 0.001) G_GAN: 0.903 G_L1: 7.191 D_real: 0.352 D_fake: 0.853 \n",
      "End of epoch 19 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 8, time: 0.148, data: 0.002) G_GAN: 1.015 G_L1: 8.299 D_real: 0.404 D_fake: 0.472 \n",
      "(epoch: 20, iters: 108, time: 0.148, data: 0.002) G_GAN: 1.325 G_L1: 9.237 D_real: 1.660 D_fake: 0.242 \n",
      "(epoch: 20, iters: 208, time: 0.147, data: 0.002) G_GAN: 0.992 G_L1: 9.340 D_real: 0.215 D_fake: 0.782 \n",
      "(epoch: 20, iters: 308, time: 0.172, data: 0.001) G_GAN: 1.084 G_L1: 9.709 D_real: 0.486 D_fake: 0.542 \n",
      "(epoch: 20, iters: 408, time: 0.147, data: 0.001) G_GAN: 0.973 G_L1: 6.861 D_real: 0.697 D_fake: 0.358 \n",
      "(epoch: 20, iters: 508, time: 0.148, data: 0.002) G_GAN: 0.981 G_L1: 6.651 D_real: 1.101 D_fake: 0.322 \n",
      "(epoch: 20, iters: 608, time: 0.148, data: 0.001) G_GAN: 0.873 G_L1: 5.175 D_real: 0.563 D_fake: 0.598 \n",
      "(epoch: 20, iters: 708, time: 0.171, data: 0.001) G_GAN: 0.725 G_L1: 7.208 D_real: 0.588 D_fake: 0.660 \n",
      "(epoch: 20, iters: 808, time: 0.147, data: 0.002) G_GAN: 0.642 G_L1: 8.075 D_real: 0.544 D_fake: 0.678 \n",
      "saving the model at the end of epoch 20, iters 17360\n",
      "End of epoch 20 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 40, time: 0.147, data: 0.002) G_GAN: 0.843 G_L1: 7.318 D_real: 0.816 D_fake: 0.357 \n",
      "(epoch: 21, iters: 140, time: 0.148, data: 0.001) G_GAN: 0.978 G_L1: 4.879 D_real: 1.872 D_fake: 0.249 \n",
      "(epoch: 21, iters: 240, time: 0.176, data: 0.001) G_GAN: 0.774 G_L1: 5.816 D_real: 0.954 D_fake: 0.348 \n",
      "(epoch: 21, iters: 340, time: 0.147, data: 0.001) G_GAN: 0.637 G_L1: 6.420 D_real: 1.269 D_fake: 0.374 \n",
      "(epoch: 21, iters: 440, time: 0.148, data: 0.001) G_GAN: 0.734 G_L1: 7.135 D_real: 0.727 D_fake: 0.470 \n",
      "(epoch: 21, iters: 540, time: 0.148, data: 0.001) G_GAN: 0.950 G_L1: 6.737 D_real: 0.766 D_fake: 0.307 \n",
      "(epoch: 21, iters: 640, time: 0.179, data: 0.001) G_GAN: 1.240 G_L1: 9.868 D_real: 0.463 D_fake: 0.526 \n",
      "(epoch: 21, iters: 740, time: 0.148, data: 0.002) G_GAN: 0.808 G_L1: 7.392 D_real: 0.737 D_fake: 0.474 \n",
      "(epoch: 21, iters: 840, time: 0.148, data: 0.001) G_GAN: 1.012 G_L1: 7.047 D_real: 0.677 D_fake: 0.547 \n",
      "End of epoch 21 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 72, time: 0.148, data: 0.001) G_GAN: 0.751 G_L1: 7.190 D_real: 0.656 D_fake: 0.547 \n",
      "(epoch: 22, iters: 172, time: 0.173, data: 0.001) G_GAN: 1.008 G_L1: 7.116 D_real: 0.638 D_fake: 0.610 \n",
      "(epoch: 22, iters: 272, time: 0.147, data: 0.001) G_GAN: 0.644 G_L1: 7.972 D_real: 0.905 D_fake: 0.434 \n",
      "(epoch: 22, iters: 372, time: 0.148, data: 0.002) G_GAN: 0.970 G_L1: 11.890 D_real: 0.544 D_fake: 1.166 \n",
      "(epoch: 22, iters: 472, time: 0.148, data: 0.001) G_GAN: 0.997 G_L1: 7.683 D_real: 0.889 D_fake: 0.329 \n",
      "(epoch: 22, iters: 572, time: 0.176, data: 0.001) G_GAN: 0.889 G_L1: 9.590 D_real: 0.415 D_fake: 0.809 \n",
      "(epoch: 22, iters: 672, time: 0.148, data: 0.002) G_GAN: 0.994 G_L1: 6.562 D_real: 0.531 D_fake: 0.663 \n",
      "(epoch: 22, iters: 772, time: 0.148, data: 0.001) G_GAN: 0.961 G_L1: 8.626 D_real: 0.733 D_fake: 0.377 \n",
      "End of epoch 22 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 4, time: 0.119, data: 0.001) G_GAN: 1.065 G_L1: 5.786 D_real: 0.948 D_fake: 0.458 \n",
      "(epoch: 23, iters: 104, time: 0.174, data: 0.002) G_GAN: 0.807 G_L1: 7.965 D_real: 0.545 D_fake: 0.401 \n",
      "(epoch: 23, iters: 204, time: 0.148, data: 0.001) G_GAN: 0.662 G_L1: 6.092 D_real: 0.852 D_fake: 0.547 \n",
      "(epoch: 23, iters: 304, time: 0.147, data: 0.001) G_GAN: 0.756 G_L1: 5.817 D_real: 1.145 D_fake: 0.241 \n",
      "(epoch: 23, iters: 404, time: 0.148, data: 0.002) G_GAN: 1.480 G_L1: 7.852 D_real: 1.035 D_fake: 0.204 \n",
      "(epoch: 23, iters: 504, time: 0.172, data: 0.002) G_GAN: 0.970 G_L1: 8.689 D_real: 0.342 D_fake: 0.580 \n",
      "(epoch: 23, iters: 604, time: 0.147, data: 0.001) G_GAN: 0.631 G_L1: 8.826 D_real: 0.616 D_fake: 0.757 \n",
      "(epoch: 23, iters: 704, time: 0.148, data: 0.001) G_GAN: 0.896 G_L1: 8.159 D_real: 0.308 D_fake: 0.625 \n",
      "(epoch: 23, iters: 804, time: 0.147, data: 0.001) G_GAN: 0.836 G_L1: 8.260 D_real: 0.871 D_fake: 0.339 \n",
      "End of epoch 23 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 36, time: 0.176, data: 0.001) G_GAN: 1.289 G_L1: 8.906 D_real: 0.186 D_fake: 0.445 \n",
      "saving the latest model (epoch 24, total_iters 20000)\n",
      "(epoch: 24, iters: 136, time: 0.147, data: 0.001) G_GAN: 0.841 G_L1: 8.693 D_real: 0.413 D_fake: 0.493 \n",
      "(epoch: 24, iters: 236, time: 0.147, data: 0.001) G_GAN: 0.632 G_L1: 7.369 D_real: 0.101 D_fake: 1.386 \n",
      "(epoch: 24, iters: 336, time: 0.147, data: 0.002) G_GAN: 0.761 G_L1: 8.023 D_real: 0.554 D_fake: 0.796 \n",
      "(epoch: 24, iters: 436, time: 0.169, data: 0.002) G_GAN: 1.268 G_L1: 9.528 D_real: 0.206 D_fake: 0.515 \n",
      "(epoch: 24, iters: 536, time: 0.147, data: 0.001) G_GAN: 1.033 G_L1: 7.486 D_real: 0.458 D_fake: 0.475 \n",
      "(epoch: 24, iters: 636, time: 0.147, data: 0.001) G_GAN: 0.655 G_L1: 8.443 D_real: 0.374 D_fake: 0.757 \n",
      "(epoch: 24, iters: 736, time: 0.148, data: 0.001) G_GAN: 0.800 G_L1: 7.686 D_real: 0.637 D_fake: 0.658 \n",
      "(epoch: 24, iters: 836, time: 0.175, data: 0.001) G_GAN: 0.958 G_L1: 6.985 D_real: 0.348 D_fake: 1.341 \n",
      "End of epoch 24 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 68, time: 0.147, data: 0.001) G_GAN: 0.977 G_L1: 7.017 D_real: 0.724 D_fake: 0.536 \n",
      "(epoch: 25, iters: 168, time: 0.147, data: 0.002) G_GAN: 0.803 G_L1: 5.905 D_real: 1.047 D_fake: 0.460 \n",
      "(epoch: 25, iters: 268, time: 0.147, data: 0.002) G_GAN: 0.810 G_L1: 8.377 D_real: 0.365 D_fake: 0.481 \n",
      "(epoch: 25, iters: 368, time: 0.173, data: 0.002) G_GAN: 0.969 G_L1: 8.838 D_real: 0.630 D_fake: 0.364 \n",
      "(epoch: 25, iters: 468, time: 0.148, data: 0.001) G_GAN: 1.184 G_L1: 9.792 D_real: 0.064 D_fake: 1.028 \n",
      "(epoch: 25, iters: 568, time: 0.148, data: 0.002) G_GAN: 0.974 G_L1: 6.944 D_real: 0.805 D_fake: 0.319 \n",
      "(epoch: 25, iters: 668, time: 0.148, data: 0.001) G_GAN: 0.661 G_L1: 9.864 D_real: 1.126 D_fake: 0.568 \n",
      "(epoch: 25, iters: 768, time: 0.177, data: 0.001) G_GAN: 0.820 G_L1: 5.085 D_real: 1.128 D_fake: 0.308 \n",
      "(epoch: 25, iters: 868, time: 0.148, data: 0.001) G_GAN: 1.117 G_L1: 9.673 D_real: 0.191 D_fake: 0.580 \n",
      "saving the model at the end of epoch 25, iters 21700\n",
      "End of epoch 25 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.148, data: 0.094) G_GAN: 0.698 G_L1: 7.444 D_real: 0.850 D_fake: 0.512 \n",
      "(epoch: 26, iters: 200, time: 0.147, data: 0.002) G_GAN: 0.924 G_L1: 7.641 D_real: 0.252 D_fake: 0.768 \n",
      "(epoch: 26, iters: 300, time: 0.172, data: 0.002) G_GAN: 0.813 G_L1: 6.218 D_real: 1.663 D_fake: 0.361 \n",
      "(epoch: 26, iters: 400, time: 0.147, data: 0.001) G_GAN: 1.120 G_L1: 7.315 D_real: 0.925 D_fake: 0.277 \n",
      "(epoch: 26, iters: 500, time: 0.147, data: 0.001) G_GAN: 1.193 G_L1: 8.188 D_real: 0.535 D_fake: 0.358 \n",
      "(epoch: 26, iters: 600, time: 0.147, data: 0.002) G_GAN: 1.295 G_L1: 10.000 D_real: 0.112 D_fake: 1.003 \n",
      "(epoch: 26, iters: 700, time: 0.173, data: 0.002) G_GAN: 0.986 G_L1: 8.520 D_real: 0.592 D_fake: 0.454 \n",
      "(epoch: 26, iters: 800, time: 0.147, data: 0.002) G_GAN: 0.969 G_L1: 8.494 D_real: 1.295 D_fake: 0.286 \n",
      "End of epoch 26 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 32, time: 0.148, data: 0.002) G_GAN: 0.845 G_L1: 7.457 D_real: 0.628 D_fake: 0.539 \n",
      "(epoch: 27, iters: 132, time: 0.148, data: 0.002) G_GAN: 0.907 G_L1: 7.901 D_real: 0.363 D_fake: 0.641 \n",
      "(epoch: 27, iters: 232, time: 0.174, data: 0.002) G_GAN: 0.615 G_L1: 6.089 D_real: 0.509 D_fake: 0.820 \n",
      "(epoch: 27, iters: 332, time: 0.148, data: 0.001) G_GAN: 0.659 G_L1: 7.882 D_real: 1.091 D_fake: 0.397 \n",
      "(epoch: 27, iters: 432, time: 0.148, data: 0.001) G_GAN: 0.888 G_L1: 8.869 D_real: 1.259 D_fake: 0.447 \n",
      "(epoch: 27, iters: 532, time: 0.147, data: 0.001) G_GAN: 0.983 G_L1: 6.141 D_real: 1.327 D_fake: 0.314 \n",
      "(epoch: 27, iters: 632, time: 0.173, data: 0.001) G_GAN: 0.968 G_L1: 8.417 D_real: 0.269 D_fake: 0.716 \n",
      "(epoch: 27, iters: 732, time: 0.147, data: 0.001) G_GAN: 1.118 G_L1: 6.403 D_real: 0.705 D_fake: 0.539 \n",
      "(epoch: 27, iters: 832, time: 0.147, data: 0.001) G_GAN: 1.578 G_L1: 5.549 D_real: 2.090 D_fake: 0.100 \n",
      "End of epoch 27 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 64, time: 0.147, data: 0.002) G_GAN: 0.940 G_L1: 6.791 D_real: 0.636 D_fake: 0.423 \n",
      "(epoch: 28, iters: 164, time: 0.178, data: 0.001) G_GAN: 0.981 G_L1: 7.161 D_real: 0.769 D_fake: 0.335 \n",
      "(epoch: 28, iters: 264, time: 0.148, data: 0.001) G_GAN: 0.775 G_L1: 6.114 D_real: 1.210 D_fake: 0.317 \n",
      "(epoch: 28, iters: 364, time: 0.147, data: 0.002) G_GAN: 1.270 G_L1: 6.585 D_real: 1.022 D_fake: 0.259 \n",
      "(epoch: 28, iters: 464, time: 0.147, data: 0.002) G_GAN: 0.846 G_L1: 7.938 D_real: 0.261 D_fake: 0.738 \n",
      "(epoch: 28, iters: 564, time: 0.173, data: 0.002) G_GAN: 0.996 G_L1: 8.517 D_real: 0.304 D_fake: 1.238 \n",
      "(epoch: 28, iters: 664, time: 0.147, data: 0.001) G_GAN: 0.836 G_L1: 5.604 D_real: 0.930 D_fake: 0.315 \n",
      "(epoch: 28, iters: 764, time: 0.147, data: 0.001) G_GAN: 1.063 G_L1: 8.335 D_real: 0.343 D_fake: 0.591 \n",
      "(epoch: 28, iters: 864, time: 0.148, data: 0.001) G_GAN: 0.666 G_L1: 6.699 D_real: 0.983 D_fake: 0.411 \n",
      "End of epoch 28 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 96, time: 0.180, data: 0.001) G_GAN: 0.782 G_L1: 7.175 D_real: 0.580 D_fake: 0.665 \n",
      "(epoch: 29, iters: 196, time: 0.148, data: 0.001) G_GAN: 0.680 G_L1: 7.594 D_real: 0.576 D_fake: 0.884 \n",
      "(epoch: 29, iters: 296, time: 0.148, data: 0.001) G_GAN: 0.847 G_L1: 7.175 D_real: 1.174 D_fake: 0.311 \n",
      "(epoch: 29, iters: 396, time: 0.148, data: 0.001) G_GAN: 1.123 G_L1: 9.103 D_real: 0.114 D_fake: 1.089 \n",
      "(epoch: 29, iters: 496, time: 0.173, data: 0.001) G_GAN: 0.893 G_L1: 5.586 D_real: 0.595 D_fake: 0.480 \n",
      "(epoch: 29, iters: 596, time: 0.148, data: 0.001) G_GAN: 0.891 G_L1: 7.156 D_real: 0.750 D_fake: 0.508 \n",
      "(epoch: 29, iters: 696, time: 0.147, data: 0.002) G_GAN: 0.891 G_L1: 6.264 D_real: 1.075 D_fake: 0.279 \n",
      "saving the latest model (epoch 29, total_iters 25000)\n",
      "(epoch: 29, iters: 796, time: 0.147, data: 0.002) G_GAN: 0.631 G_L1: 6.079 D_real: 0.613 D_fake: 0.718 \n",
      "End of epoch 29 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 28, time: 0.176, data: 0.002) G_GAN: 1.215 G_L1: 7.557 D_real: 0.101 D_fake: 1.337 \n",
      "(epoch: 30, iters: 128, time: 0.147, data: 0.001) G_GAN: 0.990 G_L1: 8.106 D_real: 0.214 D_fake: 0.890 \n",
      "(epoch: 30, iters: 228, time: 0.148, data: 0.001) G_GAN: 0.921 G_L1: 8.934 D_real: 1.357 D_fake: 0.247 \n",
      "(epoch: 30, iters: 328, time: 0.148, data: 0.002) G_GAN: 0.996 G_L1: 8.250 D_real: 0.254 D_fake: 0.723 \n",
      "(epoch: 30, iters: 428, time: 0.175, data: 0.001) G_GAN: 1.453 G_L1: 9.630 D_real: 0.179 D_fake: 0.519 \n",
      "(epoch: 30, iters: 528, time: 0.148, data: 0.001) G_GAN: 0.913 G_L1: 8.782 D_real: 0.369 D_fake: 0.975 \n",
      "(epoch: 30, iters: 628, time: 0.148, data: 0.001) G_GAN: 0.918 G_L1: 8.378 D_real: 0.600 D_fake: 0.617 \n",
      "(epoch: 30, iters: 728, time: 0.148, data: 0.002) G_GAN: 0.930 G_L1: 6.992 D_real: 0.245 D_fake: 0.659 \n",
      "(epoch: 30, iters: 828, time: 0.176, data: 0.001) G_GAN: 0.896 G_L1: 6.971 D_real: 0.895 D_fake: 0.413 \n",
      "saving the model at the end of epoch 30, iters 26040\n",
      "End of epoch 30 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 60, time: 0.148, data: 0.002) G_GAN: 0.880 G_L1: 5.350 D_real: 0.694 D_fake: 0.526 \n",
      "(epoch: 31, iters: 160, time: 0.148, data: 0.001) G_GAN: 0.813 G_L1: 4.242 D_real: 0.843 D_fake: 0.613 \n",
      "(epoch: 31, iters: 260, time: 0.148, data: 0.002) G_GAN: 0.881 G_L1: 10.130 D_real: 0.318 D_fake: 0.857 \n",
      "(epoch: 31, iters: 360, time: 0.178, data: 0.001) G_GAN: 0.784 G_L1: 7.599 D_real: 0.398 D_fake: 1.145 \n",
      "(epoch: 31, iters: 460, time: 0.148, data: 0.002) G_GAN: 0.907 G_L1: 6.580 D_real: 0.687 D_fake: 0.637 \n",
      "(epoch: 31, iters: 560, time: 0.147, data: 0.002) G_GAN: 0.900 G_L1: 7.897 D_real: 0.526 D_fake: 0.613 \n",
      "(epoch: 31, iters: 660, time: 0.148, data: 0.001) G_GAN: 1.072 G_L1: 8.281 D_real: 1.383 D_fake: 0.314 \n",
      "(epoch: 31, iters: 760, time: 0.175, data: 0.001) G_GAN: 0.723 G_L1: 8.765 D_real: 0.804 D_fake: 0.517 \n",
      "(epoch: 31, iters: 860, time: 0.147, data: 0.001) G_GAN: 1.008 G_L1: 7.917 D_real: 0.522 D_fake: 0.546 \n",
      "End of epoch 31 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 92, time: 0.148, data: 0.002) G_GAN: 1.044 G_L1: 9.360 D_real: 0.477 D_fake: 0.435 \n",
      "(epoch: 32, iters: 192, time: 0.148, data: 0.001) G_GAN: 1.044 G_L1: 7.231 D_real: 0.569 D_fake: 0.374 \n",
      "(epoch: 32, iters: 292, time: 0.174, data: 0.002) G_GAN: 1.010 G_L1: 7.450 D_real: 0.404 D_fake: 0.747 \n",
      "(epoch: 32, iters: 392, time: 0.148, data: 0.001) G_GAN: 1.001 G_L1: 7.406 D_real: 0.734 D_fake: 0.331 \n",
      "(epoch: 32, iters: 492, time: 0.148, data: 0.001) G_GAN: 1.005 G_L1: 6.865 D_real: 0.787 D_fake: 0.402 \n",
      "(epoch: 32, iters: 592, time: 0.147, data: 0.002) G_GAN: 0.886 G_L1: 6.102 D_real: 1.098 D_fake: 0.306 \n",
      "(epoch: 32, iters: 692, time: 0.175, data: 0.002) G_GAN: 1.154 G_L1: 7.061 D_real: 0.505 D_fake: 0.450 \n",
      "(epoch: 32, iters: 792, time: 0.148, data: 0.002) G_GAN: 0.650 G_L1: 7.053 D_real: 0.530 D_fake: 0.645 \n",
      "End of epoch 32 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 24, time: 0.148, data: 0.001) G_GAN: 1.168 G_L1: 10.176 D_real: 0.093 D_fake: 0.995 \n",
      "(epoch: 33, iters: 124, time: 0.148, data: 0.001) G_GAN: 0.904 G_L1: 6.803 D_real: 0.543 D_fake: 0.592 \n",
      "(epoch: 33, iters: 224, time: 0.177, data: 0.001) G_GAN: 0.755 G_L1: 7.387 D_real: 0.625 D_fake: 0.749 \n",
      "(epoch: 33, iters: 324, time: 0.148, data: 0.002) G_GAN: 0.898 G_L1: 7.787 D_real: 0.383 D_fake: 1.081 \n",
      "(epoch: 33, iters: 424, time: 0.148, data: 0.002) G_GAN: 1.277 G_L1: 6.492 D_real: 1.137 D_fake: 0.244 \n",
      "(epoch: 33, iters: 524, time: 0.148, data: 0.002) G_GAN: 1.016 G_L1: 8.388 D_real: 0.355 D_fake: 0.976 \n",
      "(epoch: 33, iters: 624, time: 0.176, data: 0.001) G_GAN: 1.211 G_L1: 7.833 D_real: 1.149 D_fake: 0.252 \n",
      "(epoch: 33, iters: 724, time: 0.148, data: 0.001) G_GAN: 0.658 G_L1: 7.060 D_real: 0.360 D_fake: 1.189 \n",
      "(epoch: 33, iters: 824, time: 0.147, data: 0.002) G_GAN: 0.671 G_L1: 7.208 D_real: 0.987 D_fake: 0.245 \n",
      "End of epoch 33 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 56, time: 0.148, data: 0.002) G_GAN: 0.823 G_L1: 8.533 D_real: 1.068 D_fake: 0.368 \n",
      "(epoch: 34, iters: 156, time: 0.186, data: 0.002) G_GAN: 0.843 G_L1: 8.594 D_real: 0.210 D_fake: 1.255 \n",
      "(epoch: 34, iters: 256, time: 0.148, data: 0.001) G_GAN: 1.024 G_L1: 6.800 D_real: 0.447 D_fake: 0.634 \n",
      "(epoch: 34, iters: 356, time: 0.148, data: 0.002) G_GAN: 0.858 G_L1: 8.557 D_real: 0.355 D_fake: 2.048 \n",
      "(epoch: 34, iters: 456, time: 0.148, data: 0.002) G_GAN: 0.831 G_L1: 5.612 D_real: 1.209 D_fake: 0.299 \n",
      "(epoch: 34, iters: 556, time: 0.175, data: 0.001) G_GAN: 0.845 G_L1: 6.480 D_real: 0.410 D_fake: 0.647 \n",
      "(epoch: 34, iters: 656, time: 0.148, data: 0.001) G_GAN: 1.014 G_L1: 7.544 D_real: 1.141 D_fake: 0.300 \n",
      "(epoch: 34, iters: 756, time: 0.147, data: 0.001) G_GAN: 0.829 G_L1: 5.104 D_real: 1.180 D_fake: 0.311 \n",
      "(epoch: 34, iters: 856, time: 0.148, data: 0.001) G_GAN: 1.123 G_L1: 7.186 D_real: 0.405 D_fake: 0.614 \n",
      "End of epoch 34 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 88, time: 0.178, data: 0.001) G_GAN: 0.987 G_L1: 7.441 D_real: 0.490 D_fake: 0.495 \n",
      "(epoch: 35, iters: 188, time: 0.149, data: 0.002) G_GAN: 0.612 G_L1: 6.003 D_real: 0.814 D_fake: 0.629 \n",
      "(epoch: 35, iters: 288, time: 0.147, data: 0.001) G_GAN: 0.921 G_L1: 8.051 D_real: 0.720 D_fake: 0.642 \n",
      "(epoch: 35, iters: 388, time: 0.148, data: 0.002) G_GAN: 1.222 G_L1: 8.308 D_real: 0.366 D_fake: 0.959 \n",
      "(epoch: 35, iters: 488, time: 0.171, data: 0.001) G_GAN: 0.603 G_L1: 5.651 D_real: 1.217 D_fake: 0.300 \n",
      "saving the latest model (epoch 35, total_iters 30000)\n",
      "(epoch: 35, iters: 588, time: 0.148, data: 0.002) G_GAN: 0.932 G_L1: 6.707 D_real: 0.399 D_fake: 0.936 \n",
      "(epoch: 35, iters: 688, time: 0.147, data: 0.002) G_GAN: 0.879 G_L1: 7.722 D_real: 1.009 D_fake: 0.275 \n",
      "(epoch: 35, iters: 788, time: 0.148, data: 0.002) G_GAN: 1.199 G_L1: 8.379 D_real: 0.327 D_fake: 0.456 \n",
      "saving the model at the end of epoch 35, iters 30380\n",
      "End of epoch 35 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 20, time: 0.179, data: 0.002) G_GAN: 0.686 G_L1: 7.149 D_real: 1.498 D_fake: 0.272 \n",
      "(epoch: 36, iters: 120, time: 0.147, data: 0.001) G_GAN: 0.766 G_L1: 7.425 D_real: 0.435 D_fake: 0.976 \n",
      "(epoch: 36, iters: 220, time: 0.148, data: 0.002) G_GAN: 1.376 G_L1: 9.517 D_real: 0.256 D_fake: 0.597 \n",
      "(epoch: 36, iters: 320, time: 0.147, data: 0.002) G_GAN: 1.142 G_L1: 7.451 D_real: 0.500 D_fake: 0.320 \n",
      "(epoch: 36, iters: 420, time: 0.175, data: 0.002) G_GAN: 0.822 G_L1: 7.482 D_real: 0.394 D_fake: 0.586 \n",
      "(epoch: 36, iters: 520, time: 0.147, data: 0.001) G_GAN: 0.797 G_L1: 7.794 D_real: 0.643 D_fake: 0.486 \n",
      "(epoch: 36, iters: 620, time: 0.147, data: 0.002) G_GAN: 0.869 G_L1: 6.749 D_real: 0.393 D_fake: 0.925 \n",
      "(epoch: 36, iters: 720, time: 0.148, data: 0.002) G_GAN: 1.003 G_L1: 7.374 D_real: 1.208 D_fake: 0.343 \n",
      "(epoch: 36, iters: 820, time: 0.179, data: 0.002) G_GAN: 0.863 G_L1: 7.235 D_real: 0.618 D_fake: 0.704 \n",
      "End of epoch 36 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 52, time: 0.147, data: 0.001) G_GAN: 0.952 G_L1: 6.323 D_real: 0.138 D_fake: 1.310 \n",
      "(epoch: 37, iters: 152, time: 0.147, data: 0.002) G_GAN: 0.925 G_L1: 7.338 D_real: 0.569 D_fake: 0.545 \n",
      "(epoch: 37, iters: 252, time: 0.147, data: 0.001) G_GAN: 0.988 G_L1: 8.177 D_real: 0.197 D_fake: 0.924 \n",
      "(epoch: 37, iters: 352, time: 0.179, data: 0.002) G_GAN: 0.865 G_L1: 8.672 D_real: 0.250 D_fake: 1.339 \n",
      "(epoch: 37, iters: 452, time: 0.147, data: 0.002) G_GAN: 0.502 G_L1: 6.606 D_real: 1.412 D_fake: 0.242 \n",
      "(epoch: 37, iters: 552, time: 0.148, data: 0.002) G_GAN: 0.936 G_L1: 8.362 D_real: 0.774 D_fake: 0.416 \n",
      "(epoch: 37, iters: 652, time: 0.147, data: 0.002) G_GAN: 0.877 G_L1: 8.712 D_real: 0.511 D_fake: 0.469 \n",
      "(epoch: 37, iters: 752, time: 0.177, data: 0.001) G_GAN: 0.791 G_L1: 7.484 D_real: 0.844 D_fake: 0.476 \n",
      "(epoch: 37, iters: 852, time: 0.147, data: 0.002) G_GAN: 0.874 G_L1: 6.893 D_real: 0.502 D_fake: 0.525 \n",
      "End of epoch 37 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 84, time: 0.148, data: 0.001) G_GAN: 1.004 G_L1: 9.113 D_real: 0.942 D_fake: 0.175 \n",
      "(epoch: 38, iters: 184, time: 0.147, data: 0.002) G_GAN: 0.807 G_L1: 6.264 D_real: 0.576 D_fake: 0.640 \n",
      "(epoch: 38, iters: 284, time: 0.182, data: 0.002) G_GAN: 0.856 G_L1: 6.884 D_real: 0.512 D_fake: 0.575 \n",
      "(epoch: 38, iters: 384, time: 0.147, data: 0.001) G_GAN: 0.997 G_L1: 9.038 D_real: 0.207 D_fake: 0.816 \n",
      "(epoch: 38, iters: 484, time: 0.148, data: 0.002) G_GAN: 0.834 G_L1: 5.892 D_real: 0.625 D_fake: 0.343 \n",
      "(epoch: 38, iters: 584, time: 0.148, data: 0.001) G_GAN: 0.906 G_L1: 6.169 D_real: 0.731 D_fake: 0.627 \n",
      "(epoch: 38, iters: 684, time: 0.177, data: 0.001) G_GAN: 0.750 G_L1: 6.831 D_real: 0.672 D_fake: 0.439 \n",
      "(epoch: 38, iters: 784, time: 0.147, data: 0.002) G_GAN: 0.938 G_L1: 6.514 D_real: 0.785 D_fake: 0.501 \n",
      "End of epoch 38 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 16, time: 0.148, data: 0.002) G_GAN: 1.171 G_L1: 9.085 D_real: 0.386 D_fake: 0.518 \n",
      "(epoch: 39, iters: 116, time: 0.147, data: 0.003) G_GAN: 1.134 G_L1: 7.491 D_real: 0.233 D_fake: 1.106 \n",
      "(epoch: 39, iters: 216, time: 0.177, data: 0.001) G_GAN: 1.060 G_L1: 6.637 D_real: 0.225 D_fake: 0.847 \n",
      "(epoch: 39, iters: 316, time: 0.147, data: 0.001) G_GAN: 0.939 G_L1: 7.436 D_real: 1.108 D_fake: 0.223 \n",
      "(epoch: 39, iters: 416, time: 0.148, data: 0.002) G_GAN: 1.146 G_L1: 7.305 D_real: 0.277 D_fake: 0.849 \n",
      "(epoch: 39, iters: 516, time: 0.147, data: 0.001) G_GAN: 1.173 G_L1: 5.376 D_real: 0.406 D_fake: 0.504 \n",
      "(epoch: 39, iters: 616, time: 0.176, data: 0.002) G_GAN: 1.116 G_L1: 6.347 D_real: 0.489 D_fake: 0.475 \n",
      "(epoch: 39, iters: 716, time: 0.148, data: 0.002) G_GAN: 0.874 G_L1: 6.420 D_real: 0.957 D_fake: 0.307 \n",
      "(epoch: 39, iters: 816, time: 0.148, data: 0.002) G_GAN: 1.201 G_L1: 8.163 D_real: 0.664 D_fake: 0.240 \n",
      "End of epoch 39 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 48, time: 0.148, data: 0.002) G_GAN: 0.968 G_L1: 7.585 D_real: 0.918 D_fake: 0.419 \n",
      "(epoch: 40, iters: 148, time: 0.179, data: 0.002) G_GAN: 0.971 G_L1: 6.052 D_real: 0.733 D_fake: 0.411 \n",
      "(epoch: 40, iters: 248, time: 0.148, data: 0.002) G_GAN: 0.800 G_L1: 6.878 D_real: 0.882 D_fake: 0.559 \n",
      "(epoch: 40, iters: 348, time: 0.148, data: 0.002) G_GAN: 1.134 G_L1: 7.559 D_real: 0.472 D_fake: 0.762 \n",
      "(epoch: 40, iters: 448, time: 0.147, data: 0.001) G_GAN: 1.655 G_L1: 7.358 D_real: 0.091 D_fake: 1.305 \n",
      "(epoch: 40, iters: 548, time: 0.178, data: 0.002) G_GAN: 0.937 G_L1: 8.136 D_real: 0.881 D_fake: 0.294 \n",
      "(epoch: 40, iters: 648, time: 0.147, data: 0.002) G_GAN: 0.756 G_L1: 7.405 D_real: 0.654 D_fake: 0.533 \n",
      "(epoch: 40, iters: 748, time: 0.148, data: 0.001) G_GAN: 1.321 G_L1: 9.973 D_real: 0.265 D_fake: 0.438 \n",
      "(epoch: 40, iters: 848, time: 0.147, data: 0.002) G_GAN: 1.416 G_L1: 8.201 D_real: 0.270 D_fake: 0.650 \n",
      "saving the model at the end of epoch 40, iters 34720\n",
      "End of epoch 40 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 80, time: 0.181, data: 0.002) G_GAN: 0.686 G_L1: 7.056 D_real: 0.922 D_fake: 0.385 \n",
      "(epoch: 41, iters: 180, time: 0.148, data: 0.002) G_GAN: 0.897 G_L1: 7.910 D_real: 0.440 D_fake: 0.979 \n",
      "(epoch: 41, iters: 280, time: 0.148, data: 0.002) G_GAN: 1.138 G_L1: 6.984 D_real: 0.276 D_fake: 1.137 \n",
      "saving the latest model (epoch 41, total_iters 35000)\n",
      "(epoch: 41, iters: 380, time: 0.147, data: 0.002) G_GAN: 0.718 G_L1: 5.848 D_real: 0.842 D_fake: 0.502 \n",
      "(epoch: 41, iters: 480, time: 0.180, data: 0.002) G_GAN: 1.123 G_L1: 8.310 D_real: 0.475 D_fake: 0.456 \n",
      "(epoch: 41, iters: 580, time: 0.148, data: 0.001) G_GAN: 0.770 G_L1: 6.406 D_real: 1.797 D_fake: 0.186 \n",
      "(epoch: 41, iters: 680, time: 0.148, data: 0.001) G_GAN: 1.241 G_L1: 9.011 D_real: 0.646 D_fake: 0.459 \n",
      "(epoch: 41, iters: 780, time: 0.148, data: 0.001) G_GAN: 0.997 G_L1: 5.667 D_real: 0.829 D_fake: 0.431 \n",
      "End of epoch 41 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 12, time: 0.181, data: 0.002) G_GAN: 0.832 G_L1: 5.900 D_real: 1.665 D_fake: 0.255 \n",
      "(epoch: 42, iters: 112, time: 0.148, data: 0.001) G_GAN: 1.018 G_L1: 4.439 D_real: 1.209 D_fake: 0.259 \n",
      "(epoch: 42, iters: 212, time: 0.148, data: 0.002) G_GAN: 0.917 G_L1: 6.105 D_real: 0.804 D_fake: 0.244 \n",
      "(epoch: 42, iters: 312, time: 0.147, data: 0.002) G_GAN: 0.888 G_L1: 7.237 D_real: 0.680 D_fake: 0.535 \n",
      "(epoch: 42, iters: 412, time: 0.180, data: 0.002) G_GAN: 0.909 G_L1: 5.970 D_real: 0.462 D_fake: 0.742 \n",
      "(epoch: 42, iters: 512, time: 0.147, data: 0.002) G_GAN: 0.946 G_L1: 7.821 D_real: 0.421 D_fake: 0.432 \n",
      "(epoch: 42, iters: 612, time: 0.147, data: 0.002) G_GAN: 0.588 G_L1: 6.443 D_real: 0.738 D_fake: 0.715 \n",
      "(epoch: 42, iters: 712, time: 0.148, data: 0.002) G_GAN: 1.166 G_L1: 7.799 D_real: 0.825 D_fake: 0.230 \n",
      "(epoch: 42, iters: 812, time: 0.181, data: 0.001) G_GAN: 0.906 G_L1: 6.708 D_real: 0.704 D_fake: 0.431 \n",
      "End of epoch 42 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 44, time: 0.147, data: 0.002) G_GAN: 0.591 G_L1: 4.876 D_real: 1.491 D_fake: 0.258 \n",
      "(epoch: 43, iters: 144, time: 0.147, data: 0.002) G_GAN: 0.942 G_L1: 7.439 D_real: 0.701 D_fake: 0.355 \n",
      "(epoch: 43, iters: 244, time: 0.147, data: 0.001) G_GAN: 1.289 G_L1: 8.091 D_real: 0.345 D_fake: 0.510 \n",
      "(epoch: 43, iters: 344, time: 0.186, data: 0.002) G_GAN: 1.076 G_L1: 5.823 D_real: 1.435 D_fake: 0.238 \n",
      "(epoch: 43, iters: 444, time: 0.147, data: 0.001) G_GAN: 1.242 G_L1: 7.296 D_real: 0.508 D_fake: 0.436 \n",
      "(epoch: 43, iters: 544, time: 0.147, data: 0.002) G_GAN: 0.960 G_L1: 7.422 D_real: 0.413 D_fake: 0.632 \n",
      "(epoch: 43, iters: 644, time: 0.147, data: 0.002) G_GAN: 0.736 G_L1: 5.259 D_real: 0.691 D_fake: 0.631 \n",
      "(epoch: 43, iters: 744, time: 0.181, data: 0.002) G_GAN: 1.047 G_L1: 7.278 D_real: 0.478 D_fake: 0.681 \n",
      "(epoch: 43, iters: 844, time: 0.148, data: 0.001) G_GAN: 0.856 G_L1: 8.092 D_real: 0.863 D_fake: 0.436 \n",
      "End of epoch 43 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 76, time: 0.147, data: 0.002) G_GAN: 1.116 G_L1: 7.696 D_real: 0.506 D_fake: 0.416 \n",
      "(epoch: 44, iters: 176, time: 0.148, data: 0.002) G_GAN: 0.812 G_L1: 9.520 D_real: 2.045 D_fake: 0.167 \n",
      "(epoch: 44, iters: 276, time: 0.179, data: 0.002) G_GAN: 0.911 G_L1: 10.059 D_real: 0.539 D_fake: 0.797 \n",
      "(epoch: 44, iters: 376, time: 0.148, data: 0.002) G_GAN: 0.576 G_L1: 7.158 D_real: 1.140 D_fake: 0.312 \n",
      "(epoch: 44, iters: 476, time: 0.148, data: 0.002) G_GAN: 1.072 G_L1: 8.290 D_real: 0.875 D_fake: 0.316 \n",
      "(epoch: 44, iters: 576, time: 0.148, data: 0.002) G_GAN: 1.139 G_L1: 6.891 D_real: 0.800 D_fake: 0.354 \n",
      "(epoch: 44, iters: 676, time: 0.180, data: 0.002) G_GAN: 1.204 G_L1: 7.315 D_real: 0.176 D_fake: 0.752 \n",
      "(epoch: 44, iters: 776, time: 0.148, data: 0.002) G_GAN: 1.089 G_L1: 8.277 D_real: 0.481 D_fake: 0.364 \n",
      "End of epoch 44 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 8, time: 0.148, data: 0.001) G_GAN: 0.939 G_L1: 8.501 D_real: 0.090 D_fake: 1.727 \n",
      "(epoch: 45, iters: 108, time: 0.148, data: 0.001) G_GAN: 1.153 G_L1: 6.528 D_real: 0.904 D_fake: 0.348 \n",
      "(epoch: 45, iters: 208, time: 0.182, data: 0.002) G_GAN: 1.078 G_L1: 7.225 D_real: 0.559 D_fake: 0.455 \n",
      "(epoch: 45, iters: 308, time: 0.148, data: 0.002) G_GAN: 1.046 G_L1: 7.962 D_real: 0.657 D_fake: 0.407 \n",
      "(epoch: 45, iters: 408, time: 0.147, data: 0.002) G_GAN: 1.203 G_L1: 6.935 D_real: 1.157 D_fake: 0.236 \n",
      "(epoch: 45, iters: 508, time: 0.148, data: 0.002) G_GAN: 0.957 G_L1: 7.792 D_real: 0.718 D_fake: 0.295 \n",
      "(epoch: 45, iters: 608, time: 0.175, data: 0.002) G_GAN: 0.833 G_L1: 6.042 D_real: 0.622 D_fake: 0.520 \n",
      "(epoch: 45, iters: 708, time: 0.147, data: 0.001) G_GAN: 1.318 G_L1: 7.332 D_real: 0.276 D_fake: 1.016 \n",
      "(epoch: 45, iters: 808, time: 0.148, data: 0.001) G_GAN: 0.904 G_L1: 10.002 D_real: 0.416 D_fake: 0.653 \n",
      "saving the model at the end of epoch 45, iters 39060\n",
      "End of epoch 45 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 40, time: 0.147, data: 0.002) G_GAN: 0.992 G_L1: 5.717 D_real: 1.228 D_fake: 0.221 \n",
      "(epoch: 46, iters: 140, time: 0.180, data: 0.001) G_GAN: 1.187 G_L1: 7.667 D_real: 0.229 D_fake: 1.325 \n",
      "(epoch: 46, iters: 240, time: 0.148, data: 0.002) G_GAN: 0.939 G_L1: 6.588 D_real: 0.764 D_fake: 0.243 \n",
      "(epoch: 46, iters: 340, time: 0.148, data: 0.002) G_GAN: 0.863 G_L1: 6.649 D_real: 0.765 D_fake: 0.717 \n",
      "(epoch: 46, iters: 440, time: 0.148, data: 0.002) G_GAN: 0.742 G_L1: 7.384 D_real: 0.380 D_fake: 0.804 \n",
      "(epoch: 46, iters: 540, time: 0.179, data: 0.002) G_GAN: 0.838 G_L1: 6.150 D_real: 1.129 D_fake: 0.382 \n",
      "(epoch: 46, iters: 640, time: 0.148, data: 0.002) G_GAN: 0.824 G_L1: 7.934 D_real: 0.345 D_fake: 1.124 \n",
      "(epoch: 46, iters: 740, time: 0.148, data: 0.002) G_GAN: 1.080 G_L1: 6.890 D_real: 1.135 D_fake: 0.307 \n",
      "(epoch: 46, iters: 840, time: 0.147, data: 0.001) G_GAN: 0.732 G_L1: 7.726 D_real: 0.109 D_fake: 2.096 \n",
      "End of epoch 46 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 72, time: 0.180, data: 0.002) G_GAN: 0.772 G_L1: 6.637 D_real: 0.846 D_fake: 0.429 \n",
      "saving the latest model (epoch 47, total_iters 40000)\n",
      "(epoch: 47, iters: 172, time: 0.148, data: 0.002) G_GAN: 0.837 G_L1: 7.332 D_real: 0.842 D_fake: 0.501 \n",
      "(epoch: 47, iters: 272, time: 0.148, data: 0.001) G_GAN: 1.403 G_L1: 7.701 D_real: 0.105 D_fake: 0.898 \n",
      "(epoch: 47, iters: 372, time: 0.148, data: 0.002) G_GAN: 0.904 G_L1: 6.576 D_real: 0.856 D_fake: 0.444 \n",
      "(epoch: 47, iters: 472, time: 0.182, data: 0.002) G_GAN: 0.782 G_L1: 6.113 D_real: 0.751 D_fake: 0.616 \n",
      "(epoch: 47, iters: 572, time: 0.148, data: 0.001) G_GAN: 0.809 G_L1: 7.534 D_real: 0.323 D_fake: 0.713 \n",
      "(epoch: 47, iters: 672, time: 0.148, data: 0.001) G_GAN: 0.893 G_L1: 7.148 D_real: 0.802 D_fake: 0.371 \n",
      "(epoch: 47, iters: 772, time: 0.148, data: 0.002) G_GAN: 0.859 G_L1: 7.913 D_real: 0.478 D_fake: 0.581 \n",
      "End of epoch 47 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 4, time: 0.154, data: 0.002) G_GAN: 0.973 G_L1: 6.811 D_real: 1.142 D_fake: 0.220 \n",
      "(epoch: 48, iters: 104, time: 0.148, data: 0.001) G_GAN: 0.974 G_L1: 7.270 D_real: 0.771 D_fake: 0.554 \n",
      "(epoch: 48, iters: 204, time: 0.148, data: 0.002) G_GAN: 1.189 G_L1: 8.605 D_real: 0.251 D_fake: 1.046 \n",
      "(epoch: 48, iters: 304, time: 0.148, data: 0.002) G_GAN: 1.044 G_L1: 7.317 D_real: 0.467 D_fake: 0.815 \n",
      "(epoch: 48, iters: 404, time: 0.185, data: 0.002) G_GAN: 0.872 G_L1: 5.206 D_real: 1.307 D_fake: 0.426 \n",
      "(epoch: 48, iters: 504, time: 0.148, data: 0.001) G_GAN: 0.792 G_L1: 7.060 D_real: 0.297 D_fake: 0.893 \n",
      "(epoch: 48, iters: 604, time: 0.148, data: 0.002) G_GAN: 0.958 G_L1: 6.459 D_real: 1.300 D_fake: 0.217 \n",
      "(epoch: 48, iters: 704, time: 0.147, data: 0.002) G_GAN: 1.256 G_L1: 7.804 D_real: 0.260 D_fake: 0.587 \n",
      "(epoch: 48, iters: 804, time: 0.184, data: 0.001) G_GAN: 0.871 G_L1: 7.052 D_real: 0.606 D_fake: 0.780 \n",
      "End of epoch 48 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 36, time: 0.148, data: 0.002) G_GAN: 1.425 G_L1: 6.271 D_real: 0.740 D_fake: 0.315 \n",
      "(epoch: 49, iters: 136, time: 0.148, data: 0.002) G_GAN: 0.936 G_L1: 7.827 D_real: 0.129 D_fake: 1.161 \n",
      "(epoch: 49, iters: 236, time: 0.148, data: 0.001) G_GAN: 0.849 G_L1: 7.151 D_real: 0.667 D_fake: 0.692 \n",
      "(epoch: 49, iters: 336, time: 0.180, data: 0.001) G_GAN: 1.167 G_L1: 6.461 D_real: 0.542 D_fake: 0.673 \n",
      "(epoch: 49, iters: 436, time: 0.148, data: 0.002) G_GAN: 0.469 G_L1: 6.815 D_real: 0.992 D_fake: 0.519 \n",
      "(epoch: 49, iters: 536, time: 0.148, data: 0.001) G_GAN: 0.921 G_L1: 8.034 D_real: 0.352 D_fake: 0.627 \n",
      "(epoch: 49, iters: 636, time: 0.148, data: 0.002) G_GAN: 0.923 G_L1: 7.111 D_real: 0.310 D_fake: 0.770 \n",
      "(epoch: 49, iters: 736, time: 0.185, data: 0.002) G_GAN: 0.695 G_L1: 7.392 D_real: 0.484 D_fake: 0.821 \n",
      "(epoch: 49, iters: 836, time: 0.148, data: 0.002) G_GAN: 1.106 G_L1: 7.686 D_real: 0.604 D_fake: 0.728 \n",
      "End of epoch 49 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 68, time: 0.148, data: 0.002) G_GAN: 1.377 G_L1: 7.737 D_real: 0.479 D_fake: 0.455 \n",
      "(epoch: 50, iters: 168, time: 0.148, data: 0.001) G_GAN: 1.019 G_L1: 8.002 D_real: 0.344 D_fake: 0.431 \n",
      "(epoch: 50, iters: 268, time: 0.182, data: 0.001) G_GAN: 1.061 G_L1: 6.195 D_real: 0.935 D_fake: 0.388 \n",
      "(epoch: 50, iters: 368, time: 0.148, data: 0.002) G_GAN: 1.027 G_L1: 8.612 D_real: 0.530 D_fake: 0.427 \n",
      "(epoch: 50, iters: 468, time: 0.148, data: 0.001) G_GAN: 1.154 G_L1: 6.669 D_real: 0.267 D_fake: 0.929 \n",
      "(epoch: 50, iters: 568, time: 0.148, data: 0.001) G_GAN: 0.861 G_L1: 6.911 D_real: 1.241 D_fake: 0.328 \n",
      "(epoch: 50, iters: 668, time: 0.193, data: 0.002) G_GAN: 0.721 G_L1: 7.477 D_real: 1.160 D_fake: 0.269 \n",
      "(epoch: 50, iters: 768, time: 0.148, data: 0.002) G_GAN: 0.886 G_L1: 10.056 D_real: 0.077 D_fake: 1.504 \n",
      "(epoch: 50, iters: 868, time: 0.148, data: 0.002) G_GAN: 1.167 G_L1: 8.218 D_real: 0.311 D_fake: 0.755 \n",
      "saving the model at the end of epoch 50, iters 43400\n",
      "End of epoch 50 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.148, data: 0.091) G_GAN: 1.185 G_L1: 7.752 D_real: 0.648 D_fake: 0.335 \n",
      "(epoch: 51, iters: 200, time: 0.181, data: 0.002) G_GAN: 1.093 G_L1: 7.594 D_real: 0.229 D_fake: 1.192 \n",
      "(epoch: 51, iters: 300, time: 0.148, data: 0.001) G_GAN: 1.102 G_L1: 6.420 D_real: 0.264 D_fake: 1.348 \n",
      "(epoch: 51, iters: 400, time: 0.147, data: 0.002) G_GAN: 0.854 G_L1: 6.537 D_real: 0.922 D_fake: 0.454 \n",
      "(epoch: 51, iters: 500, time: 0.148, data: 0.002) G_GAN: 0.800 G_L1: 8.338 D_real: 0.710 D_fake: 0.242 \n",
      "(epoch: 51, iters: 600, time: 0.183, data: 0.001) G_GAN: 0.890 G_L1: 8.242 D_real: 0.844 D_fake: 0.832 \n",
      "(epoch: 51, iters: 700, time: 0.147, data: 0.002) G_GAN: 1.065 G_L1: 6.862 D_real: 0.407 D_fake: 0.431 \n",
      "(epoch: 51, iters: 800, time: 0.147, data: 0.001) G_GAN: 0.721 G_L1: 4.983 D_real: 0.595 D_fake: 0.947 \n",
      "End of epoch 51 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 32, time: 0.148, data: 0.001) G_GAN: 1.199 G_L1: 7.058 D_real: 0.626 D_fake: 0.336 \n",
      "(epoch: 52, iters: 132, time: 0.184, data: 0.002) G_GAN: 1.047 G_L1: 6.863 D_real: 0.291 D_fake: 0.733 \n",
      "(epoch: 52, iters: 232, time: 0.148, data: 0.001) G_GAN: 1.015 G_L1: 6.845 D_real: 0.455 D_fake: 0.367 \n",
      "(epoch: 52, iters: 332, time: 0.148, data: 0.001) G_GAN: 0.877 G_L1: 4.875 D_real: 0.749 D_fake: 0.531 \n",
      "(epoch: 52, iters: 432, time: 0.148, data: 0.002) G_GAN: 1.187 G_L1: 7.197 D_real: 0.470 D_fake: 0.594 \n",
      "(epoch: 52, iters: 532, time: 0.185, data: 0.002) G_GAN: 1.194 G_L1: 8.389 D_real: 0.759 D_fake: 0.232 \n",
      "(epoch: 52, iters: 632, time: 0.148, data: 0.001) G_GAN: 0.854 G_L1: 6.206 D_real: 0.556 D_fake: 0.786 \n",
      "(epoch: 52, iters: 732, time: 0.147, data: 0.002) G_GAN: 1.222 G_L1: 8.946 D_real: 0.576 D_fake: 0.414 \n",
      "saving the latest model (epoch 52, total_iters 45000)\n",
      "(epoch: 52, iters: 832, time: 0.148, data: 0.002) G_GAN: 1.001 G_L1: 5.815 D_real: 0.572 D_fake: 0.503 \n",
      "End of epoch 52 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 64, time: 0.182, data: 0.002) G_GAN: 0.880 G_L1: 6.429 D_real: 0.982 D_fake: 0.264 \n",
      "(epoch: 53, iters: 164, time: 0.147, data: 0.001) G_GAN: 0.947 G_L1: 7.641 D_real: 1.324 D_fake: 0.358 \n",
      "(epoch: 53, iters: 264, time: 0.147, data: 0.002) G_GAN: 1.034 G_L1: 5.856 D_real: 0.869 D_fake: 0.531 \n",
      "(epoch: 53, iters: 364, time: 0.148, data: 0.002) G_GAN: 1.402 G_L1: 7.367 D_real: 0.735 D_fake: 0.240 \n",
      "(epoch: 53, iters: 464, time: 0.180, data: 0.002) G_GAN: 1.057 G_L1: 8.791 D_real: 0.172 D_fake: 0.800 \n",
      "(epoch: 53, iters: 564, time: 0.148, data: 0.002) G_GAN: 0.921 G_L1: 7.423 D_real: 0.184 D_fake: 0.824 \n",
      "(epoch: 53, iters: 664, time: 0.148, data: 0.002) G_GAN: 1.258 G_L1: 8.676 D_real: 0.321 D_fake: 0.508 \n",
      "(epoch: 53, iters: 764, time: 0.148, data: 0.001) G_GAN: 0.802 G_L1: 6.220 D_real: 0.393 D_fake: 0.942 \n",
      "(epoch: 53, iters: 864, time: 0.184, data: 0.001) G_GAN: 0.960 G_L1: 6.172 D_real: 1.319 D_fake: 0.192 \n",
      "End of epoch 53 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 96, time: 0.147, data: 0.001) G_GAN: 0.977 G_L1: 7.899 D_real: 0.919 D_fake: 0.226 \n",
      "(epoch: 54, iters: 196, time: 0.147, data: 0.002) G_GAN: 0.798 G_L1: 6.030 D_real: 0.923 D_fake: 0.507 \n",
      "(epoch: 54, iters: 296, time: 0.148, data: 0.001) G_GAN: 0.832 G_L1: 4.376 D_real: 1.331 D_fake: 0.240 \n",
      "(epoch: 54, iters: 396, time: 0.187, data: 0.002) G_GAN: 0.847 G_L1: 6.235 D_real: 1.027 D_fake: 0.239 \n",
      "(epoch: 54, iters: 496, time: 0.148, data: 0.002) G_GAN: 1.268 G_L1: 7.042 D_real: 0.443 D_fake: 0.380 \n",
      "(epoch: 54, iters: 596, time: 0.148, data: 0.002) G_GAN: 1.297 G_L1: 7.576 D_real: 0.289 D_fake: 0.834 \n",
      "(epoch: 54, iters: 696, time: 0.147, data: 0.001) G_GAN: 1.433 G_L1: 8.586 D_real: 0.193 D_fake: 0.613 \n",
      "(epoch: 54, iters: 796, time: 0.187, data: 0.002) G_GAN: 1.396 G_L1: 6.793 D_real: 0.170 D_fake: 0.803 \n",
      "End of epoch 54 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 28, time: 0.147, data: 0.002) G_GAN: 0.687 G_L1: 5.909 D_real: 0.636 D_fake: 0.502 \n",
      "(epoch: 55, iters: 128, time: 0.148, data: 0.001) G_GAN: 0.532 G_L1: 6.712 D_real: 0.711 D_fake: 0.556 \n",
      "(epoch: 55, iters: 228, time: 0.147, data: 0.002) G_GAN: 1.034 G_L1: 7.137 D_real: 0.127 D_fake: 1.459 \n",
      "(epoch: 55, iters: 328, time: 0.184, data: 0.002) G_GAN: 0.718 G_L1: 6.868 D_real: 0.896 D_fake: 0.534 \n",
      "(epoch: 55, iters: 428, time: 0.147, data: 0.001) G_GAN: 0.827 G_L1: 6.698 D_real: 0.900 D_fake: 0.258 \n",
      "(epoch: 55, iters: 528, time: 0.147, data: 0.001) G_GAN: 1.304 G_L1: 8.055 D_real: 0.289 D_fake: 1.225 \n",
      "(epoch: 55, iters: 628, time: 0.148, data: 0.002) G_GAN: 0.853 G_L1: 7.195 D_real: 0.528 D_fake: 0.566 \n",
      "(epoch: 55, iters: 728, time: 0.184, data: 0.002) G_GAN: 1.093 G_L1: 7.787 D_real: 0.266 D_fake: 0.736 \n",
      "(epoch: 55, iters: 828, time: 0.147, data: 0.002) G_GAN: 0.910 G_L1: 6.353 D_real: 0.508 D_fake: 0.523 \n",
      "saving the model at the end of epoch 55, iters 47740\n",
      "End of epoch 55 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 60, time: 0.148, data: 0.002) G_GAN: 0.834 G_L1: 7.249 D_real: 1.228 D_fake: 0.314 \n",
      "(epoch: 56, iters: 160, time: 0.148, data: 0.002) G_GAN: 0.883 G_L1: 5.804 D_real: 0.801 D_fake: 0.575 \n",
      "(epoch: 56, iters: 260, time: 0.187, data: 0.002) G_GAN: 1.474 G_L1: 8.521 D_real: 0.280 D_fake: 0.653 \n",
      "(epoch: 56, iters: 360, time: 0.148, data: 0.001) G_GAN: 0.993 G_L1: 7.605 D_real: 0.354 D_fake: 0.727 \n",
      "(epoch: 56, iters: 460, time: 0.148, data: 0.002) G_GAN: 0.677 G_L1: 7.869 D_real: 1.212 D_fake: 0.316 \n",
      "(epoch: 56, iters: 560, time: 0.147, data: 0.001) G_GAN: 0.727 G_L1: 5.525 D_real: 1.605 D_fake: 0.277 \n",
      "(epoch: 56, iters: 660, time: 0.186, data: 0.001) G_GAN: 1.057 G_L1: 7.810 D_real: 0.441 D_fake: 0.739 \n",
      "(epoch: 56, iters: 760, time: 0.147, data: 0.001) G_GAN: 0.831 G_L1: 7.415 D_real: 0.698 D_fake: 0.336 \n",
      "(epoch: 56, iters: 860, time: 0.147, data: 0.002) G_GAN: 1.145 G_L1: 6.931 D_real: 0.070 D_fake: 1.663 \n",
      "End of epoch 56 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 92, time: 0.147, data: 0.002) G_GAN: 1.223 G_L1: 7.707 D_real: 0.540 D_fake: 0.230 \n",
      "(epoch: 57, iters: 192, time: 0.195, data: 0.001) G_GAN: 0.605 G_L1: 4.599 D_real: 1.389 D_fake: 0.305 \n",
      "(epoch: 57, iters: 292, time: 0.147, data: 0.001) G_GAN: 0.789 G_L1: 4.746 D_real: 0.747 D_fake: 0.484 \n",
      "(epoch: 57, iters: 392, time: 0.148, data: 0.001) G_GAN: 0.981 G_L1: 6.620 D_real: 0.574 D_fake: 0.342 \n",
      "(epoch: 57, iters: 492, time: 0.148, data: 0.001) G_GAN: 1.004 G_L1: 5.978 D_real: 0.424 D_fake: 0.664 \n",
      "(epoch: 57, iters: 592, time: 0.181, data: 0.001) G_GAN: 1.100 G_L1: 6.410 D_real: 0.419 D_fake: 0.668 \n",
      "(epoch: 57, iters: 692, time: 0.148, data: 0.002) G_GAN: 1.146 G_L1: 6.826 D_real: 0.533 D_fake: 0.485 \n",
      "(epoch: 57, iters: 792, time: 0.148, data: 0.002) G_GAN: 0.842 G_L1: 5.545 D_real: 1.083 D_fake: 0.237 \n",
      "End of epoch 57 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 24, time: 0.148, data: 0.002) G_GAN: 1.141 G_L1: 6.662 D_real: 0.241 D_fake: 0.899 \n",
      "(epoch: 58, iters: 124, time: 0.179, data: 0.001) G_GAN: 0.851 G_L1: 5.328 D_real: 1.515 D_fake: 0.255 \n",
      "(epoch: 58, iters: 224, time: 0.148, data: 0.002) G_GAN: 1.087 G_L1: 5.852 D_real: 0.682 D_fake: 0.284 \n",
      "(epoch: 58, iters: 324, time: 0.148, data: 0.002) G_GAN: 1.125 G_L1: 8.628 D_real: 0.646 D_fake: 0.426 \n",
      "(epoch: 58, iters: 424, time: 0.148, data: 0.002) G_GAN: 0.692 G_L1: 6.405 D_real: 0.575 D_fake: 0.644 \n",
      "(epoch: 58, iters: 524, time: 0.183, data: 0.002) G_GAN: 1.017 G_L1: 5.849 D_real: 0.883 D_fake: 0.342 \n",
      "saving the latest model (epoch 58, total_iters 50000)\n",
      "(epoch: 58, iters: 624, time: 0.148, data: 0.003) G_GAN: 0.936 G_L1: 7.081 D_real: 0.712 D_fake: 0.368 \n",
      "(epoch: 58, iters: 724, time: 0.147, data: 0.002) G_GAN: 0.466 G_L1: 7.260 D_real: 0.938 D_fake: 0.419 \n",
      "(epoch: 58, iters: 824, time: 0.148, data: 0.002) G_GAN: 1.305 G_L1: 7.930 D_real: 0.288 D_fake: 0.919 \n",
      "End of epoch 58 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 56, time: 0.187, data: 0.002) G_GAN: 0.934 G_L1: 6.832 D_real: 0.272 D_fake: 0.830 \n",
      "(epoch: 59, iters: 156, time: 0.148, data: 0.002) G_GAN: 0.680 G_L1: 5.865 D_real: 0.971 D_fake: 0.344 \n",
      "(epoch: 59, iters: 256, time: 0.148, data: 0.002) G_GAN: 0.685 G_L1: 6.167 D_real: 0.568 D_fake: 0.546 \n",
      "(epoch: 59, iters: 356, time: 0.148, data: 0.002) G_GAN: 1.580 G_L1: 7.832 D_real: 0.742 D_fake: 0.162 \n",
      "(epoch: 59, iters: 456, time: 0.188, data: 0.002) G_GAN: 0.899 G_L1: 7.027 D_real: 0.554 D_fake: 0.734 \n",
      "(epoch: 59, iters: 556, time: 0.148, data: 0.002) G_GAN: 0.904 G_L1: 5.331 D_real: 1.108 D_fake: 0.257 \n",
      "(epoch: 59, iters: 656, time: 0.148, data: 0.002) G_GAN: 0.730 G_L1: 6.849 D_real: 0.285 D_fake: 1.431 \n",
      "(epoch: 59, iters: 756, time: 0.148, data: 0.001) G_GAN: 0.781 G_L1: 5.986 D_real: 0.558 D_fake: 0.707 \n",
      "(epoch: 59, iters: 856, time: 0.185, data: 0.002) G_GAN: 0.873 G_L1: 6.561 D_real: 0.511 D_fake: 0.502 \n",
      "End of epoch 59 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 88, time: 0.148, data: 0.001) G_GAN: 1.076 G_L1: 7.042 D_real: 0.391 D_fake: 0.699 \n",
      "(epoch: 60, iters: 188, time: 0.148, data: 0.001) G_GAN: 1.235 G_L1: 6.546 D_real: 0.533 D_fake: 0.433 \n",
      "(epoch: 60, iters: 288, time: 0.148, data: 0.001) G_GAN: 0.762 G_L1: 7.624 D_real: 0.499 D_fake: 0.722 \n",
      "(epoch: 60, iters: 388, time: 0.191, data: 0.001) G_GAN: 0.763 G_L1: 8.222 D_real: 0.684 D_fake: 0.480 \n",
      "(epoch: 60, iters: 488, time: 0.147, data: 0.002) G_GAN: 0.948 G_L1: 6.476 D_real: 0.178 D_fake: 1.308 \n",
      "(epoch: 60, iters: 588, time: 0.147, data: 0.002) G_GAN: 0.671 G_L1: 6.721 D_real: 0.753 D_fake: 0.513 \n",
      "(epoch: 60, iters: 688, time: 0.146, data: 0.001) G_GAN: 0.514 G_L1: 8.300 D_real: 1.235 D_fake: 0.576 \n",
      "(epoch: 60, iters: 788, time: 0.185, data: 0.001) G_GAN: 1.400 G_L1: 7.920 D_real: 0.466 D_fake: 0.447 \n",
      "saving the model at the end of epoch 60, iters 52080\n",
      "End of epoch 60 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 20, time: 0.147, data: 0.002) G_GAN: 1.331 G_L1: 10.279 D_real: 0.168 D_fake: 0.733 \n",
      "(epoch: 61, iters: 120, time: 0.147, data: 0.003) G_GAN: 0.831 G_L1: 6.099 D_real: 0.582 D_fake: 0.937 \n",
      "(epoch: 61, iters: 220, time: 0.148, data: 0.001) G_GAN: 0.715 G_L1: 6.299 D_real: 0.629 D_fake: 0.741 \n",
      "(epoch: 61, iters: 320, time: 0.189, data: 0.002) G_GAN: 0.854 G_L1: 6.002 D_real: 0.620 D_fake: 0.475 \n",
      "(epoch: 61, iters: 420, time: 0.147, data: 0.001) G_GAN: 0.991 G_L1: 7.547 D_real: 0.202 D_fake: 0.779 \n",
      "(epoch: 61, iters: 520, time: 0.148, data: 0.002) G_GAN: 0.899 G_L1: 6.855 D_real: 0.317 D_fake: 1.228 \n",
      "(epoch: 61, iters: 620, time: 0.148, data: 0.002) G_GAN: 0.819 G_L1: 6.566 D_real: 0.470 D_fake: 0.940 \n",
      "(epoch: 61, iters: 720, time: 0.186, data: 0.001) G_GAN: 0.550 G_L1: 7.653 D_real: 1.228 D_fake: 0.772 \n",
      "(epoch: 61, iters: 820, time: 0.147, data: 0.002) G_GAN: 1.049 G_L1: 7.363 D_real: 0.522 D_fake: 0.494 \n",
      "End of epoch 61 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 52, time: 0.147, data: 0.002) G_GAN: 0.884 G_L1: 6.700 D_real: 1.136 D_fake: 0.344 \n",
      "(epoch: 62, iters: 152, time: 0.148, data: 0.001) G_GAN: 1.403 G_L1: 8.539 D_real: 0.362 D_fake: 0.418 \n",
      "(epoch: 62, iters: 252, time: 0.187, data: 0.001) G_GAN: 0.777 G_L1: 7.184 D_real: 0.548 D_fake: 0.452 \n",
      "(epoch: 62, iters: 352, time: 0.147, data: 0.002) G_GAN: 1.397 G_L1: 6.247 D_real: 1.402 D_fake: 0.129 \n",
      "(epoch: 62, iters: 452, time: 0.148, data: 0.002) G_GAN: 0.696 G_L1: 6.870 D_real: 0.658 D_fake: 0.515 \n",
      "(epoch: 62, iters: 552, time: 0.148, data: 0.002) G_GAN: 0.897 G_L1: 6.495 D_real: 0.761 D_fake: 0.484 \n",
      "(epoch: 62, iters: 652, time: 0.193, data: 0.001) G_GAN: 0.663 G_L1: 7.026 D_real: 1.490 D_fake: 0.300 \n",
      "(epoch: 62, iters: 752, time: 0.148, data: 0.002) G_GAN: 1.124 G_L1: 7.229 D_real: 0.154 D_fake: 1.815 \n",
      "(epoch: 62, iters: 852, time: 0.147, data: 0.001) G_GAN: 1.187 G_L1: 6.029 D_real: 0.305 D_fake: 0.676 \n",
      "End of epoch 62 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 84, time: 0.147, data: 0.002) G_GAN: 1.156 G_L1: 6.174 D_real: 0.354 D_fake: 0.622 \n",
      "(epoch: 63, iters: 184, time: 0.186, data: 0.001) G_GAN: 0.836 G_L1: 6.777 D_real: 0.464 D_fake: 0.650 \n",
      "(epoch: 63, iters: 284, time: 0.147, data: 0.002) G_GAN: 1.017 G_L1: 6.014 D_real: 1.410 D_fake: 0.275 \n",
      "(epoch: 63, iters: 384, time: 0.147, data: 0.002) G_GAN: 0.514 G_L1: 6.058 D_real: 0.994 D_fake: 0.663 \n",
      "(epoch: 63, iters: 484, time: 0.147, data: 0.001) G_GAN: 0.846 G_L1: 7.221 D_real: 0.195 D_fake: 1.130 \n",
      "(epoch: 63, iters: 584, time: 0.188, data: 0.002) G_GAN: 0.901 G_L1: 5.902 D_real: 0.778 D_fake: 0.376 \n",
      "(epoch: 63, iters: 684, time: 0.147, data: 0.001) G_GAN: 0.744 G_L1: 6.914 D_real: 0.843 D_fake: 0.491 \n",
      "(epoch: 63, iters: 784, time: 0.147, data: 0.002) G_GAN: 1.083 G_L1: 7.576 D_real: 0.244 D_fake: 1.143 \n",
      "End of epoch 63 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 16, time: 0.148, data: 0.002) G_GAN: 1.231 G_L1: 6.614 D_real: 0.330 D_fake: 0.757 \n",
      "(epoch: 64, iters: 116, time: 0.189, data: 0.001) G_GAN: 0.692 G_L1: 6.114 D_real: 0.537 D_fake: 0.988 \n",
      "(epoch: 64, iters: 216, time: 0.148, data: 0.001) G_GAN: 1.350 G_L1: 10.251 D_real: 0.159 D_fake: 0.879 \n",
      "(epoch: 64, iters: 316, time: 0.148, data: 0.002) G_GAN: 1.088 G_L1: 7.687 D_real: 0.260 D_fake: 0.884 \n",
      "saving the latest model (epoch 64, total_iters 55000)\n",
      "(epoch: 64, iters: 416, time: 0.147, data: 0.001) G_GAN: 1.018 G_L1: 4.700 D_real: 0.746 D_fake: 0.256 \n",
      "(epoch: 64, iters: 516, time: 0.186, data: 0.002) G_GAN: 0.929 G_L1: 5.583 D_real: 0.606 D_fake: 0.646 \n",
      "(epoch: 64, iters: 616, time: 0.147, data: 0.002) G_GAN: 1.343 G_L1: 6.982 D_real: 1.167 D_fake: 0.187 \n",
      "(epoch: 64, iters: 716, time: 0.147, data: 0.002) G_GAN: 1.000 G_L1: 6.435 D_real: 1.269 D_fake: 0.302 \n",
      "(epoch: 64, iters: 816, time: 0.147, data: 0.002) G_GAN: 0.916 G_L1: 7.021 D_real: 0.721 D_fake: 0.319 \n",
      "End of epoch 64 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 48, time: 0.190, data: 0.002) G_GAN: 1.352 G_L1: 7.699 D_real: 0.827 D_fake: 0.268 \n",
      "(epoch: 65, iters: 148, time: 0.147, data: 0.002) G_GAN: 1.136 G_L1: 6.726 D_real: 0.248 D_fake: 0.791 \n",
      "(epoch: 65, iters: 248, time: 0.147, data: 0.002) G_GAN: 1.017 G_L1: 6.709 D_real: 0.976 D_fake: 0.251 \n",
      "(epoch: 65, iters: 348, time: 0.147, data: 0.002) G_GAN: 0.970 G_L1: 7.663 D_real: 0.944 D_fake: 0.419 \n",
      "(epoch: 65, iters: 448, time: 0.187, data: 0.002) G_GAN: 0.888 G_L1: 7.658 D_real: 0.324 D_fake: 1.009 \n",
      "(epoch: 65, iters: 548, time: 0.147, data: 0.001) G_GAN: 1.228 G_L1: 6.813 D_real: 0.485 D_fake: 0.784 \n",
      "(epoch: 65, iters: 648, time: 0.147, data: 0.001) G_GAN: 1.007 G_L1: 6.789 D_real: 1.447 D_fake: 0.098 \n",
      "(epoch: 65, iters: 748, time: 0.147, data: 0.002) G_GAN: 0.644 G_L1: 6.579 D_real: 0.568 D_fake: 0.732 \n",
      "(epoch: 65, iters: 848, time: 0.190, data: 0.002) G_GAN: 0.926 G_L1: 7.066 D_real: 0.380 D_fake: 0.735 \n",
      "saving the model at the end of epoch 65, iters 56420\n",
      "End of epoch 65 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 80, time: 0.147, data: 0.001) G_GAN: 0.726 G_L1: 6.953 D_real: 0.566 D_fake: 0.671 \n",
      "(epoch: 66, iters: 180, time: 0.147, data: 0.002) G_GAN: 0.583 G_L1: 6.424 D_real: 0.531 D_fake: 0.638 \n",
      "(epoch: 66, iters: 280, time: 0.147, data: 0.002) G_GAN: 0.872 G_L1: 7.162 D_real: 0.532 D_fake: 0.967 \n",
      "(epoch: 66, iters: 380, time: 0.187, data: 0.001) G_GAN: 1.074 G_L1: 5.188 D_real: 1.155 D_fake: 0.258 \n",
      "(epoch: 66, iters: 480, time: 0.147, data: 0.002) G_GAN: 0.711 G_L1: 7.110 D_real: 0.793 D_fake: 0.309 \n",
      "(epoch: 66, iters: 580, time: 0.147, data: 0.002) G_GAN: 0.954 G_L1: 6.397 D_real: 0.376 D_fake: 0.537 \n",
      "(epoch: 66, iters: 680, time: 0.147, data: 0.002) G_GAN: 0.889 G_L1: 5.792 D_real: 0.889 D_fake: 0.460 \n",
      "(epoch: 66, iters: 780, time: 0.184, data: 0.002) G_GAN: 1.203 G_L1: 5.727 D_real: 1.273 D_fake: 0.185 \n",
      "End of epoch 66 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 12, time: 0.147, data: 0.001) G_GAN: 1.451 G_L1: 7.633 D_real: 0.356 D_fake: 0.376 \n",
      "(epoch: 67, iters: 112, time: 0.148, data: 0.001) G_GAN: 1.029 G_L1: 6.795 D_real: 0.641 D_fake: 0.473 \n",
      "(epoch: 67, iters: 212, time: 0.147, data: 0.002) G_GAN: 1.128 G_L1: 6.988 D_real: 1.059 D_fake: 0.292 \n",
      "(epoch: 67, iters: 312, time: 0.188, data: 0.002) G_GAN: 1.003 G_L1: 5.094 D_real: 0.598 D_fake: 0.498 \n",
      "(epoch: 67, iters: 412, time: 0.147, data: 0.001) G_GAN: 1.264 G_L1: 7.950 D_real: 0.217 D_fake: 0.568 \n",
      "(epoch: 67, iters: 512, time: 0.147, data: 0.001) G_GAN: 0.591 G_L1: 5.304 D_real: 1.284 D_fake: 0.400 \n",
      "(epoch: 67, iters: 612, time: 0.148, data: 0.002) G_GAN: 1.090 G_L1: 6.126 D_real: 0.655 D_fake: 0.370 \n",
      "(epoch: 67, iters: 712, time: 0.200, data: 0.001) G_GAN: 1.498 G_L1: 9.119 D_real: 0.274 D_fake: 0.371 \n",
      "(epoch: 67, iters: 812, time: 0.148, data: 0.002) G_GAN: 1.089 G_L1: 6.637 D_real: 0.464 D_fake: 0.478 \n",
      "End of epoch 67 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 44, time: 0.148, data: 0.002) G_GAN: 0.760 G_L1: 6.063 D_real: 0.415 D_fake: 0.692 \n",
      "(epoch: 68, iters: 144, time: 0.148, data: 0.002) G_GAN: 0.740 G_L1: 5.381 D_real: 0.799 D_fake: 0.631 \n",
      "(epoch: 68, iters: 244, time: 0.192, data: 0.002) G_GAN: 0.854 G_L1: 6.384 D_real: 0.582 D_fake: 0.694 \n",
      "(epoch: 68, iters: 344, time: 0.147, data: 0.001) G_GAN: 0.816 G_L1: 6.545 D_real: 0.806 D_fake: 0.438 \n",
      "(epoch: 68, iters: 444, time: 0.147, data: 0.001) G_GAN: 1.410 G_L1: 8.337 D_real: 0.208 D_fake: 0.448 \n",
      "(epoch: 68, iters: 544, time: 0.147, data: 0.002) G_GAN: 0.838 G_L1: 6.650 D_real: 0.239 D_fake: 1.000 \n",
      "(epoch: 68, iters: 644, time: 0.188, data: 0.001) G_GAN: 1.254 G_L1: 8.036 D_real: 0.188 D_fake: 0.951 \n",
      "(epoch: 68, iters: 744, time: 0.147, data: 0.002) G_GAN: 1.020 G_L1: 7.872 D_real: 0.273 D_fake: 1.028 \n",
      "(epoch: 68, iters: 844, time: 0.147, data: 0.002) G_GAN: 1.501 G_L1: 8.105 D_real: 0.436 D_fake: 0.379 \n",
      "End of epoch 68 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 76, time: 0.147, data: 0.002) G_GAN: 1.028 G_L1: 5.872 D_real: 0.557 D_fake: 0.487 \n",
      "(epoch: 69, iters: 176, time: 0.190, data: 0.002) G_GAN: 1.260 G_L1: 7.799 D_real: 0.970 D_fake: 0.289 \n",
      "(epoch: 69, iters: 276, time: 0.148, data: 0.001) G_GAN: 1.026 G_L1: 7.097 D_real: 0.236 D_fake: 1.125 \n",
      "(epoch: 69, iters: 376, time: 0.147, data: 0.002) G_GAN: 1.102 G_L1: 7.450 D_real: 0.656 D_fake: 0.539 \n",
      "(epoch: 69, iters: 476, time: 0.147, data: 0.001) G_GAN: 1.153 G_L1: 5.976 D_real: 0.473 D_fake: 0.780 \n",
      "(epoch: 69, iters: 576, time: 0.187, data: 0.002) G_GAN: 1.180 G_L1: 7.834 D_real: 0.313 D_fake: 0.350 \n",
      "(epoch: 69, iters: 676, time: 0.147, data: 0.001) G_GAN: 1.149 G_L1: 6.047 D_real: 0.227 D_fake: 0.603 \n",
      "(epoch: 69, iters: 776, time: 0.147, data: 0.002) G_GAN: 1.396 G_L1: 6.046 D_real: 0.822 D_fake: 0.190 \n",
      "End of epoch 69 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 8, time: 0.147, data: 0.001) G_GAN: 1.122 G_L1: 9.189 D_real: 0.236 D_fake: 0.697 \n",
      "(epoch: 70, iters: 108, time: 0.190, data: 0.001) G_GAN: 1.284 G_L1: 8.148 D_real: 0.238 D_fake: 0.934 \n",
      "saving the latest model (epoch 70, total_iters 60000)\n",
      "(epoch: 70, iters: 208, time: 0.147, data: 0.001) G_GAN: 1.051 G_L1: 6.756 D_real: 0.371 D_fake: 0.927 \n",
      "(epoch: 70, iters: 308, time: 0.147, data: 0.002) G_GAN: 1.055 G_L1: 6.439 D_real: 0.303 D_fake: 0.697 \n",
      "(epoch: 70, iters: 408, time: 0.147, data: 0.002) G_GAN: 0.990 G_L1: 6.973 D_real: 0.533 D_fake: 0.384 \n",
      "(epoch: 70, iters: 508, time: 0.190, data: 0.002) G_GAN: 1.386 G_L1: 6.294 D_real: 0.267 D_fake: 1.152 \n",
      "(epoch: 70, iters: 608, time: 0.147, data: 0.001) G_GAN: 1.208 G_L1: 6.574 D_real: 0.178 D_fake: 0.752 \n",
      "(epoch: 70, iters: 708, time: 0.147, data: 0.001) G_GAN: 1.323 G_L1: 6.731 D_real: 2.564 D_fake: 0.087 \n",
      "(epoch: 70, iters: 808, time: 0.147, data: 0.002) G_GAN: 1.196 G_L1: 6.812 D_real: 0.613 D_fake: 0.661 \n",
      "saving the model at the end of epoch 70, iters 60760\n",
      "End of epoch 70 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 40, time: 0.190, data: 0.002) G_GAN: 1.289 G_L1: 7.215 D_real: 0.504 D_fake: 0.347 \n",
      "(epoch: 71, iters: 140, time: 0.147, data: 0.002) G_GAN: 0.650 G_L1: 5.694 D_real: 0.848 D_fake: 0.698 \n",
      "(epoch: 71, iters: 240, time: 0.147, data: 0.001) G_GAN: 1.383 G_L1: 7.489 D_real: 0.170 D_fake: 0.716 \n",
      "(epoch: 71, iters: 340, time: 0.148, data: 0.001) G_GAN: 1.143 G_L1: 6.172 D_real: 1.748 D_fake: 0.159 \n",
      "(epoch: 71, iters: 440, time: 0.188, data: 0.002) G_GAN: 0.968 G_L1: 6.232 D_real: 0.904 D_fake: 0.316 \n",
      "(epoch: 71, iters: 540, time: 0.147, data: 0.002) G_GAN: 0.688 G_L1: 6.493 D_real: 0.536 D_fake: 0.859 \n",
      "(epoch: 71, iters: 640, time: 0.148, data: 0.002) G_GAN: 1.183 G_L1: 9.765 D_real: 0.444 D_fake: 0.478 \n",
      "(epoch: 71, iters: 740, time: 0.147, data: 0.002) G_GAN: 0.954 G_L1: 6.177 D_real: 0.491 D_fake: 0.475 \n",
      "(epoch: 71, iters: 840, time: 0.190, data: 0.001) G_GAN: 1.043 G_L1: 6.327 D_real: 0.330 D_fake: 1.119 \n",
      "End of epoch 71 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 72, time: 0.148, data: 0.001) G_GAN: 1.206 G_L1: 6.144 D_real: 0.749 D_fake: 0.397 \n",
      "(epoch: 72, iters: 172, time: 0.147, data: 0.002) G_GAN: 1.081 G_L1: 5.082 D_real: 0.569 D_fake: 0.580 \n",
      "(epoch: 72, iters: 272, time: 0.148, data: 0.002) G_GAN: 1.163 G_L1: 7.462 D_real: 0.297 D_fake: 0.581 \n",
      "(epoch: 72, iters: 372, time: 0.192, data: 0.001) G_GAN: 0.891 G_L1: 6.643 D_real: 0.514 D_fake: 0.428 \n",
      "(epoch: 72, iters: 472, time: 0.147, data: 0.001) G_GAN: 1.005 G_L1: 6.650 D_real: 0.359 D_fake: 0.595 \n",
      "(epoch: 72, iters: 572, time: 0.146, data: 0.002) G_GAN: 1.601 G_L1: 7.248 D_real: 1.012 D_fake: 0.129 \n",
      "(epoch: 72, iters: 672, time: 0.146, data: 0.002) G_GAN: 1.114 G_L1: 7.781 D_real: 0.170 D_fake: 1.097 \n",
      "(epoch: 72, iters: 772, time: 0.205, data: 0.001) G_GAN: 1.249 G_L1: 5.840 D_real: 1.587 D_fake: 0.180 \n",
      "End of epoch 72 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 4, time: 0.117, data: 0.001) G_GAN: 1.003 G_L1: 6.833 D_real: 0.723 D_fake: 0.310 \n",
      "(epoch: 73, iters: 104, time: 0.147, data: 0.003) G_GAN: 0.845 G_L1: 5.520 D_real: 0.368 D_fake: 0.847 \n",
      "(epoch: 73, iters: 204, time: 0.147, data: 0.002) G_GAN: 0.819 G_L1: 6.022 D_real: 0.422 D_fake: 0.865 \n",
      "(epoch: 73, iters: 304, time: 0.189, data: 0.002) G_GAN: 1.062 G_L1: 6.614 D_real: 0.563 D_fake: 0.616 \n",
      "(epoch: 73, iters: 404, time: 0.147, data: 0.001) G_GAN: 0.962 G_L1: 5.628 D_real: 1.209 D_fake: 0.213 \n",
      "(epoch: 73, iters: 504, time: 0.147, data: 0.002) G_GAN: 1.027 G_L1: 6.455 D_real: 1.221 D_fake: 0.207 \n",
      "(epoch: 73, iters: 604, time: 0.147, data: 0.001) G_GAN: 1.552 G_L1: 8.366 D_real: 0.103 D_fake: 0.942 \n",
      "(epoch: 73, iters: 704, time: 0.192, data: 0.002) G_GAN: 0.938 G_L1: 7.045 D_real: 0.251 D_fake: 1.101 \n",
      "(epoch: 73, iters: 804, time: 0.148, data: 0.002) G_GAN: 1.130 G_L1: 7.769 D_real: 0.153 D_fake: 1.109 \n",
      "End of epoch 73 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 36, time: 0.147, data: 0.001) G_GAN: 0.923 G_L1: 6.228 D_real: 0.835 D_fake: 0.755 \n",
      "(epoch: 74, iters: 136, time: 0.148, data: 0.002) G_GAN: 0.945 G_L1: 6.255 D_real: 1.031 D_fake: 0.316 \n",
      "(epoch: 74, iters: 236, time: 0.193, data: 0.002) G_GAN: 1.016 G_L1: 7.120 D_real: 0.444 D_fake: 0.906 \n",
      "(epoch: 74, iters: 336, time: 0.148, data: 0.002) G_GAN: 1.639 G_L1: 8.794 D_real: 0.065 D_fake: 0.950 \n",
      "(epoch: 74, iters: 436, time: 0.147, data: 0.002) G_GAN: 1.132 G_L1: 6.085 D_real: 0.727 D_fake: 0.487 \n",
      "(epoch: 74, iters: 536, time: 0.148, data: 0.002) G_GAN: 1.076 G_L1: 7.027 D_real: 0.567 D_fake: 0.560 \n",
      "(epoch: 74, iters: 636, time: 0.192, data: 0.002) G_GAN: 1.082 G_L1: 6.163 D_real: 0.796 D_fake: 0.282 \n",
      "(epoch: 74, iters: 736, time: 0.148, data: 0.001) G_GAN: 1.462 G_L1: 7.182 D_real: 0.201 D_fake: 0.351 \n",
      "(epoch: 74, iters: 836, time: 0.148, data: 0.002) G_GAN: 0.953 G_L1: 7.294 D_real: 0.225 D_fake: 1.283 \n",
      "End of epoch 74 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 68, time: 0.148, data: 0.002) G_GAN: 1.157 G_L1: 5.064 D_real: 0.826 D_fake: 0.170 \n",
      "(epoch: 75, iters: 168, time: 0.194, data: 0.002) G_GAN: 0.698 G_L1: 6.071 D_real: 1.203 D_fake: 0.275 \n",
      "(epoch: 75, iters: 268, time: 0.148, data: 0.001) G_GAN: 0.833 G_L1: 7.009 D_real: 0.373 D_fake: 0.929 \n",
      "(epoch: 75, iters: 368, time: 0.148, data: 0.002) G_GAN: 1.132 G_L1: 8.021 D_real: 0.185 D_fake: 1.078 \n",
      "(epoch: 75, iters: 468, time: 0.147, data: 0.002) G_GAN: 1.214 G_L1: 7.969 D_real: 0.779 D_fake: 0.307 \n",
      "(epoch: 75, iters: 568, time: 0.188, data: 0.002) G_GAN: 0.895 G_L1: 4.813 D_real: 0.756 D_fake: 0.326 \n",
      "(epoch: 75, iters: 668, time: 0.147, data: 0.002) G_GAN: 0.868 G_L1: 5.720 D_real: 0.634 D_fake: 0.459 \n",
      "(epoch: 75, iters: 768, time: 0.148, data: 0.002) G_GAN: 1.155 G_L1: 9.322 D_real: 0.154 D_fake: 0.534 \n",
      "saving the latest model (epoch 75, total_iters 65000)\n",
      "(epoch: 75, iters: 868, time: 0.148, data: 0.002) G_GAN: 1.308 G_L1: 7.409 D_real: 0.486 D_fake: 0.583 \n",
      "saving the model at the end of epoch 75, iters 65100\n",
      "End of epoch 75 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 100, time: 0.191, data: 0.091) G_GAN: 1.085 G_L1: 5.346 D_real: 0.507 D_fake: 0.597 \n",
      "(epoch: 76, iters: 200, time: 0.148, data: 0.002) G_GAN: 1.474 G_L1: 5.562 D_real: 1.031 D_fake: 0.215 \n",
      "(epoch: 76, iters: 300, time: 0.148, data: 0.002) G_GAN: 0.576 G_L1: 4.072 D_real: 0.798 D_fake: 0.459 \n",
      "(epoch: 76, iters: 400, time: 0.148, data: 0.002) G_GAN: 0.583 G_L1: 6.699 D_real: 1.054 D_fake: 0.510 \n",
      "(epoch: 76, iters: 500, time: 0.193, data: 0.001) G_GAN: 0.732 G_L1: 9.002 D_real: 0.770 D_fake: 0.663 \n",
      "(epoch: 76, iters: 600, time: 0.148, data: 0.001) G_GAN: 1.076 G_L1: 7.272 D_real: 0.236 D_fake: 1.044 \n",
      "(epoch: 76, iters: 700, time: 0.147, data: 0.002) G_GAN: 0.613 G_L1: 4.051 D_real: 1.142 D_fake: 0.287 \n",
      "(epoch: 76, iters: 800, time: 0.147, data: 0.002) G_GAN: 1.025 G_L1: 4.272 D_real: 0.362 D_fake: 1.025 \n",
      "End of epoch 76 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 32, time: 0.195, data: 0.001) G_GAN: 2.112 G_L1: 8.211 D_real: 0.314 D_fake: 0.276 \n",
      "(epoch: 77, iters: 132, time: 0.147, data: 0.001) G_GAN: 1.428 G_L1: 7.202 D_real: 0.149 D_fake: 0.963 \n",
      "(epoch: 77, iters: 232, time: 0.147, data: 0.001) G_GAN: 0.897 G_L1: 5.983 D_real: 0.963 D_fake: 0.416 \n",
      "(epoch: 77, iters: 332, time: 0.147, data: 0.002) G_GAN: 0.921 G_L1: 6.384 D_real: 0.272 D_fake: 0.972 \n",
      "(epoch: 77, iters: 432, time: 0.202, data: 0.002) G_GAN: 1.154 G_L1: 7.528 D_real: 0.962 D_fake: 0.168 \n",
      "(epoch: 77, iters: 532, time: 0.148, data: 0.002) G_GAN: 0.808 G_L1: 7.089 D_real: 0.770 D_fake: 0.525 \n",
      "(epoch: 77, iters: 632, time: 0.147, data: 0.002) G_GAN: 1.154 G_L1: 6.341 D_real: 0.187 D_fake: 0.876 \n",
      "(epoch: 77, iters: 732, time: 0.147, data: 0.002) G_GAN: 1.377 G_L1: 7.973 D_real: 0.451 D_fake: 0.364 \n",
      "(epoch: 77, iters: 832, time: 0.192, data: 0.001) G_GAN: 1.437 G_L1: 7.418 D_real: 0.928 D_fake: 0.190 \n",
      "End of epoch 77 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 64, time: 0.147, data: 0.001) G_GAN: 1.323 G_L1: 6.335 D_real: 1.368 D_fake: 0.129 \n",
      "(epoch: 78, iters: 164, time: 0.147, data: 0.001) G_GAN: 0.870 G_L1: 6.097 D_real: 0.698 D_fake: 0.441 \n",
      "(epoch: 78, iters: 264, time: 0.147, data: 0.002) G_GAN: 0.626 G_L1: 5.781 D_real: 0.653 D_fake: 0.696 \n",
      "(epoch: 78, iters: 364, time: 0.195, data: 0.001) G_GAN: 1.445 G_L1: 8.584 D_real: 0.344 D_fake: 0.434 \n",
      "(epoch: 78, iters: 464, time: 0.147, data: 0.002) G_GAN: 1.590 G_L1: 6.357 D_real: 0.215 D_fake: 1.285 \n",
      "(epoch: 78, iters: 564, time: 0.147, data: 0.002) G_GAN: 1.077 G_L1: 5.420 D_real: 0.614 D_fake: 0.505 \n",
      "(epoch: 78, iters: 664, time: 0.147, data: 0.002) G_GAN: 1.157 G_L1: 6.899 D_real: 0.390 D_fake: 0.638 \n",
      "(epoch: 78, iters: 764, time: 0.196, data: 0.002) G_GAN: 0.869 G_L1: 7.333 D_real: 1.097 D_fake: 0.379 \n",
      "(epoch: 78, iters: 864, time: 0.147, data: 0.002) G_GAN: 1.281 G_L1: 4.940 D_real: 0.427 D_fake: 0.540 \n",
      "End of epoch 78 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 96, time: 0.147, data: 0.002) G_GAN: 2.119 G_L1: 8.597 D_real: 0.094 D_fake: 1.028 \n",
      "(epoch: 79, iters: 196, time: 0.147, data: 0.002) G_GAN: 1.007 G_L1: 6.812 D_real: 0.633 D_fake: 0.291 \n",
      "(epoch: 79, iters: 296, time: 0.195, data: 0.001) G_GAN: 1.022 G_L1: 5.782 D_real: 0.644 D_fake: 0.716 \n",
      "(epoch: 79, iters: 396, time: 0.148, data: 0.002) G_GAN: 0.841 G_L1: 5.999 D_real: 0.607 D_fake: 0.495 \n",
      "(epoch: 79, iters: 496, time: 0.148, data: 0.002) G_GAN: 0.756 G_L1: 5.769 D_real: 0.743 D_fake: 0.420 \n",
      "(epoch: 79, iters: 596, time: 0.148, data: 0.001) G_GAN: 1.296 G_L1: 8.165 D_real: 0.707 D_fake: 0.466 \n",
      "(epoch: 79, iters: 696, time: 0.199, data: 0.002) G_GAN: 0.767 G_L1: 6.802 D_real: 1.020 D_fake: 0.285 \n",
      "(epoch: 79, iters: 796, time: 0.147, data: 0.002) G_GAN: 0.927 G_L1: 6.072 D_real: 0.580 D_fake: 0.472 \n",
      "End of epoch 79 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 28, time: 0.148, data: 0.002) G_GAN: 1.017 G_L1: 6.038 D_real: 0.417 D_fake: 1.074 \n",
      "(epoch: 80, iters: 128, time: 0.147, data: 0.001) G_GAN: 1.243 G_L1: 8.400 D_real: 0.773 D_fake: 0.236 \n",
      "(epoch: 80, iters: 228, time: 0.193, data: 0.002) G_GAN: 0.805 G_L1: 6.139 D_real: 0.297 D_fake: 1.430 \n",
      "(epoch: 80, iters: 328, time: 0.147, data: 0.001) G_GAN: 1.092 G_L1: 6.258 D_real: 1.151 D_fake: 0.161 \n",
      "(epoch: 80, iters: 428, time: 0.147, data: 0.002) G_GAN: 0.858 G_L1: 5.063 D_real: 0.560 D_fake: 1.052 \n",
      "(epoch: 80, iters: 528, time: 0.147, data: 0.002) G_GAN: 0.798 G_L1: 5.674 D_real: 0.495 D_fake: 0.625 \n",
      "(epoch: 80, iters: 628, time: 0.195, data: 0.002) G_GAN: 0.872 G_L1: 6.521 D_real: 0.685 D_fake: 0.524 \n",
      "(epoch: 80, iters: 728, time: 0.147, data: 0.001) G_GAN: 1.143 G_L1: 6.891 D_real: 0.319 D_fake: 0.956 \n",
      "(epoch: 80, iters: 828, time: 0.147, data: 0.002) G_GAN: 1.224 G_L1: 4.925 D_real: 0.417 D_fake: 0.871 \n",
      "saving the model at the end of epoch 80, iters 69440\n",
      "End of epoch 80 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 60, time: 0.147, data: 0.001) G_GAN: 1.410 G_L1: 8.352 D_real: 0.293 D_fake: 0.780 \n",
      "(epoch: 81, iters: 160, time: 0.194, data: 0.002) G_GAN: 0.818 G_L1: 7.786 D_real: 0.825 D_fake: 0.424 \n",
      "(epoch: 81, iters: 260, time: 0.148, data: 0.002) G_GAN: 1.003 G_L1: 5.450 D_real: 0.391 D_fake: 0.744 \n",
      "(epoch: 81, iters: 360, time: 0.148, data: 0.001) G_GAN: 1.132 G_L1: 5.292 D_real: 0.495 D_fake: 0.619 \n",
      "(epoch: 81, iters: 460, time: 0.148, data: 0.002) G_GAN: 0.631 G_L1: 7.596 D_real: 0.573 D_fake: 0.564 \n",
      "(epoch: 81, iters: 560, time: 0.206, data: 0.002) G_GAN: 0.716 G_L1: 6.633 D_real: 0.552 D_fake: 0.693 \n",
      "saving the latest model (epoch 81, total_iters 70000)\n",
      "(epoch: 81, iters: 660, time: 0.147, data: 0.002) G_GAN: 1.232 G_L1: 5.265 D_real: 0.424 D_fake: 0.554 \n",
      "(epoch: 81, iters: 760, time: 0.147, data: 0.002) G_GAN: 0.766 G_L1: 6.048 D_real: 0.849 D_fake: 0.365 \n",
      "(epoch: 81, iters: 860, time: 0.146, data: 0.001) G_GAN: 1.191 G_L1: 6.689 D_real: 0.156 D_fake: 1.030 \n",
      "End of epoch 81 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 92, time: 0.195, data: 0.002) G_GAN: 1.170 G_L1: 7.641 D_real: 0.197 D_fake: 1.017 \n",
      "(epoch: 82, iters: 192, time: 0.147, data: 0.002) G_GAN: 0.903 G_L1: 5.770 D_real: 0.456 D_fake: 0.503 \n",
      "(epoch: 82, iters: 292, time: 0.147, data: 0.002) G_GAN: 0.878 G_L1: 6.532 D_real: 0.662 D_fake: 0.753 \n",
      "(epoch: 82, iters: 392, time: 0.147, data: 0.001) G_GAN: 0.746 G_L1: 5.618 D_real: 0.670 D_fake: 0.406 \n",
      "(epoch: 82, iters: 492, time: 0.196, data: 0.002) G_GAN: 1.041 G_L1: 6.333 D_real: 0.320 D_fake: 1.035 \n",
      "(epoch: 82, iters: 592, time: 0.147, data: 0.001) G_GAN: 1.127 G_L1: 7.299 D_real: 0.451 D_fake: 0.771 \n",
      "(epoch: 82, iters: 692, time: 0.148, data: 0.002) G_GAN: 1.048 G_L1: 6.456 D_real: 0.506 D_fake: 0.638 \n",
      "(epoch: 82, iters: 792, time: 0.148, data: 0.001) G_GAN: 1.095 G_L1: 8.595 D_real: 0.717 D_fake: 0.292 \n",
      "End of epoch 82 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 24, time: 0.196, data: 0.002) G_GAN: 1.559 G_L1: 6.094 D_real: 0.192 D_fake: 0.567 \n",
      "(epoch: 83, iters: 124, time: 0.147, data: 0.002) G_GAN: 1.660 G_L1: 6.345 D_real: 0.219 D_fake: 0.926 \n",
      "(epoch: 83, iters: 224, time: 0.147, data: 0.002) G_GAN: 0.942 G_L1: 6.391 D_real: 0.456 D_fake: 0.361 \n",
      "(epoch: 83, iters: 324, time: 0.147, data: 0.001) G_GAN: 0.383 G_L1: 6.630 D_real: 1.186 D_fake: 0.401 \n",
      "(epoch: 83, iters: 424, time: 0.193, data: 0.001) G_GAN: 1.164 G_L1: 7.061 D_real: 0.243 D_fake: 0.578 \n",
      "(epoch: 83, iters: 524, time: 0.147, data: 0.001) G_GAN: 1.203 G_L1: 4.354 D_real: 0.552 D_fake: 0.591 \n",
      "(epoch: 83, iters: 624, time: 0.147, data: 0.002) G_GAN: 1.014 G_L1: 6.976 D_real: 0.424 D_fake: 0.685 \n",
      "(epoch: 83, iters: 724, time: 0.147, data: 0.002) G_GAN: 1.300 G_L1: 6.071 D_real: 1.067 D_fake: 0.273 \n",
      "(epoch: 83, iters: 824, time: 0.190, data: 0.002) G_GAN: 0.974 G_L1: 7.057 D_real: 0.437 D_fake: 0.451 \n",
      "End of epoch 83 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 56, time: 0.148, data: 0.002) G_GAN: 0.668 G_L1: 6.010 D_real: 0.612 D_fake: 0.634 \n",
      "(epoch: 84, iters: 156, time: 0.148, data: 0.002) G_GAN: 0.880 G_L1: 6.857 D_real: 0.272 D_fake: 1.094 \n",
      "(epoch: 84, iters: 256, time: 0.147, data: 0.002) G_GAN: 1.402 G_L1: 5.933 D_real: 1.379 D_fake: 0.161 \n",
      "(epoch: 84, iters: 356, time: 0.193, data: 0.002) G_GAN: 1.086 G_L1: 8.716 D_real: 0.374 D_fake: 0.393 \n",
      "(epoch: 84, iters: 456, time: 0.148, data: 0.002) G_GAN: 1.000 G_L1: 5.041 D_real: 0.500 D_fake: 0.559 \n",
      "(epoch: 84, iters: 556, time: 0.147, data: 0.002) G_GAN: 1.110 G_L1: 6.068 D_real: 0.623 D_fake: 0.423 \n",
      "(epoch: 84, iters: 656, time: 0.147, data: 0.001) G_GAN: 0.667 G_L1: 6.128 D_real: 0.960 D_fake: 0.522 \n",
      "(epoch: 84, iters: 756, time: 0.195, data: 0.001) G_GAN: 0.820 G_L1: 5.825 D_real: 0.907 D_fake: 0.401 \n",
      "(epoch: 84, iters: 856, time: 0.147, data: 0.002) G_GAN: 0.898 G_L1: 4.642 D_real: 0.674 D_fake: 0.387 \n",
      "End of epoch 84 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 88, time: 0.147, data: 0.001) G_GAN: 1.516 G_L1: 7.671 D_real: 0.673 D_fake: 0.313 \n",
      "(epoch: 85, iters: 188, time: 0.147, data: 0.002) G_GAN: 0.587 G_L1: 6.431 D_real: 0.422 D_fake: 1.263 \n",
      "(epoch: 85, iters: 288, time: 0.193, data: 0.001) G_GAN: 0.936 G_L1: 5.538 D_real: 0.679 D_fake: 0.818 \n",
      "(epoch: 85, iters: 388, time: 0.147, data: 0.002) G_GAN: 0.833 G_L1: 7.006 D_real: 1.307 D_fake: 0.133 \n",
      "(epoch: 85, iters: 488, time: 0.147, data: 0.002) G_GAN: 1.326 G_L1: 8.485 D_real: 0.044 D_fake: 0.897 \n",
      "(epoch: 85, iters: 588, time: 0.147, data: 0.002) G_GAN: 0.674 G_L1: 5.847 D_real: 0.728 D_fake: 0.568 \n",
      "(epoch: 85, iters: 688, time: 0.190, data: 0.002) G_GAN: 1.236 G_L1: 5.665 D_real: 0.430 D_fake: 0.837 \n",
      "(epoch: 85, iters: 788, time: 0.147, data: 0.001) G_GAN: 0.901 G_L1: 5.747 D_real: 0.221 D_fake: 0.862 \n",
      "saving the model at the end of epoch 85, iters 73780\n",
      "End of epoch 85 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 20, time: 0.147, data: 0.002) G_GAN: 1.154 G_L1: 5.305 D_real: 1.330 D_fake: 0.227 \n",
      "(epoch: 86, iters: 120, time: 0.147, data: 0.003) G_GAN: 0.584 G_L1: 6.869 D_real: 0.961 D_fake: 0.463 \n",
      "(epoch: 86, iters: 220, time: 0.196, data: 0.001) G_GAN: 1.099 G_L1: 6.232 D_real: 0.763 D_fake: 0.177 \n",
      "(epoch: 86, iters: 320, time: 0.148, data: 0.002) G_GAN: 0.780 G_L1: 5.904 D_real: 0.875 D_fake: 0.565 \n",
      "(epoch: 86, iters: 420, time: 0.148, data: 0.002) G_GAN: 0.916 G_L1: 5.372 D_real: 0.496 D_fake: 0.520 \n",
      "(epoch: 86, iters: 520, time: 0.148, data: 0.002) G_GAN: 0.863 G_L1: 7.343 D_real: 0.812 D_fake: 0.816 \n",
      "(epoch: 86, iters: 620, time: 0.197, data: 0.002) G_GAN: 0.800 G_L1: 7.247 D_real: 0.376 D_fake: 0.520 \n",
      "(epoch: 86, iters: 720, time: 0.148, data: 0.001) G_GAN: 0.705 G_L1: 7.514 D_real: 0.426 D_fake: 0.681 \n",
      "(epoch: 86, iters: 820, time: 0.148, data: 0.002) G_GAN: 0.975 G_L1: 6.052 D_real: 0.522 D_fake: 0.763 \n",
      "End of epoch 86 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 52, time: 0.148, data: 0.002) G_GAN: 1.069 G_L1: 6.653 D_real: 0.121 D_fake: 1.226 \n",
      "(epoch: 87, iters: 152, time: 0.197, data: 0.001) G_GAN: 1.093 G_L1: 7.130 D_real: 1.020 D_fake: 0.150 \n",
      "(epoch: 87, iters: 252, time: 0.147, data: 0.002) G_GAN: 1.035 G_L1: 6.748 D_real: 0.554 D_fake: 0.401 \n",
      "(epoch: 87, iters: 352, time: 0.147, data: 0.001) G_GAN: 0.860 G_L1: 6.407 D_real: 0.310 D_fake: 0.736 \n",
      "saving the latest model (epoch 87, total_iters 75000)\n",
      "(epoch: 87, iters: 452, time: 0.147, data: 0.001) G_GAN: 1.145 G_L1: 5.600 D_real: 1.245 D_fake: 0.185 \n",
      "(epoch: 87, iters: 552, time: 0.194, data: 0.002) G_GAN: 0.971 G_L1: 5.324 D_real: 1.438 D_fake: 0.190 \n",
      "(epoch: 87, iters: 652, time: 0.147, data: 0.001) G_GAN: 1.462 G_L1: 8.979 D_real: 0.229 D_fake: 0.594 \n",
      "(epoch: 87, iters: 752, time: 0.147, data: 0.001) G_GAN: 0.955 G_L1: 6.246 D_real: 0.744 D_fake: 0.357 \n",
      "(epoch: 87, iters: 852, time: 0.148, data: 0.001) G_GAN: 1.511 G_L1: 6.294 D_real: 0.213 D_fake: 0.742 \n",
      "End of epoch 87 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 84, time: 0.197, data: 0.001) G_GAN: 1.068 G_L1: 7.877 D_real: 0.136 D_fake: 0.949 \n",
      "(epoch: 88, iters: 184, time: 0.147, data: 0.002) G_GAN: 1.069 G_L1: 5.018 D_real: 0.418 D_fake: 0.656 \n",
      "(epoch: 88, iters: 284, time: 0.148, data: 0.001) G_GAN: 1.112 G_L1: 6.726 D_real: 0.069 D_fake: 2.208 \n",
      "(epoch: 88, iters: 384, time: 0.147, data: 0.002) G_GAN: 1.260 G_L1: 5.253 D_real: 0.560 D_fake: 0.769 \n",
      "(epoch: 88, iters: 484, time: 0.194, data: 0.002) G_GAN: 0.652 G_L1: 4.752 D_real: 1.567 D_fake: 0.239 \n",
      "(epoch: 88, iters: 584, time: 0.147, data: 0.002) G_GAN: 0.653 G_L1: 6.476 D_real: 0.642 D_fake: 0.388 \n",
      "(epoch: 88, iters: 684, time: 0.147, data: 0.002) G_GAN: 1.069 G_L1: 5.545 D_real: 1.342 D_fake: 0.179 \n",
      "(epoch: 88, iters: 784, time: 0.147, data: 0.002) G_GAN: 0.751 G_L1: 6.192 D_real: 1.325 D_fake: 0.342 \n",
      "End of epoch 88 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 16, time: 0.199, data: 0.002) G_GAN: 1.083 G_L1: 10.704 D_real: 0.009 D_fake: 1.854 \n",
      "(epoch: 89, iters: 116, time: 0.148, data: 0.002) G_GAN: 1.512 G_L1: 6.082 D_real: 0.295 D_fake: 1.054 \n",
      "(epoch: 89, iters: 216, time: 0.148, data: 0.001) G_GAN: 1.631 G_L1: 6.321 D_real: 0.179 D_fake: 0.363 \n",
      "(epoch: 89, iters: 316, time: 0.147, data: 0.002) G_GAN: 1.146 G_L1: 5.688 D_real: 0.291 D_fake: 0.909 \n",
      "(epoch: 89, iters: 416, time: 0.194, data: 0.002) G_GAN: 0.861 G_L1: 5.246 D_real: 0.531 D_fake: 0.833 \n",
      "(epoch: 89, iters: 516, time: 0.147, data: 0.002) G_GAN: 0.791 G_L1: 5.881 D_real: 0.638 D_fake: 0.450 \n",
      "(epoch: 89, iters: 616, time: 0.147, data: 0.002) G_GAN: 0.857 G_L1: 5.847 D_real: 0.545 D_fake: 0.608 \n",
      "(epoch: 89, iters: 716, time: 0.147, data: 0.002) G_GAN: 1.011 G_L1: 7.614 D_real: 0.266 D_fake: 0.901 \n",
      "(epoch: 89, iters: 816, time: 0.206, data: 0.002) G_GAN: 1.299 G_L1: 5.673 D_real: 1.603 D_fake: 0.123 \n",
      "End of epoch 89 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 48, time: 0.147, data: 0.001) G_GAN: 0.972 G_L1: 6.625 D_real: 0.375 D_fake: 0.762 \n",
      "(epoch: 90, iters: 148, time: 0.148, data: 0.002) G_GAN: 1.642 G_L1: 10.346 D_real: 0.098 D_fake: 0.823 \n",
      "(epoch: 90, iters: 248, time: 0.148, data: 0.002) G_GAN: 0.705 G_L1: 5.782 D_real: 0.872 D_fake: 0.287 \n",
      "(epoch: 90, iters: 348, time: 0.195, data: 0.002) G_GAN: 1.216 G_L1: 6.473 D_real: 0.172 D_fake: 0.848 \n",
      "(epoch: 90, iters: 448, time: 0.147, data: 0.001) G_GAN: 0.715 G_L1: 6.793 D_real: 0.989 D_fake: 0.284 \n",
      "(epoch: 90, iters: 548, time: 0.146, data: 0.002) G_GAN: 0.926 G_L1: 7.662 D_real: 0.087 D_fake: 1.062 \n",
      "(epoch: 90, iters: 648, time: 0.146, data: 0.001) G_GAN: 1.173 G_L1: 6.296 D_real: 0.726 D_fake: 0.378 \n",
      "(epoch: 90, iters: 748, time: 0.194, data: 0.001) G_GAN: 1.182 G_L1: 7.127 D_real: 0.328 D_fake: 0.369 \n",
      "(epoch: 90, iters: 848, time: 0.146, data: 0.002) G_GAN: 1.051 G_L1: 6.354 D_real: 0.792 D_fake: 0.236 \n",
      "saving the model at the end of epoch 90, iters 78120\n",
      "End of epoch 90 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 80, time: 0.146, data: 0.001) G_GAN: 0.604 G_L1: 6.393 D_real: 1.104 D_fake: 0.533 \n",
      "(epoch: 91, iters: 180, time: 0.147, data: 0.002) G_GAN: 1.471 G_L1: 7.542 D_real: 0.185 D_fake: 0.728 \n",
      "(epoch: 91, iters: 280, time: 0.197, data: 0.002) G_GAN: 1.989 G_L1: 7.890 D_real: 1.554 D_fake: 0.083 \n",
      "(epoch: 91, iters: 380, time: 0.147, data: 0.002) G_GAN: 1.133 G_L1: 6.409 D_real: 0.948 D_fake: 0.306 \n",
      "(epoch: 91, iters: 480, time: 0.147, data: 0.002) G_GAN: 0.972 G_L1: 5.635 D_real: 0.531 D_fake: 0.630 \n",
      "(epoch: 91, iters: 580, time: 0.147, data: 0.002) G_GAN: 1.113 G_L1: 7.805 D_real: 0.495 D_fake: 0.344 \n",
      "(epoch: 91, iters: 680, time: 0.195, data: 0.001) G_GAN: 1.169 G_L1: 6.707 D_real: 0.936 D_fake: 0.213 \n",
      "(epoch: 91, iters: 780, time: 0.148, data: 0.002) G_GAN: 1.105 G_L1: 6.321 D_real: 0.695 D_fake: 0.221 \n",
      "End of epoch 91 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 12, time: 0.148, data: 0.002) G_GAN: 0.999 G_L1: 4.508 D_real: 1.005 D_fake: 0.244 \n",
      "(epoch: 92, iters: 112, time: 0.147, data: 0.001) G_GAN: 1.448 G_L1: 7.649 D_real: 0.407 D_fake: 0.432 \n",
      "(epoch: 92, iters: 212, time: 0.198, data: 0.002) G_GAN: 0.975 G_L1: 9.197 D_real: 0.111 D_fake: 1.459 \n",
      "(epoch: 92, iters: 312, time: 0.147, data: 0.002) G_GAN: 0.705 G_L1: 7.391 D_real: 0.662 D_fake: 0.412 \n",
      "(epoch: 92, iters: 412, time: 0.147, data: 0.002) G_GAN: 0.974 G_L1: 5.189 D_real: 0.276 D_fake: 0.515 \n",
      "(epoch: 92, iters: 512, time: 0.148, data: 0.001) G_GAN: 1.042 G_L1: 6.631 D_real: 0.362 D_fake: 0.660 \n",
      "(epoch: 92, iters: 612, time: 0.196, data: 0.001) G_GAN: 0.762 G_L1: 4.797 D_real: 1.090 D_fake: 0.367 \n",
      "(epoch: 92, iters: 712, time: 0.148, data: 0.002) G_GAN: 0.655 G_L1: 5.509 D_real: 0.731 D_fake: 0.335 \n",
      "(epoch: 92, iters: 812, time: 0.148, data: 0.001) G_GAN: 0.768 G_L1: 6.250 D_real: 0.968 D_fake: 0.327 \n",
      "End of epoch 92 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 44, time: 0.148, data: 0.002) G_GAN: 1.204 G_L1: 6.809 D_real: 0.102 D_fake: 1.574 \n",
      "(epoch: 93, iters: 144, time: 0.201, data: 0.001) G_GAN: 0.957 G_L1: 6.214 D_real: 0.846 D_fake: 0.297 \n",
      "saving the latest model (epoch 93, total_iters 80000)\n",
      "(epoch: 93, iters: 244, time: 0.147, data: 0.002) G_GAN: 1.374 G_L1: 5.120 D_real: 0.193 D_fake: 1.587 \n",
      "(epoch: 93, iters: 344, time: 0.146, data: 0.002) G_GAN: 0.575 G_L1: 6.366 D_real: 1.037 D_fake: 0.354 \n",
      "(epoch: 93, iters: 444, time: 0.146, data: 0.002) G_GAN: 0.530 G_L1: 5.017 D_real: 1.092 D_fake: 0.384 \n",
      "(epoch: 93, iters: 544, time: 0.203, data: 0.001) G_GAN: 1.126 G_L1: 8.148 D_real: 0.055 D_fake: 1.381 \n",
      "(epoch: 93, iters: 644, time: 0.146, data: 0.001) G_GAN: 1.361 G_L1: 5.038 D_real: 0.596 D_fake: 0.325 \n",
      "(epoch: 93, iters: 744, time: 0.147, data: 0.002) G_GAN: 1.364 G_L1: 6.110 D_real: 0.426 D_fake: 0.967 \n",
      "(epoch: 93, iters: 844, time: 0.147, data: 0.002) G_GAN: 1.359 G_L1: 6.133 D_real: 1.112 D_fake: 0.261 \n",
      "End of epoch 93 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 76, time: 0.199, data: 0.002) G_GAN: 1.109 G_L1: 6.263 D_real: 0.415 D_fake: 0.434 \n",
      "(epoch: 94, iters: 176, time: 0.147, data: 0.002) G_GAN: 0.814 G_L1: 4.870 D_real: 0.540 D_fake: 0.715 \n",
      "(epoch: 94, iters: 276, time: 0.147, data: 0.002) G_GAN: 0.783 G_L1: 5.276 D_real: 0.709 D_fake: 0.776 \n",
      "(epoch: 94, iters: 376, time: 0.147, data: 0.002) G_GAN: 0.649 G_L1: 4.156 D_real: 0.659 D_fake: 0.527 \n",
      "(epoch: 94, iters: 476, time: 0.197, data: 0.002) G_GAN: 1.409 G_L1: 7.289 D_real: 0.192 D_fake: 1.200 \n",
      "(epoch: 94, iters: 576, time: 0.148, data: 0.002) G_GAN: 1.304 G_L1: 5.608 D_real: 0.530 D_fake: 0.337 \n",
      "(epoch: 94, iters: 676, time: 0.147, data: 0.002) G_GAN: 1.142 G_L1: 6.205 D_real: 1.243 D_fake: 0.236 \n",
      "(epoch: 94, iters: 776, time: 0.148, data: 0.001) G_GAN: 1.170 G_L1: 7.535 D_real: 0.345 D_fake: 0.927 \n",
      "End of epoch 94 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 8, time: 0.202, data: 0.002) G_GAN: 0.907 G_L1: 6.442 D_real: 0.547 D_fake: 0.678 \n",
      "(epoch: 95, iters: 108, time: 0.147, data: 0.001) G_GAN: 1.202 G_L1: 4.780 D_real: 0.221 D_fake: 1.552 \n",
      "(epoch: 95, iters: 208, time: 0.148, data: 0.001) G_GAN: 0.926 G_L1: 6.960 D_real: 1.175 D_fake: 0.269 \n",
      "(epoch: 95, iters: 308, time: 0.147, data: 0.002) G_GAN: 1.534 G_L1: 5.507 D_real: 0.155 D_fake: 1.550 \n",
      "(epoch: 95, iters: 408, time: 0.198, data: 0.002) G_GAN: 0.746 G_L1: 4.926 D_real: 1.522 D_fake: 0.293 \n",
      "(epoch: 95, iters: 508, time: 0.147, data: 0.001) G_GAN: 1.130 G_L1: 5.460 D_real: 0.963 D_fake: 0.286 \n",
      "(epoch: 95, iters: 608, time: 0.147, data: 0.002) G_GAN: 0.924 G_L1: 6.844 D_real: 0.572 D_fake: 0.364 \n",
      "(epoch: 95, iters: 708, time: 0.146, data: 0.001) G_GAN: 0.910 G_L1: 6.151 D_real: 0.680 D_fake: 0.485 \n",
      "(epoch: 95, iters: 808, time: 0.197, data: 0.002) G_GAN: 0.793 G_L1: 4.826 D_real: 0.634 D_fake: 0.528 \n",
      "saving the model at the end of epoch 95, iters 82460\n",
      "End of epoch 95 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 40, time: 0.147, data: 0.002) G_GAN: 0.612 G_L1: 4.847 D_real: 0.902 D_fake: 0.469 \n",
      "(epoch: 96, iters: 140, time: 0.147, data: 0.001) G_GAN: 1.544 G_L1: 4.897 D_real: 0.276 D_fake: 0.905 \n",
      "(epoch: 96, iters: 240, time: 0.147, data: 0.001) G_GAN: 1.269 G_L1: 6.542 D_real: 0.405 D_fake: 0.386 \n",
      "(epoch: 96, iters: 340, time: 0.199, data: 0.002) G_GAN: 0.952 G_L1: 6.383 D_real: 0.691 D_fake: 0.570 \n",
      "(epoch: 96, iters: 440, time: 0.147, data: 0.001) G_GAN: 1.016 G_L1: 6.293 D_real: 0.562 D_fake: 1.143 \n",
      "(epoch: 96, iters: 540, time: 0.147, data: 0.002) G_GAN: 0.778 G_L1: 7.191 D_real: 1.579 D_fake: 0.257 \n",
      "(epoch: 96, iters: 640, time: 0.147, data: 0.002) G_GAN: 0.732 G_L1: 6.697 D_real: 0.626 D_fake: 0.500 \n",
      "(epoch: 96, iters: 740, time: 0.200, data: 0.001) G_GAN: 0.815 G_L1: 6.268 D_real: 1.100 D_fake: 0.302 \n",
      "(epoch: 96, iters: 840, time: 0.147, data: 0.001) G_GAN: 1.498 G_L1: 6.292 D_real: 1.061 D_fake: 0.269 \n",
      "End of epoch 96 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 72, time: 0.147, data: 0.002) G_GAN: 1.252 G_L1: 4.473 D_real: 0.301 D_fake: 1.103 \n",
      "(epoch: 97, iters: 172, time: 0.148, data: 0.001) G_GAN: 1.100 G_L1: 8.426 D_real: 0.433 D_fake: 0.391 \n",
      "(epoch: 97, iters: 272, time: 0.212, data: 0.002) G_GAN: 1.134 G_L1: 7.106 D_real: 0.680 D_fake: 1.062 \n",
      "(epoch: 97, iters: 372, time: 0.148, data: 0.002) G_GAN: 0.921 G_L1: 7.583 D_real: 0.315 D_fake: 0.661 \n",
      "(epoch: 97, iters: 472, time: 0.148, data: 0.002) G_GAN: 1.507 G_L1: 8.683 D_real: 0.153 D_fake: 0.702 \n",
      "(epoch: 97, iters: 572, time: 0.148, data: 0.002) G_GAN: 1.005 G_L1: 4.833 D_real: 0.776 D_fake: 0.435 \n",
      "(epoch: 97, iters: 672, time: 0.200, data: 0.002) G_GAN: 0.977 G_L1: 5.703 D_real: 0.807 D_fake: 0.443 \n",
      "(epoch: 97, iters: 772, time: 0.147, data: 0.001) G_GAN: 1.168 G_L1: 4.704 D_real: 0.991 D_fake: 0.309 \n",
      "End of epoch 97 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 4, time: 0.117, data: 0.002) G_GAN: 0.738 G_L1: 6.303 D_real: 0.780 D_fake: 0.478 \n",
      "(epoch: 98, iters: 104, time: 0.147, data: 0.001) G_GAN: 0.789 G_L1: 6.624 D_real: 1.218 D_fake: 0.323 \n",
      "(epoch: 98, iters: 204, time: 0.201, data: 0.001) G_GAN: 0.646 G_L1: 5.256 D_real: 0.957 D_fake: 0.364 \n",
      "(epoch: 98, iters: 304, time: 0.147, data: 0.002) G_GAN: 0.647 G_L1: 6.164 D_real: 0.855 D_fake: 0.533 \n",
      "(epoch: 98, iters: 404, time: 0.147, data: 0.001) G_GAN: 0.491 G_L1: 6.243 D_real: 1.009 D_fake: 0.397 \n",
      "(epoch: 98, iters: 504, time: 0.147, data: 0.002) G_GAN: 0.881 G_L1: 6.400 D_real: 0.596 D_fake: 0.543 \n",
      "(epoch: 98, iters: 604, time: 0.195, data: 0.002) G_GAN: 1.372 G_L1: 6.350 D_real: 0.148 D_fake: 1.258 \n",
      "(epoch: 98, iters: 704, time: 0.147, data: 0.002) G_GAN: 1.018 G_L1: 6.997 D_real: 0.641 D_fake: 0.463 \n",
      "(epoch: 98, iters: 804, time: 0.146, data: 0.002) G_GAN: 0.569 G_L1: 5.121 D_real: 0.835 D_fake: 0.468 \n",
      "saving the latest model (epoch 98, total_iters 85000)\n",
      "End of epoch 98 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 36, time: 0.146, data: 0.001) G_GAN: 1.111 G_L1: 6.132 D_real: 0.633 D_fake: 0.488 \n",
      "(epoch: 99, iters: 136, time: 0.200, data: 0.002) G_GAN: 1.062 G_L1: 7.187 D_real: 0.607 D_fake: 0.362 \n",
      "(epoch: 99, iters: 236, time: 0.147, data: 0.001) G_GAN: 1.112 G_L1: 7.581 D_real: 0.620 D_fake: 0.547 \n",
      "(epoch: 99, iters: 336, time: 0.147, data: 0.002) G_GAN: 0.982 G_L1: 6.165 D_real: 0.948 D_fake: 0.245 \n",
      "(epoch: 99, iters: 436, time: 0.147, data: 0.002) G_GAN: 0.942 G_L1: 5.431 D_real: 0.889 D_fake: 0.356 \n",
      "(epoch: 99, iters: 536, time: 0.198, data: 0.002) G_GAN: 0.956 G_L1: 6.530 D_real: 0.702 D_fake: 0.312 \n",
      "(epoch: 99, iters: 636, time: 0.148, data: 0.002) G_GAN: 1.269 G_L1: 6.925 D_real: 0.298 D_fake: 0.687 \n",
      "(epoch: 99, iters: 736, time: 0.148, data: 0.001) G_GAN: 1.576 G_L1: 6.307 D_real: 0.234 D_fake: 1.119 \n",
      "(epoch: 99, iters: 836, time: 0.148, data: 0.002) G_GAN: 1.622 G_L1: 7.451 D_real: 0.112 D_fake: 0.819 \n",
      "End of epoch 99 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 68, time: 0.203, data: 0.002) G_GAN: 0.768 G_L1: 4.095 D_real: 0.635 D_fake: 0.708 \n",
      "(epoch: 100, iters: 168, time: 0.147, data: 0.002) G_GAN: 0.824 G_L1: 6.341 D_real: 0.386 D_fake: 1.115 \n",
      "(epoch: 100, iters: 268, time: 0.147, data: 0.001) G_GAN: 1.430 G_L1: 7.347 D_real: 0.087 D_fake: 1.322 \n",
      "(epoch: 100, iters: 368, time: 0.147, data: 0.002) G_GAN: 1.093 G_L1: 4.497 D_real: 0.506 D_fake: 0.657 \n",
      "(epoch: 100, iters: 468, time: 0.198, data: 0.002) G_GAN: 1.054 G_L1: 5.122 D_real: 0.368 D_fake: 0.841 \n",
      "(epoch: 100, iters: 568, time: 0.147, data: 0.002) G_GAN: 1.035 G_L1: 10.051 D_real: 0.004 D_fake: 2.914 \n",
      "(epoch: 100, iters: 668, time: 0.147, data: 0.002) G_GAN: 1.034 G_L1: 5.194 D_real: 0.241 D_fake: 0.901 \n",
      "(epoch: 100, iters: 768, time: 0.148, data: 0.002) G_GAN: 0.821 G_L1: 5.442 D_real: 0.798 D_fake: 0.309 \n",
      "(epoch: 100, iters: 868, time: 0.214, data: 0.002) G_GAN: 0.576 G_L1: 6.216 D_real: 0.833 D_fake: 0.470 \n",
      "saving the model at the end of epoch 100, iters 86800\n",
      "End of epoch 100 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.147, data: 0.093) G_GAN: 0.938 G_L1: 5.742 D_real: 0.305 D_fake: 1.048 \n",
      "(epoch: 101, iters: 200, time: 0.147, data: 0.002) G_GAN: 0.764 G_L1: 6.235 D_real: 0.797 D_fake: 0.213 \n",
      "(epoch: 101, iters: 300, time: 0.147, data: 0.001) G_GAN: 0.845 G_L1: 6.133 D_real: 0.924 D_fake: 0.489 \n",
      "(epoch: 101, iters: 400, time: 0.203, data: 0.002) G_GAN: 0.752 G_L1: 7.233 D_real: 0.881 D_fake: 0.950 \n",
      "(epoch: 101, iters: 500, time: 0.147, data: 0.002) G_GAN: 1.403 G_L1: 6.523 D_real: 0.333 D_fake: 0.327 \n",
      "(epoch: 101, iters: 600, time: 0.146, data: 0.002) G_GAN: 1.111 G_L1: 5.858 D_real: 0.575 D_fake: 0.430 \n",
      "(epoch: 101, iters: 700, time: 0.147, data: 0.001) G_GAN: 0.954 G_L1: 5.699 D_real: 0.311 D_fake: 0.735 \n",
      "(epoch: 101, iters: 800, time: 0.203, data: 0.002) G_GAN: 1.497 G_L1: 7.126 D_real: 0.309 D_fake: 0.492 \n",
      "End of epoch 101 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 32, time: 0.147, data: 0.002) G_GAN: 0.684 G_L1: 5.567 D_real: 1.102 D_fake: 0.740 \n",
      "(epoch: 102, iters: 132, time: 0.147, data: 0.001) G_GAN: 0.712 G_L1: 4.551 D_real: 0.921 D_fake: 0.556 \n",
      "(epoch: 102, iters: 232, time: 0.148, data: 0.001) G_GAN: 1.048 G_L1: 5.412 D_real: 0.496 D_fake: 0.738 \n",
      "(epoch: 102, iters: 332, time: 0.200, data: 0.002) G_GAN: 0.779 G_L1: 6.443 D_real: 0.675 D_fake: 0.495 \n",
      "(epoch: 102, iters: 432, time: 0.147, data: 0.001) G_GAN: 1.147 G_L1: 6.484 D_real: 0.367 D_fake: 0.836 \n",
      "(epoch: 102, iters: 532, time: 0.147, data: 0.001) G_GAN: 0.739 G_L1: 6.524 D_real: 1.257 D_fake: 0.294 \n",
      "(epoch: 102, iters: 632, time: 0.147, data: 0.001) G_GAN: 0.823 G_L1: 6.373 D_real: 0.558 D_fake: 0.542 \n",
      "(epoch: 102, iters: 732, time: 0.201, data: 0.002) G_GAN: 0.728 G_L1: 6.016 D_real: 0.654 D_fake: 0.357 \n",
      "(epoch: 102, iters: 832, time: 0.147, data: 0.002) G_GAN: 0.692 G_L1: 6.172 D_real: 0.691 D_fake: 0.514 \n",
      "End of epoch 102 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 64, time: 0.148, data: 0.002) G_GAN: 0.878 G_L1: 6.901 D_real: 0.294 D_fake: 1.067 \n",
      "(epoch: 103, iters: 164, time: 0.148, data: 0.002) G_GAN: 0.811 G_L1: 6.701 D_real: 0.749 D_fake: 0.516 \n",
      "(epoch: 103, iters: 264, time: 0.203, data: 0.002) G_GAN: 0.893 G_L1: 5.400 D_real: 0.487 D_fake: 0.774 \n",
      "(epoch: 103, iters: 364, time: 0.147, data: 0.002) G_GAN: 0.889 G_L1: 6.163 D_real: 0.193 D_fake: 0.991 \n",
      "(epoch: 103, iters: 464, time: 0.147, data: 0.002) G_GAN: 1.441 G_L1: 7.273 D_real: 0.248 D_fake: 0.736 \n",
      "(epoch: 103, iters: 564, time: 0.147, data: 0.001) G_GAN: 0.333 G_L1: 6.563 D_real: 1.510 D_fake: 0.365 \n",
      "(epoch: 103, iters: 664, time: 0.201, data: 0.001) G_GAN: 0.850 G_L1: 4.678 D_real: 0.925 D_fake: 0.287 \n",
      "(epoch: 103, iters: 764, time: 0.148, data: 0.002) G_GAN: 1.253 G_L1: 7.486 D_real: 0.538 D_fake: 0.327 \n",
      "(epoch: 103, iters: 864, time: 0.147, data: 0.002) G_GAN: 1.360 G_L1: 7.232 D_real: 0.239 D_fake: 1.061 \n",
      "End of epoch 103 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 96, time: 0.147, data: 0.002) G_GAN: 0.949 G_L1: 6.326 D_real: 0.551 D_fake: 0.952 \n",
      "(epoch: 104, iters: 196, time: 0.212, data: 0.002) G_GAN: 1.661 G_L1: 7.778 D_real: 0.044 D_fake: 0.668 \n",
      "(epoch: 104, iters: 296, time: 0.147, data: 0.002) G_GAN: 0.489 G_L1: 4.812 D_real: 0.854 D_fake: 0.514 \n",
      "(epoch: 104, iters: 396, time: 0.148, data: 0.002) G_GAN: 0.819 G_L1: 5.954 D_real: 0.715 D_fake: 0.459 \n",
      "(epoch: 104, iters: 496, time: 0.148, data: 0.002) G_GAN: 0.888 G_L1: 5.670 D_real: 0.844 D_fake: 0.378 \n",
      "(epoch: 104, iters: 596, time: 0.199, data: 0.002) G_GAN: 0.867 G_L1: 6.333 D_real: 0.391 D_fake: 0.610 \n",
      "saving the latest model (epoch 104, total_iters 90000)\n",
      "(epoch: 104, iters: 696, time: 0.147, data: 0.002) G_GAN: 0.780 G_L1: 4.848 D_real: 0.937 D_fake: 0.576 \n",
      "(epoch: 104, iters: 796, time: 0.147, data: 0.002) G_GAN: 1.005 G_L1: 6.191 D_real: 0.513 D_fake: 0.475 \n",
      "End of epoch 104 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 28, time: 0.147, data: 0.002) G_GAN: 0.893 G_L1: 6.598 D_real: 0.701 D_fake: 0.354 \n",
      "(epoch: 105, iters: 128, time: 0.199, data: 0.001) G_GAN: 1.515 G_L1: 8.777 D_real: 0.899 D_fake: 0.171 \n",
      "(epoch: 105, iters: 228, time: 0.147, data: 0.001) G_GAN: 1.221 G_L1: 7.759 D_real: 0.052 D_fake: 1.369 \n",
      "(epoch: 105, iters: 328, time: 0.147, data: 0.002) G_GAN: 1.564 G_L1: 7.023 D_real: 0.094 D_fake: 1.205 \n",
      "(epoch: 105, iters: 428, time: 0.147, data: 0.002) G_GAN: 0.490 G_L1: 5.275 D_real: 1.315 D_fake: 0.243 \n",
      "(epoch: 105, iters: 528, time: 0.202, data: 0.002) G_GAN: 1.109 G_L1: 6.022 D_real: 0.279 D_fake: 0.627 \n",
      "(epoch: 105, iters: 628, time: 0.147, data: 0.002) G_GAN: 0.602 G_L1: 5.059 D_real: 0.797 D_fake: 0.447 \n",
      "(epoch: 105, iters: 728, time: 0.147, data: 0.002) G_GAN: 1.108 G_L1: 5.587 D_real: 0.659 D_fake: 0.338 \n",
      "(epoch: 105, iters: 828, time: 0.148, data: 0.002) G_GAN: 1.565 G_L1: 5.946 D_real: 0.558 D_fake: 0.230 \n",
      "saving the model at the end of epoch 105, iters 91140\n",
      "End of epoch 105 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 60, time: 0.202, data: 0.002) G_GAN: 1.162 G_L1: 6.468 D_real: 0.333 D_fake: 0.629 \n",
      "(epoch: 106, iters: 160, time: 0.147, data: 0.002) G_GAN: 0.987 G_L1: 6.719 D_real: 0.225 D_fake: 1.032 \n",
      "(epoch: 106, iters: 260, time: 0.148, data: 0.002) G_GAN: 1.261 G_L1: 5.401 D_real: 0.647 D_fake: 0.221 \n",
      "(epoch: 106, iters: 360, time: 0.147, data: 0.001) G_GAN: 0.662 G_L1: 6.029 D_real: 1.695 D_fake: 0.246 \n",
      "(epoch: 106, iters: 460, time: 0.203, data: 0.002) G_GAN: 1.429 G_L1: 5.739 D_real: 0.134 D_fake: 1.315 \n",
      "(epoch: 106, iters: 560, time: 0.147, data: 0.002) G_GAN: 0.561 G_L1: 5.066 D_real: 1.117 D_fake: 0.757 \n",
      "(epoch: 106, iters: 660, time: 0.147, data: 0.002) G_GAN: 1.084 G_L1: 6.297 D_real: 0.332 D_fake: 0.831 \n",
      "(epoch: 106, iters: 760, time: 0.148, data: 0.002) G_GAN: 0.694 G_L1: 5.978 D_real: 1.039 D_fake: 0.415 \n",
      "(epoch: 106, iters: 860, time: 0.200, data: 0.001) G_GAN: 1.180 G_L1: 7.369 D_real: 0.067 D_fake: 1.914 \n",
      "End of epoch 106 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 92, time: 0.147, data: 0.002) G_GAN: 0.873 G_L1: 7.124 D_real: 0.899 D_fake: 0.503 \n",
      "(epoch: 107, iters: 192, time: 0.147, data: 0.002) G_GAN: 1.047 G_L1: 4.931 D_real: 0.373 D_fake: 0.955 \n",
      "(epoch: 107, iters: 292, time: 0.147, data: 0.002) G_GAN: 0.796 G_L1: 5.516 D_real: 0.473 D_fake: 0.735 \n",
      "(epoch: 107, iters: 392, time: 0.215, data: 0.002) G_GAN: 0.980 G_L1: 6.526 D_real: 0.239 D_fake: 0.934 \n",
      "(epoch: 107, iters: 492, time: 0.147, data: 0.002) G_GAN: 1.414 G_L1: 5.268 D_real: 0.287 D_fake: 0.969 \n",
      "(epoch: 107, iters: 592, time: 0.148, data: 0.002) G_GAN: 1.379 G_L1: 7.997 D_real: 0.141 D_fake: 0.996 \n",
      "(epoch: 107, iters: 692, time: 0.148, data: 0.002) G_GAN: 1.107 G_L1: 6.674 D_real: 0.498 D_fake: 0.436 \n",
      "(epoch: 107, iters: 792, time: 0.201, data: 0.002) G_GAN: 1.349 G_L1: 6.441 D_real: 0.597 D_fake: 0.319 \n",
      "End of epoch 107 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 24, time: 0.147, data: 0.002) G_GAN: 0.936 G_L1: 5.556 D_real: 0.607 D_fake: 0.471 \n",
      "(epoch: 108, iters: 124, time: 0.147, data: 0.002) G_GAN: 0.827 G_L1: 5.740 D_real: 1.207 D_fake: 0.180 \n",
      "(epoch: 108, iters: 224, time: 0.147, data: 0.002) G_GAN: 0.860 G_L1: 6.371 D_real: 0.612 D_fake: 0.410 \n",
      "(epoch: 108, iters: 324, time: 0.204, data: 0.002) G_GAN: 0.784 G_L1: 7.351 D_real: 0.280 D_fake: 0.889 \n",
      "(epoch: 108, iters: 424, time: 0.147, data: 0.001) G_GAN: 1.125 G_L1: 6.185 D_real: 0.373 D_fake: 0.506 \n",
      "(epoch: 108, iters: 524, time: 0.147, data: 0.002) G_GAN: 1.090 G_L1: 7.100 D_real: 0.445 D_fake: 0.728 \n",
      "(epoch: 108, iters: 624, time: 0.147, data: 0.002) G_GAN: 0.615 G_L1: 6.032 D_real: 0.891 D_fake: 0.238 \n",
      "(epoch: 108, iters: 724, time: 0.202, data: 0.001) G_GAN: 0.908 G_L1: 5.532 D_real: 0.627 D_fake: 0.625 \n",
      "(epoch: 108, iters: 824, time: 0.147, data: 0.002) G_GAN: 1.012 G_L1: 7.948 D_real: 0.153 D_fake: 0.746 \n",
      "End of epoch 108 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 56, time: 0.147, data: 0.002) G_GAN: 0.871 G_L1: 5.470 D_real: 0.690 D_fake: 0.507 \n",
      "(epoch: 109, iters: 156, time: 0.147, data: 0.001) G_GAN: 0.682 G_L1: 5.482 D_real: 0.234 D_fake: 1.307 \n",
      "(epoch: 109, iters: 256, time: 0.202, data: 0.002) G_GAN: 1.093 G_L1: 6.247 D_real: 0.267 D_fake: 0.826 \n",
      "(epoch: 109, iters: 356, time: 0.147, data: 0.001) G_GAN: 1.032 G_L1: 6.030 D_real: 1.156 D_fake: 0.194 \n",
      "(epoch: 109, iters: 456, time: 0.147, data: 0.001) G_GAN: 1.486 G_L1: 6.220 D_real: 0.204 D_fake: 0.962 \n",
      "(epoch: 109, iters: 556, time: 0.147, data: 0.002) G_GAN: 0.926 G_L1: 4.039 D_real: 0.601 D_fake: 0.620 \n",
      "(epoch: 109, iters: 656, time: 0.204, data: 0.002) G_GAN: 0.717 G_L1: 4.284 D_real: 1.252 D_fake: 0.235 \n",
      "(epoch: 109, iters: 756, time: 0.147, data: 0.002) G_GAN: 0.776 G_L1: 5.949 D_real: 1.044 D_fake: 0.345 \n",
      "(epoch: 109, iters: 856, time: 0.148, data: 0.002) G_GAN: 1.038 G_L1: 5.657 D_real: 0.576 D_fake: 0.536 \n",
      "End of epoch 109 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 88, time: 0.147, data: 0.001) G_GAN: 0.931 G_L1: 6.381 D_real: 1.202 D_fake: 0.325 \n",
      "(epoch: 110, iters: 188, time: 0.203, data: 0.002) G_GAN: 1.098 G_L1: 5.162 D_real: 0.956 D_fake: 0.299 \n",
      "(epoch: 110, iters: 288, time: 0.148, data: 0.002) G_GAN: 0.745 G_L1: 6.409 D_real: 0.231 D_fake: 1.495 \n",
      "(epoch: 110, iters: 388, time: 0.148, data: 0.002) G_GAN: 0.865 G_L1: 6.132 D_real: 0.734 D_fake: 0.395 \n",
      "saving the latest model (epoch 110, total_iters 95000)\n",
      "(epoch: 110, iters: 488, time: 0.147, data: 0.002) G_GAN: 0.885 G_L1: 5.599 D_real: 0.588 D_fake: 0.391 \n",
      "(epoch: 110, iters: 588, time: 0.212, data: 0.002) G_GAN: 1.135 G_L1: 7.542 D_real: 0.095 D_fake: 1.380 \n",
      "(epoch: 110, iters: 688, time: 0.147, data: 0.002) G_GAN: 1.087 G_L1: 6.303 D_real: 0.590 D_fake: 0.445 \n",
      "(epoch: 110, iters: 788, time: 0.145, data: 0.002) G_GAN: 0.883 G_L1: 6.489 D_real: 1.649 D_fake: 0.201 \n",
      "saving the model at the end of epoch 110, iters 95480\n",
      "End of epoch 110 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 20, time: 0.146, data: 0.002) G_GAN: 0.901 G_L1: 5.744 D_real: 1.636 D_fake: 0.197 \n",
      "(epoch: 111, iters: 120, time: 0.205, data: 0.002) G_GAN: 0.637 G_L1: 5.512 D_real: 1.023 D_fake: 0.429 \n",
      "(epoch: 111, iters: 220, time: 0.146, data: 0.002) G_GAN: 0.538 G_L1: 7.235 D_real: 0.806 D_fake: 0.833 \n",
      "(epoch: 111, iters: 320, time: 0.146, data: 0.002) G_GAN: 1.185 G_L1: 6.220 D_real: 1.134 D_fake: 0.231 \n",
      "(epoch: 111, iters: 420, time: 0.146, data: 0.002) G_GAN: 1.126 G_L1: 6.344 D_real: 0.251 D_fake: 0.753 \n",
      "(epoch: 111, iters: 520, time: 0.206, data: 0.002) G_GAN: 0.739 G_L1: 6.301 D_real: 0.525 D_fake: 0.590 \n",
      "(epoch: 111, iters: 620, time: 0.146, data: 0.002) G_GAN: 0.858 G_L1: 5.318 D_real: 0.107 D_fake: 1.490 \n",
      "(epoch: 111, iters: 720, time: 0.146, data: 0.002) G_GAN: 0.906 G_L1: 9.412 D_real: 0.306 D_fake: 0.717 \n",
      "(epoch: 111, iters: 820, time: 0.147, data: 0.002) G_GAN: 0.821 G_L1: 6.159 D_real: 0.740 D_fake: 0.469 \n",
      "End of epoch 111 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 52, time: 0.206, data: 0.002) G_GAN: 0.997 G_L1: 6.053 D_real: 0.770 D_fake: 0.555 \n",
      "(epoch: 112, iters: 152, time: 0.147, data: 0.002) G_GAN: 1.085 G_L1: 6.146 D_real: 0.476 D_fake: 0.492 \n",
      "(epoch: 112, iters: 252, time: 0.147, data: 0.001) G_GAN: 0.622 G_L1: 8.413 D_real: 0.042 D_fake: 2.474 \n",
      "(epoch: 112, iters: 352, time: 0.147, data: 0.002) G_GAN: 0.710 G_L1: 5.826 D_real: 0.627 D_fake: 0.852 \n",
      "(epoch: 112, iters: 452, time: 0.202, data: 0.002) G_GAN: 0.915 G_L1: 5.985 D_real: 0.679 D_fake: 0.587 \n",
      "(epoch: 112, iters: 552, time: 0.148, data: 0.002) G_GAN: 0.945 G_L1: 5.787 D_real: 0.364 D_fake: 0.649 \n",
      "(epoch: 112, iters: 652, time: 0.148, data: 0.001) G_GAN: 1.328 G_L1: 7.213 D_real: 0.414 D_fake: 0.649 \n",
      "(epoch: 112, iters: 752, time: 0.148, data: 0.002) G_GAN: 1.742 G_L1: 6.650 D_real: 0.681 D_fake: 1.290 \n",
      "(epoch: 112, iters: 852, time: 0.206, data: 0.001) G_GAN: 1.195 G_L1: 6.914 D_real: 0.325 D_fake: 0.494 \n",
      "End of epoch 112 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 84, time: 0.147, data: 0.001) G_GAN: 1.017 G_L1: 5.586 D_real: 0.867 D_fake: 0.312 \n",
      "(epoch: 113, iters: 184, time: 0.147, data: 0.001) G_GAN: 0.727 G_L1: 4.621 D_real: 0.869 D_fake: 0.586 \n",
      "(epoch: 113, iters: 284, time: 0.147, data: 0.001) G_GAN: 1.222 G_L1: 8.352 D_real: 0.442 D_fake: 0.642 \n",
      "(epoch: 113, iters: 384, time: 0.203, data: 0.001) G_GAN: 0.907 G_L1: 5.991 D_real: 0.362 D_fake: 0.855 \n",
      "(epoch: 113, iters: 484, time: 0.147, data: 0.002) G_GAN: 0.892 G_L1: 4.437 D_real: 0.317 D_fake: 1.017 \n",
      "(epoch: 113, iters: 584, time: 0.147, data: 0.002) G_GAN: 0.572 G_L1: 5.355 D_real: 1.136 D_fake: 0.385 \n",
      "(epoch: 113, iters: 684, time: 0.147, data: 0.001) G_GAN: 1.077 G_L1: 6.752 D_real: 0.298 D_fake: 0.665 \n",
      "(epoch: 113, iters: 784, time: 0.213, data: 0.001) G_GAN: 0.882 G_L1: 6.372 D_real: 0.712 D_fake: 0.328 \n",
      "End of epoch 113 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 16, time: 0.147, data: 0.002) G_GAN: 0.840 G_L1: 6.581 D_real: 0.549 D_fake: 0.584 \n",
      "(epoch: 114, iters: 116, time: 0.147, data: 0.003) G_GAN: 1.645 G_L1: 8.245 D_real: 0.139 D_fake: 0.378 \n",
      "(epoch: 114, iters: 216, time: 0.147, data: 0.001) G_GAN: 1.424 G_L1: 7.567 D_real: 0.441 D_fake: 0.818 \n",
      "(epoch: 114, iters: 316, time: 0.206, data: 0.002) G_GAN: 0.816 G_L1: 7.352 D_real: 0.083 D_fake: 1.668 \n",
      "(epoch: 114, iters: 416, time: 0.148, data: 0.002) G_GAN: 0.692 G_L1: 4.357 D_real: 0.758 D_fake: 0.695 \n",
      "(epoch: 114, iters: 516, time: 0.148, data: 0.002) G_GAN: 1.115 G_L1: 8.477 D_real: 0.552 D_fake: 0.340 \n",
      "(epoch: 114, iters: 616, time: 0.148, data: 0.002) G_GAN: 1.124 G_L1: 7.486 D_real: 0.557 D_fake: 0.509 \n",
      "(epoch: 114, iters: 716, time: 0.206, data: 0.002) G_GAN: 0.978 G_L1: 6.486 D_real: 0.832 D_fake: 0.555 \n",
      "(epoch: 114, iters: 816, time: 0.148, data: 0.001) G_GAN: 1.028 G_L1: 4.911 D_real: 0.561 D_fake: 0.428 \n",
      "End of epoch 114 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 48, time: 0.147, data: 0.002) G_GAN: 1.046 G_L1: 5.888 D_real: 0.205 D_fake: 1.092 \n",
      "(epoch: 115, iters: 148, time: 0.146, data: 0.002) G_GAN: 0.756 G_L1: 5.912 D_real: 0.436 D_fake: 1.159 \n",
      "(epoch: 115, iters: 248, time: 0.203, data: 0.002) G_GAN: 0.705 G_L1: 6.596 D_real: 0.514 D_fake: 0.477 \n",
      "(epoch: 115, iters: 348, time: 0.147, data: 0.002) G_GAN: 1.261 G_L1: 7.544 D_real: 0.263 D_fake: 0.679 \n",
      "(epoch: 115, iters: 448, time: 0.147, data: 0.002) G_GAN: 1.228 G_L1: 5.474 D_real: 0.307 D_fake: 0.773 \n",
      "(epoch: 115, iters: 548, time: 0.147, data: 0.002) G_GAN: 1.161 G_L1: 6.048 D_real: 0.719 D_fake: 0.322 \n",
      "(epoch: 115, iters: 648, time: 0.202, data: 0.002) G_GAN: 1.023 G_L1: 5.443 D_real: 0.269 D_fake: 0.691 \n",
      "(epoch: 115, iters: 748, time: 0.148, data: 0.002) G_GAN: 1.129 G_L1: 5.954 D_real: 1.904 D_fake: 0.116 \n",
      "(epoch: 115, iters: 848, time: 0.147, data: 0.002) G_GAN: 0.532 G_L1: 5.605 D_real: 0.986 D_fake: 0.486 \n",
      "saving the model at the end of epoch 115, iters 99820\n",
      "End of epoch 115 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 80, time: 0.147, data: 0.002) G_GAN: 0.849 G_L1: 4.909 D_real: 0.533 D_fake: 0.635 \n",
      "(epoch: 116, iters: 180, time: 0.205, data: 0.002) G_GAN: 1.281 G_L1: 5.679 D_real: 0.295 D_fake: 0.998 \n",
      "saving the latest model (epoch 116, total_iters 100000)\n",
      "(epoch: 116, iters: 280, time: 0.148, data: 0.001) G_GAN: 0.595 G_L1: 5.575 D_real: 0.675 D_fake: 0.597 \n",
      "(epoch: 116, iters: 380, time: 0.147, data: 0.002) G_GAN: 0.939 G_L1: 5.293 D_real: 0.174 D_fake: 0.922 \n",
      "(epoch: 116, iters: 480, time: 0.147, data: 0.001) G_GAN: 0.910 G_L1: 5.078 D_real: 0.583 D_fake: 0.567 \n",
      "(epoch: 116, iters: 580, time: 0.219, data: 0.002) G_GAN: 0.798 G_L1: 5.702 D_real: 0.164 D_fake: 0.856 \n",
      "(epoch: 116, iters: 680, time: 0.148, data: 0.001) G_GAN: 0.799 G_L1: 7.625 D_real: 0.551 D_fake: 0.549 \n",
      "(epoch: 116, iters: 780, time: 0.147, data: 0.002) G_GAN: 1.039 G_L1: 5.734 D_real: 0.764 D_fake: 0.515 \n",
      "End of epoch 116 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 12, time: 0.147, data: 0.001) G_GAN: 1.208 G_L1: 6.130 D_real: 0.459 D_fake: 0.468 \n",
      "(epoch: 117, iters: 112, time: 0.206, data: 0.001) G_GAN: 1.428 G_L1: 7.117 D_real: 0.589 D_fake: 0.264 \n",
      "(epoch: 117, iters: 212, time: 0.147, data: 0.001) G_GAN: 0.901 G_L1: 6.637 D_real: 0.840 D_fake: 0.449 \n",
      "(epoch: 117, iters: 312, time: 0.147, data: 0.002) G_GAN: 0.928 G_L1: 6.723 D_real: 0.389 D_fake: 0.544 \n",
      "(epoch: 117, iters: 412, time: 0.147, data: 0.002) G_GAN: 1.211 G_L1: 6.563 D_real: 0.671 D_fake: 0.358 \n",
      "(epoch: 117, iters: 512, time: 0.208, data: 0.002) G_GAN: 0.904 G_L1: 6.345 D_real: 0.169 D_fake: 1.197 \n",
      "(epoch: 117, iters: 612, time: 0.148, data: 0.002) G_GAN: 0.738 G_L1: 5.251 D_real: 0.252 D_fake: 1.376 \n",
      "(epoch: 117, iters: 712, time: 0.148, data: 0.002) G_GAN: 1.104 G_L1: 6.567 D_real: 0.365 D_fake: 0.719 \n",
      "(epoch: 117, iters: 812, time: 0.147, data: 0.002) G_GAN: 0.835 G_L1: 6.493 D_real: 0.126 D_fake: 1.572 \n",
      "End of epoch 117 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 44, time: 0.209, data: 0.002) G_GAN: 0.613 G_L1: 6.767 D_real: 1.320 D_fake: 0.468 \n",
      "(epoch: 118, iters: 144, time: 0.148, data: 0.002) G_GAN: 0.736 G_L1: 6.585 D_real: 0.159 D_fake: 1.318 \n",
      "(epoch: 118, iters: 244, time: 0.148, data: 0.002) G_GAN: 0.707 G_L1: 6.321 D_real: 1.019 D_fake: 0.431 \n",
      "(epoch: 118, iters: 344, time: 0.148, data: 0.002) G_GAN: 1.328 G_L1: 5.874 D_real: 0.676 D_fake: 0.241 \n",
      "(epoch: 118, iters: 444, time: 0.209, data: 0.002) G_GAN: 1.146 G_L1: 6.137 D_real: 0.462 D_fake: 0.372 \n",
      "(epoch: 118, iters: 544, time: 0.148, data: 0.002) G_GAN: 0.716 G_L1: 6.502 D_real: 0.526 D_fake: 0.819 \n",
      "(epoch: 118, iters: 644, time: 0.148, data: 0.002) G_GAN: 0.951 G_L1: 5.049 D_real: 0.800 D_fake: 0.473 \n",
      "(epoch: 118, iters: 744, time: 0.147, data: 0.001) G_GAN: 0.697 G_L1: 6.015 D_real: 0.865 D_fake: 0.516 \n",
      "(epoch: 118, iters: 844, time: 0.204, data: 0.002) G_GAN: 1.508 G_L1: 8.907 D_real: 0.112 D_fake: 0.744 \n",
      "End of epoch 118 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 76, time: 0.147, data: 0.001) G_GAN: 0.907 G_L1: 6.620 D_real: 0.841 D_fake: 0.332 \n",
      "(epoch: 119, iters: 176, time: 0.148, data: 0.002) G_GAN: 1.154 G_L1: 5.413 D_real: 0.391 D_fake: 0.586 \n",
      "(epoch: 119, iters: 276, time: 0.147, data: 0.001) G_GAN: 1.090 G_L1: 5.706 D_real: 0.244 D_fake: 1.038 \n",
      "(epoch: 119, iters: 376, time: 0.207, data: 0.002) G_GAN: 1.007 G_L1: 5.853 D_real: 0.252 D_fake: 0.741 \n",
      "(epoch: 119, iters: 476, time: 0.148, data: 0.002) G_GAN: 1.574 G_L1: 7.984 D_real: 0.189 D_fake: 0.367 \n",
      "(epoch: 119, iters: 576, time: 0.148, data: 0.002) G_GAN: 0.530 G_L1: 6.894 D_real: 0.881 D_fake: 0.349 \n",
      "(epoch: 119, iters: 676, time: 0.147, data: 0.002) G_GAN: 1.071 G_L1: 5.549 D_real: 1.345 D_fake: 0.291 \n",
      "(epoch: 119, iters: 776, time: 0.216, data: 0.002) G_GAN: 0.647 G_L1: 6.353 D_real: 0.806 D_fake: 0.313 \n",
      "End of epoch 119 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 8, time: 0.147, data: 0.002) G_GAN: 0.736 G_L1: 5.891 D_real: 0.520 D_fake: 1.008 \n",
      "(epoch: 120, iters: 108, time: 0.147, data: 0.001) G_GAN: 1.207 G_L1: 6.503 D_real: 0.133 D_fake: 0.965 \n",
      "(epoch: 120, iters: 208, time: 0.147, data: 0.002) G_GAN: 1.075 G_L1: 5.307 D_real: 0.198 D_fake: 1.224 \n",
      "(epoch: 120, iters: 308, time: 0.206, data: 0.001) G_GAN: 0.942 G_L1: 6.625 D_real: 0.369 D_fake: 1.050 \n",
      "(epoch: 120, iters: 408, time: 0.148, data: 0.001) G_GAN: 1.435 G_L1: 7.667 D_real: 0.735 D_fake: 0.190 \n",
      "(epoch: 120, iters: 508, time: 0.147, data: 0.002) G_GAN: 0.801 G_L1: 7.817 D_real: 0.758 D_fake: 0.379 \n",
      "(epoch: 120, iters: 608, time: 0.148, data: 0.002) G_GAN: 0.845 G_L1: 6.805 D_real: 0.826 D_fake: 0.322 \n",
      "(epoch: 120, iters: 708, time: 0.208, data: 0.002) G_GAN: 0.632 G_L1: 5.938 D_real: 0.696 D_fake: 0.480 \n",
      "(epoch: 120, iters: 808, time: 0.147, data: 0.002) G_GAN: 0.838 G_L1: 6.501 D_real: 1.329 D_fake: 0.278 \n",
      "saving the model at the end of epoch 120, iters 104160\n",
      "End of epoch 120 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 40, time: 0.147, data: 0.002) G_GAN: 1.017 G_L1: 5.447 D_real: 0.210 D_fake: 0.771 \n",
      "(epoch: 121, iters: 140, time: 0.146, data: 0.002) G_GAN: 0.974 G_L1: 6.716 D_real: 1.471 D_fake: 0.197 \n",
      "(epoch: 121, iters: 240, time: 0.209, data: 0.002) G_GAN: 0.753 G_L1: 6.766 D_real: 0.588 D_fake: 0.711 \n",
      "(epoch: 121, iters: 340, time: 0.147, data: 0.001) G_GAN: 0.762 G_L1: 4.797 D_real: 0.932 D_fake: 0.360 \n",
      "(epoch: 121, iters: 440, time: 0.147, data: 0.001) G_GAN: 1.083 G_L1: 4.422 D_real: 0.743 D_fake: 0.427 \n",
      "(epoch: 121, iters: 540, time: 0.147, data: 0.001) G_GAN: 1.267 G_L1: 7.009 D_real: 0.319 D_fake: 0.490 \n",
      "(epoch: 121, iters: 640, time: 0.210, data: 0.002) G_GAN: 0.991 G_L1: 6.889 D_real: 0.367 D_fake: 0.661 \n",
      "(epoch: 121, iters: 740, time: 0.148, data: 0.002) G_GAN: 1.302 G_L1: 6.015 D_real: 0.901 D_fake: 0.301 \n",
      "(epoch: 121, iters: 840, time: 0.148, data: 0.002) G_GAN: 1.427 G_L1: 6.033 D_real: 1.435 D_fake: 0.085 \n",
      "saving the latest model (epoch 121, total_iters 105000)\n",
      "End of epoch 121 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 72, time: 0.147, data: 0.001) G_GAN: 1.566 G_L1: 5.247 D_real: 0.331 D_fake: 0.370 \n",
      "(epoch: 122, iters: 172, time: 0.199, data: 0.001) G_GAN: 0.956 G_L1: 5.285 D_real: 1.141 D_fake: 0.308 \n",
      "(epoch: 122, iters: 272, time: 0.147, data: 0.001) G_GAN: 0.790 G_L1: 4.287 D_real: 0.764 D_fake: 0.417 \n",
      "(epoch: 122, iters: 372, time: 0.147, data: 0.002) G_GAN: 0.890 G_L1: 7.065 D_real: 0.493 D_fake: 0.578 \n",
      "(epoch: 122, iters: 472, time: 0.146, data: 0.002) G_GAN: 0.878 G_L1: 3.597 D_real: 0.966 D_fake: 0.389 \n",
      "(epoch: 122, iters: 572, time: 0.218, data: 0.002) G_GAN: 0.945 G_L1: 7.433 D_real: 0.145 D_fake: 1.498 \n",
      "(epoch: 122, iters: 672, time: 0.146, data: 0.002) G_GAN: 0.857 G_L1: 5.815 D_real: 0.218 D_fake: 0.802 \n",
      "(epoch: 122, iters: 772, time: 0.146, data: 0.002) G_GAN: 1.030 G_L1: 6.115 D_real: 0.899 D_fake: 0.395 \n",
      "End of epoch 122 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 4, time: 0.117, data: 0.002) G_GAN: 0.950 G_L1: 4.792 D_real: 0.349 D_fake: 1.193 \n",
      "(epoch: 123, iters: 104, time: 0.207, data: 0.001) G_GAN: 0.906 G_L1: 5.664 D_real: 0.778 D_fake: 0.456 \n",
      "(epoch: 123, iters: 204, time: 0.147, data: 0.002) G_GAN: 0.898 G_L1: 5.615 D_real: 0.520 D_fake: 0.625 \n",
      "(epoch: 123, iters: 304, time: 0.147, data: 0.002) G_GAN: 1.372 G_L1: 4.420 D_real: 1.746 D_fake: 0.102 \n",
      "(epoch: 123, iters: 404, time: 0.148, data: 0.002) G_GAN: 1.121 G_L1: 5.008 D_real: 1.119 D_fake: 0.210 \n",
      "(epoch: 123, iters: 504, time: 0.210, data: 0.001) G_GAN: 1.019 G_L1: 7.330 D_real: 0.259 D_fake: 0.699 \n",
      "(epoch: 123, iters: 604, time: 0.147, data: 0.002) G_GAN: 1.039 G_L1: 5.925 D_real: 0.384 D_fake: 0.711 \n",
      "(epoch: 123, iters: 704, time: 0.147, data: 0.002) G_GAN: 1.141 G_L1: 6.657 D_real: 0.936 D_fake: 0.219 \n",
      "(epoch: 123, iters: 804, time: 0.147, data: 0.002) G_GAN: 0.817 G_L1: 3.650 D_real: 0.531 D_fake: 0.536 \n",
      "End of epoch 123 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 36, time: 0.211, data: 0.001) G_GAN: 0.926 G_L1: 5.638 D_real: 0.431 D_fake: 0.582 \n",
      "(epoch: 124, iters: 136, time: 0.147, data: 0.002) G_GAN: 1.294 G_L1: 6.582 D_real: 0.349 D_fake: 0.636 \n",
      "(epoch: 124, iters: 236, time: 0.148, data: 0.002) G_GAN: 1.345 G_L1: 6.654 D_real: 0.110 D_fake: 1.182 \n",
      "(epoch: 124, iters: 336, time: 0.148, data: 0.002) G_GAN: 0.804 G_L1: 4.706 D_real: 0.358 D_fake: 1.046 \n",
      "(epoch: 124, iters: 436, time: 0.209, data: 0.001) G_GAN: 0.823 G_L1: 7.007 D_real: 0.398 D_fake: 0.952 \n",
      "(epoch: 124, iters: 536, time: 0.147, data: 0.001) G_GAN: 1.223 G_L1: 5.986 D_real: 0.166 D_fake: 0.870 \n",
      "(epoch: 124, iters: 636, time: 0.148, data: 0.002) G_GAN: 0.940 G_L1: 5.703 D_real: 1.028 D_fake: 0.277 \n",
      "(epoch: 124, iters: 736, time: 0.147, data: 0.002) G_GAN: 1.314 G_L1: 7.062 D_real: 0.299 D_fake: 0.544 \n",
      "(epoch: 124, iters: 836, time: 0.211, data: 0.002) G_GAN: 0.873 G_L1: 6.074 D_real: 1.140 D_fake: 0.298 \n",
      "End of epoch 124 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 68, time: 0.148, data: 0.002) G_GAN: 0.790 G_L1: 5.281 D_real: 1.480 D_fake: 0.180 \n",
      "(epoch: 125, iters: 168, time: 0.147, data: 0.002) G_GAN: 0.592 G_L1: 4.233 D_real: 1.171 D_fake: 0.250 \n",
      "(epoch: 125, iters: 268, time: 0.146, data: 0.002) G_GAN: 0.816 G_L1: 4.675 D_real: 0.522 D_fake: 0.624 \n",
      "(epoch: 125, iters: 368, time: 0.220, data: 0.002) G_GAN: 0.727 G_L1: 5.734 D_real: 0.585 D_fake: 0.459 \n",
      "(epoch: 125, iters: 468, time: 0.147, data: 0.002) G_GAN: 0.983 G_L1: 5.274 D_real: 0.348 D_fake: 0.589 \n",
      "(epoch: 125, iters: 568, time: 0.147, data: 0.002) G_GAN: 0.858 G_L1: 6.021 D_real: 0.511 D_fake: 0.379 \n",
      "(epoch: 125, iters: 668, time: 0.147, data: 0.002) G_GAN: 1.042 G_L1: 5.133 D_real: 1.042 D_fake: 0.247 \n",
      "(epoch: 125, iters: 768, time: 0.206, data: 0.002) G_GAN: 1.345 G_L1: 6.552 D_real: 0.183 D_fake: 1.251 \n",
      "(epoch: 125, iters: 868, time: 0.147, data: 0.002) G_GAN: 0.638 G_L1: 4.651 D_real: 0.725 D_fake: 0.656 \n",
      "saving the model at the end of epoch 125, iters 108500\n",
      "End of epoch 125 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 100, time: 0.147, data: 0.095) G_GAN: 1.722 G_L1: 9.309 D_real: 0.148 D_fake: 1.032 \n",
      "(epoch: 126, iters: 200, time: 0.148, data: 0.002) G_GAN: 0.902 G_L1: 4.322 D_real: 0.692 D_fake: 0.684 \n",
      "(epoch: 126, iters: 300, time: 0.204, data: 0.001) G_GAN: 1.284 G_L1: 6.637 D_real: 0.387 D_fake: 0.473 \n",
      "(epoch: 126, iters: 400, time: 0.148, data: 0.002) G_GAN: 1.097 G_L1: 8.127 D_real: 0.424 D_fake: 0.548 \n",
      "(epoch: 126, iters: 500, time: 0.148, data: 0.001) G_GAN: 0.669 G_L1: 5.730 D_real: 0.524 D_fake: 0.723 \n",
      "(epoch: 126, iters: 600, time: 0.148, data: 0.002) G_GAN: 0.819 G_L1: 5.844 D_real: 0.883 D_fake: 0.294 \n",
      "(epoch: 126, iters: 700, time: 0.213, data: 0.002) G_GAN: 1.284 G_L1: 8.623 D_real: 0.085 D_fake: 0.965 \n",
      "(epoch: 126, iters: 800, time: 0.148, data: 0.002) G_GAN: 0.767 G_L1: 6.130 D_real: 1.411 D_fake: 0.706 \n",
      "End of epoch 126 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 32, time: 0.148, data: 0.002) G_GAN: 1.084 G_L1: 5.640 D_real: 0.284 D_fake: 0.524 \n",
      "(epoch: 127, iters: 132, time: 0.147, data: 0.002) G_GAN: 1.013 G_L1: 5.217 D_real: 0.268 D_fake: 1.314 \n",
      "(epoch: 127, iters: 232, time: 0.207, data: 0.002) G_GAN: 1.140 G_L1: 5.883 D_real: 0.661 D_fake: 0.410 \n",
      "(epoch: 127, iters: 332, time: 0.147, data: 0.002) G_GAN: 0.850 G_L1: 5.640 D_real: 1.000 D_fake: 0.299 \n",
      "(epoch: 127, iters: 432, time: 0.147, data: 0.002) G_GAN: 0.811 G_L1: 4.721 D_real: 0.399 D_fake: 0.858 \n",
      "(epoch: 127, iters: 532, time: 0.147, data: 0.002) G_GAN: 0.882 G_L1: 7.248 D_real: 1.450 D_fake: 0.363 \n",
      "(epoch: 127, iters: 632, time: 0.208, data: 0.002) G_GAN: 1.150 G_L1: 5.169 D_real: 1.062 D_fake: 0.321 \n",
      "saving the latest model (epoch 127, total_iters 110000)\n",
      "(epoch: 127, iters: 732, time: 0.147, data: 0.003) G_GAN: 1.086 G_L1: 3.776 D_real: 1.447 D_fake: 0.285 \n",
      "(epoch: 127, iters: 832, time: 0.147, data: 0.002) G_GAN: 1.843 G_L1: 10.828 D_real: 0.013 D_fake: 1.064 \n",
      "End of epoch 127 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 64, time: 0.147, data: 0.001) G_GAN: 1.435 G_L1: 7.509 D_real: 0.239 D_fake: 0.722 \n",
      "(epoch: 128, iters: 164, time: 0.222, data: 0.002) G_GAN: 0.921 G_L1: 6.686 D_real: 0.271 D_fake: 0.812 \n",
      "(epoch: 128, iters: 264, time: 0.147, data: 0.002) G_GAN: 1.080 G_L1: 5.475 D_real: 1.045 D_fake: 0.257 \n",
      "(epoch: 128, iters: 364, time: 0.148, data: 0.001) G_GAN: 0.562 G_L1: 6.732 D_real: 1.147 D_fake: 0.459 \n",
      "(epoch: 128, iters: 464, time: 0.148, data: 0.002) G_GAN: 1.624 G_L1: 6.445 D_real: 0.312 D_fake: 0.423 \n",
      "(epoch: 128, iters: 564, time: 0.209, data: 0.002) G_GAN: 0.848 G_L1: 6.084 D_real: 1.628 D_fake: 0.193 \n",
      "(epoch: 128, iters: 664, time: 0.147, data: 0.002) G_GAN: 1.101 G_L1: 2.992 D_real: 1.840 D_fake: 0.254 \n",
      "(epoch: 128, iters: 764, time: 0.148, data: 0.002) G_GAN: 0.983 G_L1: 6.156 D_real: 0.236 D_fake: 0.919 \n",
      "(epoch: 128, iters: 864, time: 0.148, data: 0.002) G_GAN: 0.697 G_L1: 5.364 D_real: 0.452 D_fake: 0.908 \n",
      "End of epoch 128 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 96, time: 0.211, data: 0.002) G_GAN: 1.030 G_L1: 6.362 D_real: 1.154 D_fake: 0.304 \n",
      "(epoch: 129, iters: 196, time: 0.148, data: 0.002) G_GAN: 0.952 G_L1: 6.080 D_real: 0.771 D_fake: 0.358 \n",
      "(epoch: 129, iters: 296, time: 0.148, data: 0.002) G_GAN: 0.828 G_L1: 4.381 D_real: 0.326 D_fake: 1.102 \n",
      "(epoch: 129, iters: 396, time: 0.148, data: 0.001) G_GAN: 0.806 G_L1: 6.071 D_real: 0.924 D_fake: 0.449 \n",
      "(epoch: 129, iters: 496, time: 0.208, data: 0.002) G_GAN: 0.881 G_L1: 6.616 D_real: 0.725 D_fake: 0.290 \n",
      "(epoch: 129, iters: 596, time: 0.147, data: 0.001) G_GAN: 0.777 G_L1: 5.388 D_real: 0.595 D_fake: 0.545 \n",
      "(epoch: 129, iters: 696, time: 0.147, data: 0.002) G_GAN: 0.865 G_L1: 6.425 D_real: 0.688 D_fake: 0.382 \n",
      "(epoch: 129, iters: 796, time: 0.147, data: 0.002) G_GAN: 0.856 G_L1: 4.573 D_real: 1.029 D_fake: 0.401 \n",
      "End of epoch 129 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 28, time: 0.212, data: 0.002) G_GAN: 1.008 G_L1: 6.004 D_real: 0.326 D_fake: 0.924 \n",
      "(epoch: 130, iters: 128, time: 0.147, data: 0.001) G_GAN: 0.923 G_L1: 5.689 D_real: 0.301 D_fake: 0.611 \n",
      "(epoch: 130, iters: 228, time: 0.148, data: 0.001) G_GAN: 0.679 G_L1: 7.063 D_real: 0.595 D_fake: 0.930 \n",
      "(epoch: 130, iters: 328, time: 0.147, data: 0.002) G_GAN: 1.091 G_L1: 6.532 D_real: 0.272 D_fake: 0.559 \n",
      "(epoch: 130, iters: 428, time: 0.210, data: 0.001) G_GAN: 1.329 G_L1: 6.610 D_real: 0.527 D_fake: 0.512 \n",
      "(epoch: 130, iters: 528, time: 0.148, data: 0.002) G_GAN: 0.753 G_L1: 5.771 D_real: 0.183 D_fake: 1.125 \n",
      "(epoch: 130, iters: 628, time: 0.148, data: 0.001) G_GAN: 1.327 G_L1: 5.337 D_real: 0.743 D_fake: 0.223 \n",
      "(epoch: 130, iters: 728, time: 0.148, data: 0.001) G_GAN: 1.280 G_L1: 6.249 D_real: 0.367 D_fake: 0.603 \n",
      "(epoch: 130, iters: 828, time: 0.223, data: 0.002) G_GAN: 0.982 G_L1: 5.294 D_real: 1.040 D_fake: 0.182 \n",
      "saving the model at the end of epoch 130, iters 112840\n",
      "End of epoch 130 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 60, time: 0.148, data: 0.001) G_GAN: 0.939 G_L1: 5.487 D_real: 0.447 D_fake: 0.719 \n",
      "(epoch: 131, iters: 160, time: 0.148, data: 0.002) G_GAN: 1.239 G_L1: 4.271 D_real: 0.784 D_fake: 0.322 \n",
      "(epoch: 131, iters: 260, time: 0.148, data: 0.001) G_GAN: 0.927 G_L1: 6.697 D_real: 0.811 D_fake: 0.470 \n",
      "(epoch: 131, iters: 360, time: 0.215, data: 0.002) G_GAN: 1.419 G_L1: 3.453 D_real: 1.244 D_fake: 0.147 \n",
      "(epoch: 131, iters: 460, time: 0.148, data: 0.002) G_GAN: 0.894 G_L1: 5.628 D_real: 1.102 D_fake: 0.265 \n",
      "(epoch: 131, iters: 560, time: 0.147, data: 0.002) G_GAN: 1.047 G_L1: 7.347 D_real: 0.700 D_fake: 0.527 \n",
      "(epoch: 131, iters: 660, time: 0.148, data: 0.002) G_GAN: 0.967 G_L1: 5.775 D_real: 0.835 D_fake: 0.460 \n",
      "(epoch: 131, iters: 760, time: 0.212, data: 0.002) G_GAN: 0.881 G_L1: 4.876 D_real: 1.118 D_fake: 0.373 \n",
      "(epoch: 131, iters: 860, time: 0.147, data: 0.001) G_GAN: 0.648 G_L1: 5.717 D_real: 1.069 D_fake: 0.377 \n",
      "End of epoch 131 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 92, time: 0.148, data: 0.001) G_GAN: 0.894 G_L1: 5.361 D_real: 0.636 D_fake: 0.496 \n",
      "(epoch: 132, iters: 192, time: 0.148, data: 0.002) G_GAN: 0.900 G_L1: 5.455 D_real: 1.249 D_fake: 0.274 \n",
      "(epoch: 132, iters: 292, time: 0.211, data: 0.001) G_GAN: 1.019 G_L1: 5.280 D_real: 0.619 D_fake: 0.309 \n",
      "(epoch: 132, iters: 392, time: 0.148, data: 0.002) G_GAN: 1.229 G_L1: 6.839 D_real: 0.236 D_fake: 0.564 \n",
      "(epoch: 132, iters: 492, time: 0.148, data: 0.001) G_GAN: 1.065 G_L1: 6.796 D_real: 0.268 D_fake: 0.979 \n",
      "(epoch: 132, iters: 592, time: 0.147, data: 0.002) G_GAN: 0.805 G_L1: 5.608 D_real: 0.920 D_fake: 0.424 \n",
      "(epoch: 132, iters: 692, time: 0.206, data: 0.002) G_GAN: 1.185 G_L1: 5.902 D_real: 0.723 D_fake: 0.387 \n",
      "(epoch: 132, iters: 792, time: 0.147, data: 0.001) G_GAN: 0.922 G_L1: 5.236 D_real: 0.741 D_fake: 0.484 \n",
      "End of epoch 132 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 24, time: 0.147, data: 0.002) G_GAN: 0.802 G_L1: 5.533 D_real: 0.556 D_fake: 0.457 \n",
      "(epoch: 133, iters: 124, time: 0.148, data: 0.001) G_GAN: 1.273 G_L1: 6.154 D_real: 0.300 D_fake: 0.434 \n",
      "(epoch: 133, iters: 224, time: 0.223, data: 0.002) G_GAN: 0.930 G_L1: 5.928 D_real: 0.350 D_fake: 0.896 \n",
      "(epoch: 133, iters: 324, time: 0.147, data: 0.002) G_GAN: 1.003 G_L1: 5.741 D_real: 0.567 D_fake: 0.585 \n",
      "(epoch: 133, iters: 424, time: 0.148, data: 0.001) G_GAN: 0.947 G_L1: 7.025 D_real: 0.136 D_fake: 1.341 \n",
      "saving the latest model (epoch 133, total_iters 115000)\n",
      "(epoch: 133, iters: 524, time: 0.148, data: 0.003) G_GAN: 1.180 G_L1: 7.176 D_real: 0.175 D_fake: 0.641 \n",
      "(epoch: 133, iters: 624, time: 0.210, data: 0.002) G_GAN: 0.922 G_L1: 4.306 D_real: 0.723 D_fake: 0.506 \n",
      "(epoch: 133, iters: 724, time: 0.148, data: 0.002) G_GAN: 1.283 G_L1: 6.088 D_real: 0.200 D_fake: 1.223 \n",
      "(epoch: 133, iters: 824, time: 0.148, data: 0.001) G_GAN: 0.672 G_L1: 7.002 D_real: 1.132 D_fake: 0.446 \n",
      "End of epoch 133 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 56, time: 0.148, data: 0.002) G_GAN: 0.974 G_L1: 6.561 D_real: 1.245 D_fake: 0.251 \n",
      "(epoch: 134, iters: 156, time: 0.211, data: 0.002) G_GAN: 0.864 G_L1: 5.133 D_real: 0.575 D_fake: 0.464 \n",
      "(epoch: 134, iters: 256, time: 0.148, data: 0.002) G_GAN: 1.187 G_L1: 5.160 D_real: 0.144 D_fake: 1.534 \n",
      "(epoch: 134, iters: 356, time: 0.148, data: 0.002) G_GAN: 0.764 G_L1: 6.427 D_real: 1.424 D_fake: 0.297 \n",
      "(epoch: 134, iters: 456, time: 0.148, data: 0.002) G_GAN: 1.024 G_L1: 4.660 D_real: 1.106 D_fake: 0.316 \n",
      "(epoch: 134, iters: 556, time: 0.210, data: 0.002) G_GAN: 1.294 G_L1: 7.219 D_real: 0.170 D_fake: 1.123 \n",
      "(epoch: 134, iters: 656, time: 0.147, data: 0.002) G_GAN: 0.989 G_L1: 6.834 D_real: 0.218 D_fake: 0.811 \n",
      "(epoch: 134, iters: 756, time: 0.147, data: 0.002) G_GAN: 1.161 G_L1: 7.641 D_real: 0.322 D_fake: 0.453 \n",
      "(epoch: 134, iters: 856, time: 0.147, data: 0.002) G_GAN: 0.952 G_L1: 6.873 D_real: 0.482 D_fake: 0.593 \n",
      "End of epoch 134 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 88, time: 0.215, data: 0.002) G_GAN: 1.078 G_L1: 6.002 D_real: 0.464 D_fake: 0.450 \n",
      "(epoch: 135, iters: 188, time: 0.147, data: 0.002) G_GAN: 0.802 G_L1: 7.675 D_real: 0.067 D_fake: 1.553 \n",
      "(epoch: 135, iters: 288, time: 0.147, data: 0.001) G_GAN: 0.880 G_L1: 6.196 D_real: 1.371 D_fake: 0.213 \n",
      "(epoch: 135, iters: 388, time: 0.147, data: 0.001) G_GAN: 0.858 G_L1: 6.022 D_real: 0.611 D_fake: 0.442 \n",
      "(epoch: 135, iters: 488, time: 0.212, data: 0.002) G_GAN: 1.055 G_L1: 5.701 D_real: 0.882 D_fake: 0.320 \n",
      "(epoch: 135, iters: 588, time: 0.147, data: 0.002) G_GAN: 0.925 G_L1: 6.868 D_real: 0.206 D_fake: 0.920 \n",
      "(epoch: 135, iters: 688, time: 0.147, data: 0.002) G_GAN: 1.031 G_L1: 5.779 D_real: 0.405 D_fake: 0.636 \n",
      "(epoch: 135, iters: 788, time: 0.148, data: 0.002) G_GAN: 1.088 G_L1: 6.486 D_real: 0.663 D_fake: 0.351 \n",
      "saving the model at the end of epoch 135, iters 117180\n",
      "End of epoch 135 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 20, time: 0.217, data: 0.002) G_GAN: 1.086 G_L1: 5.341 D_real: 0.581 D_fake: 0.332 \n",
      "(epoch: 136, iters: 120, time: 0.147, data: 0.001) G_GAN: 1.238 G_L1: 5.637 D_real: 0.679 D_fake: 0.470 \n",
      "(epoch: 136, iters: 220, time: 0.147, data: 0.002) G_GAN: 1.067 G_L1: 4.409 D_real: 0.637 D_fake: 0.264 \n",
      "(epoch: 136, iters: 320, time: 0.148, data: 0.001) G_GAN: 0.596 G_L1: 5.997 D_real: 0.847 D_fake: 0.749 \n",
      "(epoch: 136, iters: 420, time: 0.212, data: 0.002) G_GAN: 0.971 G_L1: 6.573 D_real: 0.543 D_fake: 0.395 \n",
      "(epoch: 136, iters: 520, time: 0.148, data: 0.001) G_GAN: 0.993 G_L1: 4.964 D_real: 0.835 D_fake: 0.618 \n",
      "(epoch: 136, iters: 620, time: 0.147, data: 0.002) G_GAN: 0.700 G_L1: 6.370 D_real: 0.537 D_fake: 0.617 \n",
      "(epoch: 136, iters: 720, time: 0.147, data: 0.001) G_GAN: 0.950 G_L1: 5.983 D_real: 0.703 D_fake: 0.415 \n",
      "(epoch: 136, iters: 820, time: 0.216, data: 0.001) G_GAN: 1.225 G_L1: 7.540 D_real: 0.237 D_fake: 0.562 \n",
      "End of epoch 136 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 52, time: 0.148, data: 0.002) G_GAN: 0.837 G_L1: 5.481 D_real: 0.873 D_fake: 0.473 \n",
      "(epoch: 137, iters: 152, time: 0.147, data: 0.002) G_GAN: 0.876 G_L1: 6.001 D_real: 0.433 D_fake: 0.707 \n",
      "(epoch: 137, iters: 252, time: 0.148, data: 0.002) G_GAN: 1.089 G_L1: 8.282 D_real: 0.096 D_fake: 1.067 \n",
      "(epoch: 137, iters: 352, time: 0.214, data: 0.002) G_GAN: 0.976 G_L1: 6.633 D_real: 0.780 D_fake: 0.408 \n",
      "(epoch: 137, iters: 452, time: 0.147, data: 0.001) G_GAN: 1.111 G_L1: 7.573 D_real: 0.130 D_fake: 0.781 \n",
      "(epoch: 137, iters: 552, time: 0.147, data: 0.002) G_GAN: 0.747 G_L1: 5.338 D_real: 0.669 D_fake: 0.825 \n",
      "(epoch: 137, iters: 652, time: 0.147, data: 0.002) G_GAN: 0.853 G_L1: 6.640 D_real: 0.409 D_fake: 1.262 \n",
      "(epoch: 137, iters: 752, time: 0.210, data: 0.002) G_GAN: 0.775 G_L1: 6.621 D_real: 0.801 D_fake: 0.370 \n",
      "(epoch: 137, iters: 852, time: 0.146, data: 0.002) G_GAN: 1.170 G_L1: 6.078 D_real: 1.221 D_fake: 0.141 \n",
      "End of epoch 137 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 84, time: 0.147, data: 0.001) G_GAN: 1.021 G_L1: 6.300 D_real: 0.829 D_fake: 0.433 \n",
      "(epoch: 138, iters: 184, time: 0.146, data: 0.001) G_GAN: 1.489 G_L1: 5.203 D_real: 0.149 D_fake: 1.434 \n",
      "(epoch: 138, iters: 284, time: 0.231, data: 0.002) G_GAN: 0.787 G_L1: 5.128 D_real: 0.880 D_fake: 0.456 \n",
      "(epoch: 138, iters: 384, time: 0.147, data: 0.002) G_GAN: 1.021 G_L1: 5.890 D_real: 0.711 D_fake: 0.629 \n",
      "(epoch: 138, iters: 484, time: 0.147, data: 0.002) G_GAN: 0.778 G_L1: 4.255 D_real: 0.592 D_fake: 0.520 \n",
      "(epoch: 138, iters: 584, time: 0.147, data: 0.002) G_GAN: 1.397 G_L1: 6.016 D_real: 0.661 D_fake: 0.270 \n",
      "(epoch: 138, iters: 684, time: 0.215, data: 0.001) G_GAN: 1.003 G_L1: 5.090 D_real: 1.038 D_fake: 0.281 \n",
      "(epoch: 138, iters: 784, time: 0.147, data: 0.002) G_GAN: 1.023 G_L1: 6.723 D_real: 1.130 D_fake: 0.225 \n",
      "End of epoch 138 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 16, time: 0.147, data: 0.002) G_GAN: 1.041 G_L1: 5.027 D_real: 0.521 D_fake: 0.558 \n",
      "(epoch: 139, iters: 116, time: 0.147, data: 0.002) G_GAN: 0.809 G_L1: 4.725 D_real: 0.447 D_fake: 0.640 \n",
      "(epoch: 139, iters: 216, time: 0.214, data: 0.002) G_GAN: 0.838 G_L1: 6.158 D_real: 0.652 D_fake: 0.634 \n",
      "saving the latest model (epoch 139, total_iters 120000)\n",
      "(epoch: 139, iters: 316, time: 0.148, data: 0.001) G_GAN: 0.599 G_L1: 7.323 D_real: 0.853 D_fake: 0.388 \n",
      "(epoch: 139, iters: 416, time: 0.148, data: 0.002) G_GAN: 0.824 G_L1: 6.444 D_real: 0.798 D_fake: 0.488 \n",
      "(epoch: 139, iters: 516, time: 0.147, data: 0.001) G_GAN: 0.704 G_L1: 6.675 D_real: 0.654 D_fake: 0.562 \n",
      "(epoch: 139, iters: 616, time: 0.214, data: 0.002) G_GAN: 1.013 G_L1: 6.653 D_real: 0.360 D_fake: 0.918 \n",
      "(epoch: 139, iters: 716, time: 0.147, data: 0.002) G_GAN: 0.814 G_L1: 5.099 D_real: 0.506 D_fake: 0.717 \n",
      "(epoch: 139, iters: 816, time: 0.146, data: 0.002) G_GAN: 1.111 G_L1: 8.593 D_real: 0.445 D_fake: 0.319 \n",
      "End of epoch 139 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 48, time: 0.146, data: 0.002) G_GAN: 0.707 G_L1: 5.456 D_real: 0.676 D_fake: 0.523 \n",
      "(epoch: 140, iters: 148, time: 0.213, data: 0.001) G_GAN: 1.080 G_L1: 4.244 D_real: 0.671 D_fake: 0.402 \n",
      "(epoch: 140, iters: 248, time: 0.146, data: 0.001) G_GAN: 1.593 G_L1: 8.058 D_real: 0.042 D_fake: 0.340 \n",
      "(epoch: 140, iters: 348, time: 0.146, data: 0.002) G_GAN: 1.667 G_L1: 6.015 D_real: 0.243 D_fake: 0.840 \n",
      "(epoch: 140, iters: 448, time: 0.147, data: 0.002) G_GAN: 1.028 G_L1: 5.342 D_real: 0.334 D_fake: 1.016 \n",
      "(epoch: 140, iters: 548, time: 0.216, data: 0.002) G_GAN: 1.055 G_L1: 6.215 D_real: 0.584 D_fake: 0.616 \n",
      "(epoch: 140, iters: 648, time: 0.147, data: 0.002) G_GAN: 1.113 G_L1: 5.210 D_real: 0.556 D_fake: 0.442 \n",
      "(epoch: 140, iters: 748, time: 0.147, data: 0.002) G_GAN: 0.752 G_L1: 5.461 D_real: 0.817 D_fake: 0.407 \n",
      "(epoch: 140, iters: 848, time: 0.147, data: 0.002) G_GAN: 0.821 G_L1: 5.274 D_real: 0.808 D_fake: 0.305 \n",
      "saving the model at the end of epoch 140, iters 121520\n",
      "End of epoch 140 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 80, time: 0.230, data: 0.002) G_GAN: 0.871 G_L1: 5.816 D_real: 0.502 D_fake: 0.449 \n",
      "(epoch: 141, iters: 180, time: 0.147, data: 0.002) G_GAN: 1.113 G_L1: 5.548 D_real: 0.205 D_fake: 1.136 \n",
      "(epoch: 141, iters: 280, time: 0.147, data: 0.001) G_GAN: 1.053 G_L1: 4.181 D_real: 1.045 D_fake: 0.235 \n",
      "(epoch: 141, iters: 380, time: 0.147, data: 0.002) G_GAN: 0.848 G_L1: 5.417 D_real: 0.336 D_fake: 0.881 \n",
      "(epoch: 141, iters: 480, time: 0.213, data: 0.002) G_GAN: 0.778 G_L1: 4.520 D_real: 1.043 D_fake: 0.328 \n",
      "(epoch: 141, iters: 580, time: 0.147, data: 0.002) G_GAN: 1.219 G_L1: 7.129 D_real: 0.605 D_fake: 0.335 \n",
      "(epoch: 141, iters: 680, time: 0.147, data: 0.001) G_GAN: 0.822 G_L1: 4.767 D_real: 0.737 D_fake: 0.450 \n",
      "(epoch: 141, iters: 780, time: 0.147, data: 0.002) G_GAN: 1.064 G_L1: 4.704 D_real: 1.251 D_fake: 0.195 \n",
      "End of epoch 141 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 12, time: 0.215, data: 0.002) G_GAN: 1.054 G_L1: 5.374 D_real: 0.325 D_fake: 0.393 \n",
      "(epoch: 142, iters: 112, time: 0.146, data: 0.001) G_GAN: 0.835 G_L1: 6.332 D_real: 0.485 D_fake: 0.740 \n",
      "(epoch: 142, iters: 212, time: 0.147, data: 0.002) G_GAN: 0.987 G_L1: 5.278 D_real: 1.077 D_fake: 0.330 \n",
      "(epoch: 142, iters: 312, time: 0.147, data: 0.001) G_GAN: 1.110 G_L1: 6.225 D_real: 0.419 D_fake: 0.724 \n",
      "(epoch: 142, iters: 412, time: 0.215, data: 0.002) G_GAN: 1.106 G_L1: 4.240 D_real: 0.882 D_fake: 0.267 \n",
      "(epoch: 142, iters: 512, time: 0.147, data: 0.002) G_GAN: 0.719 G_L1: 5.095 D_real: 0.573 D_fake: 0.802 \n",
      "(epoch: 142, iters: 612, time: 0.147, data: 0.002) G_GAN: 1.224 G_L1: 5.961 D_real: 0.673 D_fake: 0.284 \n",
      "(epoch: 142, iters: 712, time: 0.147, data: 0.001) G_GAN: 0.708 G_L1: 5.350 D_real: 1.008 D_fake: 0.359 \n",
      "(epoch: 142, iters: 812, time: 0.218, data: 0.002) G_GAN: 0.694 G_L1: 4.163 D_real: 0.755 D_fake: 0.602 \n",
      "End of epoch 142 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 44, time: 0.147, data: 0.001) G_GAN: 0.913 G_L1: 5.851 D_real: 0.880 D_fake: 0.432 \n",
      "(epoch: 143, iters: 144, time: 0.147, data: 0.002) G_GAN: 0.662 G_L1: 5.459 D_real: 1.175 D_fake: 0.555 \n",
      "(epoch: 143, iters: 244, time: 0.147, data: 0.001) G_GAN: 0.567 G_L1: 4.419 D_real: 0.849 D_fake: 0.371 \n",
      "(epoch: 143, iters: 344, time: 0.225, data: 0.002) G_GAN: 0.933 G_L1: 5.440 D_real: 0.408 D_fake: 0.765 \n",
      "(epoch: 143, iters: 444, time: 0.147, data: 0.002) G_GAN: 0.847 G_L1: 5.371 D_real: 0.423 D_fake: 0.851 \n",
      "(epoch: 143, iters: 544, time: 0.147, data: 0.002) G_GAN: 0.902 G_L1: 4.710 D_real: 0.995 D_fake: 0.390 \n",
      "(epoch: 143, iters: 644, time: 0.147, data: 0.001) G_GAN: 1.408 G_L1: 5.056 D_real: 0.711 D_fake: 0.239 \n",
      "(epoch: 143, iters: 744, time: 0.212, data: 0.002) G_GAN: 0.948 G_L1: 7.269 D_real: 0.311 D_fake: 0.824 \n",
      "(epoch: 143, iters: 844, time: 0.147, data: 0.002) G_GAN: 0.814 G_L1: 5.414 D_real: 1.406 D_fake: 0.239 \n",
      "End of epoch 143 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 76, time: 0.147, data: 0.002) G_GAN: 1.003 G_L1: 3.859 D_real: 1.178 D_fake: 0.323 \n",
      "(epoch: 144, iters: 176, time: 0.147, data: 0.001) G_GAN: 0.872 G_L1: 6.295 D_real: 0.685 D_fake: 0.368 \n",
      "(epoch: 144, iters: 276, time: 0.216, data: 0.002) G_GAN: 0.853 G_L1: 5.598 D_real: 0.165 D_fake: 1.410 \n",
      "(epoch: 144, iters: 376, time: 0.147, data: 0.002) G_GAN: 0.973 G_L1: 6.377 D_real: 0.603 D_fake: 0.439 \n",
      "(epoch: 144, iters: 476, time: 0.147, data: 0.002) G_GAN: 0.738 G_L1: 5.036 D_real: 0.544 D_fake: 0.681 \n",
      "(epoch: 144, iters: 576, time: 0.148, data: 0.002) G_GAN: 0.850 G_L1: 2.898 D_real: 1.006 D_fake: 0.279 \n",
      "(epoch: 144, iters: 676, time: 0.214, data: 0.002) G_GAN: 0.962 G_L1: 4.923 D_real: 0.805 D_fake: 0.364 \n",
      "(epoch: 144, iters: 776, time: 0.148, data: 0.001) G_GAN: 1.382 G_L1: 6.278 D_real: 1.665 D_fake: 0.123 \n",
      "End of epoch 144 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 8, time: 0.147, data: 0.001) G_GAN: 0.853 G_L1: 5.799 D_real: 0.524 D_fake: 0.497 \n",
      "saving the latest model (epoch 145, total_iters 125000)\n",
      "(epoch: 145, iters: 108, time: 0.147, data: 0.002) G_GAN: 1.139 G_L1: 6.360 D_real: 0.785 D_fake: 0.307 \n",
      "(epoch: 145, iters: 208, time: 0.216, data: 0.002) G_GAN: 1.127 G_L1: 6.371 D_real: 1.587 D_fake: 0.159 \n",
      "(epoch: 145, iters: 308, time: 0.147, data: 0.002) G_GAN: 1.025 G_L1: 5.956 D_real: 0.280 D_fake: 0.651 \n",
      "(epoch: 145, iters: 408, time: 0.147, data: 0.001) G_GAN: 0.863 G_L1: 5.223 D_real: 0.949 D_fake: 0.387 \n",
      "(epoch: 145, iters: 508, time: 0.148, data: 0.001) G_GAN: 0.924 G_L1: 6.836 D_real: 0.177 D_fake: 1.029 \n",
      "(epoch: 145, iters: 608, time: 0.223, data: 0.002) G_GAN: 0.932 G_L1: 6.116 D_real: 0.580 D_fake: 0.549 \n",
      "(epoch: 145, iters: 708, time: 0.148, data: 0.002) G_GAN: 1.206 G_L1: 9.089 D_real: 0.172 D_fake: 0.985 \n",
      "(epoch: 145, iters: 808, time: 0.147, data: 0.002) G_GAN: 1.108 G_L1: 5.561 D_real: 0.372 D_fake: 0.518 \n",
      "saving the model at the end of epoch 145, iters 125860\n",
      "End of epoch 145 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 40, time: 0.148, data: 0.002) G_GAN: 1.230 G_L1: 7.395 D_real: 0.363 D_fake: 0.477 \n",
      "(epoch: 146, iters: 140, time: 0.217, data: 0.001) G_GAN: 1.091 G_L1: 6.650 D_real: 1.100 D_fake: 0.175 \n",
      "(epoch: 146, iters: 240, time: 0.148, data: 0.001) G_GAN: 1.755 G_L1: 8.939 D_real: 0.072 D_fake: 0.642 \n",
      "(epoch: 146, iters: 340, time: 0.148, data: 0.002) G_GAN: 1.057 G_L1: 5.423 D_real: 0.676 D_fake: 0.381 \n",
      "(epoch: 146, iters: 440, time: 0.148, data: 0.002) G_GAN: 0.696 G_L1: 5.897 D_real: 0.985 D_fake: 0.480 \n",
      "(epoch: 146, iters: 540, time: 0.213, data: 0.001) G_GAN: 0.485 G_L1: 5.298 D_real: 1.126 D_fake: 0.220 \n",
      "(epoch: 146, iters: 640, time: 0.147, data: 0.002) G_GAN: 1.060 G_L1: 4.117 D_real: 0.549 D_fake: 0.391 \n",
      "(epoch: 146, iters: 740, time: 0.146, data: 0.002) G_GAN: 0.639 G_L1: 5.173 D_real: 0.750 D_fake: 0.516 \n",
      "(epoch: 146, iters: 840, time: 0.147, data: 0.002) G_GAN: 0.927 G_L1: 6.701 D_real: 0.678 D_fake: 0.580 \n",
      "End of epoch 146 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 72, time: 0.216, data: 0.002) G_GAN: 0.916 G_L1: 4.698 D_real: 0.674 D_fake: 0.356 \n",
      "(epoch: 147, iters: 172, time: 0.147, data: 0.002) G_GAN: 0.759 G_L1: 6.577 D_real: 0.630 D_fake: 0.439 \n",
      "(epoch: 147, iters: 272, time: 0.147, data: 0.002) G_GAN: 0.986 G_L1: 4.530 D_real: 0.343 D_fake: 0.611 \n",
      "(epoch: 147, iters: 372, time: 0.148, data: 0.002) G_GAN: 1.064 G_L1: 6.191 D_real: 1.111 D_fake: 0.197 \n",
      "(epoch: 147, iters: 472, time: 0.214, data: 0.002) G_GAN: 0.915 G_L1: 5.518 D_real: 0.373 D_fake: 0.526 \n",
      "(epoch: 147, iters: 572, time: 0.148, data: 0.002) G_GAN: 0.718 G_L1: 4.962 D_real: 1.066 D_fake: 0.301 \n",
      "(epoch: 147, iters: 672, time: 0.148, data: 0.002) G_GAN: 1.205 G_L1: 4.933 D_real: 0.613 D_fake: 0.387 \n",
      "(epoch: 147, iters: 772, time: 0.148, data: 0.001) G_GAN: 0.978 G_L1: 4.828 D_real: 1.064 D_fake: 0.357 \n",
      "End of epoch 147 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 4, time: 0.195, data: 0.002) G_GAN: 1.342 G_L1: 6.686 D_real: 0.136 D_fake: 0.668 \n",
      "(epoch: 148, iters: 104, time: 0.148, data: 0.003) G_GAN: 1.159 G_L1: 6.457 D_real: 0.158 D_fake: 0.760 \n",
      "(epoch: 148, iters: 204, time: 0.148, data: 0.002) G_GAN: 1.197 G_L1: 7.459 D_real: 0.610 D_fake: 0.365 \n",
      "(epoch: 148, iters: 304, time: 0.148, data: 0.002) G_GAN: 1.091 G_L1: 4.461 D_real: 0.884 D_fake: 0.352 \n",
      "(epoch: 148, iters: 404, time: 0.219, data: 0.001) G_GAN: 1.357 G_L1: 6.734 D_real: 0.948 D_fake: 0.270 \n",
      "(epoch: 148, iters: 504, time: 0.148, data: 0.001) G_GAN: 0.817 G_L1: 6.316 D_real: 1.141 D_fake: 0.272 \n",
      "(epoch: 148, iters: 604, time: 0.147, data: 0.002) G_GAN: 0.962 G_L1: 8.376 D_real: 0.552 D_fake: 0.398 \n",
      "(epoch: 148, iters: 704, time: 0.147, data: 0.002) G_GAN: 0.939 G_L1: 5.998 D_real: 0.459 D_fake: 0.617 \n",
      "(epoch: 148, iters: 804, time: 0.215, data: 0.001) G_GAN: 1.320 G_L1: 6.494 D_real: 0.159 D_fake: 1.183 \n",
      "End of epoch 148 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 36, time: 0.147, data: 0.001) G_GAN: 1.098 G_L1: 4.243 D_real: 0.892 D_fake: 0.274 \n",
      "(epoch: 149, iters: 136, time: 0.147, data: 0.002) G_GAN: 0.747 G_L1: 5.362 D_real: 0.814 D_fake: 0.568 \n",
      "(epoch: 149, iters: 236, time: 0.147, data: 0.002) G_GAN: 0.903 G_L1: 5.062 D_real: 0.908 D_fake: 0.404 \n",
      "(epoch: 149, iters: 336, time: 0.217, data: 0.002) G_GAN: 0.918 G_L1: 6.835 D_real: 0.279 D_fake: 0.842 \n",
      "(epoch: 149, iters: 436, time: 0.148, data: 0.002) G_GAN: 0.813 G_L1: 7.274 D_real: 0.230 D_fake: 1.222 \n",
      "(epoch: 149, iters: 536, time: 0.147, data: 0.001) G_GAN: 1.527 G_L1: 5.439 D_real: 0.704 D_fake: 0.236 \n",
      "(epoch: 149, iters: 636, time: 0.148, data: 0.002) G_GAN: 0.932 G_L1: 5.648 D_real: 0.545 D_fake: 0.608 \n",
      "(epoch: 149, iters: 736, time: 0.214, data: 0.002) G_GAN: 0.949 G_L1: 6.209 D_real: 0.586 D_fake: 0.508 \n",
      "(epoch: 149, iters: 836, time: 0.147, data: 0.002) G_GAN: 0.568 G_L1: 5.445 D_real: 0.420 D_fake: 1.116 \n",
      "End of epoch 149 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 68, time: 0.148, data: 0.001) G_GAN: 0.935 G_L1: 6.434 D_real: 0.401 D_fake: 0.569 \n",
      "(epoch: 150, iters: 168, time: 0.148, data: 0.001) G_GAN: 1.225 G_L1: 6.577 D_real: 0.384 D_fake: 0.542 \n",
      "(epoch: 150, iters: 268, time: 0.230, data: 0.002) G_GAN: 0.919 G_L1: 3.850 D_real: 0.241 D_fake: 0.901 \n",
      "(epoch: 150, iters: 368, time: 0.148, data: 0.001) G_GAN: 1.003 G_L1: 6.747 D_real: 0.185 D_fake: 0.532 \n",
      "(epoch: 150, iters: 468, time: 0.147, data: 0.001) G_GAN: 1.206 G_L1: 5.114 D_real: 0.299 D_fake: 1.138 \n",
      "(epoch: 150, iters: 568, time: 0.147, data: 0.002) G_GAN: 1.113 G_L1: 5.255 D_real: 0.301 D_fake: 1.013 \n",
      "(epoch: 150, iters: 668, time: 0.210, data: 0.001) G_GAN: 1.505 G_L1: 5.380 D_real: 0.416 D_fake: 0.251 \n",
      "saving the latest model (epoch 150, total_iters 130000)\n",
      "(epoch: 150, iters: 768, time: 0.148, data: 0.002) G_GAN: 1.034 G_L1: 5.981 D_real: 0.490 D_fake: 0.831 \n",
      "(epoch: 150, iters: 868, time: 0.147, data: 0.001) G_GAN: 1.395 G_L1: 7.020 D_real: 0.925 D_fake: 0.140 \n",
      "saving the model at the end of epoch 150, iters 130200\n",
      "End of epoch 150 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 100, time: 0.147, data: 0.099) G_GAN: 0.498 G_L1: 4.800 D_real: 1.009 D_fake: 0.354 \n",
      "(epoch: 151, iters: 200, time: 0.219, data: 0.002) G_GAN: 0.889 G_L1: 4.611 D_real: 0.594 D_fake: 0.428 \n",
      "(epoch: 151, iters: 300, time: 0.148, data: 0.002) G_GAN: 1.062 G_L1: 6.534 D_real: 0.477 D_fake: 0.383 \n",
      "(epoch: 151, iters: 400, time: 0.147, data: 0.002) G_GAN: 0.872 G_L1: 4.843 D_real: 0.496 D_fake: 0.724 \n",
      "(epoch: 151, iters: 500, time: 0.147, data: 0.002) G_GAN: 0.777 G_L1: 4.862 D_real: 0.496 D_fake: 0.628 \n",
      "(epoch: 151, iters: 600, time: 0.218, data: 0.001) G_GAN: 0.896 G_L1: 5.895 D_real: 0.850 D_fake: 0.571 \n",
      "(epoch: 151, iters: 700, time: 0.147, data: 0.002) G_GAN: 0.748 G_L1: 6.514 D_real: 0.743 D_fake: 0.537 \n",
      "(epoch: 151, iters: 800, time: 0.147, data: 0.002) G_GAN: 1.027 G_L1: 5.390 D_real: 0.589 D_fake: 0.268 \n",
      "End of epoch 151 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 32, time: 0.147, data: 0.002) G_GAN: 0.758 G_L1: 5.727 D_real: 0.349 D_fake: 1.337 \n",
      "(epoch: 152, iters: 132, time: 0.219, data: 0.002) G_GAN: 0.799 G_L1: 5.002 D_real: 0.758 D_fake: 0.620 \n",
      "(epoch: 152, iters: 232, time: 0.147, data: 0.001) G_GAN: 1.302 G_L1: 6.495 D_real: 0.109 D_fake: 0.797 \n",
      "(epoch: 152, iters: 332, time: 0.147, data: 0.002) G_GAN: 0.940 G_L1: 5.085 D_real: 1.069 D_fake: 0.267 \n",
      "(epoch: 152, iters: 432, time: 0.147, data: 0.002) G_GAN: 0.943 G_L1: 5.263 D_real: 0.533 D_fake: 0.891 \n",
      "(epoch: 152, iters: 532, time: 0.229, data: 0.002) G_GAN: 0.968 G_L1: 5.363 D_real: 0.828 D_fake: 0.457 \n",
      "(epoch: 152, iters: 632, time: 0.147, data: 0.001) G_GAN: 1.399 G_L1: 5.203 D_real: 0.944 D_fake: 0.209 \n",
      "(epoch: 152, iters: 732, time: 0.148, data: 0.002) G_GAN: 1.015 G_L1: 5.655 D_real: 0.486 D_fake: 0.556 \n",
      "(epoch: 152, iters: 832, time: 0.149, data: 0.001) G_GAN: 1.141 G_L1: 3.692 D_real: 0.921 D_fake: 0.362 \n",
      "End of epoch 152 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 64, time: 0.221, data: 0.002) G_GAN: 0.688 G_L1: 6.959 D_real: 0.406 D_fake: 0.887 \n",
      "(epoch: 153, iters: 164, time: 0.147, data: 0.001) G_GAN: 0.831 G_L1: 5.350 D_real: 0.605 D_fake: 0.437 \n",
      "(epoch: 153, iters: 264, time: 0.147, data: 0.001) G_GAN: 0.959 G_L1: 6.170 D_real: 0.756 D_fake: 0.324 \n",
      "(epoch: 153, iters: 364, time: 0.147, data: 0.001) G_GAN: 0.709 G_L1: 5.844 D_real: 0.826 D_fake: 0.577 \n",
      "(epoch: 153, iters: 464, time: 0.215, data: 0.002) G_GAN: 1.330 G_L1: 6.204 D_real: 0.330 D_fake: 0.417 \n",
      "(epoch: 153, iters: 564, time: 0.147, data: 0.002) G_GAN: 0.971 G_L1: 6.167 D_real: 0.295 D_fake: 0.972 \n",
      "(epoch: 153, iters: 664, time: 0.147, data: 0.002) G_GAN: 1.310 G_L1: 6.107 D_real: 0.393 D_fake: 0.433 \n",
      "(epoch: 153, iters: 764, time: 0.147, data: 0.002) G_GAN: 0.937 G_L1: 4.826 D_real: 0.508 D_fake: 0.442 \n",
      "(epoch: 153, iters: 864, time: 0.220, data: 0.002) G_GAN: 1.094 G_L1: 5.886 D_real: 0.831 D_fake: 0.368 \n",
      "End of epoch 153 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 96, time: 0.147, data: 0.001) G_GAN: 0.766 G_L1: 6.234 D_real: 0.650 D_fake: 0.473 \n",
      "(epoch: 154, iters: 196, time: 0.147, data: 0.002) G_GAN: 0.519 G_L1: 5.970 D_real: 0.308 D_fake: 1.285 \n",
      "(epoch: 154, iters: 296, time: 0.147, data: 0.001) G_GAN: 0.862 G_L1: 5.837 D_real: 0.473 D_fake: 0.606 \n",
      "(epoch: 154, iters: 396, time: 0.220, data: 0.001) G_GAN: 1.445 G_L1: 7.754 D_real: 0.272 D_fake: 0.445 \n",
      "(epoch: 154, iters: 496, time: 0.147, data: 0.002) G_GAN: 0.748 G_L1: 5.457 D_real: 0.844 D_fake: 0.504 \n",
      "(epoch: 154, iters: 596, time: 0.147, data: 0.002) G_GAN: 1.114 G_L1: 4.978 D_real: 0.824 D_fake: 0.294 \n",
      "(epoch: 154, iters: 696, time: 0.148, data: 0.001) G_GAN: 1.220 G_L1: 6.117 D_real: 0.313 D_fake: 0.623 \n",
      "(epoch: 154, iters: 796, time: 0.228, data: 0.002) G_GAN: 0.969 G_L1: 5.928 D_real: 0.371 D_fake: 0.766 \n",
      "End of epoch 154 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 28, time: 0.147, data: 0.001) G_GAN: 1.008 G_L1: 6.428 D_real: 0.398 D_fake: 0.699 \n",
      "(epoch: 155, iters: 128, time: 0.147, data: 0.001) G_GAN: 1.053 G_L1: 4.849 D_real: 0.239 D_fake: 0.801 \n",
      "(epoch: 155, iters: 228, time: 0.147, data: 0.001) G_GAN: 0.550 G_L1: 6.252 D_real: 0.366 D_fake: 1.138 \n",
      "(epoch: 155, iters: 328, time: 0.217, data: 0.001) G_GAN: 0.873 G_L1: 6.934 D_real: 0.614 D_fake: 0.468 \n",
      "(epoch: 155, iters: 428, time: 0.148, data: 0.001) G_GAN: 0.715 G_L1: 5.542 D_real: 0.876 D_fake: 0.631 \n",
      "(epoch: 155, iters: 528, time: 0.147, data: 0.002) G_GAN: 1.034 G_L1: 5.571 D_real: 0.892 D_fake: 0.314 \n",
      "(epoch: 155, iters: 628, time: 0.147, data: 0.002) G_GAN: 1.027 G_L1: 6.070 D_real: 0.200 D_fake: 0.936 \n",
      "(epoch: 155, iters: 728, time: 0.219, data: 0.002) G_GAN: 0.721 G_L1: 6.225 D_real: 1.004 D_fake: 0.302 \n",
      "(epoch: 155, iters: 828, time: 0.148, data: 0.002) G_GAN: 0.717 G_L1: 6.067 D_real: 0.673 D_fake: 0.722 \n",
      "saving the model at the end of epoch 155, iters 134540\n",
      "End of epoch 155 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 60, time: 0.147, data: 0.002) G_GAN: 0.774 G_L1: 3.722 D_real: 0.699 D_fake: 0.481 \n",
      "(epoch: 156, iters: 160, time: 0.147, data: 0.002) G_GAN: 0.921 G_L1: 8.240 D_real: 0.152 D_fake: 0.907 \n",
      "(epoch: 156, iters: 260, time: 0.219, data: 0.001) G_GAN: 0.876 G_L1: 8.276 D_real: 0.336 D_fake: 0.709 \n",
      "(epoch: 156, iters: 360, time: 0.147, data: 0.002) G_GAN: 1.011 G_L1: 7.101 D_real: 0.308 D_fake: 0.679 \n",
      "(epoch: 156, iters: 460, time: 0.147, data: 0.002) G_GAN: 0.935 G_L1: 4.284 D_real: 0.888 D_fake: 0.386 \n",
      "saving the latest model (epoch 156, total_iters 135000)\n",
      "(epoch: 156, iters: 560, time: 0.147, data: 0.001) G_GAN: 1.101 G_L1: 4.624 D_real: 0.608 D_fake: 0.669 \n",
      "(epoch: 156, iters: 660, time: 0.214, data: 0.002) G_GAN: 0.746 G_L1: 3.822 D_real: 0.729 D_fake: 0.470 \n",
      "(epoch: 156, iters: 760, time: 0.147, data: 0.002) G_GAN: 1.437 G_L1: 6.361 D_real: 0.704 D_fake: 0.278 \n",
      "(epoch: 156, iters: 860, time: 0.147, data: 0.002) G_GAN: 0.935 G_L1: 5.148 D_real: 0.393 D_fake: 0.784 \n",
      "End of epoch 156 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 92, time: 0.147, data: 0.002) G_GAN: 1.101 G_L1: 5.014 D_real: 1.192 D_fake: 0.262 \n",
      "(epoch: 157, iters: 192, time: 0.231, data: 0.001) G_GAN: 0.938 G_L1: 6.325 D_real: 0.389 D_fake: 0.632 \n",
      "(epoch: 157, iters: 292, time: 0.147, data: 0.002) G_GAN: 0.890 G_L1: 6.447 D_real: 0.496 D_fake: 0.513 \n",
      "(epoch: 157, iters: 392, time: 0.147, data: 0.001) G_GAN: 0.800 G_L1: 5.701 D_real: 0.254 D_fake: 1.141 \n",
      "(epoch: 157, iters: 492, time: 0.147, data: 0.002) G_GAN: 0.634 G_L1: 4.969 D_real: 0.567 D_fake: 0.767 \n",
      "(epoch: 157, iters: 592, time: 0.216, data: 0.001) G_GAN: 1.033 G_L1: 4.905 D_real: 0.922 D_fake: 0.405 \n",
      "(epoch: 157, iters: 692, time: 0.147, data: 0.002) G_GAN: 1.058 G_L1: 5.857 D_real: 0.492 D_fake: 0.646 \n",
      "(epoch: 157, iters: 792, time: 0.147, data: 0.002) G_GAN: 1.357 G_L1: 5.171 D_real: 0.573 D_fake: 0.274 \n",
      "End of epoch 157 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 24, time: 0.147, data: 0.002) G_GAN: 1.211 G_L1: 3.071 D_real: 1.340 D_fake: 0.217 \n",
      "(epoch: 158, iters: 124, time: 0.231, data: 0.001) G_GAN: 1.023 G_L1: 6.583 D_real: 0.520 D_fake: 0.420 \n",
      "(epoch: 158, iters: 224, time: 0.147, data: 0.002) G_GAN: 1.242 G_L1: 5.424 D_real: 0.640 D_fake: 0.288 \n",
      "(epoch: 158, iters: 324, time: 0.147, data: 0.002) G_GAN: 0.900 G_L1: 5.884 D_real: 0.462 D_fake: 0.728 \n",
      "(epoch: 158, iters: 424, time: 0.147, data: 0.002) G_GAN: 1.090 G_L1: 5.203 D_real: 0.249 D_fake: 0.604 \n",
      "(epoch: 158, iters: 524, time: 0.218, data: 0.001) G_GAN: 0.762 G_L1: 4.868 D_real: 0.428 D_fake: 0.759 \n",
      "(epoch: 158, iters: 624, time: 0.147, data: 0.002) G_GAN: 0.906 G_L1: 4.263 D_real: 0.580 D_fake: 0.477 \n",
      "(epoch: 158, iters: 724, time: 0.147, data: 0.002) G_GAN: 1.162 G_L1: 4.668 D_real: 0.477 D_fake: 0.659 \n",
      "(epoch: 158, iters: 824, time: 0.147, data: 0.002) G_GAN: 0.915 G_L1: 5.702 D_real: 0.436 D_fake: 0.610 \n",
      "End of epoch 158 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 56, time: 0.218, data: 0.001) G_GAN: 0.789 G_L1: 4.334 D_real: 1.101 D_fake: 0.419 \n",
      "(epoch: 159, iters: 156, time: 0.147, data: 0.002) G_GAN: 0.766 G_L1: 5.706 D_real: 0.302 D_fake: 0.894 \n",
      "(epoch: 159, iters: 256, time: 0.147, data: 0.002) G_GAN: 0.911 G_L1: 4.618 D_real: 0.332 D_fake: 0.672 \n",
      "(epoch: 159, iters: 356, time: 0.147, data: 0.001) G_GAN: 0.986 G_L1: 5.608 D_real: 0.626 D_fake: 0.522 \n",
      "(epoch: 159, iters: 456, time: 0.230, data: 0.001) G_GAN: 0.971 G_L1: 5.697 D_real: 0.815 D_fake: 0.347 \n",
      "(epoch: 159, iters: 556, time: 0.148, data: 0.002) G_GAN: 0.874 G_L1: 5.153 D_real: 0.816 D_fake: 0.325 \n",
      "(epoch: 159, iters: 656, time: 0.147, data: 0.002) G_GAN: 1.294 G_L1: 6.160 D_real: 0.555 D_fake: 0.432 \n",
      "(epoch: 159, iters: 756, time: 0.148, data: 0.001) G_GAN: 0.994 G_L1: 8.281 D_real: 0.153 D_fake: 1.178 \n",
      "(epoch: 159, iters: 856, time: 0.219, data: 0.002) G_GAN: 1.250 G_L1: 9.056 D_real: 0.101 D_fake: 1.043 \n",
      "End of epoch 159 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 88, time: 0.147, data: 0.002) G_GAN: 0.788 G_L1: 6.308 D_real: 0.943 D_fake: 0.404 \n",
      "(epoch: 160, iters: 188, time: 0.147, data: 0.002) G_GAN: 0.823 G_L1: 5.954 D_real: 0.323 D_fake: 1.142 \n",
      "(epoch: 160, iters: 288, time: 0.147, data: 0.001) G_GAN: 1.260 G_L1: 6.211 D_real: 0.182 D_fake: 0.755 \n",
      "(epoch: 160, iters: 388, time: 0.222, data: 0.002) G_GAN: 1.172 G_L1: 4.832 D_real: 0.696 D_fake: 0.366 \n",
      "(epoch: 160, iters: 488, time: 0.147, data: 0.002) G_GAN: 0.914 G_L1: 7.033 D_real: 0.515 D_fake: 0.564 \n",
      "(epoch: 160, iters: 588, time: 0.147, data: 0.002) G_GAN: 0.900 G_L1: 5.856 D_real: 0.466 D_fake: 0.517 \n",
      "(epoch: 160, iters: 688, time: 0.147, data: 0.002) G_GAN: 0.831 G_L1: 6.417 D_real: 0.744 D_fake: 0.553 \n",
      "(epoch: 160, iters: 788, time: 0.223, data: 0.002) G_GAN: 1.127 G_L1: 8.533 D_real: 0.057 D_fake: 0.761 \n",
      "saving the model at the end of epoch 160, iters 138880\n",
      "End of epoch 160 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 20, time: 0.147, data: 0.001) G_GAN: 1.253 G_L1: 6.131 D_real: 0.462 D_fake: 0.279 \n",
      "(epoch: 161, iters: 120, time: 0.147, data: 0.002) G_GAN: 0.883 G_L1: 4.737 D_real: 0.310 D_fake: 1.041 \n",
      "(epoch: 161, iters: 220, time: 0.147, data: 0.002) G_GAN: 1.032 G_L1: 6.302 D_real: 0.246 D_fake: 0.664 \n",
      "(epoch: 161, iters: 320, time: 0.223, data: 0.001) G_GAN: 0.767 G_L1: 5.738 D_real: 1.183 D_fake: 0.365 \n",
      "(epoch: 161, iters: 420, time: 0.147, data: 0.001) G_GAN: 0.726 G_L1: 9.898 D_real: 0.141 D_fake: 1.263 \n",
      "(epoch: 161, iters: 520, time: 0.147, data: 0.002) G_GAN: 0.961 G_L1: 5.858 D_real: 0.348 D_fake: 0.978 \n",
      "(epoch: 161, iters: 620, time: 0.147, data: 0.002) G_GAN: 0.822 G_L1: 6.410 D_real: 0.301 D_fake: 0.882 \n",
      "(epoch: 161, iters: 720, time: 0.233, data: 0.002) G_GAN: 0.992 G_L1: 5.410 D_real: 0.873 D_fake: 0.351 \n",
      "(epoch: 161, iters: 820, time: 0.147, data: 0.001) G_GAN: 1.146 G_L1: 3.531 D_real: 0.593 D_fake: 0.441 \n",
      "End of epoch 161 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 52, time: 0.147, data: 0.002) G_GAN: 1.054 G_L1: 8.093 D_real: 0.499 D_fake: 0.572 \n",
      "(epoch: 162, iters: 152, time: 0.147, data: 0.002) G_GAN: 1.060 G_L1: 4.647 D_real: 0.747 D_fake: 0.405 \n",
      "(epoch: 162, iters: 252, time: 0.226, data: 0.001) G_GAN: 1.156 G_L1: 5.852 D_real: 0.202 D_fake: 1.107 \n",
      "saving the latest model (epoch 162, total_iters 140000)\n",
      "(epoch: 162, iters: 352, time: 0.148, data: 0.002) G_GAN: 0.904 G_L1: 6.579 D_real: 0.606 D_fake: 0.583 \n",
      "(epoch: 162, iters: 452, time: 0.147, data: 0.001) G_GAN: 1.010 G_L1: 6.373 D_real: 0.352 D_fake: 0.691 \n",
      "(epoch: 162, iters: 552, time: 0.148, data: 0.001) G_GAN: 1.105 G_L1: 4.936 D_real: 0.743 D_fake: 0.234 \n",
      "(epoch: 162, iters: 652, time: 0.221, data: 0.002) G_GAN: 0.677 G_L1: 4.906 D_real: 0.381 D_fake: 0.983 \n",
      "(epoch: 162, iters: 752, time: 0.147, data: 0.001) G_GAN: 1.198 G_L1: 6.532 D_real: 0.498 D_fake: 0.442 \n",
      "(epoch: 162, iters: 852, time: 0.146, data: 0.002) G_GAN: 1.063 G_L1: 5.881 D_real: 0.155 D_fake: 1.012 \n",
      "End of epoch 162 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 84, time: 0.147, data: 0.002) G_GAN: 1.104 G_L1: 3.782 D_real: 1.496 D_fake: 0.322 \n",
      "(epoch: 163, iters: 184, time: 0.222, data: 0.001) G_GAN: 0.901 G_L1: 5.350 D_real: 0.590 D_fake: 0.571 \n",
      "(epoch: 163, iters: 284, time: 0.147, data: 0.001) G_GAN: 0.986 G_L1: 4.823 D_real: 0.707 D_fake: 0.566 \n",
      "(epoch: 163, iters: 384, time: 0.147, data: 0.002) G_GAN: 0.922 G_L1: 4.464 D_real: 1.191 D_fake: 0.317 \n",
      "(epoch: 163, iters: 484, time: 0.147, data: 0.002) G_GAN: 0.963 G_L1: 4.844 D_real: 0.584 D_fake: 0.507 \n",
      "(epoch: 163, iters: 584, time: 0.230, data: 0.002) G_GAN: 0.880 G_L1: 6.563 D_real: 0.640 D_fake: 0.698 \n",
      "(epoch: 163, iters: 684, time: 0.147, data: 0.002) G_GAN: 0.998 G_L1: 6.111 D_real: 0.384 D_fake: 0.698 \n",
      "(epoch: 163, iters: 784, time: 0.148, data: 0.001) G_GAN: 1.077 G_L1: 5.851 D_real: 0.750 D_fake: 0.417 \n",
      "End of epoch 163 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 16, time: 0.147, data: 0.002) G_GAN: 0.818 G_L1: 6.701 D_real: 0.854 D_fake: 0.555 \n",
      "(epoch: 164, iters: 116, time: 0.220, data: 0.001) G_GAN: 0.741 G_L1: 5.161 D_real: 0.835 D_fake: 0.597 \n",
      "(epoch: 164, iters: 216, time: 0.147, data: 0.001) G_GAN: 0.695 G_L1: 4.936 D_real: 1.354 D_fake: 0.465 \n",
      "(epoch: 164, iters: 316, time: 0.147, data: 0.001) G_GAN: 0.784 G_L1: 5.360 D_real: 0.587 D_fake: 0.591 \n",
      "(epoch: 164, iters: 416, time: 0.147, data: 0.001) G_GAN: 0.887 G_L1: 5.959 D_real: 0.331 D_fake: 0.773 \n",
      "(epoch: 164, iters: 516, time: 0.223, data: 0.002) G_GAN: 0.910 G_L1: 4.766 D_real: 1.035 D_fake: 0.377 \n",
      "(epoch: 164, iters: 616, time: 0.147, data: 0.002) G_GAN: 1.204 G_L1: 4.988 D_real: 0.913 D_fake: 0.315 \n",
      "(epoch: 164, iters: 716, time: 0.148, data: 0.001) G_GAN: 0.945 G_L1: 5.603 D_real: 0.255 D_fake: 0.869 \n",
      "(epoch: 164, iters: 816, time: 0.148, data: 0.002) G_GAN: 1.032 G_L1: 5.474 D_real: 0.628 D_fake: 0.434 \n",
      "End of epoch 164 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 48, time: 0.216, data: 0.002) G_GAN: 1.117 G_L1: 5.464 D_real: 0.174 D_fake: 0.680 \n",
      "(epoch: 165, iters: 148, time: 0.148, data: 0.001) G_GAN: 0.803 G_L1: 6.510 D_real: 0.868 D_fake: 0.439 \n",
      "(epoch: 165, iters: 248, time: 0.147, data: 0.001) G_GAN: 1.020 G_L1: 4.509 D_real: 1.659 D_fake: 0.221 \n",
      "(epoch: 165, iters: 348, time: 0.148, data: 0.001) G_GAN: 1.027 G_L1: 5.937 D_real: 0.274 D_fake: 0.732 \n",
      "(epoch: 165, iters: 448, time: 0.223, data: 0.002) G_GAN: 1.026 G_L1: 5.212 D_real: 0.500 D_fake: 0.561 \n",
      "(epoch: 165, iters: 548, time: 0.148, data: 0.002) G_GAN: 0.762 G_L1: 5.506 D_real: 0.797 D_fake: 0.546 \n",
      "(epoch: 165, iters: 648, time: 0.147, data: 0.001) G_GAN: 1.018 G_L1: 5.929 D_real: 0.547 D_fake: 0.343 \n",
      "(epoch: 165, iters: 748, time: 0.148, data: 0.002) G_GAN: 1.613 G_L1: 7.838 D_real: 0.193 D_fake: 0.273 \n",
      "(epoch: 165, iters: 848, time: 0.234, data: 0.001) G_GAN: 0.853 G_L1: 4.513 D_real: 0.542 D_fake: 0.802 \n",
      "saving the model at the end of epoch 165, iters 143220\n",
      "End of epoch 165 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 80, time: 0.148, data: 0.002) G_GAN: 1.263 G_L1: 5.773 D_real: 1.328 D_fake: 0.161 \n",
      "(epoch: 166, iters: 180, time: 0.148, data: 0.001) G_GAN: 0.739 G_L1: 3.844 D_real: 0.597 D_fake: 0.784 \n",
      "(epoch: 166, iters: 280, time: 0.148, data: 0.002) G_GAN: 1.046 G_L1: 5.508 D_real: 0.583 D_fake: 0.644 \n",
      "(epoch: 166, iters: 380, time: 0.221, data: 0.002) G_GAN: 1.124 G_L1: 5.726 D_real: 0.940 D_fake: 0.245 \n",
      "(epoch: 166, iters: 480, time: 0.147, data: 0.002) G_GAN: 0.891 G_L1: 5.882 D_real: 0.786 D_fake: 0.426 \n",
      "(epoch: 166, iters: 580, time: 0.147, data: 0.002) G_GAN: 1.039 G_L1: 5.475 D_real: 0.604 D_fake: 0.424 \n",
      "(epoch: 166, iters: 680, time: 0.147, data: 0.002) G_GAN: 0.861 G_L1: 5.347 D_real: 1.084 D_fake: 0.505 \n",
      "(epoch: 166, iters: 780, time: 0.223, data: 0.002) G_GAN: 0.990 G_L1: 5.567 D_real: 0.511 D_fake: 0.467 \n",
      "End of epoch 166 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 12, time: 0.147, data: 0.001) G_GAN: 1.368 G_L1: 6.526 D_real: 1.252 D_fake: 0.139 \n",
      "(epoch: 167, iters: 112, time: 0.147, data: 0.001) G_GAN: 1.015 G_L1: 5.240 D_real: 0.814 D_fake: 0.382 \n",
      "(epoch: 167, iters: 212, time: 0.147, data: 0.002) G_GAN: 1.105 G_L1: 5.571 D_real: 0.434 D_fake: 0.377 \n",
      "(epoch: 167, iters: 312, time: 0.223, data: 0.002) G_GAN: 1.238 G_L1: 6.177 D_real: 0.399 D_fake: 0.401 \n",
      "(epoch: 167, iters: 412, time: 0.148, data: 0.002) G_GAN: 0.951 G_L1: 6.523 D_real: 0.809 D_fake: 0.414 \n",
      "(epoch: 167, iters: 512, time: 0.148, data: 0.002) G_GAN: 0.940 G_L1: 3.700 D_real: 0.638 D_fake: 0.472 \n",
      "(epoch: 167, iters: 612, time: 0.147, data: 0.002) G_GAN: 1.102 G_L1: 5.121 D_real: 1.197 D_fake: 0.323 \n",
      "(epoch: 167, iters: 712, time: 0.237, data: 0.002) G_GAN: 1.084 G_L1: 5.873 D_real: 0.913 D_fake: 0.418 \n",
      "(epoch: 167, iters: 812, time: 0.148, data: 0.001) G_GAN: 1.127 G_L1: 4.528 D_real: 1.043 D_fake: 0.311 \n",
      "End of epoch 167 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 44, time: 0.148, data: 0.002) G_GAN: 0.825 G_L1: 5.827 D_real: 0.312 D_fake: 0.983 \n",
      "saving the latest model (epoch 168, total_iters 145000)\n",
      "(epoch: 168, iters: 144, time: 0.148, data: 0.001) G_GAN: 0.962 G_L1: 5.474 D_real: 0.370 D_fake: 0.663 \n",
      "(epoch: 168, iters: 244, time: 0.222, data: 0.002) G_GAN: 0.768 G_L1: 6.367 D_real: 0.267 D_fake: 1.072 \n",
      "(epoch: 168, iters: 344, time: 0.147, data: 0.002) G_GAN: 0.855 G_L1: 5.318 D_real: 0.368 D_fake: 0.812 \n",
      "(epoch: 168, iters: 444, time: 0.146, data: 0.001) G_GAN: 0.793 G_L1: 6.296 D_real: 0.596 D_fake: 0.634 \n",
      "(epoch: 168, iters: 544, time: 0.147, data: 0.002) G_GAN: 1.124 G_L1: 5.567 D_real: 0.711 D_fake: 0.385 \n",
      "(epoch: 168, iters: 644, time: 0.223, data: 0.002) G_GAN: 1.468 G_L1: 5.594 D_real: 0.774 D_fake: 0.214 \n",
      "(epoch: 168, iters: 744, time: 0.147, data: 0.002) G_GAN: 1.193 G_L1: 5.388 D_real: 0.352 D_fake: 0.484 \n",
      "(epoch: 168, iters: 844, time: 0.147, data: 0.001) G_GAN: 0.918 G_L1: 5.149 D_real: 0.568 D_fake: 0.619 \n",
      "End of epoch 168 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 76, time: 0.147, data: 0.002) G_GAN: 0.898 G_L1: 5.541 D_real: 0.506 D_fake: 0.549 \n",
      "(epoch: 169, iters: 176, time: 0.229, data: 0.001) G_GAN: 1.269 G_L1: 6.055 D_real: 0.409 D_fake: 0.353 \n",
      "(epoch: 169, iters: 276, time: 0.148, data: 0.002) G_GAN: 1.188 G_L1: 6.250 D_real: 0.721 D_fake: 0.372 \n",
      "(epoch: 169, iters: 376, time: 0.147, data: 0.002) G_GAN: 0.806 G_L1: 5.896 D_real: 0.550 D_fake: 0.733 \n",
      "(epoch: 169, iters: 476, time: 0.147, data: 0.001) G_GAN: 0.615 G_L1: 5.779 D_real: 0.303 D_fake: 1.112 \n",
      "(epoch: 169, iters: 576, time: 0.220, data: 0.002) G_GAN: 0.836 G_L1: 5.503 D_real: 0.450 D_fake: 0.687 \n",
      "(epoch: 169, iters: 676, time: 0.147, data: 0.002) G_GAN: 1.068 G_L1: 7.369 D_real: 0.200 D_fake: 0.661 \n",
      "(epoch: 169, iters: 776, time: 0.147, data: 0.002) G_GAN: 0.771 G_L1: 5.911 D_real: 0.395 D_fake: 0.962 \n",
      "End of epoch 169 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 8, time: 0.147, data: 0.002) G_GAN: 1.146 G_L1: 5.923 D_real: 0.858 D_fake: 0.443 \n",
      "(epoch: 170, iters: 108, time: 0.237, data: 0.001) G_GAN: 1.136 G_L1: 6.530 D_real: 0.384 D_fake: 0.529 \n",
      "(epoch: 170, iters: 208, time: 0.148, data: 0.001) G_GAN: 0.704 G_L1: 3.801 D_real: 1.056 D_fake: 0.452 \n",
      "(epoch: 170, iters: 308, time: 0.147, data: 0.002) G_GAN: 0.871 G_L1: 5.618 D_real: 0.578 D_fake: 0.399 \n",
      "(epoch: 170, iters: 408, time: 0.147, data: 0.002) G_GAN: 1.040 G_L1: 4.968 D_real: 0.559 D_fake: 0.646 \n",
      "(epoch: 170, iters: 508, time: 0.223, data: 0.001) G_GAN: 1.121 G_L1: 4.924 D_real: 0.671 D_fake: 0.266 \n",
      "(epoch: 170, iters: 608, time: 0.147, data: 0.002) G_GAN: 0.888 G_L1: 5.699 D_real: 0.274 D_fake: 0.731 \n",
      "(epoch: 170, iters: 708, time: 0.147, data: 0.002) G_GAN: 1.015 G_L1: 4.954 D_real: 0.579 D_fake: 0.558 \n",
      "(epoch: 170, iters: 808, time: 0.147, data: 0.001) G_GAN: 1.082 G_L1: 6.935 D_real: 0.494 D_fake: 0.472 \n",
      "saving the model at the end of epoch 170, iters 147560\n",
      "End of epoch 170 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 40, time: 0.229, data: 0.002) G_GAN: 0.859 G_L1: 5.323 D_real: 0.585 D_fake: 0.444 \n",
      "(epoch: 171, iters: 140, time: 0.148, data: 0.001) G_GAN: 0.885 G_L1: 6.434 D_real: 0.451 D_fake: 0.553 \n",
      "(epoch: 171, iters: 240, time: 0.147, data: 0.002) G_GAN: 0.770 G_L1: 4.614 D_real: 0.794 D_fake: 0.687 \n",
      "(epoch: 171, iters: 340, time: 0.147, data: 0.002) G_GAN: 0.844 G_L1: 6.105 D_real: 0.326 D_fake: 0.772 \n",
      "(epoch: 171, iters: 440, time: 0.224, data: 0.001) G_GAN: 0.736 G_L1: 7.389 D_real: 0.213 D_fake: 1.403 \n",
      "(epoch: 171, iters: 540, time: 0.147, data: 0.001) G_GAN: 0.688 G_L1: 5.960 D_real: 0.203 D_fake: 1.040 \n",
      "(epoch: 171, iters: 640, time: 0.146, data: 0.001) G_GAN: 0.761 G_L1: 6.270 D_real: 0.618 D_fake: 0.732 \n",
      "(epoch: 171, iters: 740, time: 0.146, data: 0.002) G_GAN: 0.834 G_L1: 5.543 D_real: 1.143 D_fake: 0.375 \n",
      "(epoch: 171, iters: 840, time: 0.237, data: 0.001) G_GAN: 0.981 G_L1: 5.825 D_real: 0.746 D_fake: 0.382 \n",
      "End of epoch 171 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 72, time: 0.147, data: 0.002) G_GAN: 0.831 G_L1: 6.020 D_real: 0.591 D_fake: 0.606 \n",
      "(epoch: 172, iters: 172, time: 0.147, data: 0.001) G_GAN: 1.084 G_L1: 5.053 D_real: 0.924 D_fake: 0.285 \n",
      "(epoch: 172, iters: 272, time: 0.147, data: 0.002) G_GAN: 0.711 G_L1: 5.287 D_real: 0.535 D_fake: 0.855 \n",
      "(epoch: 172, iters: 372, time: 0.228, data: 0.001) G_GAN: 1.345 G_L1: 6.418 D_real: 0.820 D_fake: 0.267 \n",
      "(epoch: 172, iters: 472, time: 0.148, data: 0.002) G_GAN: 1.692 G_L1: 7.075 D_real: 0.330 D_fake: 0.210 \n",
      "(epoch: 172, iters: 572, time: 0.147, data: 0.002) G_GAN: 0.860 G_L1: 4.680 D_real: 0.736 D_fake: 0.640 \n",
      "(epoch: 172, iters: 672, time: 0.147, data: 0.002) G_GAN: 1.513 G_L1: 9.047 D_real: 0.044 D_fake: 0.581 \n",
      "(epoch: 172, iters: 772, time: 0.222, data: 0.001) G_GAN: 1.006 G_L1: 3.962 D_real: 0.952 D_fake: 0.369 \n",
      "End of epoch 172 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 4, time: 0.118, data: 0.002) G_GAN: 0.804 G_L1: 5.414 D_real: 0.243 D_fake: 1.102 \n",
      "(epoch: 173, iters: 104, time: 0.147, data: 0.001) G_GAN: 0.802 G_L1: 5.051 D_real: 1.217 D_fake: 0.429 \n",
      "(epoch: 173, iters: 204, time: 0.147, data: 0.001) G_GAN: 1.027 G_L1: 5.352 D_real: 0.289 D_fake: 0.753 \n",
      "(epoch: 173, iters: 304, time: 0.227, data: 0.002) G_GAN: 1.079 G_L1: 3.848 D_real: 0.718 D_fake: 0.427 \n",
      "(epoch: 173, iters: 404, time: 0.147, data: 0.002) G_GAN: 1.194 G_L1: 4.519 D_real: 1.131 D_fake: 0.362 \n",
      "(epoch: 173, iters: 504, time: 0.147, data: 0.002) G_GAN: 0.812 G_L1: 5.896 D_real: 0.628 D_fake: 0.713 \n",
      "(epoch: 173, iters: 604, time: 0.147, data: 0.002) G_GAN: 0.883 G_L1: 5.515 D_real: 0.257 D_fake: 0.993 \n",
      "(epoch: 173, iters: 704, time: 0.224, data: 0.001) G_GAN: 0.906 G_L1: 5.436 D_real: 0.776 D_fake: 0.469 \n",
      "saving the latest model (epoch 173, total_iters 150000)\n",
      "(epoch: 173, iters: 804, time: 0.148, data: 0.001) G_GAN: 1.428 G_L1: 4.491 D_real: 1.618 D_fake: 0.143 \n",
      "End of epoch 173 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 36, time: 0.148, data: 0.002) G_GAN: 1.045 G_L1: 5.218 D_real: 1.001 D_fake: 0.371 \n",
      "(epoch: 174, iters: 136, time: 0.148, data: 0.002) G_GAN: 0.794 G_L1: 5.370 D_real: 0.681 D_fake: 0.568 \n",
      "(epoch: 174, iters: 236, time: 0.241, data: 0.002) G_GAN: 0.779 G_L1: 5.363 D_real: 0.959 D_fake: 0.463 \n",
      "(epoch: 174, iters: 336, time: 0.147, data: 0.002) G_GAN: 0.938 G_L1: 4.457 D_real: 0.362 D_fake: 0.725 \n",
      "(epoch: 174, iters: 436, time: 0.147, data: 0.002) G_GAN: 0.816 G_L1: 4.575 D_real: 0.650 D_fake: 0.529 \n",
      "(epoch: 174, iters: 536, time: 0.147, data: 0.001) G_GAN: 0.922 G_L1: 6.033 D_real: 0.211 D_fake: 0.841 \n",
      "(epoch: 174, iters: 636, time: 0.221, data: 0.002) G_GAN: 1.246 G_L1: 6.254 D_real: 0.571 D_fake: 0.440 \n",
      "(epoch: 174, iters: 736, time: 0.147, data: 0.001) G_GAN: 1.109 G_L1: 7.773 D_real: 0.215 D_fake: 0.599 \n",
      "(epoch: 174, iters: 836, time: 0.147, data: 0.002) G_GAN: 0.894 G_L1: 5.377 D_real: 1.380 D_fake: 0.411 \n",
      "End of epoch 174 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 68, time: 0.148, data: 0.002) G_GAN: 0.980 G_L1: 6.127 D_real: 0.547 D_fake: 0.380 \n",
      "(epoch: 175, iters: 168, time: 0.224, data: 0.002) G_GAN: 1.474 G_L1: 5.527 D_real: 1.659 D_fake: 0.159 \n",
      "(epoch: 175, iters: 268, time: 0.147, data: 0.002) G_GAN: 0.880 G_L1: 5.997 D_real: 0.337 D_fake: 0.932 \n",
      "(epoch: 175, iters: 368, time: 0.147, data: 0.002) G_GAN: 0.884 G_L1: 5.730 D_real: 0.800 D_fake: 0.559 \n",
      "(epoch: 175, iters: 468, time: 0.148, data: 0.002) G_GAN: 0.907 G_L1: 5.211 D_real: 0.869 D_fake: 0.436 \n",
      "(epoch: 175, iters: 568, time: 0.219, data: 0.002) G_GAN: 1.276 G_L1: 5.169 D_real: 0.177 D_fake: 0.589 \n",
      "(epoch: 175, iters: 668, time: 0.148, data: 0.002) G_GAN: 1.511 G_L1: 7.821 D_real: 0.091 D_fake: 0.272 \n",
      "(epoch: 175, iters: 768, time: 0.147, data: 0.002) G_GAN: 1.040 G_L1: 5.128 D_real: 0.179 D_fake: 0.793 \n",
      "(epoch: 175, iters: 868, time: 0.148, data: 0.001) G_GAN: 1.130 G_L1: 5.195 D_real: 0.811 D_fake: 0.334 \n",
      "saving the model at the end of epoch 175, iters 151900\n",
      "End of epoch 175 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 100, time: 0.239, data: 0.103) G_GAN: 1.292 G_L1: 5.863 D_real: 0.379 D_fake: 0.443 \n",
      "(epoch: 176, iters: 200, time: 0.147, data: 0.002) G_GAN: 0.839 G_L1: 6.747 D_real: 0.469 D_fake: 0.716 \n",
      "(epoch: 176, iters: 300, time: 0.147, data: 0.002) G_GAN: 0.521 G_L1: 4.248 D_real: 0.353 D_fake: 1.274 \n",
      "(epoch: 176, iters: 400, time: 0.148, data: 0.002) G_GAN: 1.193 G_L1: 5.512 D_real: 0.561 D_fake: 0.403 \n",
      "(epoch: 176, iters: 500, time: 0.231, data: 0.001) G_GAN: 1.353 G_L1: 5.314 D_real: 0.736 D_fake: 0.249 \n",
      "(epoch: 176, iters: 600, time: 0.147, data: 0.002) G_GAN: 0.787 G_L1: 5.754 D_real: 0.467 D_fake: 0.694 \n",
      "(epoch: 176, iters: 700, time: 0.148, data: 0.002) G_GAN: 0.947 G_L1: 8.154 D_real: 0.319 D_fake: 0.645 \n",
      "(epoch: 176, iters: 800, time: 0.147, data: 0.002) G_GAN: 1.053 G_L1: 5.288 D_real: 0.633 D_fake: 0.470 \n",
      "End of epoch 176 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 32, time: 0.230, data: 0.002) G_GAN: 0.906 G_L1: 5.916 D_real: 0.768 D_fake: 0.555 \n",
      "(epoch: 177, iters: 132, time: 0.148, data: 0.002) G_GAN: 0.720 G_L1: 4.782 D_real: 0.899 D_fake: 0.663 \n",
      "(epoch: 177, iters: 232, time: 0.148, data: 0.002) G_GAN: 0.962 G_L1: 4.714 D_real: 0.945 D_fake: 0.366 \n",
      "(epoch: 177, iters: 332, time: 0.148, data: 0.002) G_GAN: 1.190 G_L1: 6.169 D_real: 0.332 D_fake: 0.593 \n",
      "(epoch: 177, iters: 432, time: 0.231, data: 0.001) G_GAN: 1.017 G_L1: 4.358 D_real: 0.819 D_fake: 0.338 \n",
      "(epoch: 177, iters: 532, time: 0.147, data: 0.002) G_GAN: 0.681 G_L1: 6.304 D_real: 0.248 D_fake: 1.097 \n",
      "(epoch: 177, iters: 632, time: 0.147, data: 0.002) G_GAN: 1.096 G_L1: 4.751 D_real: 0.777 D_fake: 0.399 \n",
      "(epoch: 177, iters: 732, time: 0.147, data: 0.002) G_GAN: 0.794 G_L1: 5.679 D_real: 0.416 D_fake: 0.932 \n",
      "(epoch: 177, iters: 832, time: 0.240, data: 0.002) G_GAN: 0.691 G_L1: 5.755 D_real: 0.581 D_fake: 0.758 \n",
      "End of epoch 177 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 64, time: 0.147, data: 0.002) G_GAN: 1.058 G_L1: 4.730 D_real: 0.772 D_fake: 0.396 \n",
      "(epoch: 178, iters: 164, time: 0.148, data: 0.002) G_GAN: 0.854 G_L1: 6.685 D_real: 0.512 D_fake: 0.717 \n",
      "(epoch: 178, iters: 264, time: 0.148, data: 0.002) G_GAN: 0.750 G_L1: 5.095 D_real: 0.683 D_fake: 0.695 \n",
      "(epoch: 178, iters: 364, time: 0.229, data: 0.001) G_GAN: 0.797 G_L1: 6.822 D_real: 0.410 D_fake: 0.745 \n",
      "(epoch: 178, iters: 464, time: 0.148, data: 0.002) G_GAN: 0.888 G_L1: 5.445 D_real: 0.709 D_fake: 0.434 \n",
      "(epoch: 178, iters: 564, time: 0.148, data: 0.002) G_GAN: 0.726 G_L1: 6.132 D_real: 0.522 D_fake: 0.692 \n",
      "(epoch: 178, iters: 664, time: 0.148, data: 0.002) G_GAN: 0.920 G_L1: 5.753 D_real: 0.567 D_fake: 0.484 \n",
      "(epoch: 178, iters: 764, time: 0.226, data: 0.002) G_GAN: 1.179 G_L1: 5.334 D_real: 0.943 D_fake: 0.243 \n",
      "(epoch: 178, iters: 864, time: 0.148, data: 0.002) G_GAN: 0.903 G_L1: 5.316 D_real: 0.890 D_fake: 0.454 \n",
      "End of epoch 178 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 96, time: 0.148, data: 0.002) G_GAN: 0.905 G_L1: 4.743 D_real: 0.325 D_fake: 0.844 \n",
      "(epoch: 179, iters: 196, time: 0.147, data: 0.002) G_GAN: 1.153 G_L1: 5.283 D_real: 0.608 D_fake: 0.347 \n",
      "(epoch: 179, iters: 296, time: 0.229, data: 0.002) G_GAN: 0.973 G_L1: 4.431 D_real: 0.869 D_fake: 0.372 \n",
      "(epoch: 179, iters: 396, time: 0.148, data: 0.002) G_GAN: 0.941 G_L1: 4.820 D_real: 0.834 D_fake: 0.405 \n",
      "(epoch: 179, iters: 496, time: 0.148, data: 0.002) G_GAN: 0.819 G_L1: 6.876 D_real: 0.380 D_fake: 0.725 \n",
      "saving the latest model (epoch 179, total_iters 155000)\n",
      "(epoch: 179, iters: 596, time: 0.148, data: 0.001) G_GAN: 1.762 G_L1: 6.296 D_real: 1.115 D_fake: 0.145 \n",
      "(epoch: 179, iters: 696, time: 0.241, data: 0.001) G_GAN: 1.041 G_L1: 6.140 D_real: 0.425 D_fake: 0.591 \n",
      "(epoch: 179, iters: 796, time: 0.147, data: 0.002) G_GAN: 0.967 G_L1: 6.162 D_real: 1.001 D_fake: 0.478 \n",
      "End of epoch 179 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000416\n",
      "(epoch: 180, iters: 28, time: 0.148, data: 0.002) G_GAN: 1.103 G_L1: 6.397 D_real: 0.740 D_fake: 0.375 \n",
      "(epoch: 180, iters: 128, time: 0.147, data: 0.001) G_GAN: 0.825 G_L1: 7.173 D_real: 0.457 D_fake: 0.665 \n",
      "(epoch: 180, iters: 228, time: 0.228, data: 0.002) G_GAN: 0.712 G_L1: 4.950 D_real: 0.596 D_fake: 0.817 \n",
      "(epoch: 180, iters: 328, time: 0.148, data: 0.002) G_GAN: 0.720 G_L1: 7.350 D_real: 0.484 D_fake: 0.744 \n",
      "(epoch: 180, iters: 428, time: 0.148, data: 0.002) G_GAN: 1.145 G_L1: 6.595 D_real: 0.361 D_fake: 0.458 \n",
      "(epoch: 180, iters: 528, time: 0.148, data: 0.002) G_GAN: 0.888 G_L1: 5.839 D_real: 0.659 D_fake: 0.688 \n",
      "(epoch: 180, iters: 628, time: 0.224, data: 0.001) G_GAN: 0.851 G_L1: 6.364 D_real: 0.149 D_fake: 0.952 \n",
      "(epoch: 180, iters: 728, time: 0.147, data: 0.002) G_GAN: 1.300 G_L1: 5.131 D_real: 1.566 D_fake: 0.201 \n",
      "(epoch: 180, iters: 828, time: 0.147, data: 0.002) G_GAN: 0.669 G_L1: 5.608 D_real: 0.656 D_fake: 0.788 \n",
      "saving the model at the end of epoch 180, iters 156240\n",
      "End of epoch 180 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 60, time: 0.147, data: 0.002) G_GAN: 1.065 G_L1: 5.149 D_real: 0.889 D_fake: 0.325 \n",
      "(epoch: 181, iters: 160, time: 0.224, data: 0.001) G_GAN: 0.974 G_L1: 5.176 D_real: 0.265 D_fake: 0.588 \n",
      "(epoch: 181, iters: 260, time: 0.147, data: 0.002) G_GAN: 0.887 G_L1: 7.301 D_real: 0.907 D_fake: 0.432 \n",
      "(epoch: 181, iters: 360, time: 0.147, data: 0.002) G_GAN: 0.882 G_L1: 4.699 D_real: 0.819 D_fake: 0.460 \n",
      "(epoch: 181, iters: 460, time: 0.148, data: 0.002) G_GAN: 1.470 G_L1: 6.182 D_real: 0.171 D_fake: 0.309 \n",
      "(epoch: 181, iters: 560, time: 0.228, data: 0.002) G_GAN: 1.176 G_L1: 5.941 D_real: 0.926 D_fake: 0.329 \n",
      "(epoch: 181, iters: 660, time: 0.147, data: 0.002) G_GAN: 0.810 G_L1: 4.796 D_real: 0.472 D_fake: 0.719 \n",
      "(epoch: 181, iters: 760, time: 0.147, data: 0.001) G_GAN: 0.920 G_L1: 5.998 D_real: 0.524 D_fake: 0.528 \n",
      "(epoch: 181, iters: 860, time: 0.147, data: 0.002) G_GAN: 0.648 G_L1: 6.146 D_real: 0.502 D_fake: 0.885 \n",
      "End of epoch 181 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 92, time: 0.239, data: 0.002) G_GAN: 1.083 G_L1: 5.256 D_real: 0.667 D_fake: 0.413 \n",
      "(epoch: 182, iters: 192, time: 0.148, data: 0.002) G_GAN: 0.883 G_L1: 4.628 D_real: 0.960 D_fake: 0.545 \n",
      "(epoch: 182, iters: 292, time: 0.148, data: 0.001) G_GAN: 0.792 G_L1: 5.702 D_real: 0.362 D_fake: 0.713 \n",
      "(epoch: 182, iters: 392, time: 0.147, data: 0.001) G_GAN: 0.708 G_L1: 5.029 D_real: 0.407 D_fake: 0.893 \n",
      "(epoch: 182, iters: 492, time: 0.245, data: 0.002) G_GAN: 0.686 G_L1: 5.024 D_real: 0.257 D_fake: 1.205 \n",
      "(epoch: 182, iters: 592, time: 0.148, data: 0.002) G_GAN: 1.155 G_L1: 5.608 D_real: 0.441 D_fake: 0.439 \n",
      "(epoch: 182, iters: 692, time: 0.148, data: 0.002) G_GAN: 0.760 G_L1: 5.307 D_real: 0.435 D_fake: 0.844 \n",
      "(epoch: 182, iters: 792, time: 0.148, data: 0.001) G_GAN: 1.220 G_L1: 5.786 D_real: 0.859 D_fake: 0.292 \n",
      "End of epoch 182 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 24, time: 0.235, data: 0.002) G_GAN: 1.019 G_L1: 5.395 D_real: 0.724 D_fake: 0.533 \n",
      "(epoch: 183, iters: 124, time: 0.147, data: 0.001) G_GAN: 0.964 G_L1: 5.259 D_real: 0.591 D_fake: 0.515 \n",
      "(epoch: 183, iters: 224, time: 0.147, data: 0.001) G_GAN: 0.998 G_L1: 4.554 D_real: 1.307 D_fake: 0.349 \n",
      "(epoch: 183, iters: 324, time: 0.148, data: 0.001) G_GAN: 0.790 G_L1: 5.828 D_real: 0.568 D_fake: 0.706 \n",
      "(epoch: 183, iters: 424, time: 0.227, data: 0.002) G_GAN: 0.962 G_L1: 6.749 D_real: 0.504 D_fake: 0.521 \n",
      "(epoch: 183, iters: 524, time: 0.148, data: 0.002) G_GAN: 1.094 G_L1: 5.338 D_real: 0.347 D_fake: 0.534 \n",
      "(epoch: 183, iters: 624, time: 0.148, data: 0.002) G_GAN: 1.357 G_L1: 6.041 D_real: 0.196 D_fake: 0.375 \n",
      "(epoch: 183, iters: 724, time: 0.148, data: 0.001) G_GAN: 0.925 G_L1: 5.948 D_real: 1.150 D_fake: 0.490 \n",
      "(epoch: 183, iters: 824, time: 0.244, data: 0.001) G_GAN: 1.003 G_L1: 5.658 D_real: 0.526 D_fake: 0.497 \n",
      "End of epoch 183 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 56, time: 0.148, data: 0.002) G_GAN: 1.186 G_L1: 4.908 D_real: 0.931 D_fake: 0.324 \n",
      "(epoch: 184, iters: 156, time: 0.147, data: 0.002) G_GAN: 0.846 G_L1: 5.752 D_real: 0.119 D_fake: 0.830 \n",
      "(epoch: 184, iters: 256, time: 0.147, data: 0.002) G_GAN: 1.362 G_L1: 4.790 D_real: 0.540 D_fake: 0.296 \n",
      "(epoch: 184, iters: 356, time: 0.228, data: 0.002) G_GAN: 0.870 G_L1: 4.921 D_real: 0.519 D_fake: 0.688 \n",
      "(epoch: 184, iters: 456, time: 0.148, data: 0.002) G_GAN: 0.798 G_L1: 4.409 D_real: 0.472 D_fake: 0.766 \n",
      "(epoch: 184, iters: 556, time: 0.147, data: 0.002) G_GAN: 0.847 G_L1: 4.618 D_real: 0.444 D_fake: 0.764 \n",
      "(epoch: 184, iters: 656, time: 0.148, data: 0.001) G_GAN: 0.765 G_L1: 5.717 D_real: 0.632 D_fake: 0.639 \n",
      "(epoch: 184, iters: 756, time: 0.233, data: 0.001) G_GAN: 0.853 G_L1: 5.626 D_real: 0.738 D_fake: 0.604 \n",
      "(epoch: 184, iters: 856, time: 0.148, data: 0.002) G_GAN: 1.205 G_L1: 5.174 D_real: 0.567 D_fake: 0.332 \n",
      "End of epoch 184 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 88, time: 0.148, data: 0.001) G_GAN: 0.560 G_L1: 5.928 D_real: 0.386 D_fake: 1.248 \n",
      "(epoch: 185, iters: 188, time: 0.148, data: 0.002) G_GAN: 0.857 G_L1: 5.112 D_real: 0.512 D_fake: 0.641 \n",
      "(epoch: 185, iters: 288, time: 0.228, data: 0.002) G_GAN: 1.449 G_L1: 6.867 D_real: 0.393 D_fake: 0.269 \n",
      "saving the latest model (epoch 185, total_iters 160000)\n",
      "(epoch: 185, iters: 388, time: 0.148, data: 0.001) G_GAN: 0.919 G_L1: 5.061 D_real: 0.721 D_fake: 0.514 \n",
      "(epoch: 185, iters: 488, time: 0.148, data: 0.002) G_GAN: 0.996 G_L1: 8.181 D_real: 0.252 D_fake: 0.705 \n",
      "(epoch: 185, iters: 588, time: 0.148, data: 0.002) G_GAN: 0.811 G_L1: 4.792 D_real: 0.257 D_fake: 0.907 \n",
      "(epoch: 185, iters: 688, time: 0.236, data: 0.001) G_GAN: 0.893 G_L1: 5.755 D_real: 0.880 D_fake: 0.603 \n",
      "(epoch: 185, iters: 788, time: 0.148, data: 0.001) G_GAN: 0.793 G_L1: 5.750 D_real: 0.330 D_fake: 0.811 \n",
      "saving the model at the end of epoch 185, iters 160580\n",
      "End of epoch 185 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 20, time: 0.147, data: 0.002) G_GAN: 1.485 G_L1: 6.960 D_real: 1.168 D_fake: 0.182 \n",
      "(epoch: 186, iters: 120, time: 0.148, data: 0.001) G_GAN: 0.750 G_L1: 6.114 D_real: 0.465 D_fake: 0.802 \n",
      "(epoch: 186, iters: 220, time: 0.230, data: 0.001) G_GAN: 1.332 G_L1: 4.242 D_real: 1.098 D_fake: 0.288 \n",
      "(epoch: 186, iters: 320, time: 0.148, data: 0.002) G_GAN: 0.794 G_L1: 5.370 D_real: 0.511 D_fake: 0.709 \n",
      "(epoch: 186, iters: 420, time: 0.147, data: 0.002) G_GAN: 1.259 G_L1: 7.135 D_real: 0.500 D_fake: 0.325 \n",
      "(epoch: 186, iters: 520, time: 0.148, data: 0.002) G_GAN: 0.853 G_L1: 5.766 D_real: 0.798 D_fake: 0.538 \n",
      "(epoch: 186, iters: 620, time: 0.231, data: 0.002) G_GAN: 0.961 G_L1: 6.032 D_real: 0.377 D_fake: 0.605 \n",
      "(epoch: 186, iters: 720, time: 0.147, data: 0.002) G_GAN: 0.996 G_L1: 5.292 D_real: 1.056 D_fake: 0.436 \n",
      "(epoch: 186, iters: 820, time: 0.147, data: 0.002) G_GAN: 1.136 G_L1: 7.266 D_real: 0.561 D_fake: 0.403 \n",
      "End of epoch 186 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 52, time: 0.147, data: 0.002) G_GAN: 1.549 G_L1: 6.181 D_real: 0.614 D_fake: 0.226 \n",
      "(epoch: 187, iters: 152, time: 0.226, data: 0.002) G_GAN: 1.290 G_L1: 4.790 D_real: 0.837 D_fake: 0.280 \n",
      "(epoch: 187, iters: 252, time: 0.147, data: 0.002) G_GAN: 0.831 G_L1: 6.925 D_real: 0.625 D_fake: 0.651 \n",
      "(epoch: 187, iters: 352, time: 0.148, data: 0.001) G_GAN: 0.781 G_L1: 4.918 D_real: 0.369 D_fake: 0.817 \n",
      "(epoch: 187, iters: 452, time: 0.147, data: 0.002) G_GAN: 0.963 G_L1: 5.988 D_real: 0.431 D_fake: 0.631 \n",
      "(epoch: 187, iters: 552, time: 0.245, data: 0.002) G_GAN: 0.824 G_L1: 7.097 D_real: 0.471 D_fake: 0.722 \n",
      "(epoch: 187, iters: 652, time: 0.147, data: 0.002) G_GAN: 1.043 G_L1: 5.930 D_real: 0.301 D_fake: 0.514 \n",
      "(epoch: 187, iters: 752, time: 0.148, data: 0.002) G_GAN: 0.817 G_L1: 6.231 D_real: 0.587 D_fake: 0.653 \n",
      "(epoch: 187, iters: 852, time: 0.148, data: 0.002) G_GAN: 1.210 G_L1: 5.352 D_real: 0.769 D_fake: 0.355 \n",
      "End of epoch 187 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 84, time: 0.234, data: 0.001) G_GAN: 0.772 G_L1: 5.470 D_real: 0.200 D_fake: 0.857 \n",
      "(epoch: 188, iters: 184, time: 0.147, data: 0.001) G_GAN: 1.184 G_L1: 5.860 D_real: 1.375 D_fake: 0.291 \n",
      "(epoch: 188, iters: 284, time: 0.147, data: 0.002) G_GAN: 0.663 G_L1: 4.811 D_real: 0.658 D_fake: 0.889 \n",
      "(epoch: 188, iters: 384, time: 0.147, data: 0.001) G_GAN: 0.894 G_L1: 5.252 D_real: 0.590 D_fake: 0.526 \n",
      "(epoch: 188, iters: 484, time: 0.248, data: 0.002) G_GAN: 1.055 G_L1: 6.181 D_real: 1.157 D_fake: 0.399 \n",
      "(epoch: 188, iters: 584, time: 0.161, data: 0.002) G_GAN: 0.835 G_L1: 5.510 D_real: 0.522 D_fake: 0.594 \n",
      "(epoch: 188, iters: 684, time: 0.147, data: 0.001) G_GAN: 1.543 G_L1: 5.799 D_real: 1.281 D_fake: 0.175 \n",
      "(epoch: 188, iters: 784, time: 0.147, data: 0.001) G_GAN: 1.243 G_L1: 4.374 D_real: 1.108 D_fake: 0.319 \n",
      "End of epoch 188 / 200 \t Time Taken: 84 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 16, time: 0.232, data: 0.002) G_GAN: 1.528 G_L1: 3.608 D_real: 0.818 D_fake: 0.240 \n",
      "(epoch: 189, iters: 116, time: 0.147, data: 0.003) G_GAN: 0.886 G_L1: 4.304 D_real: 1.152 D_fake: 0.486 \n",
      "(epoch: 189, iters: 216, time: 0.154, data: 0.002) G_GAN: 0.775 G_L1: 4.953 D_real: 0.718 D_fake: 0.630 \n",
      "(epoch: 189, iters: 316, time: 0.147, data: 0.002) G_GAN: 0.927 G_L1: 2.599 D_real: 0.872 D_fake: 0.434 \n",
      "(epoch: 189, iters: 416, time: 0.245, data: 0.002) G_GAN: 0.950 G_L1: 5.181 D_real: 0.511 D_fake: 0.577 \n",
      "(epoch: 189, iters: 516, time: 0.147, data: 0.002) G_GAN: 1.168 G_L1: 5.249 D_real: 0.617 D_fake: 0.349 \n",
      "(epoch: 189, iters: 616, time: 0.147, data: 0.002) G_GAN: 0.736 G_L1: 5.324 D_real: 0.270 D_fake: 1.011 \n",
      "(epoch: 189, iters: 716, time: 0.147, data: 0.002) G_GAN: 0.909 G_L1: 6.379 D_real: 0.338 D_fake: 0.602 \n",
      "(epoch: 189, iters: 816, time: 0.229, data: 0.001) G_GAN: 1.102 G_L1: 6.231 D_real: 0.451 D_fake: 0.411 \n",
      "End of epoch 189 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 48, time: 0.147, data: 0.002) G_GAN: 0.923 G_L1: 5.108 D_real: 0.320 D_fake: 0.614 \n",
      "(epoch: 190, iters: 148, time: 0.147, data: 0.002) G_GAN: 0.960 G_L1: 5.521 D_real: 0.447 D_fake: 0.587 \n",
      "(epoch: 190, iters: 248, time: 0.148, data: 0.002) G_GAN: 0.665 G_L1: 5.193 D_real: 0.639 D_fake: 0.852 \n",
      "(epoch: 190, iters: 348, time: 0.233, data: 0.002) G_GAN: 0.722 G_L1: 5.661 D_real: 0.253 D_fake: 0.849 \n",
      "(epoch: 190, iters: 448, time: 0.147, data: 0.002) G_GAN: 1.423 G_L1: 5.024 D_real: 0.815 D_fake: 0.294 \n",
      "(epoch: 190, iters: 548, time: 0.148, data: 0.002) G_GAN: 0.691 G_L1: 6.334 D_real: 0.145 D_fake: 1.206 \n",
      "(epoch: 190, iters: 648, time: 1.143, data: 0.003) G_GAN: 0.966 G_L1: 4.974 D_real: 0.811 D_fake: 0.435 \n",
      "(epoch: 190, iters: 748, time: 0.224, data: 0.002) G_GAN: 0.805 G_L1: 4.838 D_real: 0.631 D_fake: 0.681 \n",
      "(epoch: 190, iters: 848, time: 0.144, data: 0.002) G_GAN: 0.867 G_L1: 6.586 D_real: 0.638 D_fake: 0.605 \n",
      "saving the model at the end of epoch 190, iters 164920\n",
      "End of epoch 190 / 200 \t Time Taken: 174 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 80, time: 0.146, data: 0.002) G_GAN: 0.902 G_L1: 6.138 D_real: 1.070 D_fake: 0.504 \n",
      "saving the latest model (epoch 191, total_iters 165000)\n",
      "(epoch: 191, iters: 180, time: 0.147, data: 0.001) G_GAN: 0.969 G_L1: 6.291 D_real: 0.773 D_fake: 0.524 \n",
      "(epoch: 191, iters: 280, time: 0.242, data: 0.002) G_GAN: 1.101 G_L1: 3.643 D_real: 1.021 D_fake: 0.309 \n",
      "(epoch: 191, iters: 380, time: 0.148, data: 0.002) G_GAN: 1.193 G_L1: 6.762 D_real: 0.485 D_fake: 0.393 \n",
      "(epoch: 191, iters: 480, time: 0.148, data: 0.002) G_GAN: 1.667 G_L1: 4.560 D_real: 0.249 D_fake: 0.230 \n",
      "(epoch: 191, iters: 580, time: 0.148, data: 0.002) G_GAN: 1.039 G_L1: 5.266 D_real: 0.498 D_fake: 0.441 \n",
      "(epoch: 191, iters: 680, time: 0.231, data: 0.002) G_GAN: 0.892 G_L1: 4.874 D_real: 0.532 D_fake: 0.577 \n",
      "(epoch: 191, iters: 780, time: 0.147, data: 0.002) G_GAN: 1.794 G_L1: 6.782 D_real: 0.853 D_fake: 0.174 \n",
      "End of epoch 191 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 12, time: 0.147, data: 0.001) G_GAN: 0.717 G_L1: 5.286 D_real: 0.555 D_fake: 0.737 \n",
      "(epoch: 192, iters: 112, time: 0.149, data: 0.001) G_GAN: 0.732 G_L1: 5.496 D_real: 0.502 D_fake: 0.705 \n",
      "(epoch: 192, iters: 212, time: 0.233, data: 0.001) G_GAN: 1.075 G_L1: 4.850 D_real: 0.426 D_fake: 0.448 \n",
      "(epoch: 192, iters: 312, time: 0.148, data: 0.002) G_GAN: 1.053 G_L1: 4.234 D_real: 1.175 D_fake: 0.399 \n",
      "(epoch: 192, iters: 412, time: 0.147, data: 0.002) G_GAN: 0.710 G_L1: 5.679 D_real: 0.366 D_fake: 0.797 \n",
      "(epoch: 192, iters: 512, time: 0.150, data: 0.002) G_GAN: 1.203 G_L1: 4.812 D_real: 1.033 D_fake: 0.351 \n",
      "(epoch: 192, iters: 612, time: 0.232, data: 0.002) G_GAN: 0.877 G_L1: 5.599 D_real: 0.696 D_fake: 0.508 \n",
      "(epoch: 192, iters: 712, time: 0.147, data: 0.002) G_GAN: 0.970 G_L1: 7.213 D_real: 0.348 D_fake: 0.517 \n",
      "(epoch: 192, iters: 812, time: 0.147, data: 0.002) G_GAN: 0.898 G_L1: 5.159 D_real: 0.399 D_fake: 0.589 \n",
      "End of epoch 192 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 44, time: 0.148, data: 0.001) G_GAN: 0.682 G_L1: 4.154 D_real: 0.336 D_fake: 0.847 \n",
      "(epoch: 193, iters: 144, time: 0.243, data: 0.002) G_GAN: 0.856 G_L1: 6.200 D_real: 0.601 D_fake: 0.570 \n",
      "(epoch: 193, iters: 244, time: 0.147, data: 0.001) G_GAN: 0.988 G_L1: 5.302 D_real: 0.623 D_fake: 0.493 \n",
      "(epoch: 193, iters: 344, time: 0.147, data: 0.001) G_GAN: 1.038 G_L1: 5.405 D_real: 0.700 D_fake: 0.447 \n",
      "(epoch: 193, iters: 444, time: 0.147, data: 0.002) G_GAN: 0.801 G_L1: 5.461 D_real: 0.467 D_fake: 0.702 \n",
      "(epoch: 193, iters: 544, time: 0.237, data: 0.001) G_GAN: 1.172 G_L1: 5.549 D_real: 0.643 D_fake: 0.374 \n",
      "(epoch: 193, iters: 644, time: 0.147, data: 0.002) G_GAN: 1.273 G_L1: 6.236 D_real: 0.930 D_fake: 0.312 \n",
      "(epoch: 193, iters: 744, time: 0.147, data: 0.001) G_GAN: 1.099 G_L1: 6.174 D_real: 0.884 D_fake: 0.387 \n",
      "(epoch: 193, iters: 844, time: 0.153, data: 0.002) G_GAN: 1.045 G_L1: 6.694 D_real: 0.608 D_fake: 0.450 \n",
      "End of epoch 193 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 76, time: 0.234, data: 0.001) G_GAN: 1.363 G_L1: 5.953 D_real: 0.421 D_fake: 0.334 \n",
      "(epoch: 194, iters: 176, time: 0.147, data: 0.002) G_GAN: 1.306 G_L1: 4.363 D_real: 0.927 D_fake: 0.290 \n",
      "(epoch: 194, iters: 276, time: 0.147, data: 0.001) G_GAN: 0.735 G_L1: 5.349 D_real: 0.359 D_fake: 0.743 \n",
      "(epoch: 194, iters: 376, time: 0.147, data: 0.002) G_GAN: 1.293 G_L1: 4.748 D_real: 0.615 D_fake: 0.317 \n",
      "(epoch: 194, iters: 476, time: 0.232, data: 0.002) G_GAN: 0.635 G_L1: 6.661 D_real: 0.429 D_fake: 0.848 \n",
      "(epoch: 194, iters: 576, time: 0.147, data: 0.002) G_GAN: 0.738 G_L1: 4.909 D_real: 0.600 D_fake: 0.766 \n",
      "(epoch: 194, iters: 676, time: 0.147, data: 0.002) G_GAN: 1.025 G_L1: 5.786 D_real: 0.693 D_fake: 0.451 \n",
      "(epoch: 194, iters: 776, time: 0.148, data: 0.001) G_GAN: 0.721 G_L1: 6.398 D_real: 0.629 D_fake: 0.724 \n",
      "End of epoch 194 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 8, time: 0.246, data: 0.002) G_GAN: 1.194 G_L1: 6.678 D_real: 0.672 D_fake: 0.360 \n",
      "(epoch: 195, iters: 108, time: 0.147, data: 0.001) G_GAN: 0.775 G_L1: 4.359 D_real: 0.862 D_fake: 0.661 \n",
      "(epoch: 195, iters: 208, time: 0.148, data: 0.002) G_GAN: 0.832 G_L1: 4.960 D_real: 1.108 D_fake: 0.547 \n",
      "(epoch: 195, iters: 308, time: 0.147, data: 0.001) G_GAN: 0.442 G_L1: 6.776 D_real: 0.278 D_fake: 1.235 \n",
      "(epoch: 195, iters: 408, time: 0.236, data: 0.002) G_GAN: 0.826 G_L1: 5.728 D_real: 0.511 D_fake: 0.635 \n",
      "(epoch: 195, iters: 508, time: 0.148, data: 0.002) G_GAN: 1.114 G_L1: 7.274 D_real: 0.305 D_fake: 0.444 \n",
      "(epoch: 195, iters: 608, time: 0.147, data: 0.001) G_GAN: 0.835 G_L1: 5.591 D_real: 0.488 D_fake: 0.615 \n",
      "(epoch: 195, iters: 708, time: 0.147, data: 0.002) G_GAN: 0.964 G_L1: 4.975 D_real: 0.664 D_fake: 0.493 \n",
      "(epoch: 195, iters: 808, time: 0.235, data: 0.002) G_GAN: 1.533 G_L1: 5.093 D_real: 0.940 D_fake: 0.228 \n",
      "saving the model at the end of epoch 195, iters 169260\n",
      "End of epoch 195 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 40, time: 0.146, data: 0.002) G_GAN: 0.588 G_L1: 5.405 D_real: 0.464 D_fake: 0.932 \n",
      "(epoch: 196, iters: 140, time: 0.146, data: 0.001) G_GAN: 1.436 G_L1: 3.810 D_real: 1.223 D_fake: 0.241 \n",
      "(epoch: 196, iters: 240, time: 0.147, data: 0.002) G_GAN: 1.062 G_L1: 5.100 D_real: 0.519 D_fake: 0.461 \n",
      "(epoch: 196, iters: 340, time: 0.240, data: 0.002) G_GAN: 1.277 G_L1: 6.326 D_real: 1.280 D_fake: 0.306 \n",
      "(epoch: 196, iters: 440, time: 0.147, data: 0.001) G_GAN: 0.640 G_L1: 7.040 D_real: 0.302 D_fake: 0.904 \n",
      "(epoch: 196, iters: 540, time: 0.147, data: 0.001) G_GAN: 1.349 G_L1: 6.218 D_real: 0.666 D_fake: 0.315 \n",
      "(epoch: 196, iters: 640, time: 0.147, data: 0.002) G_GAN: 0.905 G_L1: 6.142 D_real: 0.323 D_fake: 0.551 \n",
      "(epoch: 196, iters: 740, time: 0.232, data: 0.002) G_GAN: 1.041 G_L1: 4.870 D_real: 0.818 D_fake: 0.454 \n",
      "saving the latest model (epoch 196, total_iters 170000)\n",
      "(epoch: 196, iters: 840, time: 0.148, data: 0.002) G_GAN: 1.064 G_L1: 7.874 D_real: 0.098 D_fake: 0.491 \n",
      "End of epoch 196 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 72, time: 0.148, data: 0.001) G_GAN: 0.617 G_L1: 5.332 D_real: 0.200 D_fake: 1.026 \n",
      "(epoch: 197, iters: 172, time: 0.148, data: 0.002) G_GAN: 0.888 G_L1: 5.077 D_real: 0.630 D_fake: 0.543 \n",
      "(epoch: 197, iters: 272, time: 0.235, data: 0.002) G_GAN: 0.589 G_L1: 4.391 D_real: 0.237 D_fake: 1.014 \n",
      "(epoch: 197, iters: 372, time: 0.149, data: 0.002) G_GAN: 1.081 G_L1: 6.443 D_real: 0.586 D_fake: 0.424 \n",
      "(epoch: 197, iters: 472, time: 0.147, data: 0.002) G_GAN: 1.069 G_L1: 5.345 D_real: 0.649 D_fake: 0.434 \n",
      "(epoch: 197, iters: 572, time: 0.147, data: 0.002) G_GAN: 1.125 G_L1: 4.240 D_real: 1.114 D_fake: 0.384 \n",
      "(epoch: 197, iters: 672, time: 0.232, data: 0.002) G_GAN: 0.822 G_L1: 3.618 D_real: 0.723 D_fake: 0.594 \n",
      "(epoch: 197, iters: 772, time: 0.147, data: 0.001) G_GAN: 1.303 G_L1: 5.668 D_real: 0.391 D_fake: 0.338 \n",
      "End of epoch 197 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 4, time: 0.118, data: 0.001) G_GAN: 0.483 G_L1: 6.726 D_real: 0.370 D_fake: 1.079 \n",
      "(epoch: 198, iters: 104, time: 0.147, data: 0.003) G_GAN: 0.751 G_L1: 6.673 D_real: 0.317 D_fake: 0.691 \n",
      "(epoch: 198, iters: 204, time: 0.246, data: 0.002) G_GAN: 0.899 G_L1: 5.079 D_real: 0.696 D_fake: 0.546 \n",
      "(epoch: 198, iters: 304, time: 0.147, data: 0.002) G_GAN: 0.821 G_L1: 6.275 D_real: 0.225 D_fake: 0.632 \n",
      "(epoch: 198, iters: 404, time: 0.148, data: 0.002) G_GAN: 1.285 G_L1: 3.024 D_real: 1.025 D_fake: 0.320 \n",
      "(epoch: 198, iters: 504, time: 0.147, data: 0.002) G_GAN: 1.239 G_L1: 5.828 D_real: 0.976 D_fake: 0.355 \n",
      "(epoch: 198, iters: 604, time: 0.232, data: 0.002) G_GAN: 0.700 G_L1: 6.179 D_real: 0.269 D_fake: 0.763 \n",
      "(epoch: 198, iters: 704, time: 0.147, data: 0.001) G_GAN: 1.097 G_L1: 5.109 D_real: 0.575 D_fake: 0.415 \n",
      "(epoch: 198, iters: 804, time: 0.147, data: 0.002) G_GAN: 0.727 G_L1: 5.812 D_real: 0.351 D_fake: 0.792 \n",
      "End of epoch 198 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 36, time: 0.147, data: 0.002) G_GAN: 0.992 G_L1: 4.588 D_real: 0.820 D_fake: 0.480 \n",
      "(epoch: 199, iters: 136, time: 0.234, data: 0.001) G_GAN: 0.918 G_L1: 6.716 D_real: 0.225 D_fake: 0.548 \n",
      "(epoch: 199, iters: 236, time: 0.146, data: 0.001) G_GAN: 1.370 G_L1: 6.191 D_real: 0.813 D_fake: 0.304 \n",
      "(epoch: 199, iters: 336, time: 0.147, data: 0.001) G_GAN: 1.375 G_L1: 4.879 D_real: 1.302 D_fake: 0.304 \n",
      "(epoch: 199, iters: 436, time: 0.147, data: 0.001) G_GAN: 1.060 G_L1: 5.898 D_real: 0.516 D_fake: 0.462 \n",
      "(epoch: 199, iters: 536, time: 0.232, data: 0.001) G_GAN: 1.058 G_L1: 8.175 D_real: 0.163 D_fake: 0.461 \n",
      "(epoch: 199, iters: 636, time: 0.147, data: 0.002) G_GAN: 0.911 G_L1: 5.903 D_real: 0.631 D_fake: 0.538 \n",
      "(epoch: 199, iters: 736, time: 0.148, data: 0.002) G_GAN: 0.705 G_L1: 5.785 D_real: 0.344 D_fake: 0.736 \n",
      "(epoch: 199, iters: 836, time: 0.147, data: 0.001) G_GAN: 0.931 G_L1: 6.808 D_real: 0.417 D_fake: 0.533 \n",
      "End of epoch 199 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 68, time: 0.249, data: 0.002) G_GAN: 0.420 G_L1: 7.424 D_real: 0.165 D_fake: 1.146 \n",
      "(epoch: 200, iters: 168, time: 0.148, data: 0.002) G_GAN: 0.804 G_L1: 5.352 D_real: 0.298 D_fake: 0.637 \n",
      "(epoch: 200, iters: 268, time: 0.147, data: 0.002) G_GAN: 0.771 G_L1: 5.099 D_real: 0.734 D_fake: 0.652 \n",
      "(epoch: 200, iters: 368, time: 0.147, data: 0.001) G_GAN: 1.122 G_L1: 4.243 D_real: 0.569 D_fake: 0.413 \n",
      "(epoch: 200, iters: 468, time: 0.233, data: 0.001) G_GAN: 0.980 G_L1: 6.273 D_real: 0.674 D_fake: 0.495 \n",
      "(epoch: 200, iters: 568, time: 0.147, data: 0.002) G_GAN: 0.667 G_L1: 5.172 D_real: 0.822 D_fake: 0.755 \n",
      "(epoch: 200, iters: 668, time: 0.147, data: 0.001) G_GAN: 0.770 G_L1: 4.347 D_real: 0.822 D_fake: 0.651 \n",
      "(epoch: 200, iters: 768, time: 0.147, data: 0.002) G_GAN: 1.098 G_L1: 4.838 D_real: 0.839 D_fake: 0.422 \n",
      "(epoch: 200, iters: 868, time: 0.237, data: 0.002) G_GAN: 0.515 G_L1: 7.715 D_real: 0.135 D_fake: 0.995 \n",
      "saving the model at the end of epoch 200, iters 173600\n",
      "End of epoch 200 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot syndata --model pix2pix --checkpoints_dir jun23  --no_flip --batch_size 4  --netG resnet_9blocks --preprocess crop --load_size 512 --name synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimg --results_dir results_mar24_300 --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name pix2pixKSB --input_nc 1 --no_flip --output_nc 1 --norm instance --checkpoints_dir mar24_300 --batch_size 4 --preprocess none --name mar24_300_noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train AB dir 300 images with no preprocess and default flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dB3MY2iwUQmQ",
    "outputId": "b74bcfca-5edf-4e21-d469-d226b42eaf78"
   },
   "outputs": [],
   "source": [
    "!python train.py --dataroot AB --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4  --netG resnet_9blocks --preprocess none --name img300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train AB dir 300 images with no preprocess and noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot AB --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4  --netG resnet_9blocks --preprocess none --no_flip --name img300_noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train AB dir 300 images with crop and default flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot AB --netG resnet_9blocks --preprocess crop  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --name img300_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train AB dir 300 images with crop and noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot AB --netG resnet_9blocks --preprocess crop  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --no_flip --name img300_crop_noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train diff 300 images with crop and default flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot diff --netG resnet_9blocks --preprocess crop  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28_300 --gpu_ids 0,1 --batch_size 4 --name mar28_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train diff 300 images with no preprocess  and no flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot diff --netG resnet_9blocks --preprocess none  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28_300 --gpu_ids 0,1 --batch_size 4 --name mar28_diff_noflip --no_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train nov 1300 images with no preprocess and default flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot nov/AB --netG resnet_9blocks --preprocess none  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --name img1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train nov 1300 images with no preprocess and noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot nov/AB --netG resnet_9blocks --preprocess none  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --name img1300_noflip --no_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train nov 1300 images with crop and default flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot nov/AB --netG resnet_9blocks --crop_size 400 --preprocess crop  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --name img1300_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train nov 1300 images with crop and noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot nov/AB --crop_size 384 --netG resnet_9blocks --preprocess crop  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --name img1300_crop300_noflip --no_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot syn_real_diff_1000/AB --netG resnet_9blocks --preprocess none --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar30 --gpu_ids 0,1 --batch_size 4 --no_flip --name img1000_noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot syn_real_diff_1000/AB --netG resnet_9blocks --preprocess none --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar30 --gpu_ids 0,1 --batch_size 4 --name img1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img1000 --input_nc 1 --norm instance --checkpoints_dir mar30 --batch_size 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img1000_noflip --no_flip --input_nc 1 --norm instance --checkpoints_dir mar30 --batch_size 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SnH_jgPke48o"
   },
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img1300 --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --no_flip --name img1300_noflip --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --no_flip --name img1300_crop_noflip --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img1300_crop --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img300 --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --no_flip --name img300_crop_noflip --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --no_flip --name img300_noflip --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img300_crop --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot lp --results_dir results_lp --model test --dataset_mode single --netG resnet_9blocks --preprocess none --no_flip --name mar28_diff_noflip --input_nc 1 --norm instance --checkpoints_dir mar28_300 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot kalai-cyclegan  --name cyclebw --netG resnet_9blocks --preprocess crop --input_nc 1 --output_nc 1 --norm instance  --checkpoints_dir apr3 --continue_train --epoch_count 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot extracolor/AB --model pix2pix --input_nc 1 --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4  --netG resnet_9blocks --preprocess none --name img300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot ctest --no_dropout --dataset_mode single --model test --results_dir results_cyc --netG resnet_9blocks --preprocess none --name cyclebw  --norm instance --checkpoints_dir apr3 --input_nc 1 --output_nc 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot extracolor/AB --model pix2pix --input_nc 1 --output_nc 1 --norm batch --checkpoints_dir apr18 --netG resnet_9blocks --preprocess none --name apr19real417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: apr18                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: marked_gray/testA             \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: True                          \t[default: False]\n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: apr19real417                  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "                    ntest: inf                           \n",
      "                 num_test: 144                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_apr19real41           \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from apr18/apr19real417/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.371 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['marked_gray/testA/001.jpg']\n",
      "processing (0005)-th image... ['marked_gray/testA/0054-160-m3h--5-h-ksb-etanorm-g-100-200-g11.jpg']\n",
      "processing (0010)-th image... ['marked_gray/testA/010.jpg']\n",
      "processing (0015)-th image... ['marked_gray/testA/015.jpg']\n",
      "processing (0020)-th image... ['marked_gray/testA/020.jpg']\n",
      "processing (0025)-th image... ['marked_gray/testA/025.jpg']\n",
      "processing (0030)-th image... ['marked_gray/testA/030.jpg']\n",
      "processing (0035)-th image... ['marked_gray/testA/035.jpg']\n",
      "processing (0040)-th image... ['marked_gray/testA/040.jpg']\n",
      "processing (0045)-th image... ['marked_gray/testA/045.jpg']\n",
      "processing (0050)-th image... ['marked_gray/testA/050.jpg']\n",
      "processing (0055)-th image... ['marked_gray/testA/055.jpg']\n",
      "processing (0060)-th image... ['marked_gray/testA/060.jpg']\n",
      "processing (0065)-th image... ['marked_gray/testA/065.jpg']\n",
      "processing (0070)-th image... ['marked_gray/testA/070.jpg']\n",
      "processing (0075)-th image... ['marked_gray/testA/075.jpg']\n",
      "processing (0080)-th image... ['marked_gray/testA/080.jpg']\n",
      "processing (0085)-th image... ['marked_gray/testA/085.jpg']\n",
      "processing (0090)-th image... ['marked_gray/testA/090.jpg']\n",
      "processing (0095)-th image... ['marked_gray/testA/095.jpg']\n",
      "processing (0100)-th image... ['marked_gray/testA/1.jpg']\n",
      "The image size needs to be a multiple of 4. The loaded image size was (1801, 1169), so it was adjusted to (1800, 1168). This adjustment will be done to all images whose sizes are not multiples of 4\n",
      "processing (0105)-th image... ['marked_gray/testA/17J-SG02_17J-SG02 nameplate.jpg']\n",
      "processing (0110)-th image... ['marked_gray/testA/2968_3.jpg']\n",
      "processing (0115)-th image... ['marked_gray/testA/4.jpg']\n",
      "processing (0120)-th image... ['marked_gray/testA/7506_3.jpg']\n",
      "processing (0125)-th image... ['marked_gray/testA/NamePlate110.jpg']\n",
      "processing (0130)-th image... ['marked_gray/testA/i_03195718.jpg']\n",
      "processing (0135)-th image... ['marked_gray/testA/image_293.jpg']\n",
      "processing (0140)-th image... ['marked_gray/testA/n2-oil-pumps-ksb-for-boilers.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot marked_gray/testA --num_test 144 --dataset_mode single --eval --model test --results_dir results_apr19real41 --netG resnet_9blocks --preprocess none --name apr19real417  --norm batch --checkpoints_dir apr18 --input_nc 1 --output_nc 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot extrarealsyncolor/AB --model pix2pix --no_dropout --output_nc 1 --norm batch --checkpoints_dir apr19 --netG resnet_9blocks --preprocess none --name apr19realsyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: apr19                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: marked_gray/testA             \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: apr19realsyn                  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "                    ntest: inf                           \n",
      "                 num_test: 144                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_apr19realsyn1         \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from apr19/apr19realsyn/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['marked_gray/testA/001.jpg']\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kalai/anaconda3/envs/my_env/lib/python3.7/site-packages/PIL/ImageFile.py\", line 496, in _save\n",
      "    fh = fp.fileno()\n",
      "AttributeError: '_idat' object has no attribute 'fileno'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"test.py\", line 65, in <module>\n",
      "    save_images(webpage, visuals, img_path, aspect_ratio=opt.aspect_ratio, width=opt.display_winsize)\n",
      "  File \"/home/kalai/exp/pytorch-CycleGAN-and-pix2pix/util/visualizer.py\", line 39, in save_images\n",
      "    util.save_image(im, save_path, aspect_ratio=aspect_ratio)\n",
      "  File \"/home/kalai/exp/pytorch-CycleGAN-and-pix2pix/util/util.py\", line 64, in save_image\n",
      "    image_pil.save(image_path)\n",
      "  File \"/home/kalai/anaconda3/envs/my_env/lib/python3.7/site-packages/PIL/Image.py\", line 2134, in save\n",
      "    save_handler(self, fp, filename)\n",
      "  File \"/home/kalai/anaconda3/envs/my_env/lib/python3.7/site-packages/PIL/PngImagePlugin.py\", line 1299, in _save\n",
      "    ImageFile._save(im, _idat(fp, chunk), [(\"zip\", (0, 0) + im.size, 0, rawmode)])\n",
      "  File \"/home/kalai/anaconda3/envs/my_env/lib/python3.7/site-packages/PIL/ImageFile.py\", line 510, in _save\n",
      "    l, s, d = e.encode(bufsize)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot marked_gray/testA --num_test 144 --dataset_mode single --model test --results_dir results_apr19realsyn1 --netG resnet_9blocks --preprocess none --name apr19realsyn  --norm batch --checkpoints_dir apr19 --output_nc 1 --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: apr19                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: testoutdist                   \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: apr19realsyn                  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_apr25                 \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from apr19/apr19realsyn/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "-----------------------------------------------\n",
      "The image size needs to be a multiple of 4. The loaded image size was (974, 678), so it was adjusted to (976, 680). This adjustment will be done to all images whose sizes are not multiples of 4\n",
      "processing (0000)-th image... ['testoutdist/t01.jpg']\n",
      "processing (0005)-th image... ['testoutdist/t07.jpg']\n",
      "processing (0010)-th image... ['testoutdist/t13.jpeg']\n",
      "processing (0015)-th image... ['testoutdist/t18.jpg']\n",
      "processing (0020)-th image... ['testoutdist/t24.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot testoutdist --dataset_mode single --model test --results_dir results_apr25 --netG resnet_9blocks --preprocess none --name apr19realsyn  --norm batch --checkpoints_dir apr19 --output_nc 1 --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: apr19                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: tod                           \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: apr19realsyn                  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_apr252                \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from apr19/apr19realsyn/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['tod/t01.jpg']\n",
      "processing (0005)-th image... ['tod/t07.jpg']\n",
      "processing (0010)-th image... ['tod/t13.jpg']\n",
      "processing (0015)-th image... ['tod/t18.jpg']\n",
      "processing (0020)-th image... ['tod/t24.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot tod --dataset_mode single --model test --results_dir results_apr252 --netG resnet_9blocks --preprocess none --name apr19realsyn  --norm batch --checkpoints_dir apr19 --output_nc 1 --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: apr25                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 128                           \t[default: 256]\n",
      "                 dataroot: extrarealsyncolor/AB          \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: apr19realcrop256              \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 500\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "[Network D] Total number of parameters : 2.767 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory apr25/apr19realcrop256/web...\n",
      "(epoch: 1, iters: 100, time: 0.057, data: 0.089) G_GAN: 1.813 G_L1: 8.554 D_real: 0.039 D_fake: 0.481 \n",
      "(epoch: 1, iters: 200, time: 0.070, data: 0.001) G_GAN: 1.680 G_L1: 9.651 D_real: 0.550 D_fake: 0.134 \n",
      "(epoch: 1, iters: 300, time: 0.056, data: 0.001) G_GAN: 2.148 G_L1: 14.622 D_real: 0.029 D_fake: 0.153 \n",
      "(epoch: 1, iters: 400, time: 0.088, data: 0.001) G_GAN: 1.428 G_L1: 13.015 D_real: 2.010 D_fake: 0.181 \n",
      "(epoch: 1, iters: 500, time: 0.058, data: 0.001) G_GAN: 2.215 G_L1: 17.867 D_real: 0.047 D_fake: 0.344 \n",
      "End of epoch 1 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 100, time: 0.056, data: 0.058) G_GAN: 1.884 G_L1: 16.864 D_real: 0.509 D_fake: 0.143 \n",
      "(epoch: 2, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.174 G_L1: 12.246 D_real: 0.806 D_fake: 0.714 \n",
      "(epoch: 2, iters: 300, time: 0.083, data: 0.001) G_GAN: 1.419 G_L1: 18.011 D_real: 0.001 D_fake: 0.462 \n",
      "(epoch: 2, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.764 G_L1: 18.460 D_real: 0.004 D_fake: 0.611 \n",
      "(epoch: 2, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.643 G_L1: 13.946 D_real: 0.028 D_fake: 0.226 \n",
      "End of epoch 2 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 100, time: 0.057, data: 0.058) G_GAN: 1.265 G_L1: 8.636 D_real: 1.604 D_fake: 0.376 \n",
      "(epoch: 3, iters: 200, time: 0.085, data: 0.001) G_GAN: 1.728 G_L1: 12.025 D_real: 2.072 D_fake: 0.195 \n",
      "(epoch: 3, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.227 G_L1: 10.724 D_real: 0.119 D_fake: 0.397 \n",
      "(epoch: 3, iters: 400, time: 0.063, data: 0.001) G_GAN: 1.099 G_L1: 7.538 D_real: 0.862 D_fake: 0.425 \n",
      "(epoch: 3, iters: 500, time: 0.061, data: 0.001) G_GAN: 1.241 G_L1: 12.132 D_real: 0.090 D_fake: 0.507 \n",
      "End of epoch 3 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 100, time: 0.107, data: 0.060) G_GAN: 1.022 G_L1: 19.468 D_real: 0.003 D_fake: 0.947 \n",
      "(epoch: 4, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.281 G_L1: 13.873 D_real: 0.975 D_fake: 0.269 \n",
      "(epoch: 4, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.374 G_L1: 20.142 D_real: 0.007 D_fake: 0.494 \n",
      "(epoch: 4, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.798 G_L1: 23.525 D_real: 0.025 D_fake: 0.283 \n",
      "(epoch: 4, iters: 500, time: 0.088, data: 0.001) G_GAN: 1.282 G_L1: 17.144 D_real: 0.006 D_fake: 0.356 \n",
      "End of epoch 4 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 100, time: 0.057, data: 0.059) G_GAN: 1.966 G_L1: 19.159 D_real: 0.638 D_fake: 0.150 \n",
      "(epoch: 5, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.986 G_L1: 9.212 D_real: 0.313 D_fake: 0.546 \n",
      "(epoch: 5, iters: 300, time: 0.057, data: 0.001) G_GAN: 0.874 G_L1: 12.834 D_real: 0.687 D_fake: 1.117 \n",
      "(epoch: 5, iters: 400, time: 0.083, data: 0.001) G_GAN: 1.666 G_L1: 15.551 D_real: 0.254 D_fake: 0.201 \n",
      "(epoch: 5, iters: 500, time: 0.057, data: 0.001) G_GAN: 1.331 G_L1: 12.497 D_real: 0.283 D_fake: 0.290 \n",
      "saving the model at the end of epoch 5, iters 2500\n",
      "End of epoch 5 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.057, data: 0.060) G_GAN: 1.523 G_L1: 18.307 D_real: 0.005 D_fake: 0.298 \n",
      "(epoch: 6, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.265 G_L1: 7.682 D_real: 1.232 D_fake: 0.295 \n",
      "(epoch: 6, iters: 300, time: 0.115, data: 0.001) G_GAN: 1.217 G_L1: 19.299 D_real: 0.243 D_fake: 0.369 \n",
      "(epoch: 6, iters: 400, time: 0.068, data: 0.001) G_GAN: 1.079 G_L1: 18.315 D_real: 0.054 D_fake: 0.469 \n",
      "(epoch: 6, iters: 500, time: 0.057, data: 0.001) G_GAN: 1.419 G_L1: 13.361 D_real: 0.285 D_fake: 0.265 \n",
      "End of epoch 6 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 100, time: 0.056, data: 0.068) G_GAN: 1.163 G_L1: 8.972 D_real: 0.499 D_fake: 0.373 \n",
      "(epoch: 7, iters: 200, time: 0.089, data: 0.001) G_GAN: 1.435 G_L1: 8.056 D_real: 0.211 D_fake: 0.301 \n",
      "(epoch: 7, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.118 G_L1: 20.734 D_real: 0.003 D_fake: 0.684 \n",
      "(epoch: 7, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.727 G_L1: 21.172 D_real: 0.218 D_fake: 0.183 \n",
      "(epoch: 7, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.935 G_L1: 7.572 D_real: 1.099 D_fake: 0.380 \n",
      "End of epoch 7 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 100, time: 0.091, data: 0.062) G_GAN: 0.983 G_L1: 9.979 D_real: 0.810 D_fake: 0.474 \n",
      "(epoch: 8, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.225 G_L1: 15.989 D_real: 0.009 D_fake: 0.400 \n",
      "(epoch: 8, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.225 G_L1: 16.268 D_real: 0.008 D_fake: 0.490 \n",
      "(epoch: 8, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.104 G_L1: 7.496 D_real: 1.042 D_fake: 0.280 \n",
      "(epoch: 8, iters: 500, time: 0.089, data: 0.001) G_GAN: 0.990 G_L1: 7.352 D_real: 1.339 D_fake: 0.332 \n",
      "End of epoch 8 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 100, time: 0.058, data: 0.063) G_GAN: 1.081 G_L1: 9.517 D_real: 0.142 D_fake: 0.638 \n",
      "(epoch: 9, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.243 G_L1: 10.869 D_real: 1.216 D_fake: 0.215 \n",
      "(epoch: 9, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.170 G_L1: 7.073 D_real: 1.283 D_fake: 0.526 \n",
      "(epoch: 9, iters: 400, time: 0.088, data: 0.001) G_GAN: 0.821 G_L1: 10.099 D_real: 1.020 D_fake: 0.501 \n",
      "(epoch: 9, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.502 G_L1: 14.476 D_real: 0.045 D_fake: 0.711 \n",
      "End of epoch 9 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.225 G_L1: 4.779 D_real: 1.435 D_fake: 0.227 \n",
      "(epoch: 10, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.820 G_L1: 2.579 D_real: 1.103 D_fake: 0.466 \n",
      "(epoch: 10, iters: 300, time: 0.094, data: 0.001) G_GAN: 0.877 G_L1: 7.146 D_real: 0.740 D_fake: 0.533 \n",
      "(epoch: 10, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.657 G_L1: 9.203 D_real: 0.652 D_fake: 0.696 \n",
      "(epoch: 10, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.012 G_L1: 10.609 D_real: 0.053 D_fake: 0.738 \n",
      "saving the latest model (epoch 10, total_iters 5000)\n",
      "saving the model at the end of epoch 10, iters 5000\n",
      "End of epoch 10 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.058, data: 0.062) G_GAN: 1.615 G_L1: 9.647 D_real: 0.074 D_fake: 0.231 \n",
      "(epoch: 11, iters: 200, time: 0.092, data: 0.001) G_GAN: 1.222 G_L1: 10.193 D_real: 0.117 D_fake: 0.542 \n",
      "(epoch: 11, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.267 G_L1: 13.351 D_real: 0.146 D_fake: 0.353 \n",
      "(epoch: 11, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.075 G_L1: 11.160 D_real: 0.530 D_fake: 0.384 \n",
      "(epoch: 11, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.207 G_L1: 14.224 D_real: 0.003 D_fake: 1.821 \n",
      "End of epoch 11 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 100, time: 0.095, data: 0.062) G_GAN: 1.115 G_L1: 6.798 D_real: 0.545 D_fake: 0.334 \n",
      "(epoch: 12, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.199 G_L1: 7.564 D_real: 0.480 D_fake: 0.416 \n",
      "(epoch: 12, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.277 G_L1: 10.567 D_real: 0.571 D_fake: 0.272 \n",
      "(epoch: 12, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.951 G_L1: 8.579 D_real: 1.387 D_fake: 0.392 \n",
      "(epoch: 12, iters: 500, time: 0.091, data: 0.001) G_GAN: 1.466 G_L1: 7.131 D_real: 0.336 D_fake: 0.334 \n",
      "End of epoch 12 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 100, time: 0.057, data: 0.063) G_GAN: 1.769 G_L1: 10.445 D_real: 0.125 D_fake: 0.690 \n",
      "(epoch: 13, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.351 G_L1: 13.531 D_real: 0.753 D_fake: 0.185 \n",
      "(epoch: 13, iters: 300, time: 0.057, data: 0.001) G_GAN: 0.982 G_L1: 6.734 D_real: 0.093 D_fake: 0.977 \n",
      "(epoch: 13, iters: 400, time: 0.092, data: 0.001) G_GAN: 1.529 G_L1: 14.416 D_real: 0.045 D_fake: 0.481 \n",
      "(epoch: 13, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.468 G_L1: 11.661 D_real: 0.055 D_fake: 0.392 \n",
      "End of epoch 13 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 100, time: 0.059, data: 0.063) G_GAN: 1.544 G_L1: 10.784 D_real: 0.287 D_fake: 0.272 \n",
      "(epoch: 14, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.056 G_L1: 0.213 D_real: 1.150 D_fake: 0.390 \n",
      "(epoch: 14, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.928 G_L1: 13.000 D_real: 0.224 D_fake: 0.723 \n",
      "(epoch: 14, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.267 G_L1: 4.604 D_real: 1.347 D_fake: 0.290 \n",
      "(epoch: 14, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.994 G_L1: 14.716 D_real: 0.062 D_fake: 1.958 \n",
      "End of epoch 14 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 100, time: 0.058, data: 0.062) G_GAN: 0.877 G_L1: 5.151 D_real: 0.924 D_fake: 0.419 \n",
      "(epoch: 15, iters: 200, time: 0.097, data: 0.001) G_GAN: 1.106 G_L1: 11.322 D_real: 0.037 D_fake: 1.315 \n",
      "(epoch: 15, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.439 G_L1: 5.978 D_real: 0.936 D_fake: 0.248 \n",
      "(epoch: 15, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.253 G_L1: 9.061 D_real: 0.384 D_fake: 0.480 \n",
      "(epoch: 15, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.443 G_L1: 4.557 D_real: 1.504 D_fake: 0.221 \n",
      "saving the model at the end of epoch 15, iters 7500\n",
      "End of epoch 15 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 100, time: 0.094, data: 0.065) G_GAN: 0.930 G_L1: 8.933 D_real: 0.129 D_fake: 0.838 \n",
      "(epoch: 16, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.041 G_L1: 8.209 D_real: 0.202 D_fake: 0.489 \n",
      "(epoch: 16, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.790 G_L1: 13.339 D_real: 0.147 D_fake: 1.046 \n",
      "(epoch: 16, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.662 G_L1: 11.808 D_real: 0.304 D_fake: 0.213 \n",
      "(epoch: 16, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.968 G_L1: 6.499 D_real: 1.107 D_fake: 0.242 \n",
      "End of epoch 16 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.009 G_L1: 5.034 D_real: 1.366 D_fake: 0.492 \n",
      "(epoch: 17, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.952 G_L1: 8.784 D_real: 0.659 D_fake: 0.392 \n",
      "(epoch: 17, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.920 G_L1: 7.321 D_real: 0.475 D_fake: 0.490 \n",
      "(epoch: 17, iters: 400, time: 0.096, data: 0.001) G_GAN: 1.863 G_L1: 12.536 D_real: 0.041 D_fake: 0.233 \n",
      "(epoch: 17, iters: 500, time: 0.059, data: 0.001) G_GAN: 0.913 G_L1: 6.428 D_real: 0.510 D_fake: 0.747 \n",
      "End of epoch 17 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 100, time: 0.058, data: 0.063) G_GAN: 1.118 G_L1: 7.934 D_real: 0.624 D_fake: 0.402 \n",
      "(epoch: 18, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.880 G_L1: 6.771 D_real: 0.909 D_fake: 0.424 \n",
      "(epoch: 18, iters: 300, time: 0.096, data: 0.001) G_GAN: 2.051 G_L1: 13.014 D_real: 0.115 D_fake: 0.194 \n",
      "(epoch: 18, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.859 G_L1: 7.242 D_real: 1.606 D_fake: 0.464 \n",
      "(epoch: 18, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.509 G_L1: 4.197 D_real: 0.455 D_fake: 0.322 \n",
      "End of epoch 18 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 100, time: 0.058, data: 0.063) G_GAN: 0.938 G_L1: 7.852 D_real: 1.054 D_fake: 0.339 \n",
      "(epoch: 19, iters: 200, time: 0.099, data: 0.001) G_GAN: 1.051 G_L1: 7.906 D_real: 0.416 D_fake: 0.559 \n",
      "(epoch: 19, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.580 G_L1: 6.960 D_real: 0.217 D_fake: 1.421 \n",
      "(epoch: 19, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.117 G_L1: 10.217 D_real: 0.211 D_fake: 0.412 \n",
      "(epoch: 19, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.435 G_L1: 12.150 D_real: 0.029 D_fake: 1.092 \n",
      "End of epoch 19 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 100, time: 0.104, data: 0.064) G_GAN: 1.204 G_L1: 11.068 D_real: 1.421 D_fake: 0.584 \n",
      "(epoch: 20, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.270 G_L1: 18.748 D_real: 0.001 D_fake: 1.452 \n",
      "(epoch: 20, iters: 300, time: 0.059, data: 0.001) G_GAN: 1.862 G_L1: 13.889 D_real: 0.023 D_fake: 0.802 \n",
      "(epoch: 20, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.810 G_L1: 8.834 D_real: 0.419 D_fake: 0.778 \n",
      "(epoch: 20, iters: 500, time: 0.097, data: 0.001) G_GAN: 1.765 G_L1: 15.484 D_real: 0.059 D_fake: 0.230 \n",
      "saving the latest model (epoch 20, total_iters 10000)\n",
      "saving the model at the end of epoch 20, iters 10000\n",
      "End of epoch 20 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 100, time: 0.058, data: 0.061) G_GAN: 1.358 G_L1: 7.029 D_real: 0.917 D_fake: 0.242 \n",
      "(epoch: 21, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.925 G_L1: 6.741 D_real: 1.155 D_fake: 0.288 \n",
      "(epoch: 21, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.776 G_L1: 12.659 D_real: 0.505 D_fake: 0.485 \n",
      "(epoch: 21, iters: 400, time: 0.100, data: 0.001) G_GAN: 0.592 G_L1: 10.478 D_real: 0.200 D_fake: 2.030 \n",
      "(epoch: 21, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.114 G_L1: 6.298 D_real: 0.490 D_fake: 0.362 \n",
      "End of epoch 21 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 100, time: 0.058, data: 0.062) G_GAN: 1.491 G_L1: 6.082 D_real: 1.794 D_fake: 0.173 \n",
      "(epoch: 22, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.427 G_L1: 7.338 D_real: 0.033 D_fake: 0.306 \n",
      "(epoch: 22, iters: 300, time: 0.102, data: 0.001) G_GAN: 1.225 G_L1: 8.562 D_real: 0.882 D_fake: 0.374 \n",
      "(epoch: 22, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.392 G_L1: 12.544 D_real: 0.247 D_fake: 0.353 \n",
      "(epoch: 22, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.773 G_L1: 6.091 D_real: 1.025 D_fake: 0.330 \n",
      "End of epoch 22 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 100, time: 0.058, data: 0.062) G_GAN: 1.086 G_L1: 11.709 D_real: 0.140 D_fake: 0.534 \n",
      "(epoch: 23, iters: 200, time: 0.097, data: 0.001) G_GAN: 1.439 G_L1: 13.313 D_real: 0.005 D_fake: 0.458 \n",
      "(epoch: 23, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.875 G_L1: 7.694 D_real: 0.495 D_fake: 0.731 \n",
      "(epoch: 23, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.312 G_L1: 7.289 D_real: 0.933 D_fake: 0.298 \n",
      "(epoch: 23, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.371 G_L1: 9.905 D_real: 0.135 D_fake: 0.352 \n",
      "End of epoch 23 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 100, time: 0.102, data: 0.064) G_GAN: 1.276 G_L1: 10.614 D_real: 0.623 D_fake: 0.240 \n",
      "(epoch: 24, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.802 G_L1: 0.108 D_real: 0.982 D_fake: 0.475 \n",
      "(epoch: 24, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.811 G_L1: 5.014 D_real: 0.445 D_fake: 0.256 \n",
      "(epoch: 24, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.044 G_L1: 8.952 D_real: 0.569 D_fake: 0.341 \n",
      "(epoch: 24, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.867 G_L1: 0.107 D_real: 1.031 D_fake: 0.449 \n",
      "End of epoch 24 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.210 G_L1: 6.810 D_real: 0.450 D_fake: 0.345 \n",
      "(epoch: 25, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.249 G_L1: 3.221 D_real: 1.275 D_fake: 0.299 \n",
      "(epoch: 25, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.245 G_L1: 9.257 D_real: 0.385 D_fake: 0.456 \n",
      "(epoch: 25, iters: 400, time: 0.100, data: 0.001) G_GAN: 0.920 G_L1: 12.248 D_real: 0.410 D_fake: 0.488 \n",
      "(epoch: 25, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.297 G_L1: 12.166 D_real: 0.472 D_fake: 0.309 \n",
      "saving the model at the end of epoch 25, iters 12500\n",
      "End of epoch 25 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.057, data: 0.061) G_GAN: 0.618 G_L1: 10.983 D_real: 0.760 D_fake: 0.919 \n",
      "(epoch: 26, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.001 G_L1: 12.301 D_real: 1.017 D_fake: 0.479 \n",
      "(epoch: 26, iters: 300, time: 0.100, data: 0.001) G_GAN: 1.014 G_L1: 9.428 D_real: 0.437 D_fake: 0.571 \n",
      "(epoch: 26, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.705 G_L1: 2.438 D_real: 0.788 D_fake: 0.772 \n",
      "(epoch: 26, iters: 500, time: 0.057, data: 0.001) G_GAN: 0.997 G_L1: 8.291 D_real: 1.029 D_fake: 0.438 \n",
      "End of epoch 26 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.028 G_L1: 13.260 D_real: 0.187 D_fake: 0.674 \n",
      "(epoch: 27, iters: 200, time: 0.105, data: 0.001) G_GAN: 0.665 G_L1: 9.845 D_real: 0.594 D_fake: 0.663 \n",
      "(epoch: 27, iters: 300, time: 0.057, data: 0.001) G_GAN: 0.848 G_L1: 0.609 D_real: 0.887 D_fake: 0.578 \n",
      "(epoch: 27, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.057 G_L1: 8.259 D_real: 0.408 D_fake: 0.636 \n",
      "(epoch: 27, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.110 G_L1: 7.905 D_real: 0.608 D_fake: 0.349 \n",
      "End of epoch 27 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 100, time: 0.107, data: 0.062) G_GAN: 1.010 G_L1: 13.935 D_real: 0.095 D_fake: 1.810 \n",
      "(epoch: 28, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.603 G_L1: 6.103 D_real: 0.694 D_fake: 0.855 \n",
      "(epoch: 28, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.034 G_L1: 6.871 D_real: 0.277 D_fake: 0.989 \n",
      "(epoch: 28, iters: 400, time: 0.059, data: 0.001) G_GAN: 1.036 G_L1: 6.970 D_real: 0.566 D_fake: 0.414 \n",
      "(epoch: 28, iters: 500, time: 0.103, data: 0.001) G_GAN: 1.038 G_L1: 6.646 D_real: 1.516 D_fake: 0.297 \n",
      "End of epoch 28 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 100, time: 0.057, data: 0.064) G_GAN: 0.899 G_L1: 11.543 D_real: 0.710 D_fake: 0.665 \n",
      "(epoch: 29, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.246 G_L1: 5.914 D_real: 0.234 D_fake: 0.363 \n",
      "(epoch: 29, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.997 G_L1: 6.198 D_real: 1.218 D_fake: 0.404 \n",
      "(epoch: 29, iters: 400, time: 0.102, data: 0.001) G_GAN: 1.031 G_L1: 7.681 D_real: 0.773 D_fake: 0.531 \n",
      "(epoch: 29, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.132 G_L1: 9.836 D_real: 0.429 D_fake: 0.482 \n",
      "End of epoch 29 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 100, time: 0.057, data: 0.065) G_GAN: 1.003 G_L1: 6.289 D_real: 1.139 D_fake: 0.469 \n",
      "(epoch: 30, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.985 G_L1: 7.580 D_real: 0.170 D_fake: 1.289 \n",
      "(epoch: 30, iters: 300, time: 0.104, data: 0.001) G_GAN: 0.630 G_L1: 6.458 D_real: 0.959 D_fake: 0.444 \n",
      "(epoch: 30, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.039 G_L1: 6.078 D_real: 0.371 D_fake: 0.550 \n",
      "(epoch: 30, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.053 G_L1: 9.703 D_real: 0.777 D_fake: 0.325 \n",
      "saving the latest model (epoch 30, total_iters 15000)\n",
      "saving the model at the end of epoch 30, iters 15000\n",
      "End of epoch 30 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 100, time: 0.057, data: 0.063) G_GAN: 1.103 G_L1: 8.721 D_real: 0.592 D_fake: 0.327 \n",
      "(epoch: 31, iters: 200, time: 0.103, data: 0.001) G_GAN: 1.195 G_L1: 7.594 D_real: 0.148 D_fake: 1.301 \n",
      "(epoch: 31, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.122 G_L1: 8.015 D_real: 0.054 D_fake: 0.607 \n",
      "(epoch: 31, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.879 G_L1: 6.795 D_real: 0.747 D_fake: 0.636 \n",
      "(epoch: 31, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.209 G_L1: 4.461 D_real: 2.434 D_fake: 0.139 \n",
      "End of epoch 31 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 100, time: 0.105, data: 0.064) G_GAN: 0.852 G_L1: 8.675 D_real: 0.713 D_fake: 0.820 \n",
      "(epoch: 32, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.052 G_L1: 8.646 D_real: 0.824 D_fake: 0.100 \n",
      "(epoch: 32, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.174 G_L1: 7.052 D_real: 1.109 D_fake: 0.273 \n",
      "(epoch: 32, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.444 G_L1: 12.541 D_real: 0.217 D_fake: 0.371 \n",
      "(epoch: 32, iters: 500, time: 0.107, data: 0.001) G_GAN: 0.649 G_L1: 10.140 D_real: 0.760 D_fake: 0.276 \n",
      "End of epoch 32 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.070 G_L1: 8.473 D_real: 0.637 D_fake: 0.425 \n",
      "(epoch: 33, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.263 G_L1: 8.035 D_real: 0.148 D_fake: 0.796 \n",
      "(epoch: 33, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.060 G_L1: 10.775 D_real: 0.867 D_fake: 0.308 \n",
      "(epoch: 33, iters: 400, time: 0.103, data: 0.001) G_GAN: 0.857 G_L1: 0.145 D_real: 0.992 D_fake: 0.469 \n",
      "(epoch: 33, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.161 G_L1: 10.132 D_real: 0.148 D_fake: 0.934 \n",
      "End of epoch 33 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.392 G_L1: 7.522 D_real: 0.467 D_fake: 0.189 \n",
      "(epoch: 34, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.455 G_L1: 6.929 D_real: 0.192 D_fake: 0.279 \n",
      "(epoch: 34, iters: 300, time: 0.139, data: 0.001) G_GAN: 1.322 G_L1: 12.262 D_real: 0.172 D_fake: 0.820 \n",
      "(epoch: 34, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.228 G_L1: 7.603 D_real: 0.311 D_fake: 0.414 \n",
      "(epoch: 34, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.606 G_L1: 7.620 D_real: 0.044 D_fake: 2.072 \n",
      "End of epoch 34 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 100, time: 0.058, data: 0.063) G_GAN: 0.454 G_L1: 3.843 D_real: 1.138 D_fake: 0.388 \n",
      "(epoch: 35, iters: 200, time: 0.105, data: 0.001) G_GAN: 0.875 G_L1: 0.439 D_real: 1.016 D_fake: 0.466 \n",
      "(epoch: 35, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.180 G_L1: 8.188 D_real: 1.361 D_fake: 0.359 \n",
      "(epoch: 35, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.065 G_L1: 7.462 D_real: 0.343 D_fake: 0.465 \n",
      "(epoch: 35, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.816 G_L1: 16.673 D_real: 0.027 D_fake: 1.285 \n",
      "saving the model at the end of epoch 35, iters 17500\n",
      "End of epoch 35 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 100, time: 0.109, data: 0.064) G_GAN: 1.049 G_L1: 10.031 D_real: 0.927 D_fake: 2.267 \n",
      "(epoch: 36, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.102 G_L1: 5.575 D_real: 1.087 D_fake: 0.292 \n",
      "(epoch: 36, iters: 300, time: 0.056, data: 0.001) G_GAN: 0.934 G_L1: 7.752 D_real: 0.407 D_fake: 0.906 \n",
      "(epoch: 36, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.753 G_L1: 9.161 D_real: 0.328 D_fake: 0.775 \n",
      "(epoch: 36, iters: 500, time: 0.111, data: 0.001) G_GAN: 1.578 G_L1: 12.367 D_real: 0.261 D_fake: 0.267 \n",
      "End of epoch 36 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 100, time: 0.058, data: 0.065) G_GAN: 0.933 G_L1: 5.381 D_real: 0.793 D_fake: 0.523 \n",
      "(epoch: 37, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.080 G_L1: 8.832 D_real: 1.402 D_fake: 0.218 \n",
      "(epoch: 37, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.608 G_L1: 9.162 D_real: 0.302 D_fake: 0.393 \n",
      "(epoch: 37, iters: 400, time: 0.105, data: 0.001) G_GAN: 1.955 G_L1: 10.147 D_real: 0.039 D_fake: 0.174 \n",
      "(epoch: 37, iters: 500, time: 0.059, data: 0.001) G_GAN: 0.795 G_L1: 5.426 D_real: 1.415 D_fake: 0.289 \n",
      "End of epoch 37 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 100, time: 0.057, data: 0.062) G_GAN: 0.963 G_L1: 8.801 D_real: 1.828 D_fake: 0.223 \n",
      "(epoch: 38, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.079 G_L1: 9.202 D_real: 0.267 D_fake: 0.610 \n",
      "(epoch: 38, iters: 300, time: 0.110, data: 0.001) G_GAN: 1.023 G_L1: 8.670 D_real: 0.901 D_fake: 0.318 \n",
      "(epoch: 38, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.992 G_L1: 7.284 D_real: 0.868 D_fake: 0.472 \n",
      "(epoch: 38, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.889 G_L1: 8.286 D_real: 0.315 D_fake: 1.033 \n",
      "End of epoch 38 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 100, time: 0.057, data: 0.063) G_GAN: 1.034 G_L1: 12.238 D_real: 0.094 D_fake: 0.977 \n",
      "(epoch: 39, iters: 200, time: 0.106, data: 0.001) G_GAN: 1.131 G_L1: 7.628 D_real: 0.667 D_fake: 0.216 \n",
      "(epoch: 39, iters: 300, time: 0.057, data: 0.001) G_GAN: 0.760 G_L1: 6.376 D_real: 0.859 D_fake: 0.547 \n",
      "(epoch: 39, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.622 G_L1: 7.166 D_real: 0.065 D_fake: 1.285 \n",
      "(epoch: 39, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.152 G_L1: 8.042 D_real: 0.222 D_fake: 1.118 \n",
      "End of epoch 39 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 100, time: 0.112, data: 0.073) G_GAN: 0.895 G_L1: 13.780 D_real: 0.018 D_fake: 1.909 \n",
      "(epoch: 40, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.847 G_L1: 0.754 D_real: 1.581 D_fake: 0.232 \n",
      "(epoch: 40, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.199 G_L1: 7.831 D_real: 0.363 D_fake: 0.337 \n",
      "(epoch: 40, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.566 G_L1: 6.089 D_real: 0.455 D_fake: 1.059 \n",
      "(epoch: 40, iters: 500, time: 0.104, data: 0.001) G_GAN: 0.710 G_L1: 0.066 D_real: 0.742 D_fake: 0.680 \n",
      "saving the latest model (epoch 40, total_iters 20000)\n",
      "saving the model at the end of epoch 40, iters 20000\n",
      "End of epoch 40 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 100, time: 0.058, data: 0.070) G_GAN: 1.125 G_L1: 9.806 D_real: 0.118 D_fake: 1.070 \n",
      "(epoch: 41, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.512 G_L1: 7.173 D_real: 0.085 D_fake: 1.848 \n",
      "(epoch: 41, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.240 G_L1: 8.818 D_real: 0.675 D_fake: 0.308 \n",
      "(epoch: 41, iters: 400, time: 0.107, data: 0.001) G_GAN: 0.801 G_L1: 0.042 D_real: 0.773 D_fake: 0.633 \n",
      "(epoch: 41, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.837 G_L1: 8.590 D_real: 0.388 D_fake: 0.544 \n",
      "End of epoch 41 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 100, time: 0.057, data: 0.062) G_GAN: 0.843 G_L1: 0.128 D_real: 1.031 D_fake: 0.475 \n",
      "(epoch: 42, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.663 G_L1: 9.206 D_real: 0.118 D_fake: 0.419 \n",
      "(epoch: 42, iters: 300, time: 0.112, data: 0.001) G_GAN: 1.193 G_L1: 5.782 D_real: 0.892 D_fake: 0.341 \n",
      "(epoch: 42, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.808 G_L1: 0.082 D_real: 0.813 D_fake: 0.595 \n",
      "(epoch: 42, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.801 G_L1: 7.764 D_real: 1.107 D_fake: 0.124 \n",
      "End of epoch 42 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 100, time: 0.058, data: 0.063) G_GAN: 1.218 G_L1: 5.690 D_real: 0.321 D_fake: 0.398 \n",
      "(epoch: 43, iters: 200, time: 0.101, data: 0.001) G_GAN: 0.799 G_L1: 0.048 D_real: 0.854 D_fake: 0.578 \n",
      "(epoch: 43, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.208 G_L1: 17.454 D_real: 0.058 D_fake: 0.532 \n",
      "(epoch: 43, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.251 G_L1: 5.784 D_real: 1.376 D_fake: 0.086 \n",
      "(epoch: 43, iters: 500, time: 0.057, data: 0.001) G_GAN: 1.577 G_L1: 12.580 D_real: 0.206 D_fake: 0.304 \n",
      "End of epoch 43 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 100, time: 0.118, data: 0.063) G_GAN: 1.821 G_L1: 9.991 D_real: 0.853 D_fake: 0.157 \n",
      "(epoch: 44, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.976 G_L1: 6.068 D_real: 0.391 D_fake: 0.662 \n",
      "(epoch: 44, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.518 G_L1: 12.616 D_real: 0.083 D_fake: 0.960 \n",
      "(epoch: 44, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.763 G_L1: 8.577 D_real: 0.351 D_fake: 0.980 \n",
      "(epoch: 44, iters: 500, time: 0.111, data: 0.001) G_GAN: 1.356 G_L1: 7.258 D_real: 0.604 D_fake: 0.195 \n",
      "End of epoch 44 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 100, time: 0.058, data: 0.064) G_GAN: 0.870 G_L1: 1.517 D_real: 0.647 D_fake: 0.640 \n",
      "(epoch: 45, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.626 G_L1: 5.715 D_real: 0.296 D_fake: 0.307 \n",
      "(epoch: 45, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.500 G_L1: 9.968 D_real: 0.085 D_fake: 0.402 \n",
      "(epoch: 45, iters: 400, time: 0.112, data: 0.001) G_GAN: 1.900 G_L1: 9.607 D_real: 2.164 D_fake: 0.082 \n",
      "(epoch: 45, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.802 G_L1: 6.865 D_real: 1.137 D_fake: 0.094 \n",
      "saving the model at the end of epoch 45, iters 22500\n",
      "End of epoch 45 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 100, time: 0.058, data: 0.064) G_GAN: 0.831 G_L1: 9.721 D_real: 0.530 D_fake: 0.824 \n",
      "(epoch: 46, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.228 G_L1: 10.928 D_real: 0.090 D_fake: 4.891 \n",
      "(epoch: 46, iters: 300, time: 0.114, data: 0.001) G_GAN: 0.893 G_L1: 5.612 D_real: 0.281 D_fake: 1.145 \n",
      "(epoch: 46, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.174 G_L1: 8.542 D_real: 0.738 D_fake: 0.366 \n",
      "(epoch: 46, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.824 G_L1: 10.958 D_real: 0.104 D_fake: 1.089 \n",
      "End of epoch 46 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.154 G_L1: 9.365 D_real: 0.745 D_fake: 0.153 \n",
      "(epoch: 47, iters: 200, time: 0.104, data: 0.001) G_GAN: 0.740 G_L1: 0.079 D_real: 0.742 D_fake: 0.662 \n",
      "(epoch: 47, iters: 300, time: 0.059, data: 0.001) G_GAN: 1.194 G_L1: 8.980 D_real: 0.331 D_fake: 0.308 \n",
      "(epoch: 47, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.636 G_L1: 2.953 D_real: 1.200 D_fake: 0.647 \n",
      "(epoch: 47, iters: 500, time: 0.059, data: 0.001) G_GAN: 2.017 G_L1: 17.943 D_real: 0.010 D_fake: 0.230 \n",
      "End of epoch 47 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 100, time: 0.111, data: 0.065) G_GAN: 0.842 G_L1: 0.059 D_real: 0.953 D_fake: 0.505 \n",
      "(epoch: 48, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.243 G_L1: 6.312 D_real: 0.555 D_fake: 0.316 \n",
      "(epoch: 48, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.307 G_L1: 6.568 D_real: 0.440 D_fake: 0.341 \n",
      "(epoch: 48, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.682 G_L1: 8.814 D_real: 0.478 D_fake: 0.715 \n",
      "(epoch: 48, iters: 500, time: 0.144, data: 0.001) G_GAN: 1.087 G_L1: 9.244 D_real: 0.272 D_fake: 0.434 \n",
      "End of epoch 48 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 100, time: 0.057, data: 0.063) G_GAN: 0.676 G_L1: 8.375 D_real: 0.691 D_fake: 0.402 \n",
      "(epoch: 49, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.920 G_L1: 5.777 D_real: 0.994 D_fake: 0.350 \n",
      "(epoch: 49, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.185 G_L1: 9.517 D_real: 0.648 D_fake: 0.443 \n",
      "(epoch: 49, iters: 400, time: 0.116, data: 0.001) G_GAN: 0.874 G_L1: 4.055 D_real: 0.711 D_fake: 0.537 \n",
      "(epoch: 49, iters: 500, time: 0.058, data: 0.001) G_GAN: 2.315 G_L1: 16.618 D_real: 0.760 D_fake: 0.067 \n",
      "End of epoch 49 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 100, time: 0.058, data: 0.062) G_GAN: 0.912 G_L1: 0.458 D_real: 0.965 D_fake: 0.458 \n",
      "(epoch: 50, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.700 G_L1: 4.503 D_real: 0.502 D_fake: 0.610 \n",
      "(epoch: 50, iters: 300, time: 0.117, data: 0.001) G_GAN: 1.595 G_L1: 10.331 D_real: 1.218 D_fake: 0.165 \n",
      "(epoch: 50, iters: 400, time: 0.057, data: 0.001) G_GAN: 2.587 G_L1: 8.890 D_real: 0.015 D_fake: 0.130 \n",
      "(epoch: 50, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.699 G_L1: 11.529 D_real: 0.789 D_fake: 0.447 \n",
      "saving the latest model (epoch 50, total_iters 25000)\n",
      "saving the model at the end of epoch 50, iters 25000\n",
      "End of epoch 50 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.057, data: 0.064) G_GAN: 0.972 G_L1: 10.230 D_real: 0.101 D_fake: 0.975 \n",
      "(epoch: 51, iters: 200, time: 0.116, data: 0.001) G_GAN: 1.241 G_L1: 6.893 D_real: 0.193 D_fake: 0.463 \n",
      "(epoch: 51, iters: 300, time: 0.057, data: 0.001) G_GAN: 0.960 G_L1: 0.078 D_real: 1.363 D_fake: 0.306 \n",
      "(epoch: 51, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.821 G_L1: 4.834 D_real: 0.515 D_fake: 0.926 \n",
      "(epoch: 51, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.855 G_L1: 7.656 D_real: 0.538 D_fake: 0.146 \n",
      "End of epoch 51 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 100, time: 0.113, data: 0.063) G_GAN: 1.713 G_L1: 5.643 D_real: 0.688 D_fake: 0.203 \n",
      "(epoch: 52, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.542 G_L1: 8.723 D_real: 1.502 D_fake: 0.565 \n",
      "(epoch: 52, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.316 G_L1: 7.295 D_real: 0.117 D_fake: 0.934 \n",
      "(epoch: 52, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.722 G_L1: 5.748 D_real: 0.463 D_fake: 0.733 \n",
      "(epoch: 52, iters: 500, time: 0.117, data: 0.001) G_GAN: 1.406 G_L1: 13.638 D_real: 0.009 D_fake: 2.335 \n",
      "End of epoch 52 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.054 G_L1: 19.259 D_real: 0.039 D_fake: 0.561 \n",
      "(epoch: 53, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.938 G_L1: 5.999 D_real: 0.393 D_fake: 0.537 \n",
      "(epoch: 53, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.288 G_L1: 7.915 D_real: 0.134 D_fake: 0.598 \n",
      "(epoch: 53, iters: 400, time: 0.122, data: 0.001) G_GAN: 1.733 G_L1: 8.859 D_real: 0.689 D_fake: 0.100 \n",
      "(epoch: 53, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.934 G_L1: 10.084 D_real: 0.461 D_fake: 0.859 \n",
      "End of epoch 53 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 100, time: 0.058, data: 0.066) G_GAN: 1.084 G_L1: 7.458 D_real: 0.361 D_fake: 0.469 \n",
      "(epoch: 54, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.568 G_L1: 5.044 D_real: 1.062 D_fake: 0.143 \n",
      "(epoch: 54, iters: 300, time: 0.120, data: 0.001) G_GAN: 1.304 G_L1: 16.474 D_real: 1.699 D_fake: 0.138 \n",
      "(epoch: 54, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.923 G_L1: 7.591 D_real: 1.529 D_fake: 0.603 \n",
      "(epoch: 54, iters: 500, time: 0.058, data: 0.001) G_GAN: 3.291 G_L1: 6.515 D_real: 0.026 D_fake: 0.047 \n",
      "End of epoch 54 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 100, time: 0.058, data: 0.069) G_GAN: 1.096 G_L1: 17.642 D_real: 0.153 D_fake: 1.045 \n",
      "(epoch: 55, iters: 200, time: 0.119, data: 0.001) G_GAN: 1.169 G_L1: 9.176 D_real: 0.440 D_fake: 1.287 \n",
      "(epoch: 55, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.015 G_L1: 4.617 D_real: 0.420 D_fake: 0.445 \n",
      "(epoch: 55, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.290 G_L1: 9.461 D_real: 0.599 D_fake: 0.267 \n",
      "(epoch: 55, iters: 500, time: 0.057, data: 0.001) G_GAN: 0.910 G_L1: 6.007 D_real: 0.383 D_fake: 0.580 \n",
      "saving the model at the end of epoch 55, iters 27500\n",
      "End of epoch 55 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 100, time: 0.118, data: 0.063) G_GAN: 1.822 G_L1: 8.478 D_real: 0.070 D_fake: 0.566 \n",
      "(epoch: 56, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.717 G_L1: 5.960 D_real: 0.335 D_fake: 1.256 \n",
      "(epoch: 56, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.884 G_L1: 6.327 D_real: 0.485 D_fake: 0.611 \n",
      "(epoch: 56, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.149 G_L1: 6.792 D_real: 0.378 D_fake: 0.471 \n",
      "(epoch: 56, iters: 500, time: 0.116, data: 0.001) G_GAN: 0.988 G_L1: 5.091 D_real: 0.581 D_fake: 0.546 \n",
      "End of epoch 56 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 100, time: 0.057, data: 0.064) G_GAN: 1.845 G_L1: 12.884 D_real: 0.330 D_fake: 0.171 \n",
      "(epoch: 57, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.588 G_L1: 15.261 D_real: 0.858 D_fake: 0.079 \n",
      "(epoch: 57, iters: 300, time: 0.059, data: 0.001) G_GAN: 2.141 G_L1: 5.543 D_real: 0.351 D_fake: 0.124 \n",
      "(epoch: 57, iters: 400, time: 0.119, data: 0.001) G_GAN: 1.386 G_L1: 5.418 D_real: 0.828 D_fake: 0.505 \n",
      "(epoch: 57, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.112 G_L1: 8.948 D_real: 0.524 D_fake: 0.393 \n",
      "End of epoch 57 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 100, time: 0.058, data: 0.064) G_GAN: 0.867 G_L1: 3.166 D_real: 0.637 D_fake: 0.350 \n",
      "(epoch: 58, iters: 200, time: 0.057, data: 0.002) G_GAN: 1.281 G_L1: 9.821 D_real: 0.232 D_fake: 0.502 \n",
      "(epoch: 58, iters: 300, time: 0.124, data: 0.001) G_GAN: 2.000 G_L1: 11.517 D_real: 0.087 D_fake: 0.206 \n",
      "(epoch: 58, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.813 G_L1: 0.031 D_real: 1.294 D_fake: 0.334 \n",
      "(epoch: 58, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.105 G_L1: 6.165 D_real: 0.295 D_fake: 0.328 \n",
      "End of epoch 58 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 100, time: 0.058, data: 0.067) G_GAN: 1.141 G_L1: 5.713 D_real: 1.074 D_fake: 0.221 \n",
      "(epoch: 59, iters: 200, time: 0.162, data: 0.001) G_GAN: 1.329 G_L1: 9.860 D_real: 0.235 D_fake: 0.497 \n",
      "(epoch: 59, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.575 G_L1: 9.607 D_real: 0.405 D_fake: 0.380 \n",
      "(epoch: 59, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.613 G_L1: 8.264 D_real: 0.152 D_fake: 0.359 \n",
      "(epoch: 59, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.810 G_L1: 7.699 D_real: 0.586 D_fake: 1.041 \n",
      "End of epoch 59 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 100, time: 0.115, data: 0.065) G_GAN: 1.239 G_L1: 0.767 D_real: 0.896 D_fake: 0.380 \n",
      "(epoch: 60, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.053 G_L1: 8.698 D_real: 0.181 D_fake: 0.662 \n",
      "(epoch: 60, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.181 G_L1: 9.184 D_real: 0.201 D_fake: 1.609 \n",
      "(epoch: 60, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.164 G_L1: 8.475 D_real: 0.786 D_fake: 0.450 \n",
      "(epoch: 60, iters: 500, time: 0.125, data: 0.001) G_GAN: 0.718 G_L1: 9.327 D_real: 0.465 D_fake: 0.893 \n",
      "saving the latest model (epoch 60, total_iters 30000)\n",
      "saving the model at the end of epoch 60, iters 30000\n",
      "End of epoch 60 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.142 G_L1: 7.585 D_real: 0.165 D_fake: 0.912 \n",
      "(epoch: 61, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.619 G_L1: 5.817 D_real: 1.050 D_fake: 0.504 \n",
      "(epoch: 61, iters: 300, time: 0.058, data: 0.001) G_GAN: 3.194 G_L1: 10.881 D_real: 0.208 D_fake: 0.035 \n",
      "(epoch: 61, iters: 400, time: 0.123, data: 0.001) G_GAN: 1.430 G_L1: 5.286 D_real: 0.570 D_fake: 0.262 \n",
      "(epoch: 61, iters: 500, time: 0.058, data: 0.001) G_GAN: 2.051 G_L1: 11.069 D_real: 0.095 D_fake: 0.219 \n",
      "End of epoch 61 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 100, time: 0.058, data: 0.066) G_GAN: 2.057 G_L1: 5.260 D_real: 1.016 D_fake: 0.101 \n",
      "(epoch: 62, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.776 G_L1: 7.146 D_real: 1.460 D_fake: 0.088 \n",
      "(epoch: 62, iters: 300, time: 0.124, data: 0.001) G_GAN: 1.604 G_L1: 11.826 D_real: 0.030 D_fake: 0.623 \n",
      "(epoch: 62, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.800 G_L1: 7.119 D_real: 0.905 D_fake: 0.096 \n",
      "(epoch: 62, iters: 500, time: 0.057, data: 0.001) G_GAN: 1.378 G_L1: 5.986 D_real: 0.270 D_fake: 0.408 \n",
      "End of epoch 62 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 100, time: 0.057, data: 0.063) G_GAN: 0.641 G_L1: 5.242 D_real: 0.280 D_fake: 1.313 \n",
      "(epoch: 63, iters: 200, time: 0.126, data: 0.001) G_GAN: 1.430 G_L1: 11.045 D_real: 0.152 D_fake: 1.251 \n",
      "(epoch: 63, iters: 300, time: 0.058, data: 0.001) G_GAN: 2.220 G_L1: 11.050 D_real: 0.418 D_fake: 0.101 \n",
      "(epoch: 63, iters: 400, time: 0.059, data: 0.001) G_GAN: 1.157 G_L1: 7.610 D_real: 0.892 D_fake: 0.586 \n",
      "(epoch: 63, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.674 G_L1: 9.905 D_real: 0.051 D_fake: 0.516 \n",
      "End of epoch 63 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 100, time: 0.125, data: 0.064) G_GAN: 1.758 G_L1: 6.853 D_real: 0.037 D_fake: 0.520 \n",
      "(epoch: 64, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.977 G_L1: 7.174 D_real: 0.047 D_fake: 0.413 \n",
      "(epoch: 64, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.412 G_L1: 9.670 D_real: 0.306 D_fake: 0.565 \n",
      "(epoch: 64, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.540 G_L1: 12.696 D_real: 0.454 D_fake: 0.273 \n",
      "(epoch: 64, iters: 500, time: 0.124, data: 0.001) G_GAN: 1.014 G_L1: 9.715 D_real: 0.140 D_fake: 1.025 \n",
      "End of epoch 64 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 100, time: 0.057, data: 0.066) G_GAN: 1.235 G_L1: 8.894 D_real: 0.387 D_fake: 0.419 \n",
      "(epoch: 65, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.023 G_L1: 6.074 D_real: 0.163 D_fake: 1.096 \n",
      "(epoch: 65, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.378 G_L1: 7.076 D_real: 0.344 D_fake: 0.337 \n",
      "(epoch: 65, iters: 400, time: 0.124, data: 0.001) G_GAN: 0.988 G_L1: 9.465 D_real: 0.771 D_fake: 0.526 \n",
      "(epoch: 65, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.082 G_L1: 10.634 D_real: 1.663 D_fake: 0.084 \n",
      "saving the model at the end of epoch 65, iters 32500\n",
      "End of epoch 65 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 100, time: 0.057, data: 0.062) G_GAN: 1.373 G_L1: 9.819 D_real: 0.087 D_fake: 0.598 \n",
      "(epoch: 66, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.829 G_L1: 5.069 D_real: 1.056 D_fake: 0.624 \n",
      "(epoch: 66, iters: 300, time: 0.122, data: 0.002) G_GAN: 0.958 G_L1: 4.219 D_real: 0.927 D_fake: 0.303 \n",
      "(epoch: 66, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.299 G_L1: 9.466 D_real: 0.016 D_fake: 0.892 \n",
      "(epoch: 66, iters: 500, time: 0.058, data: 0.001) G_GAN: 3.131 G_L1: 6.498 D_real: 0.111 D_fake: 0.045 \n",
      "End of epoch 66 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 100, time: 0.057, data: 0.064) G_GAN: 1.252 G_L1: 6.190 D_real: 0.841 D_fake: 0.305 \n",
      "(epoch: 67, iters: 200, time: 0.127, data: 0.001) G_GAN: 1.153 G_L1: 11.008 D_real: 0.514 D_fake: 0.523 \n",
      "(epoch: 67, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.149 G_L1: 6.993 D_real: 0.706 D_fake: 0.524 \n",
      "(epoch: 67, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.770 G_L1: 12.671 D_real: 0.134 D_fake: 0.456 \n",
      "(epoch: 67, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.370 G_L1: 9.181 D_real: 0.348 D_fake: 0.481 \n",
      "End of epoch 67 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 100, time: 0.170, data: 0.066) G_GAN: 2.000 G_L1: 4.806 D_real: 0.896 D_fake: 0.074 \n",
      "(epoch: 68, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.534 G_L1: 9.612 D_real: 0.164 D_fake: 0.351 \n",
      "(epoch: 68, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.638 G_L1: 15.326 D_real: 1.721 D_fake: 0.218 \n",
      "(epoch: 68, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.340 G_L1: 5.116 D_real: 0.383 D_fake: 0.719 \n",
      "(epoch: 68, iters: 500, time: 0.126, data: 0.001) G_GAN: 2.058 G_L1: 3.843 D_real: 0.374 D_fake: 0.160 \n",
      "End of epoch 68 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.435 G_L1: 12.453 D_real: 0.689 D_fake: 0.209 \n",
      "(epoch: 69, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.156 G_L1: 7.510 D_real: 0.489 D_fake: 0.415 \n",
      "(epoch: 69, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.403 G_L1: 8.536 D_real: 0.286 D_fake: 0.806 \n",
      "(epoch: 69, iters: 400, time: 0.132, data: 0.001) G_GAN: 1.738 G_L1: 13.014 D_real: 2.048 D_fake: 0.065 \n",
      "(epoch: 69, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.013 G_L1: 7.513 D_real: 0.505 D_fake: 0.485 \n",
      "End of epoch 69 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 100, time: 0.057, data: 0.065) G_GAN: 1.070 G_L1: 4.963 D_real: 0.116 D_fake: 1.077 \n",
      "(epoch: 70, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.157 G_L1: 2.015 D_real: 0.761 D_fake: 0.341 \n",
      "(epoch: 70, iters: 300, time: 0.128, data: 0.001) G_GAN: 1.830 G_L1: 7.312 D_real: 0.023 D_fake: 0.171 \n",
      "(epoch: 70, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.890 G_L1: 5.771 D_real: 0.970 D_fake: 0.153 \n",
      "(epoch: 70, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.411 G_L1: 3.810 D_real: 1.574 D_fake: 1.609 \n",
      "saving the latest model (epoch 70, total_iters 35000)\n",
      "saving the model at the end of epoch 70, iters 35000\n",
      "End of epoch 70 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.436 G_L1: 7.956 D_real: 0.254 D_fake: 0.692 \n",
      "(epoch: 71, iters: 200, time: 0.131, data: 0.001) G_GAN: 2.476 G_L1: 11.787 D_real: 0.116 D_fake: 0.124 \n",
      "(epoch: 71, iters: 300, time: 0.058, data: 0.002) G_GAN: 2.170 G_L1: 12.785 D_real: 0.111 D_fake: 0.138 \n",
      "(epoch: 71, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.134 G_L1: 7.775 D_real: 0.174 D_fake: 0.816 \n",
      "(epoch: 71, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.652 G_L1: 6.752 D_real: 1.346 D_fake: 0.246 \n",
      "End of epoch 71 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 100, time: 0.132, data: 0.063) G_GAN: 1.057 G_L1: 5.533 D_real: 0.104 D_fake: 0.955 \n",
      "(epoch: 72, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.632 G_L1: 0.022 D_real: 0.575 D_fake: 0.857 \n",
      "(epoch: 72, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.599 G_L1: 11.104 D_real: 0.381 D_fake: 0.523 \n",
      "(epoch: 72, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.562 G_L1: 9.084 D_real: 0.955 D_fake: 0.170 \n",
      "(epoch: 72, iters: 500, time: 0.128, data: 0.002) G_GAN: 1.295 G_L1: 12.427 D_real: 0.514 D_fake: 0.512 \n",
      "End of epoch 72 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 100, time: 0.057, data: 0.066) G_GAN: 1.864 G_L1: 7.068 D_real: 0.046 D_fake: 0.365 \n",
      "(epoch: 73, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.088 G_L1: 7.563 D_real: 0.773 D_fake: 0.266 \n",
      "(epoch: 73, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.042 G_L1: 13.246 D_real: 0.071 D_fake: 1.397 \n",
      "(epoch: 73, iters: 400, time: 0.134, data: 0.001) G_GAN: 0.833 G_L1: 17.932 D_real: 0.017 D_fake: 2.182 \n",
      "(epoch: 73, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.885 G_L1: 3.992 D_real: 0.370 D_fake: 1.182 \n",
      "End of epoch 73 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 100, time: 0.058, data: 0.061) G_GAN: 2.145 G_L1: 10.951 D_real: 0.245 D_fake: 0.156 \n",
      "(epoch: 74, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.550 G_L1: 7.654 D_real: 0.041 D_fake: 0.800 \n",
      "(epoch: 74, iters: 300, time: 0.131, data: 0.001) G_GAN: 1.768 G_L1: 14.477 D_real: 0.129 D_fake: 0.233 \n",
      "(epoch: 74, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.913 G_L1: 4.723 D_real: 0.265 D_fake: 1.223 \n",
      "(epoch: 74, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.219 G_L1: 6.385 D_real: 1.186 D_fake: 0.146 \n",
      "End of epoch 74 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 100, time: 0.057, data: 0.065) G_GAN: 0.661 G_L1: 1.003 D_real: 0.274 D_fake: 1.024 \n",
      "(epoch: 75, iters: 200, time: 0.131, data: 0.001) G_GAN: 1.302 G_L1: 7.213 D_real: 0.061 D_fake: 0.889 \n",
      "(epoch: 75, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.393 G_L1: 6.898 D_real: 0.050 D_fake: 1.366 \n",
      "(epoch: 75, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.120 G_L1: 2.887 D_real: 0.497 D_fake: 0.683 \n",
      "(epoch: 75, iters: 500, time: 0.059, data: 0.001) G_GAN: 3.277 G_L1: 9.458 D_real: 0.116 D_fake: 0.048 \n",
      "saving the model at the end of epoch 75, iters 37500\n",
      "End of epoch 75 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 100, time: 0.133, data: 0.064) G_GAN: 1.259 G_L1: 9.313 D_real: 0.040 D_fake: 0.563 \n",
      "(epoch: 76, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.787 G_L1: 6.781 D_real: 0.594 D_fake: 0.141 \n",
      "(epoch: 76, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.384 G_L1: 5.560 D_real: 0.908 D_fake: 0.137 \n",
      "(epoch: 76, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.505 G_L1: 4.281 D_real: 0.197 D_fake: 0.290 \n",
      "(epoch: 76, iters: 500, time: 0.172, data: 0.001) G_GAN: 0.825 G_L1: 6.347 D_real: 0.066 D_fake: 1.195 \n",
      "End of epoch 76 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 100, time: 0.057, data: 0.065) G_GAN: 1.748 G_L1: 6.092 D_real: 1.303 D_fake: 0.124 \n",
      "(epoch: 77, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.558 G_L1: 0.017 D_real: 0.426 D_fake: 1.083 \n",
      "(epoch: 77, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.292 G_L1: 7.534 D_real: 0.827 D_fake: 0.222 \n",
      "(epoch: 77, iters: 400, time: 0.133, data: 0.001) G_GAN: 1.041 G_L1: 10.948 D_real: 0.366 D_fake: 0.803 \n",
      "(epoch: 77, iters: 500, time: 0.059, data: 0.001) G_GAN: 0.778 G_L1: 7.587 D_real: 0.236 D_fake: 1.359 \n",
      "End of epoch 77 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 100, time: 0.057, data: 0.067) G_GAN: 1.268 G_L1: 4.719 D_real: 0.390 D_fake: 0.390 \n",
      "(epoch: 78, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.453 G_L1: 7.151 D_real: 1.048 D_fake: 0.065 \n",
      "(epoch: 78, iters: 300, time: 0.132, data: 0.001) G_GAN: 1.291 G_L1: 12.330 D_real: 0.518 D_fake: 0.182 \n",
      "(epoch: 78, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.270 G_L1: 12.332 D_real: 0.058 D_fake: 0.688 \n",
      "(epoch: 78, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.858 G_L1: 12.810 D_real: 0.310 D_fake: 0.144 \n",
      "End of epoch 78 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.687 G_L1: 8.404 D_real: 0.380 D_fake: 0.231 \n",
      "(epoch: 79, iters: 200, time: 0.135, data: 0.001) G_GAN: 3.281 G_L1: 6.407 D_real: 0.352 D_fake: 0.037 \n",
      "(epoch: 79, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.763 G_L1: 8.883 D_real: 0.041 D_fake: 0.372 \n",
      "(epoch: 79, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.279 G_L1: 6.075 D_real: 0.611 D_fake: 0.352 \n",
      "(epoch: 79, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.685 G_L1: 0.037 D_real: 0.775 D_fake: 0.638 \n",
      "End of epoch 79 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 100, time: 0.140, data: 0.064) G_GAN: 1.896 G_L1: 13.841 D_real: 0.415 D_fake: 0.255 \n",
      "(epoch: 80, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.523 G_L1: 11.884 D_real: 0.781 D_fake: 0.210 \n",
      "(epoch: 80, iters: 300, time: 0.059, data: 0.001) G_GAN: 1.081 G_L1: 10.582 D_real: 0.324 D_fake: 1.038 \n",
      "(epoch: 80, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.978 G_L1: 5.518 D_real: 0.518 D_fake: 1.156 \n",
      "(epoch: 80, iters: 500, time: 0.135, data: 0.001) G_GAN: 2.044 G_L1: 8.257 D_real: 0.543 D_fake: 0.077 \n",
      "saving the latest model (epoch 80, total_iters 40000)\n",
      "saving the model at the end of epoch 80, iters 40000\n",
      "End of epoch 80 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 100, time: 0.058, data: 0.062) G_GAN: 0.694 G_L1: 0.031 D_real: 0.538 D_fake: 0.890 \n",
      "(epoch: 81, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.709 G_L1: 7.085 D_real: 0.072 D_fake: 0.647 \n",
      "(epoch: 81, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.436 G_L1: 7.477 D_real: 0.077 D_fake: 0.571 \n",
      "(epoch: 81, iters: 400, time: 0.140, data: 0.001) G_GAN: 1.898 G_L1: 9.937 D_real: 0.343 D_fake: 0.536 \n",
      "(epoch: 81, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.906 G_L1: 7.328 D_real: 1.013 D_fake: 0.109 \n",
      "End of epoch 81 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.548 G_L1: 6.232 D_real: 0.172 D_fake: 0.288 \n",
      "(epoch: 82, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.856 G_L1: 7.236 D_real: 0.133 D_fake: 1.794 \n",
      "(epoch: 82, iters: 300, time: 0.137, data: 0.001) G_GAN: 0.778 G_L1: 4.521 D_real: 1.433 D_fake: 0.102 \n",
      "(epoch: 82, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.483 G_L1: 8.629 D_real: 0.419 D_fake: 0.214 \n",
      "(epoch: 82, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.357 G_L1: 4.551 D_real: 0.272 D_fake: 0.403 \n",
      "End of epoch 82 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 100, time: 0.058, data: 0.065) G_GAN: 2.136 G_L1: 8.361 D_real: 0.044 D_fake: 0.151 \n",
      "(epoch: 83, iters: 200, time: 0.137, data: 0.001) G_GAN: 1.463 G_L1: 5.562 D_real: 0.441 D_fake: 0.391 \n",
      "(epoch: 83, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.886 G_L1: 9.047 D_real: 0.695 D_fake: 0.083 \n",
      "(epoch: 83, iters: 400, time: 0.058, data: 0.001) G_GAN: 3.288 G_L1: 7.329 D_real: 0.352 D_fake: 0.033 \n",
      "(epoch: 83, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.848 G_L1: 0.055 D_real: 1.142 D_fake: 0.449 \n",
      "End of epoch 83 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 100, time: 0.179, data: 0.064) G_GAN: 3.266 G_L1: 8.006 D_real: 0.042 D_fake: 0.041 \n",
      "(epoch: 84, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.645 G_L1: 6.027 D_real: 0.420 D_fake: 0.188 \n",
      "(epoch: 84, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.078 G_L1: 6.803 D_real: 0.485 D_fake: 0.605 \n",
      "(epoch: 84, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.881 G_L1: 0.981 D_real: 0.732 D_fake: 0.565 \n",
      "(epoch: 84, iters: 500, time: 0.139, data: 0.001) G_GAN: 1.440 G_L1: 6.021 D_real: 0.167 D_fake: 0.400 \n",
      "End of epoch 84 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 100, time: 0.058, data: 0.066) G_GAN: 2.237 G_L1: 10.225 D_real: 0.051 D_fake: 0.159 \n",
      "(epoch: 85, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.817 G_L1: 11.502 D_real: 0.393 D_fake: 0.142 \n",
      "(epoch: 85, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.762 G_L1: 12.349 D_real: 0.460 D_fake: 0.149 \n",
      "(epoch: 85, iters: 400, time: 0.137, data: 0.001) G_GAN: 1.327 G_L1: 9.941 D_real: 0.961 D_fake: 0.380 \n",
      "(epoch: 85, iters: 500, time: 0.059, data: 0.001) G_GAN: 2.118 G_L1: 8.121 D_real: 0.580 D_fake: 0.115 \n",
      "saving the model at the end of epoch 85, iters 42500\n",
      "End of epoch 85 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 100, time: 0.059, data: 0.065) G_GAN: 0.923 G_L1: 9.712 D_real: 0.312 D_fake: 0.868 \n",
      "(epoch: 86, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.355 G_L1: 2.848 D_real: 0.446 D_fake: 0.154 \n",
      "(epoch: 86, iters: 300, time: 0.136, data: 0.001) G_GAN: 1.605 G_L1: 5.207 D_real: 0.188 D_fake: 0.421 \n",
      "(epoch: 86, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.762 G_L1: 6.406 D_real: 0.671 D_fake: 0.061 \n",
      "(epoch: 86, iters: 500, time: 0.057, data: 0.001) G_GAN: 0.697 G_L1: 6.247 D_real: 1.364 D_fake: 0.276 \n",
      "End of epoch 86 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 100, time: 0.058, data: 0.067) G_GAN: 1.617 G_L1: 8.120 D_real: 0.113 D_fake: 0.565 \n",
      "(epoch: 87, iters: 200, time: 0.142, data: 0.001) G_GAN: 2.146 G_L1: 9.990 D_real: 0.057 D_fake: 0.199 \n",
      "(epoch: 87, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.547 G_L1: 7.320 D_real: 0.333 D_fake: 0.413 \n",
      "(epoch: 87, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.789 G_L1: 4.644 D_real: 0.469 D_fake: 0.192 \n",
      "(epoch: 87, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.660 G_L1: 8.817 D_real: 0.020 D_fake: 0.636 \n",
      "End of epoch 87 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 100, time: 0.136, data: 0.063) G_GAN: 1.678 G_L1: 8.498 D_real: 1.134 D_fake: 0.312 \n",
      "(epoch: 88, iters: 200, time: 0.059, data: 0.001) G_GAN: 2.444 G_L1: 7.166 D_real: 1.310 D_fake: 0.066 \n",
      "(epoch: 88, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.805 G_L1: 7.829 D_real: 0.323 D_fake: 0.153 \n",
      "(epoch: 88, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.211 G_L1: 6.182 D_real: 0.302 D_fake: 0.708 \n",
      "(epoch: 88, iters: 500, time: 0.142, data: 0.001) G_GAN: 1.926 G_L1: 18.049 D_real: 0.064 D_fake: 0.331 \n",
      "End of epoch 88 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 100, time: 0.058, data: 0.065) G_GAN: 0.396 G_L1: 5.232 D_real: 1.937 D_fake: 0.038 \n",
      "(epoch: 89, iters: 200, time: 0.057, data: 0.001) G_GAN: 3.136 G_L1: 11.530 D_real: 0.020 D_fake: 0.054 \n",
      "(epoch: 89, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.179 G_L1: 12.116 D_real: 0.561 D_fake: 0.629 \n",
      "(epoch: 89, iters: 400, time: 0.143, data: 0.001) G_GAN: 0.949 G_L1: 8.322 D_real: 0.644 D_fake: 0.408 \n",
      "(epoch: 89, iters: 500, time: 0.059, data: 0.001) G_GAN: 2.497 G_L1: 12.228 D_real: 0.346 D_fake: 0.138 \n",
      "End of epoch 89 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 100, time: 0.058, data: 0.062) G_GAN: 2.320 G_L1: 11.224 D_real: 0.052 D_fake: 0.182 \n",
      "(epoch: 90, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.559 G_L1: 11.945 D_real: 0.164 D_fake: 0.100 \n",
      "(epoch: 90, iters: 300, time: 0.184, data: 0.001) G_GAN: 2.813 G_L1: 7.858 D_real: 0.086 D_fake: 0.062 \n",
      "(epoch: 90, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.027 G_L1: 2.473 D_real: 0.197 D_fake: 0.751 \n",
      "(epoch: 90, iters: 500, time: 0.059, data: 0.001) G_GAN: 0.688 G_L1: 0.028 D_real: 0.601 D_fake: 0.817 \n",
      "saving the latest model (epoch 90, total_iters 45000)\n",
      "saving the model at the end of epoch 90, iters 45000\n",
      "End of epoch 90 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 100, time: 0.058, data: 0.066) G_GAN: 1.724 G_L1: 7.256 D_real: 0.550 D_fake: 0.151 \n",
      "(epoch: 91, iters: 200, time: 0.146, data: 0.001) G_GAN: 2.313 G_L1: 12.038 D_real: 0.007 D_fake: 0.180 \n",
      "(epoch: 91, iters: 300, time: 0.059, data: 0.001) G_GAN: 1.328 G_L1: 0.552 D_real: 0.915 D_fake: 0.616 \n",
      "(epoch: 91, iters: 400, time: 0.057, data: 0.001) G_GAN: 3.000 G_L1: 2.267 D_real: 0.380 D_fake: 0.056 \n",
      "(epoch: 91, iters: 500, time: 0.057, data: 0.001) G_GAN: 1.361 G_L1: 7.997 D_real: 0.039 D_fake: 0.499 \n",
      "End of epoch 91 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 100, time: 0.149, data: 0.063) G_GAN: 1.939 G_L1: 7.690 D_real: 0.318 D_fake: 0.166 \n",
      "(epoch: 92, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.411 G_L1: 7.366 D_real: 0.124 D_fake: 0.116 \n",
      "(epoch: 92, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.370 G_L1: 8.834 D_real: 0.262 D_fake: 0.574 \n",
      "(epoch: 92, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.293 G_L1: 9.285 D_real: 0.158 D_fake: 0.499 \n",
      "(epoch: 92, iters: 500, time: 0.139, data: 0.001) G_GAN: 1.419 G_L1: 8.722 D_real: 0.049 D_fake: 1.014 \n",
      "End of epoch 92 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 100, time: 0.058, data: 0.067) G_GAN: 0.681 G_L1: 0.206 D_real: 0.642 D_fake: 0.739 \n",
      "(epoch: 93, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.479 G_L1: 3.695 D_real: 0.773 D_fake: 0.056 \n",
      "(epoch: 93, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.965 G_L1: 4.742 D_real: 1.374 D_fake: 0.373 \n",
      "(epoch: 93, iters: 400, time: 0.148, data: 0.001) G_GAN: 0.698 G_L1: 4.517 D_real: 0.301 D_fake: 1.309 \n",
      "(epoch: 93, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.681 G_L1: 8.998 D_real: 0.059 D_fake: 0.559 \n",
      "End of epoch 93 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 100, time: 0.058, data: 0.063) G_GAN: 1.886 G_L1: 8.734 D_real: 0.099 D_fake: 1.234 \n",
      "(epoch: 94, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.028 G_L1: 11.225 D_real: 0.181 D_fake: 0.942 \n",
      "(epoch: 94, iters: 300, time: 0.141, data: 0.001) G_GAN: 1.700 G_L1: 5.680 D_real: 0.056 D_fake: 0.320 \n",
      "(epoch: 94, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.225 G_L1: 5.133 D_real: 0.439 D_fake: 0.640 \n",
      "(epoch: 94, iters: 500, time: 0.057, data: 0.001) G_GAN: 0.916 G_L1: 0.036 D_real: 1.478 D_fake: 0.278 \n",
      "End of epoch 94 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 100, time: 0.057, data: 0.064) G_GAN: 1.554 G_L1: 8.105 D_real: 0.284 D_fake: 0.596 \n",
      "(epoch: 95, iters: 200, time: 0.148, data: 0.001) G_GAN: 1.514 G_L1: 5.912 D_real: 0.410 D_fake: 0.389 \n",
      "(epoch: 95, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.931 G_L1: 6.943 D_real: 0.303 D_fake: 0.169 \n",
      "(epoch: 95, iters: 400, time: 0.057, data: 0.002) G_GAN: 2.096 G_L1: 10.180 D_real: 0.027 D_fake: 0.223 \n",
      "(epoch: 95, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.641 G_L1: 12.758 D_real: 0.048 D_fake: 1.798 \n",
      "saving the model at the end of epoch 95, iters 47500\n",
      "End of epoch 95 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 100, time: 0.145, data: 0.064) G_GAN: 1.772 G_L1: 4.383 D_real: 1.157 D_fake: 0.427 \n",
      "(epoch: 96, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.778 G_L1: 9.454 D_real: 0.557 D_fake: 0.051 \n",
      "(epoch: 96, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.821 G_L1: 3.738 D_real: 0.935 D_fake: 0.650 \n",
      "(epoch: 96, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.216 G_L1: 11.563 D_real: 0.465 D_fake: 0.710 \n",
      "(epoch: 96, iters: 500, time: 0.260, data: 0.001) G_GAN: 1.545 G_L1: 9.525 D_real: 0.200 D_fake: 0.633 \n",
      "End of epoch 96 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 100, time: 0.058, data: 0.068) G_GAN: 0.995 G_L1: 6.280 D_real: 0.492 D_fake: 0.499 \n",
      "(epoch: 97, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.057 G_L1: 12.107 D_real: 0.041 D_fake: 0.991 \n",
      "(epoch: 97, iters: 300, time: 0.059, data: 0.001) G_GAN: 0.665 G_L1: 7.041 D_real: 1.053 D_fake: 0.446 \n",
      "(epoch: 97, iters: 400, time: 0.148, data: 0.001) G_GAN: 1.339 G_L1: 6.623 D_real: 0.315 D_fake: 0.579 \n",
      "(epoch: 97, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.743 G_L1: 8.779 D_real: 0.191 D_fake: 0.367 \n",
      "End of epoch 97 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.296 G_L1: 6.002 D_real: 0.230 D_fake: 0.427 \n",
      "(epoch: 98, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.051 G_L1: 7.516 D_real: 3.241 D_fake: 0.328 \n",
      "(epoch: 98, iters: 300, time: 0.145, data: 0.001) G_GAN: 1.291 G_L1: 7.067 D_real: 0.394 D_fake: 0.476 \n",
      "(epoch: 98, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.095 G_L1: 5.611 D_real: 0.138 D_fake: 0.176 \n",
      "(epoch: 98, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.673 G_L1: 7.429 D_real: 0.349 D_fake: 0.397 \n",
      "End of epoch 98 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 100, time: 0.059, data: 0.065) G_GAN: 1.580 G_L1: 9.030 D_real: 0.396 D_fake: 0.195 \n",
      "(epoch: 99, iters: 200, time: 0.145, data: 0.001) G_GAN: 1.467 G_L1: 3.086 D_real: 0.310 D_fake: 0.376 \n",
      "(epoch: 99, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.096 G_L1: 6.804 D_real: 1.632 D_fake: 0.352 \n",
      "(epoch: 99, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.868 G_L1: 11.608 D_real: 0.010 D_fake: 0.260 \n",
      "(epoch: 99, iters: 500, time: 0.059, data: 0.001) G_GAN: 0.906 G_L1: 9.868 D_real: 0.593 D_fake: 0.766 \n",
      "End of epoch 99 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 100, time: 0.148, data: 0.065) G_GAN: 1.886 G_L1: 6.423 D_real: 2.042 D_fake: 0.051 \n",
      "(epoch: 100, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.389 G_L1: 9.036 D_real: 0.088 D_fake: 0.152 \n",
      "(epoch: 100, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.522 G_L1: 19.031 D_real: 0.026 D_fake: 0.604 \n",
      "(epoch: 100, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.695 G_L1: 6.853 D_real: 0.641 D_fake: 0.282 \n",
      "(epoch: 100, iters: 500, time: 0.148, data: 0.001) G_GAN: 1.436 G_L1: 8.613 D_real: 0.068 D_fake: 0.428 \n",
      "saving the latest model (epoch 100, total_iters 50000)\n",
      "saving the model at the end of epoch 100, iters 50000\n",
      "End of epoch 100 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.058, data: 0.063) G_GAN: 0.892 G_L1: 4.649 D_real: 0.337 D_fake: 0.710 \n",
      "(epoch: 101, iters: 200, time: 0.058, data: 0.001) G_GAN: 3.443 G_L1: 10.170 D_real: 0.049 D_fake: 0.612 \n",
      "(epoch: 101, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.561 G_L1: 6.619 D_real: 1.065 D_fake: 0.087 \n",
      "(epoch: 101, iters: 400, time: 0.147, data: 0.001) G_GAN: 2.203 G_L1: 5.602 D_real: 0.244 D_fake: 0.102 \n",
      "(epoch: 101, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.304 G_L1: 8.330 D_real: 0.047 D_fake: 0.467 \n",
      "End of epoch 101 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.629 G_L1: 9.944 D_real: 0.072 D_fake: 0.862 \n",
      "(epoch: 102, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.590 G_L1: 0.993 D_real: 0.332 D_fake: 0.228 \n",
      "(epoch: 102, iters: 300, time: 0.191, data: 0.001) G_GAN: 1.085 G_L1: 7.074 D_real: 0.638 D_fake: 1.150 \n",
      "(epoch: 102, iters: 400, time: 0.057, data: 0.002) G_GAN: 1.107 G_L1: 4.433 D_real: 0.361 D_fake: 0.391 \n",
      "(epoch: 102, iters: 500, time: 0.058, data: 0.001) G_GAN: 2.689 G_L1: 6.231 D_real: 0.194 D_fake: 0.086 \n",
      "End of epoch 102 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 100, time: 0.058, data: 0.061) G_GAN: 1.138 G_L1: 9.421 D_real: 0.306 D_fake: 0.859 \n",
      "(epoch: 103, iters: 200, time: 0.148, data: 0.001) G_GAN: 1.031 G_L1: 5.304 D_real: 0.926 D_fake: 0.332 \n",
      "(epoch: 103, iters: 300, time: 0.058, data: 0.001) G_GAN: 2.445 G_L1: 9.354 D_real: 0.375 D_fake: 0.079 \n",
      "(epoch: 103, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.664 G_L1: 10.917 D_real: 0.014 D_fake: 0.879 \n",
      "(epoch: 103, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.506 G_L1: 6.005 D_real: 0.256 D_fake: 0.568 \n",
      "End of epoch 103 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 100, time: 0.142, data: 0.063) G_GAN: 0.956 G_L1: 0.105 D_real: 1.275 D_fake: 0.334 \n",
      "(epoch: 104, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.156 G_L1: 4.383 D_real: 1.014 D_fake: 0.121 \n",
      "(epoch: 104, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.861 G_L1: 8.507 D_real: 0.417 D_fake: 0.900 \n",
      "(epoch: 104, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.347 G_L1: 8.969 D_real: 0.320 D_fake: 0.406 \n",
      "(epoch: 104, iters: 500, time: 0.144, data: 0.001) G_GAN: 2.663 G_L1: 4.074 D_real: 1.287 D_fake: 0.056 \n",
      "End of epoch 104 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 100, time: 0.058, data: 0.064) G_GAN: 0.997 G_L1: 3.684 D_real: 0.079 D_fake: 1.549 \n",
      "(epoch: 105, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.636 G_L1: 17.952 D_real: 0.015 D_fake: 0.328 \n",
      "(epoch: 105, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.891 G_L1: 8.591 D_real: 0.046 D_fake: 1.608 \n",
      "(epoch: 105, iters: 400, time: 0.154, data: 0.001) G_GAN: 2.061 G_L1: 9.497 D_real: 0.076 D_fake: 0.214 \n",
      "(epoch: 105, iters: 500, time: 0.059, data: 0.001) G_GAN: 0.686 G_L1: 5.096 D_real: 1.987 D_fake: 0.196 \n",
      "saving the model at the end of epoch 105, iters 52500\n",
      "End of epoch 105 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 100, time: 0.056, data: 0.063) G_GAN: 0.386 G_L1: 4.224 D_real: 0.051 D_fake: 2.375 \n",
      "(epoch: 106, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.073 G_L1: 10.390 D_real: 0.127 D_fake: 0.303 \n",
      "(epoch: 106, iters: 300, time: 0.151, data: 0.001) G_GAN: 2.006 G_L1: 5.914 D_real: 0.375 D_fake: 0.235 \n",
      "(epoch: 106, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.852 G_L1: 6.569 D_real: 0.577 D_fake: 1.074 \n",
      "(epoch: 106, iters: 500, time: 0.059, data: 0.001) G_GAN: 2.352 G_L1: 7.401 D_real: 0.270 D_fake: 0.099 \n",
      "End of epoch 106 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.967 G_L1: 9.544 D_real: 0.353 D_fake: 0.191 \n",
      "(epoch: 107, iters: 200, time: 0.150, data: 0.001) G_GAN: 1.699 G_L1: 10.943 D_real: 0.177 D_fake: 0.402 \n",
      "(epoch: 107, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.615 G_L1: 7.212 D_real: 0.707 D_fake: 0.437 \n",
      "(epoch: 107, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.215 G_L1: 7.152 D_real: 0.409 D_fake: 0.872 \n",
      "(epoch: 107, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.688 G_L1: 8.699 D_real: 0.045 D_fake: 0.476 \n",
      "End of epoch 107 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 100, time: 0.202, data: 0.061) G_GAN: 2.415 G_L1: 7.202 D_real: 2.232 D_fake: 0.055 \n",
      "(epoch: 108, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.514 G_L1: 8.984 D_real: 0.288 D_fake: 0.099 \n",
      "(epoch: 108, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.426 G_L1: 11.530 D_real: 0.086 D_fake: 0.963 \n",
      "(epoch: 108, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.516 G_L1: 8.125 D_real: 0.159 D_fake: 0.340 \n",
      "(epoch: 108, iters: 500, time: 0.150, data: 0.001) G_GAN: 1.805 G_L1: 29.456 D_real: 0.300 D_fake: 0.230 \n",
      "End of epoch 108 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.912 G_L1: 8.295 D_real: 0.260 D_fake: 0.380 \n",
      "(epoch: 109, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.684 G_L1: 7.827 D_real: 0.109 D_fake: 0.743 \n",
      "(epoch: 109, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.191 G_L1: 6.693 D_real: 1.080 D_fake: 0.537 \n",
      "(epoch: 109, iters: 400, time: 0.157, data: 0.001) G_GAN: 1.478 G_L1: 10.708 D_real: 0.111 D_fake: 0.558 \n",
      "(epoch: 109, iters: 500, time: 0.058, data: 0.001) G_GAN: 2.711 G_L1: 8.057 D_real: 0.268 D_fake: 0.075 \n",
      "End of epoch 109 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 100, time: 0.058, data: 0.067) G_GAN: 1.458 G_L1: 10.900 D_real: 0.515 D_fake: 0.319 \n",
      "(epoch: 110, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.986 G_L1: 6.377 D_real: 0.537 D_fake: 0.726 \n",
      "(epoch: 110, iters: 300, time: 0.151, data: 0.001) G_GAN: 2.508 G_L1: 4.019 D_real: 0.064 D_fake: 1.136 \n",
      "(epoch: 110, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.752 G_L1: 0.860 D_real: 1.100 D_fake: 0.424 \n",
      "(epoch: 110, iters: 500, time: 0.058, data: 0.002) G_GAN: 1.273 G_L1: 9.889 D_real: 0.110 D_fake: 0.742 \n",
      "saving the latest model (epoch 110, total_iters 55000)\n",
      "saving the model at the end of epoch 110, iters 55000\n",
      "End of epoch 110 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.358 G_L1: 12.538 D_real: 0.011 D_fake: 0.768 \n",
      "(epoch: 111, iters: 200, time: 0.155, data: 0.001) G_GAN: 2.112 G_L1: 6.036 D_real: 2.010 D_fake: 0.075 \n",
      "(epoch: 111, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.948 G_L1: 8.637 D_real: 0.882 D_fake: 0.682 \n",
      "(epoch: 111, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.547 G_L1: 8.815 D_real: 0.156 D_fake: 1.190 \n",
      "(epoch: 111, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.323 G_L1: 8.792 D_real: 0.228 D_fake: 0.968 \n",
      "End of epoch 111 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 100, time: 0.157, data: 0.065) G_GAN: 2.214 G_L1: 7.716 D_real: 0.443 D_fake: 0.105 \n",
      "(epoch: 112, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.619 G_L1: 9.844 D_real: 0.428 D_fake: 0.223 \n",
      "(epoch: 112, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.293 G_L1: 5.553 D_real: 0.461 D_fake: 0.287 \n",
      "(epoch: 112, iters: 400, time: 0.059, data: 0.001) G_GAN: 1.759 G_L1: 12.017 D_real: 0.012 D_fake: 0.579 \n",
      "(epoch: 112, iters: 500, time: 0.158, data: 0.001) G_GAN: 1.946 G_L1: 11.252 D_real: 0.130 D_fake: 0.790 \n",
      "End of epoch 112 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.620 G_L1: 8.949 D_real: 0.115 D_fake: 0.579 \n",
      "(epoch: 113, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.154 G_L1: 9.585 D_real: 0.423 D_fake: 0.105 \n",
      "(epoch: 113, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.552 G_L1: 3.183 D_real: 0.503 D_fake: 0.251 \n",
      "(epoch: 113, iters: 400, time: 0.189, data: 0.001) G_GAN: 1.519 G_L1: 3.925 D_real: 0.222 D_fake: 0.351 \n",
      "(epoch: 113, iters: 500, time: 0.059, data: 0.001) G_GAN: 2.566 G_L1: 5.948 D_real: 0.098 D_fake: 0.087 \n",
      "End of epoch 113 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 100, time: 0.057, data: 0.071) G_GAN: 1.124 G_L1: 8.101 D_real: 0.613 D_fake: 1.050 \n",
      "(epoch: 114, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.546 G_L1: 5.505 D_real: 0.278 D_fake: 0.363 \n",
      "(epoch: 114, iters: 300, time: 0.155, data: 0.002) G_GAN: 0.798 G_L1: 9.432 D_real: 0.500 D_fake: 0.998 \n",
      "(epoch: 114, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.018 G_L1: 4.701 D_real: 2.178 D_fake: 0.285 \n",
      "(epoch: 114, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.105 G_L1: 11.282 D_real: 0.159 D_fake: 1.055 \n",
      "End of epoch 114 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 100, time: 0.058, data: 0.065) G_GAN: 2.396 G_L1: 5.849 D_real: 0.434 D_fake: 0.082 \n",
      "(epoch: 115, iters: 200, time: 0.153, data: 0.001) G_GAN: 1.656 G_L1: 9.103 D_real: 0.034 D_fake: 0.533 \n",
      "(epoch: 115, iters: 300, time: 0.058, data: 0.001) G_GAN: 2.436 G_L1: 11.139 D_real: 0.200 D_fake: 0.086 \n",
      "(epoch: 115, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.992 G_L1: 7.398 D_real: 0.150 D_fake: 1.066 \n",
      "(epoch: 115, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.804 G_L1: 6.824 D_real: 1.648 D_fake: 0.296 \n",
      "saving the model at the end of epoch 115, iters 57500\n",
      "End of epoch 115 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 100, time: 0.159, data: 0.065) G_GAN: 2.025 G_L1: 12.312 D_real: 0.089 D_fake: 0.173 \n",
      "(epoch: 116, iters: 200, time: 0.058, data: 0.001) G_GAN: 3.389 G_L1: 3.595 D_real: 1.690 D_fake: 0.015 \n",
      "(epoch: 116, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.833 G_L1: 12.007 D_real: 0.066 D_fake: 0.326 \n",
      "(epoch: 116, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.419 G_L1: 5.674 D_real: 0.203 D_fake: 0.408 \n",
      "(epoch: 116, iters: 500, time: 0.162, data: 0.001) G_GAN: 2.589 G_L1: 9.517 D_real: 0.221 D_fake: 0.054 \n",
      "End of epoch 116 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.311 G_L1: 8.640 D_real: 0.460 D_fake: 0.257 \n",
      "(epoch: 117, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.143 G_L1: 3.207 D_real: 0.706 D_fake: 0.319 \n",
      "(epoch: 117, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.130 G_L1: 7.624 D_real: 1.195 D_fake: 0.389 \n",
      "(epoch: 117, iters: 400, time: 0.158, data: 0.001) G_GAN: 1.844 G_L1: 4.832 D_real: 0.072 D_fake: 0.710 \n",
      "(epoch: 117, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.610 G_L1: 0.459 D_real: 0.614 D_fake: 0.825 \n",
      "End of epoch 117 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 100, time: 0.058, data: 0.063) G_GAN: 2.020 G_L1: 9.314 D_real: 0.123 D_fake: 0.153 \n",
      "(epoch: 118, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.912 G_L1: 10.044 D_real: 0.174 D_fake: 0.335 \n",
      "(epoch: 118, iters: 300, time: 0.200, data: 0.001) G_GAN: 1.095 G_L1: 8.175 D_real: 0.103 D_fake: 0.810 \n",
      "(epoch: 118, iters: 400, time: 0.057, data: 0.001) G_GAN: 2.602 G_L1: 7.170 D_real: 0.139 D_fake: 0.098 \n",
      "(epoch: 118, iters: 500, time: 0.058, data: 0.001) G_GAN: 4.360 G_L1: 8.218 D_real: 0.715 D_fake: 0.011 \n",
      "End of epoch 118 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 100, time: 0.058, data: 0.066) G_GAN: 1.287 G_L1: 3.563 D_real: 0.536 D_fake: 0.933 \n",
      "(epoch: 119, iters: 200, time: 0.160, data: 0.001) G_GAN: 2.128 G_L1: 8.982 D_real: 0.012 D_fake: 0.243 \n",
      "(epoch: 119, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.500 G_L1: 10.635 D_real: 0.085 D_fake: 0.459 \n",
      "(epoch: 119, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.515 G_L1: 8.717 D_real: 0.139 D_fake: 0.435 \n",
      "(epoch: 119, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.464 G_L1: 14.111 D_real: 0.135 D_fake: 0.645 \n",
      "End of epoch 119 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 100, time: 0.160, data: 0.063) G_GAN: 1.737 G_L1: 5.250 D_real: 0.427 D_fake: 0.199 \n",
      "(epoch: 120, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.214 G_L1: 9.169 D_real: 0.218 D_fake: 0.688 \n",
      "(epoch: 120, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.775 G_L1: 9.469 D_real: 0.519 D_fake: 0.269 \n",
      "(epoch: 120, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.629 G_L1: 5.065 D_real: 0.841 D_fake: 0.107 \n",
      "(epoch: 120, iters: 500, time: 0.158, data: 0.001) G_GAN: 0.822 G_L1: 6.515 D_real: 0.584 D_fake: 0.714 \n",
      "saving the latest model (epoch 120, total_iters 60000)\n",
      "saving the model at the end of epoch 120, iters 60000\n",
      "End of epoch 120 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 100, time: 0.058, data: 0.064) G_GAN: 2.131 G_L1: 9.037 D_real: 0.054 D_fake: 0.159 \n",
      "(epoch: 121, iters: 200, time: 0.059, data: 0.001) G_GAN: 2.590 G_L1: 10.679 D_real: 0.093 D_fake: 0.102 \n",
      "(epoch: 121, iters: 300, time: 0.057, data: 0.001) G_GAN: 0.453 G_L1: 5.744 D_real: 1.422 D_fake: 0.421 \n",
      "(epoch: 121, iters: 400, time: 0.163, data: 0.001) G_GAN: 1.574 G_L1: 8.654 D_real: 0.086 D_fake: 0.591 \n",
      "(epoch: 121, iters: 500, time: 0.059, data: 0.001) G_GAN: 0.708 G_L1: 9.426 D_real: 0.819 D_fake: 0.396 \n",
      "End of epoch 121 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 100, time: 0.057, data: 0.064) G_GAN: 1.793 G_L1: 7.341 D_real: 0.151 D_fake: 0.266 \n",
      "(epoch: 122, iters: 200, time: 0.057, data: 0.001) G_GAN: 4.153 G_L1: 19.366 D_real: 0.045 D_fake: 0.019 \n",
      "(epoch: 122, iters: 300, time: 0.153, data: 0.001) G_GAN: 0.840 G_L1: 0.223 D_real: 1.023 D_fake: 0.488 \n",
      "(epoch: 122, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.777 G_L1: 5.385 D_real: 0.201 D_fake: 1.339 \n",
      "(epoch: 122, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.253 G_L1: 4.571 D_real: 0.367 D_fake: 0.353 \n",
      "End of epoch 122 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.923 G_L1: 5.188 D_real: 0.111 D_fake: 0.193 \n",
      "(epoch: 123, iters: 200, time: 0.207, data: 0.001) G_GAN: 1.051 G_L1: 9.314 D_real: 1.529 D_fake: 0.419 \n",
      "(epoch: 123, iters: 300, time: 0.058, data: 0.001) G_GAN: 3.071 G_L1: 5.560 D_real: 0.116 D_fake: 0.053 \n",
      "(epoch: 123, iters: 400, time: 0.057, data: 0.001) G_GAN: 2.816 G_L1: 6.152 D_real: 0.043 D_fake: 0.072 \n",
      "(epoch: 123, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.528 G_L1: 7.121 D_real: 0.463 D_fake: 0.241 \n",
      "End of epoch 123 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 100, time: 0.163, data: 0.062) G_GAN: 1.806 G_L1: 8.607 D_real: 0.143 D_fake: 0.258 \n",
      "(epoch: 124, iters: 200, time: 0.059, data: 0.001) G_GAN: 1.922 G_L1: 9.629 D_real: 0.210 D_fake: 0.243 \n",
      "(epoch: 124, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.572 G_L1: 5.501 D_real: 0.291 D_fake: 0.295 \n",
      "(epoch: 124, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.233 G_L1: 7.250 D_real: 0.169 D_fake: 0.149 \n",
      "(epoch: 124, iters: 500, time: 0.160, data: 0.001) G_GAN: 2.417 G_L1: 4.343 D_real: 0.035 D_fake: 0.115 \n",
      "End of epoch 124 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 100, time: 0.058, data: 0.064) G_GAN: 0.731 G_L1: 0.039 D_real: 0.779 D_fake: 0.646 \n",
      "(epoch: 125, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.439 G_L1: 9.044 D_real: 0.261 D_fake: 0.094 \n",
      "(epoch: 125, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.011 G_L1: 9.973 D_real: 0.203 D_fake: 0.743 \n",
      "(epoch: 125, iters: 400, time: 0.162, data: 0.001) G_GAN: 1.202 G_L1: 6.948 D_real: 0.308 D_fake: 1.062 \n",
      "(epoch: 125, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.724 G_L1: 6.873 D_real: 0.019 D_fake: 1.858 \n",
      "saving the model at the end of epoch 125, iters 62500\n",
      "End of epoch 125 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 100, time: 0.058, data: 0.063) G_GAN: 1.219 G_L1: 7.843 D_real: 0.284 D_fake: 0.390 \n",
      "(epoch: 126, iters: 200, time: 0.057, data: 0.002) G_GAN: 1.988 G_L1: 7.466 D_real: 0.051 D_fake: 0.190 \n",
      "(epoch: 126, iters: 300, time: 0.163, data: 0.001) G_GAN: 1.411 G_L1: 8.282 D_real: 0.459 D_fake: 0.285 \n",
      "(epoch: 126, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.808 G_L1: 8.996 D_real: 0.259 D_fake: 1.489 \n",
      "(epoch: 126, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.769 G_L1: 3.439 D_real: 0.215 D_fake: 0.412 \n",
      "End of epoch 126 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 100, time: 0.057, data: 0.064) G_GAN: 3.338 G_L1: 9.471 D_real: 0.863 D_fake: 0.016 \n",
      "(epoch: 127, iters: 200, time: 0.163, data: 0.001) G_GAN: 1.613 G_L1: 10.392 D_real: 0.059 D_fake: 0.379 \n",
      "(epoch: 127, iters: 300, time: 0.058, data: 0.001) G_GAN: 2.396 G_L1: 3.991 D_real: 0.690 D_fake: 0.079 \n",
      "(epoch: 127, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.088 G_L1: 9.953 D_real: 0.555 D_fake: 0.173 \n",
      "(epoch: 127, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.343 G_L1: 12.491 D_real: 0.143 D_fake: 0.801 \n",
      "End of epoch 127 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 100, time: 0.209, data: 0.064) G_GAN: 1.229 G_L1: 7.597 D_real: 1.247 D_fake: 0.261 \n",
      "(epoch: 128, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.430 G_L1: 2.124 D_real: 0.120 D_fake: 0.116 \n",
      "(epoch: 128, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.157 G_L1: 7.813 D_real: 0.067 D_fake: 1.306 \n",
      "(epoch: 128, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.260 G_L1: 9.203 D_real: 0.246 D_fake: 0.585 \n",
      "(epoch: 128, iters: 500, time: 0.154, data: 0.001) G_GAN: 2.324 G_L1: 10.037 D_real: 0.015 D_fake: 0.142 \n",
      "End of epoch 128 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 100, time: 0.057, data: 0.066) G_GAN: 1.828 G_L1: 8.287 D_real: 0.133 D_fake: 0.422 \n",
      "(epoch: 129, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.560 G_L1: 4.519 D_real: 1.134 D_fake: 0.148 \n",
      "(epoch: 129, iters: 300, time: 0.058, data: 0.001) G_GAN: 3.171 G_L1: 6.757 D_real: 0.028 D_fake: 0.060 \n",
      "(epoch: 129, iters: 400, time: 0.171, data: 0.001) G_GAN: 1.019 G_L1: 5.161 D_real: 2.537 D_fake: 0.453 \n",
      "(epoch: 129, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.420 G_L1: 7.794 D_real: 0.027 D_fake: 1.275 \n",
      "End of epoch 129 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 100, time: 0.059, data: 0.065) G_GAN: 0.923 G_L1: 7.374 D_real: 0.335 D_fake: 1.331 \n",
      "(epoch: 130, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.189 G_L1: 6.421 D_real: 0.677 D_fake: 0.574 \n",
      "(epoch: 130, iters: 300, time: 0.166, data: 0.001) G_GAN: 1.274 G_L1: 7.815 D_real: 0.231 D_fake: 0.789 \n",
      "(epoch: 130, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.712 G_L1: 9.736 D_real: 0.045 D_fake: 0.294 \n",
      "(epoch: 130, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.975 G_L1: 4.534 D_real: 0.061 D_fake: 0.581 \n",
      "saving the latest model (epoch 130, total_iters 65000)\n",
      "saving the model at the end of epoch 130, iters 65000\n",
      "End of epoch 130 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.629 G_L1: 7.260 D_real: 0.430 D_fake: 0.200 \n",
      "(epoch: 131, iters: 200, time: 0.166, data: 0.001) G_GAN: 1.602 G_L1: 9.070 D_real: 0.088 D_fake: 1.082 \n",
      "(epoch: 131, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.301 G_L1: 7.699 D_real: 0.007 D_fake: 1.679 \n",
      "(epoch: 131, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.634 G_L1: 5.739 D_real: 0.382 D_fake: 0.179 \n",
      "(epoch: 131, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.922 G_L1: 8.300 D_real: 0.010 D_fake: 0.428 \n",
      "End of epoch 131 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 100, time: 0.264, data: 0.066) G_GAN: 0.567 G_L1: 7.183 D_real: 1.619 D_fake: 0.293 \n",
      "(epoch: 132, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.080 G_L1: 4.131 D_real: 0.729 D_fake: 0.125 \n",
      "(epoch: 132, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.535 G_L1: 6.354 D_real: 0.002 D_fake: 0.400 \n",
      "(epoch: 132, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.904 G_L1: 8.558 D_real: 0.519 D_fake: 0.717 \n",
      "(epoch: 132, iters: 500, time: 0.169, data: 0.001) G_GAN: 2.903 G_L1: 5.680 D_real: 0.307 D_fake: 0.069 \n",
      "End of epoch 132 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.419 G_L1: 6.546 D_real: 0.155 D_fake: 0.727 \n",
      "(epoch: 133, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.368 G_L1: 9.561 D_real: 0.222 D_fake: 1.532 \n",
      "(epoch: 133, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.944 G_L1: 5.193 D_real: 0.682 D_fake: 0.112 \n",
      "(epoch: 133, iters: 400, time: 0.172, data: 0.001) G_GAN: 2.113 G_L1: 7.779 D_real: 0.697 D_fake: 0.132 \n",
      "(epoch: 133, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.697 G_L1: 5.054 D_real: 0.222 D_fake: 0.239 \n",
      "End of epoch 133 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 100, time: 0.058, data: 0.064) G_GAN: 0.777 G_L1: 5.844 D_real: 0.952 D_fake: 0.746 \n",
      "(epoch: 134, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.503 G_L1: 7.228 D_real: 0.608 D_fake: 0.323 \n",
      "(epoch: 134, iters: 300, time: 0.169, data: 0.001) G_GAN: 1.263 G_L1: 12.250 D_real: 0.120 D_fake: 0.665 \n",
      "(epoch: 134, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.307 G_L1: 9.374 D_real: 1.503 D_fake: 0.039 \n",
      "(epoch: 134, iters: 500, time: 0.059, data: 0.001) G_GAN: 2.664 G_L1: 5.156 D_real: 0.645 D_fake: 0.048 \n",
      "End of epoch 134 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.410 G_L1: 10.809 D_real: 0.449 D_fake: 0.290 \n",
      "(epoch: 135, iters: 200, time: 0.177, data: 0.001) G_GAN: 1.013 G_L1: 12.904 D_real: 0.896 D_fake: 0.332 \n",
      "(epoch: 135, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.694 G_L1: 12.113 D_real: 0.317 D_fake: 0.349 \n",
      "(epoch: 135, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.345 G_L1: 8.853 D_real: 0.191 D_fake: 0.465 \n",
      "(epoch: 135, iters: 500, time: 0.058, data: 0.001) G_GAN: 2.752 G_L1: 9.345 D_real: 0.235 D_fake: 0.077 \n",
      "saving the model at the end of epoch 135, iters 67500\n",
      "End of epoch 135 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 100, time: 0.173, data: 0.065) G_GAN: 0.720 G_L1: 6.701 D_real: 0.646 D_fake: 1.045 \n",
      "(epoch: 136, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.736 G_L1: 8.075 D_real: 0.557 D_fake: 0.954 \n",
      "(epoch: 136, iters: 300, time: 0.057, data: 0.001) G_GAN: 0.810 G_L1: 7.248 D_real: 0.150 D_fake: 1.204 \n",
      "(epoch: 136, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.370 G_L1: 9.319 D_real: 0.029 D_fake: 1.186 \n",
      "(epoch: 136, iters: 500, time: 0.218, data: 0.001) G_GAN: 2.919 G_L1: 9.597 D_real: 0.001 D_fake: 0.073 \n",
      "End of epoch 136 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 100, time: 0.058, data: 0.067) G_GAN: 1.873 G_L1: 8.181 D_real: 0.077 D_fake: 0.268 \n",
      "(epoch: 137, iters: 200, time: 0.058, data: 0.001) G_GAN: 3.036 G_L1: 3.592 D_real: 0.133 D_fake: 0.053 \n",
      "(epoch: 137, iters: 300, time: 0.058, data: 0.001) G_GAN: 2.388 G_L1: 10.856 D_real: 0.068 D_fake: 0.140 \n",
      "(epoch: 137, iters: 400, time: 0.166, data: 0.001) G_GAN: 2.656 G_L1: 5.794 D_real: 0.045 D_fake: 0.102 \n",
      "(epoch: 137, iters: 500, time: 0.059, data: 0.001) G_GAN: 4.255 G_L1: 6.119 D_real: 0.003 D_fake: 0.015 \n",
      "End of epoch 137 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 100, time: 0.057, data: 0.065) G_GAN: 1.402 G_L1: 5.373 D_real: 0.108 D_fake: 0.551 \n",
      "(epoch: 138, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.173 G_L1: 5.781 D_real: 1.338 D_fake: 0.067 \n",
      "(epoch: 138, iters: 300, time: 0.170, data: 0.001) G_GAN: 2.666 G_L1: 4.986 D_real: 0.201 D_fake: 0.077 \n",
      "(epoch: 138, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.444 G_L1: 6.739 D_real: 0.403 D_fake: 0.247 \n",
      "(epoch: 138, iters: 500, time: 0.059, data: 0.001) G_GAN: 6.191 G_L1: 10.534 D_real: 0.003 D_fake: 0.002 \n",
      "End of epoch 138 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 100, time: 0.058, data: 0.063) G_GAN: 1.083 G_L1: 0.012 D_real: 1.432 D_fake: 0.287 \n",
      "(epoch: 139, iters: 200, time: 0.171, data: 0.001) G_GAN: 2.477 G_L1: 9.967 D_real: 0.124 D_fake: 0.134 \n",
      "(epoch: 139, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.087 G_L1: 5.708 D_real: 0.173 D_fake: 0.990 \n",
      "(epoch: 139, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.537 G_L1: 6.078 D_real: 0.219 D_fake: 2.093 \n",
      "(epoch: 139, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.125 G_L1: 8.433 D_real: 0.213 D_fake: 0.579 \n",
      "End of epoch 139 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 100, time: 0.179, data: 0.065) G_GAN: 0.888 G_L1: 3.217 D_real: 0.362 D_fake: 1.323 \n",
      "(epoch: 140, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.956 G_L1: 6.715 D_real: 0.377 D_fake: 0.489 \n",
      "(epoch: 140, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.652 G_L1: 5.835 D_real: 0.234 D_fake: 0.257 \n",
      "(epoch: 140, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.168 G_L1: 4.113 D_real: 0.179 D_fake: 0.617 \n",
      "(epoch: 140, iters: 500, time: 0.214, data: 0.001) G_GAN: 0.954 G_L1: 10.065 D_real: 0.040 D_fake: 1.367 \n",
      "saving the latest model (epoch 140, total_iters 70000)\n",
      "saving the model at the end of epoch 140, iters 70000\n",
      "End of epoch 140 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 100, time: 0.057, data: 0.064) G_GAN: 1.671 G_L1: 6.182 D_real: 0.355 D_fake: 0.304 \n",
      "(epoch: 141, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.844 G_L1: 10.616 D_real: 0.199 D_fake: 0.240 \n",
      "(epoch: 141, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.850 G_L1: 5.951 D_real: 0.583 D_fake: 0.093 \n",
      "(epoch: 141, iters: 400, time: 0.170, data: 0.001) G_GAN: 0.811 G_L1: 4.377 D_real: 2.094 D_fake: 0.318 \n",
      "(epoch: 141, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.585 G_L1: 9.261 D_real: 0.223 D_fake: 0.419 \n",
      "End of epoch 141 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 100, time: 0.058, data: 0.066) G_GAN: 2.886 G_L1: 9.147 D_real: 0.297 D_fake: 0.055 \n",
      "(epoch: 142, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.309 G_L1: 6.702 D_real: 0.688 D_fake: 0.271 \n",
      "(epoch: 142, iters: 300, time: 0.176, data: 0.001) G_GAN: 1.840 G_L1: 6.282 D_real: 0.086 D_fake: 0.287 \n",
      "(epoch: 142, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.926 G_L1: 8.564 D_real: 0.104 D_fake: 0.205 \n",
      "(epoch: 142, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.211 G_L1: 12.628 D_real: 0.875 D_fake: 0.207 \n",
      "End of epoch 142 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 100, time: 0.057, data: 0.062) G_GAN: 0.881 G_L1: 10.552 D_real: 2.034 D_fake: 0.753 \n",
      "(epoch: 143, iters: 200, time: 0.172, data: 0.001) G_GAN: 1.083 G_L1: 7.608 D_real: 0.577 D_fake: 0.570 \n",
      "(epoch: 143, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.913 G_L1: 6.129 D_real: 0.026 D_fake: 0.247 \n",
      "(epoch: 143, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.259 G_L1: 8.160 D_real: 0.107 D_fake: 1.063 \n",
      "(epoch: 143, iters: 500, time: 0.057, data: 0.001) G_GAN: 1.640 G_L1: 3.418 D_real: 0.770 D_fake: 0.179 \n",
      "End of epoch 143 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 100, time: 0.175, data: 0.062) G_GAN: 2.513 G_L1: 10.233 D_real: 0.362 D_fake: 0.088 \n",
      "(epoch: 144, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.009 G_L1: 10.381 D_real: 0.925 D_fake: 0.745 \n",
      "(epoch: 144, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.468 G_L1: 8.557 D_real: 0.085 D_fake: 0.561 \n",
      "(epoch: 144, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.280 G_L1: 6.788 D_real: 0.258 D_fake: 0.633 \n",
      "(epoch: 144, iters: 500, time: 0.218, data: 0.001) G_GAN: 0.976 G_L1: 6.381 D_real: 0.325 D_fake: 0.784 \n",
      "End of epoch 144 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 100, time: 0.058, data: 0.065) G_GAN: 2.390 G_L1: 5.641 D_real: 0.436 D_fake: 0.064 \n",
      "(epoch: 145, iters: 200, time: 0.061, data: 0.001) G_GAN: 1.232 G_L1: 8.440 D_real: 0.941 D_fake: 0.218 \n",
      "(epoch: 145, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.865 G_L1: 1.867 D_real: 0.815 D_fake: 0.337 \n",
      "(epoch: 145, iters: 400, time: 0.178, data: 0.001) G_GAN: 1.603 G_L1: 9.919 D_real: 0.038 D_fake: 0.361 \n",
      "(epoch: 145, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.738 G_L1: 6.347 D_real: 1.897 D_fake: 0.069 \n",
      "saving the model at the end of epoch 145, iters 72500\n",
      "End of epoch 145 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 100, time: 0.059, data: 0.061) G_GAN: 0.803 G_L1: 6.826 D_real: 0.386 D_fake: 1.279 \n",
      "(epoch: 146, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.544 G_L1: 10.744 D_real: 0.001 D_fake: 0.124 \n",
      "(epoch: 146, iters: 300, time: 0.181, data: 0.001) G_GAN: 3.037 G_L1: 10.966 D_real: 0.047 D_fake: 0.066 \n",
      "(epoch: 146, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.470 G_L1: 8.607 D_real: 0.059 D_fake: 2.282 \n",
      "(epoch: 146, iters: 500, time: 0.057, data: 0.001) G_GAN: 2.006 G_L1: 8.707 D_real: 0.049 D_fake: 0.298 \n",
      "End of epoch 146 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.670 G_L1: 5.614 D_real: 0.710 D_fake: 0.236 \n",
      "(epoch: 147, iters: 200, time: 0.183, data: 0.001) G_GAN: 1.125 G_L1: 5.301 D_real: 0.146 D_fake: 0.507 \n",
      "(epoch: 147, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.715 G_L1: 9.884 D_real: 0.256 D_fake: 0.201 \n",
      "(epoch: 147, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.016 G_L1: 0.138 D_real: 1.539 D_fake: 0.276 \n",
      "(epoch: 147, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.686 G_L1: 0.016 D_real: 0.613 D_fake: 0.800 \n",
      "End of epoch 147 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 100, time: 0.182, data: 0.063) G_GAN: 1.292 G_L1: 9.022 D_real: 0.237 D_fake: 0.539 \n",
      "(epoch: 148, iters: 200, time: 0.058, data: 0.002) G_GAN: 1.643 G_L1: 6.435 D_real: 0.158 D_fake: 0.516 \n",
      "(epoch: 148, iters: 300, time: 0.058, data: 0.001) G_GAN: 2.506 G_L1: 6.930 D_real: 0.010 D_fake: 0.131 \n",
      "(epoch: 148, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.172 G_L1: 7.209 D_real: 0.186 D_fake: 0.608 \n",
      "(epoch: 148, iters: 500, time: 0.221, data: 0.001) G_GAN: 3.126 G_L1: 5.433 D_real: 0.301 D_fake: 0.043 \n",
      "End of epoch 148 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 100, time: 0.058, data: 0.064) G_GAN: 0.695 G_L1: 6.512 D_real: 0.321 D_fake: 1.369 \n",
      "(epoch: 149, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.419 G_L1: 6.525 D_real: 0.735 D_fake: 0.092 \n",
      "(epoch: 149, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.935 G_L1: 5.900 D_real: 0.404 D_fake: 0.939 \n",
      "(epoch: 149, iters: 400, time: 0.176, data: 0.001) G_GAN: 1.643 G_L1: 6.894 D_real: 0.026 D_fake: 0.325 \n",
      "(epoch: 149, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.704 G_L1: 4.419 D_real: 0.222 D_fake: 0.264 \n",
      "End of epoch 149 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 100, time: 0.058, data: 0.066) G_GAN: 2.703 G_L1: 4.023 D_real: 0.358 D_fake: 0.059 \n",
      "(epoch: 150, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.598 G_L1: 6.967 D_real: 0.226 D_fake: 0.507 \n",
      "(epoch: 150, iters: 300, time: 0.173, data: 0.001) G_GAN: 1.215 G_L1: 10.624 D_real: 1.095 D_fake: 0.230 \n",
      "(epoch: 150, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.966 G_L1: 4.660 D_real: 0.094 D_fake: 0.227 \n",
      "(epoch: 150, iters: 500, time: 0.059, data: 0.001) G_GAN: 0.669 G_L1: 0.047 D_real: 0.681 D_fake: 0.721 \n",
      "saving the latest model (epoch 150, total_iters 75000)\n",
      "saving the model at the end of epoch 150, iters 75000\n",
      "End of epoch 150 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 100, time: 0.058, data: 0.063) G_GAN: 1.689 G_L1: 8.240 D_real: 0.622 D_fake: 0.235 \n",
      "(epoch: 151, iters: 200, time: 0.178, data: 0.001) G_GAN: 1.650 G_L1: 8.830 D_real: 0.411 D_fake: 0.277 \n",
      "(epoch: 151, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.032 G_L1: 3.256 D_real: 0.111 D_fake: 0.764 \n",
      "(epoch: 151, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.664 G_L1: 7.344 D_real: 0.976 D_fake: 0.148 \n",
      "(epoch: 151, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.593 G_L1: 10.885 D_real: 0.112 D_fake: 0.337 \n",
      "End of epoch 151 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 100, time: 0.173, data: 0.065) G_GAN: 0.747 G_L1: 0.103 D_real: 0.783 D_fake: 0.612 \n",
      "(epoch: 152, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.259 G_L1: 6.830 D_real: 0.180 D_fake: 0.659 \n",
      "(epoch: 152, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.862 G_L1: 7.281 D_real: 0.340 D_fake: 0.166 \n",
      "(epoch: 152, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.755 G_L1: 6.861 D_real: 0.019 D_fake: 0.086 \n",
      "(epoch: 152, iters: 500, time: 0.222, data: 0.001) G_GAN: 2.458 G_L1: 10.299 D_real: 0.008 D_fake: 0.141 \n",
      "End of epoch 152 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 100, time: 0.058, data: 0.063) G_GAN: 1.053 G_L1: 8.171 D_real: 0.744 D_fake: 0.485 \n",
      "(epoch: 153, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.680 G_L1: 8.196 D_real: 0.547 D_fake: 0.037 \n",
      "(epoch: 153, iters: 300, time: 0.058, data: 0.001) G_GAN: 3.253 G_L1: 5.438 D_real: 0.653 D_fake: 0.031 \n",
      "(epoch: 153, iters: 400, time: 0.186, data: 0.002) G_GAN: 1.270 G_L1: 7.621 D_real: 0.176 D_fake: 1.073 \n",
      "(epoch: 153, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.669 G_L1: 8.049 D_real: 0.087 D_fake: 1.818 \n",
      "End of epoch 153 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.652 G_L1: 4.317 D_real: 0.125 D_fake: 0.342 \n",
      "(epoch: 154, iters: 200, time: 0.058, data: 0.001) G_GAN: 4.623 G_L1: 11.797 D_real: 0.093 D_fake: 0.011 \n",
      "(epoch: 154, iters: 300, time: 0.176, data: 0.001) G_GAN: 0.971 G_L1: 3.004 D_real: 0.051 D_fake: 1.036 \n",
      "(epoch: 154, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.774 G_L1: 6.250 D_real: 0.491 D_fake: 0.824 \n",
      "(epoch: 154, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.418 G_L1: 10.854 D_real: 0.310 D_fake: 2.207 \n",
      "End of epoch 154 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 100, time: 0.057, data: 0.066) G_GAN: 1.266 G_L1: 3.307 D_real: 1.387 D_fake: 0.182 \n",
      "(epoch: 155, iters: 200, time: 0.186, data: 0.001) G_GAN: 4.604 G_L1: 4.344 D_real: 0.565 D_fake: 0.011 \n",
      "(epoch: 155, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.575 G_L1: 9.104 D_real: 0.179 D_fake: 0.420 \n",
      "(epoch: 155, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.566 G_L1: 10.145 D_real: 1.185 D_fake: 0.694 \n",
      "(epoch: 155, iters: 500, time: 0.058, data: 0.001) G_GAN: 2.014 G_L1: 6.608 D_real: 1.156 D_fake: 0.108 \n",
      "saving the model at the end of epoch 155, iters 77500\n",
      "End of epoch 155 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 100, time: 0.186, data: 0.063) G_GAN: 2.066 G_L1: 14.963 D_real: 0.002 D_fake: 0.241 \n",
      "(epoch: 156, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.345 G_L1: 7.210 D_real: 0.269 D_fake: 0.406 \n",
      "(epoch: 156, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.796 G_L1: 8.348 D_real: 0.052 D_fake: 0.271 \n",
      "(epoch: 156, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.636 G_L1: 6.311 D_real: 0.173 D_fake: 0.085 \n",
      "(epoch: 156, iters: 500, time: 0.228, data: 0.001) G_GAN: 2.611 G_L1: 4.408 D_real: 1.181 D_fake: 0.041 \n",
      "End of epoch 156 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 100, time: 0.057, data: 0.063) G_GAN: 1.329 G_L1: 5.468 D_real: 0.191 D_fake: 0.446 \n",
      "(epoch: 157, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.412 G_L1: 9.811 D_real: 0.107 D_fake: 0.636 \n",
      "(epoch: 157, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.974 G_L1: 0.226 D_real: 1.168 D_fake: 0.394 \n",
      "(epoch: 157, iters: 400, time: 0.191, data: 0.001) G_GAN: 0.724 G_L1: 10.313 D_real: 0.132 D_fake: 1.496 \n",
      "(epoch: 157, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.771 G_L1: 7.058 D_real: 0.027 D_fake: 0.274 \n",
      "End of epoch 157 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.056 G_L1: 6.807 D_real: 1.821 D_fake: 0.601 \n",
      "(epoch: 158, iters: 200, time: 0.058, data: 0.002) G_GAN: 2.662 G_L1: 8.326 D_real: 0.069 D_fake: 0.086 \n",
      "(epoch: 158, iters: 300, time: 0.174, data: 0.001) G_GAN: 0.756 G_L1: 0.180 D_real: 0.878 D_fake: 0.618 \n",
      "(epoch: 158, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.049 G_L1: 3.404 D_real: 2.881 D_fake: 0.310 \n",
      "(epoch: 158, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.603 G_L1: 5.036 D_real: 0.441 D_fake: 0.285 \n",
      "End of epoch 158 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 100, time: 0.058, data: 0.065) G_GAN: 0.777 G_L1: 7.485 D_real: 1.252 D_fake: 0.760 \n",
      "(epoch: 159, iters: 200, time: 0.184, data: 0.001) G_GAN: 2.117 G_L1: 8.232 D_real: 0.821 D_fake: 0.119 \n",
      "(epoch: 159, iters: 300, time: 0.058, data: 0.001) G_GAN: 2.902 G_L1: 7.613 D_real: 0.831 D_fake: 0.064 \n",
      "(epoch: 159, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.501 G_L1: 7.499 D_real: 0.106 D_fake: 0.394 \n",
      "(epoch: 159, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.711 G_L1: 9.224 D_real: 0.651 D_fake: 0.962 \n",
      "End of epoch 159 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 100, time: 0.186, data: 0.065) G_GAN: 1.395 G_L1: 8.970 D_real: 0.327 D_fake: 0.363 \n",
      "(epoch: 160, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.373 G_L1: 5.878 D_real: 0.192 D_fake: 0.409 \n",
      "(epoch: 160, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.782 G_L1: 8.492 D_real: 0.254 D_fake: 0.226 \n",
      "(epoch: 160, iters: 400, time: 0.057, data: 0.001) G_GAN: 3.000 G_L1: 6.876 D_real: 0.637 D_fake: 0.054 \n",
      "(epoch: 160, iters: 500, time: 0.224, data: 0.002) G_GAN: 2.255 G_L1: 8.141 D_real: 0.473 D_fake: 0.114 \n",
      "saving the latest model (epoch 160, total_iters 80000)\n",
      "saving the model at the end of epoch 160, iters 80000\n",
      "End of epoch 160 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 100, time: 0.058, data: 0.063) G_GAN: 1.878 G_L1: 8.696 D_real: 0.562 D_fake: 0.176 \n",
      "(epoch: 161, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.997 G_L1: 6.615 D_real: 1.257 D_fake: 0.405 \n",
      "(epoch: 161, iters: 300, time: 0.057, data: 0.001) G_GAN: 0.724 G_L1: 13.255 D_real: 0.210 D_fake: 1.122 \n",
      "(epoch: 161, iters: 400, time: 0.185, data: 0.001) G_GAN: 2.206 G_L1: 9.562 D_real: 0.129 D_fake: 0.146 \n",
      "(epoch: 161, iters: 500, time: 0.059, data: 0.001) G_GAN: 2.118 G_L1: 17.600 D_real: 0.034 D_fake: 0.159 \n",
      "End of epoch 161 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.887 G_L1: 4.115 D_real: 0.367 D_fake: 0.181 \n",
      "(epoch: 162, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.385 G_L1: 8.550 D_real: 0.079 D_fake: 0.131 \n",
      "(epoch: 162, iters: 300, time: 0.185, data: 0.001) G_GAN: 0.770 G_L1: 0.021 D_real: 0.794 D_fake: 0.617 \n",
      "(epoch: 162, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.753 G_L1: 15.581 D_real: 0.019 D_fake: 0.071 \n",
      "(epoch: 162, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.576 G_L1: 6.542 D_real: 1.560 D_fake: 0.216 \n",
      "End of epoch 162 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.909 G_L1: 5.425 D_real: 1.297 D_fake: 0.115 \n",
      "(epoch: 163, iters: 200, time: 0.183, data: 0.001) G_GAN: 1.971 G_L1: 6.619 D_real: 1.296 D_fake: 0.113 \n",
      "(epoch: 163, iters: 300, time: 0.058, data: 0.001) G_GAN: 2.839 G_L1: 11.160 D_real: 0.214 D_fake: 0.065 \n",
      "(epoch: 163, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.649 G_L1: 4.629 D_real: 0.520 D_fake: 0.226 \n",
      "(epoch: 163, iters: 500, time: 0.058, data: 0.001) G_GAN: 3.956 G_L1: 5.415 D_real: 0.849 D_fake: 0.019 \n",
      "End of epoch 163 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 100, time: 0.249, data: 0.072) G_GAN: 1.314 G_L1: 10.641 D_real: 0.123 D_fake: 0.764 \n",
      "(epoch: 164, iters: 200, time: 0.056, data: 0.001) G_GAN: 3.671 G_L1: 8.820 D_real: 0.035 D_fake: 0.028 \n",
      "(epoch: 164, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.973 G_L1: 7.202 D_real: 0.056 D_fake: 0.254 \n",
      "(epoch: 164, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.517 G_L1: 5.150 D_real: 0.427 D_fake: 0.287 \n",
      "(epoch: 164, iters: 500, time: 0.189, data: 0.001) G_GAN: 1.472 G_L1: 8.680 D_real: 0.130 D_fake: 0.916 \n",
      "End of epoch 164 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 100, time: 0.057, data: 0.065) G_GAN: 1.937 G_L1: 7.396 D_real: 0.988 D_fake: 0.116 \n",
      "(epoch: 165, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.584 G_L1: 7.816 D_real: 0.356 D_fake: 0.268 \n",
      "(epoch: 165, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.420 G_L1: 6.236 D_real: 0.775 D_fake: 0.197 \n",
      "(epoch: 165, iters: 400, time: 0.189, data: 0.001) G_GAN: 1.604 G_L1: 9.770 D_real: 1.907 D_fake: 0.180 \n",
      "(epoch: 165, iters: 500, time: 0.059, data: 0.001) G_GAN: 0.939 G_L1: 3.780 D_real: 0.757 D_fake: 0.728 \n",
      "saving the model at the end of epoch 165, iters 82500\n",
      "End of epoch 165 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.304 G_L1: 8.385 D_real: 0.176 D_fake: 0.372 \n",
      "(epoch: 166, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.710 G_L1: 8.042 D_real: 0.257 D_fake: 0.255 \n",
      "(epoch: 166, iters: 300, time: 0.196, data: 0.001) G_GAN: 0.335 G_L1: 6.968 D_real: 0.094 D_fake: 2.263 \n",
      "(epoch: 166, iters: 400, time: 0.058, data: 0.001) G_GAN: 3.301 G_L1: 5.876 D_real: 0.072 D_fake: 0.046 \n",
      "(epoch: 166, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.652 G_L1: 6.054 D_real: 0.592 D_fake: 0.193 \n",
      "End of epoch 166 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.656 G_L1: 6.901 D_real: 0.685 D_fake: 0.161 \n",
      "(epoch: 167, iters: 200, time: 0.230, data: 0.001) G_GAN: 1.693 G_L1: 6.154 D_real: 0.272 D_fake: 0.214 \n",
      "(epoch: 167, iters: 300, time: 0.058, data: 0.001) G_GAN: 3.443 G_L1: 4.475 D_real: 0.552 D_fake: 0.025 \n",
      "(epoch: 167, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.616 G_L1: 7.933 D_real: 0.220 D_fake: 1.424 \n",
      "(epoch: 167, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.861 G_L1: 7.477 D_real: 0.181 D_fake: 0.920 \n",
      "End of epoch 167 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 100, time: 0.192, data: 0.063) G_GAN: 2.276 G_L1: 4.926 D_real: 0.078 D_fake: 0.116 \n",
      "(epoch: 168, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.123 G_L1: 6.141 D_real: 0.907 D_fake: 0.344 \n",
      "(epoch: 168, iters: 300, time: 0.059, data: 0.001) G_GAN: 4.721 G_L1: 6.018 D_real: 0.130 D_fake: 0.009 \n",
      "(epoch: 168, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.963 G_L1: 6.502 D_real: 0.789 D_fake: 0.425 \n",
      "(epoch: 168, iters: 500, time: 0.195, data: 0.002) G_GAN: 3.368 G_L1: 12.771 D_real: 0.046 D_fake: 0.050 \n",
      "End of epoch 168 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 100, time: 0.058, data: 0.063) G_GAN: 0.867 G_L1: 6.432 D_real: 0.557 D_fake: 0.854 \n",
      "(epoch: 169, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.801 G_L1: 3.528 D_real: 0.306 D_fake: 0.914 \n",
      "(epoch: 169, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.173 G_L1: 4.839 D_real: 0.725 D_fake: 0.376 \n",
      "(epoch: 169, iters: 400, time: 0.191, data: 0.001) G_GAN: 1.046 G_L1: 3.455 D_real: 2.229 D_fake: 0.265 \n",
      "(epoch: 169, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.502 G_L1: 5.164 D_real: 0.069 D_fake: 0.418 \n",
      "End of epoch 169 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 100, time: 0.057, data: 0.061) G_GAN: 1.193 G_L1: 6.228 D_real: 0.941 D_fake: 0.430 \n",
      "(epoch: 170, iters: 200, time: 0.057, data: 0.001) G_GAN: 4.372 G_L1: 7.429 D_real: 0.063 D_fake: 0.016 \n",
      "(epoch: 170, iters: 300, time: 0.188, data: 0.001) G_GAN: 1.121 G_L1: 2.593 D_real: 0.772 D_fake: 0.261 \n",
      "(epoch: 170, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.679 G_L1: 0.035 D_real: 0.666 D_fake: 0.757 \n",
      "(epoch: 170, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.310 G_L1: 13.293 D_real: 0.109 D_fake: 0.446 \n",
      "saving the latest model (epoch 170, total_iters 85000)\n",
      "saving the model at the end of epoch 170, iters 85000\n",
      "End of epoch 170 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 100, time: 0.057, data: 0.075) G_GAN: 1.300 G_L1: 5.395 D_real: 0.692 D_fake: 0.239 \n",
      "(epoch: 171, iters: 200, time: 0.238, data: 0.001) G_GAN: 0.506 G_L1: 6.609 D_real: 0.142 D_fake: 1.578 \n",
      "(epoch: 171, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.174 G_L1: 2.449 D_real: 0.520 D_fake: 0.422 \n",
      "(epoch: 171, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.807 G_L1: 5.846 D_real: 0.125 D_fake: 0.904 \n",
      "(epoch: 171, iters: 500, time: 0.058, data: 0.001) G_GAN: 4.796 G_L1: 4.438 D_real: 0.343 D_fake: 0.007 \n",
      "End of epoch 171 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 100, time: 0.199, data: 0.063) G_GAN: 1.909 G_L1: 8.092 D_real: 0.280 D_fake: 0.166 \n",
      "(epoch: 172, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.550 G_L1: 5.031 D_real: 1.358 D_fake: 1.399 \n",
      "(epoch: 172, iters: 300, time: 0.058, data: 0.001) G_GAN: 2.872 G_L1: 7.394 D_real: 0.913 D_fake: 0.071 \n",
      "(epoch: 172, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.794 G_L1: 6.720 D_real: 0.353 D_fake: 1.026 \n",
      "(epoch: 172, iters: 500, time: 0.198, data: 0.002) G_GAN: 3.575 G_L1: 10.450 D_real: 0.775 D_fake: 0.022 \n",
      "End of epoch 172 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 100, time: 0.057, data: 0.063) G_GAN: 0.699 G_L1: 4.756 D_real: 0.021 D_fake: 1.777 \n",
      "(epoch: 173, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.354 G_L1: 12.227 D_real: 0.038 D_fake: 0.116 \n",
      "(epoch: 173, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.446 G_L1: 4.079 D_real: 1.151 D_fake: 0.243 \n",
      "(epoch: 173, iters: 400, time: 0.197, data: 0.001) G_GAN: 2.924 G_L1: 10.062 D_real: 0.521 D_fake: 0.048 \n",
      "(epoch: 173, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.346 G_L1: 9.225 D_real: 0.452 D_fake: 0.378 \n",
      "End of epoch 173 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 100, time: 0.058, data: 0.065) G_GAN: 2.208 G_L1: 4.044 D_real: 0.016 D_fake: 0.135 \n",
      "(epoch: 174, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.213 G_L1: 5.456 D_real: 0.320 D_fake: 0.415 \n",
      "(epoch: 174, iters: 300, time: 0.238, data: 0.001) G_GAN: 0.949 G_L1: 4.552 D_real: 0.344 D_fake: 0.657 \n",
      "(epoch: 174, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.148 G_L1: 14.335 D_real: 0.016 D_fake: 0.577 \n",
      "(epoch: 174, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.520 G_L1: 3.668 D_real: 0.229 D_fake: 0.278 \n",
      "End of epoch 174 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 100, time: 0.058, data: 0.066) G_GAN: 1.869 G_L1: 5.803 D_real: 0.025 D_fake: 0.242 \n",
      "(epoch: 175, iters: 200, time: 0.195, data: 0.001) G_GAN: 1.109 G_L1: 5.819 D_real: 0.045 D_fake: 1.087 \n",
      "(epoch: 175, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.663 G_L1: 6.803 D_real: 0.363 D_fake: 1.059 \n",
      "(epoch: 175, iters: 400, time: 0.058, data: 0.001) G_GAN: 4.787 G_L1: 8.077 D_real: 0.024 D_fake: 0.009 \n",
      "(epoch: 175, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.993 G_L1: 9.442 D_real: 0.011 D_fake: 0.850 \n",
      "saving the model at the end of epoch 175, iters 87500\n",
      "End of epoch 175 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 100, time: 0.199, data: 0.067) G_GAN: 1.144 G_L1: 6.512 D_real: 0.203 D_fake: 0.497 \n",
      "(epoch: 176, iters: 200, time: 0.057, data: 0.001) G_GAN: 3.490 G_L1: 4.806 D_real: 0.184 D_fake: 0.040 \n",
      "(epoch: 176, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.228 G_L1: 1.329 D_real: 0.149 D_fake: 0.398 \n",
      "(epoch: 176, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.234 G_L1: 7.036 D_real: 0.946 D_fake: 0.345 \n",
      "(epoch: 176, iters: 500, time: 0.195, data: 0.001) G_GAN: 1.122 G_L1: 9.850 D_real: 0.037 D_fake: 0.970 \n",
      "End of epoch 176 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 100, time: 0.058, data: 0.068) G_GAN: 2.119 G_L1: 6.216 D_real: 0.138 D_fake: 0.145 \n",
      "(epoch: 177, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.617 G_L1: 6.038 D_real: 0.552 D_fake: 1.598 \n",
      "(epoch: 177, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.096 G_L1: 8.210 D_real: 0.003 D_fake: 0.777 \n",
      "(epoch: 177, iters: 400, time: 0.240, data: 0.001) G_GAN: 1.840 G_L1: 6.202 D_real: 0.048 D_fake: 0.206 \n",
      "(epoch: 177, iters: 500, time: 0.057, data: 0.001) G_GAN: 0.983 G_L1: 0.024 D_real: 1.145 D_fake: 0.395 \n",
      "End of epoch 177 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.533 G_L1: 6.729 D_real: 0.618 D_fake: 0.169 \n",
      "(epoch: 178, iters: 200, time: 0.058, data: 0.001) G_GAN: 2.844 G_L1: 7.094 D_real: 0.158 D_fake: 0.072 \n",
      "(epoch: 178, iters: 300, time: 0.196, data: 0.001) G_GAN: 0.961 G_L1: 0.504 D_real: 1.098 D_fake: 0.433 \n",
      "(epoch: 178, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.265 G_L1: 7.159 D_real: 0.114 D_fake: 0.119 \n",
      "(epoch: 178, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.424 G_L1: 11.603 D_real: 0.292 D_fake: 0.348 \n",
      "End of epoch 178 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.271 G_L1: 6.596 D_real: 0.729 D_fake: 0.335 \n",
      "(epoch: 179, iters: 200, time: 0.203, data: 0.001) G_GAN: 1.750 G_L1: 5.990 D_real: 1.188 D_fake: 0.184 \n",
      "(epoch: 179, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.100 G_L1: 1.583 D_real: 0.037 D_fake: 0.468 \n",
      "(epoch: 179, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.348 G_L1: 8.453 D_real: 0.930 D_fake: 0.088 \n",
      "(epoch: 179, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.027 G_L1: 22.085 D_real: 0.254 D_fake: 1.107 \n",
      "End of epoch 179 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000416\n",
      "(epoch: 180, iters: 100, time: 0.204, data: 0.065) G_GAN: 1.464 G_L1: 4.797 D_real: 0.903 D_fake: 0.260 \n",
      "(epoch: 180, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.722 G_L1: 9.603 D_real: 0.073 D_fake: 1.928 \n",
      "(epoch: 180, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.626 G_L1: 0.060 D_real: 0.630 D_fake: 0.794 \n",
      "(epoch: 180, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.789 G_L1: 7.714 D_real: 1.327 D_fake: 0.139 \n",
      "(epoch: 180, iters: 500, time: 0.239, data: 0.001) G_GAN: 3.075 G_L1: 11.912 D_real: 0.038 D_fake: 0.059 \n",
      "saving the latest model (epoch 180, total_iters 90000)\n",
      "saving the model at the end of epoch 180, iters 90000\n",
      "End of epoch 180 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 100, time: 0.058, data: 0.062) G_GAN: 1.436 G_L1: 7.577 D_real: 0.756 D_fake: 0.272 \n",
      "(epoch: 181, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.565 G_L1: 4.571 D_real: 1.160 D_fake: 0.904 \n",
      "(epoch: 181, iters: 300, time: 0.057, data: 0.001) G_GAN: 3.658 G_L1: 6.685 D_real: 0.233 D_fake: 0.028 \n",
      "(epoch: 181, iters: 400, time: 0.202, data: 0.001) G_GAN: 0.430 G_L1: 6.671 D_real: 0.088 D_fake: 1.588 \n",
      "(epoch: 181, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.596 G_L1: 7.945 D_real: 0.235 D_fake: 0.368 \n",
      "End of epoch 181 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 100, time: 0.057, data: 0.065) G_GAN: 0.783 G_L1: 0.118 D_real: 0.795 D_fake: 0.608 \n",
      "(epoch: 182, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.160 G_L1: 2.245 D_real: 1.179 D_fake: 0.634 \n",
      "(epoch: 182, iters: 300, time: 0.203, data: 0.001) G_GAN: 1.195 G_L1: 9.304 D_real: 0.081 D_fake: 0.744 \n",
      "(epoch: 182, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.162 G_L1: 5.613 D_real: 0.523 D_fake: 0.409 \n",
      "(epoch: 182, iters: 500, time: 0.058, data: 0.001) G_GAN: 3.440 G_L1: 4.955 D_real: 0.255 D_fake: 0.038 \n",
      "End of epoch 182 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 100, time: 0.057, data: 0.067) G_GAN: 3.182 G_L1: 5.998 D_real: 0.776 D_fake: 0.036 \n",
      "(epoch: 183, iters: 200, time: 0.200, data: 0.001) G_GAN: 0.992 G_L1: 6.380 D_real: 0.093 D_fake: 0.616 \n",
      "(epoch: 183, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.286 G_L1: 8.551 D_real: 0.859 D_fake: 0.341 \n",
      "(epoch: 183, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.682 G_L1: 7.328 D_real: 0.503 D_fake: 0.833 \n",
      "(epoch: 183, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.648 G_L1: 7.964 D_real: 0.507 D_fake: 0.230 \n",
      "End of epoch 183 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 100, time: 0.247, data: 0.063) G_GAN: 1.924 G_L1: 6.800 D_real: 0.034 D_fake: 0.191 \n",
      "(epoch: 184, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.229 G_L1: 9.531 D_real: 0.284 D_fake: 0.426 \n",
      "(epoch: 184, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.961 G_L1: 4.089 D_real: 0.114 D_fake: 0.172 \n",
      "(epoch: 184, iters: 400, time: 0.058, data: 0.001) G_GAN: 2.899 G_L1: 4.070 D_real: 0.167 D_fake: 0.065 \n",
      "(epoch: 184, iters: 500, time: 0.201, data: 0.001) G_GAN: 1.532 G_L1: 2.168 D_real: 0.443 D_fake: 0.281 \n",
      "End of epoch 184 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 100, time: 0.058, data: 0.064) G_GAN: 1.256 G_L1: 14.666 D_real: 0.030 D_fake: 0.484 \n",
      "(epoch: 185, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.558 G_L1: 5.666 D_real: 0.301 D_fake: 0.078 \n",
      "(epoch: 185, iters: 300, time: 0.057, data: 0.001) G_GAN: 0.790 G_L1: 9.215 D_real: 0.723 D_fake: 0.667 \n",
      "(epoch: 185, iters: 400, time: 0.203, data: 0.001) G_GAN: 2.303 G_L1: 5.999 D_real: 0.746 D_fake: 0.117 \n",
      "(epoch: 185, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.229 G_L1: 4.736 D_real: 0.040 D_fake: 0.526 \n",
      "saving the model at the end of epoch 185, iters 92500\n",
      "End of epoch 185 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 100, time: 0.058, data: 0.065) G_GAN: 1.071 G_L1: 9.022 D_real: 0.133 D_fake: 0.556 \n",
      "(epoch: 186, iters: 200, time: 0.058, data: 0.001) G_GAN: 3.176 G_L1: 9.093 D_real: 0.245 D_fake: 0.050 \n",
      "(epoch: 186, iters: 300, time: 0.201, data: 0.001) G_GAN: 0.747 G_L1: 0.453 D_real: 0.741 D_fake: 0.659 \n",
      "(epoch: 186, iters: 400, time: 0.057, data: 0.001) G_GAN: 4.870 G_L1: 7.029 D_real: 0.065 D_fake: 0.010 \n",
      "(epoch: 186, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.969 G_L1: 9.335 D_real: 0.221 D_fake: 0.546 \n",
      "End of epoch 186 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 100, time: 0.058, data: 0.062) G_GAN: 2.988 G_L1: 8.035 D_real: 0.047 D_fake: 0.064 \n",
      "(epoch: 187, iters: 200, time: 0.250, data: 0.001) G_GAN: 1.683 G_L1: 12.873 D_real: 0.191 D_fake: 0.245 \n",
      "(epoch: 187, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.974 G_L1: 10.614 D_real: 0.972 D_fake: 0.350 \n",
      "(epoch: 187, iters: 400, time: 0.057, data: 0.001) G_GAN: 0.589 G_L1: 4.120 D_real: 1.411 D_fake: 0.902 \n",
      "(epoch: 187, iters: 500, time: 0.059, data: 0.001) G_GAN: 1.703 G_L1: 7.527 D_real: 0.068 D_fake: 0.251 \n",
      "End of epoch 187 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 100, time: 0.217, data: 0.064) G_GAN: 0.521 G_L1: 6.476 D_real: 0.399 D_fake: 1.177 \n",
      "(epoch: 188, iters: 200, time: 0.058, data: 0.001) G_GAN: 3.905 G_L1: 2.998 D_real: 0.715 D_fake: 0.019 \n",
      "(epoch: 188, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.736 G_L1: 8.305 D_real: 0.567 D_fake: 0.816 \n",
      "(epoch: 188, iters: 400, time: 0.059, data: 0.001) G_GAN: 0.507 G_L1: 5.305 D_real: 0.149 D_fake: 1.209 \n",
      "(epoch: 188, iters: 500, time: 0.205, data: 0.001) G_GAN: 1.618 G_L1: 5.601 D_real: 0.669 D_fake: 0.197 \n",
      "End of epoch 188 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 100, time: 0.057, data: 0.063) G_GAN: 1.137 G_L1: 8.563 D_real: 0.225 D_fake: 0.451 \n",
      "(epoch: 189, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.704 G_L1: 4.655 D_real: 0.498 D_fake: 0.208 \n",
      "(epoch: 189, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.625 G_L1: 6.494 D_real: 0.304 D_fake: 0.262 \n",
      "(epoch: 189, iters: 400, time: 0.217, data: 0.001) G_GAN: 1.004 G_L1: 0.463 D_real: 1.001 D_fake: 0.434 \n",
      "(epoch: 189, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.618 G_L1: 9.357 D_real: 0.094 D_fake: 1.029 \n",
      "End of epoch 189 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 100, time: 0.058, data: 0.064) G_GAN: 3.287 G_L1: 7.801 D_real: 0.038 D_fake: 0.042 \n",
      "(epoch: 190, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.087 G_L1: 14.488 D_real: 0.041 D_fake: 0.514 \n",
      "(epoch: 190, iters: 300, time: 0.254, data: 0.001) G_GAN: 0.283 G_L1: 13.133 D_real: 0.078 D_fake: 2.060 \n",
      "(epoch: 190, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.051 G_L1: 7.497 D_real: 0.179 D_fake: 0.494 \n",
      "(epoch: 190, iters: 500, time: 0.058, data: 0.001) G_GAN: 0.611 G_L1: 8.285 D_real: 0.210 D_fake: 1.084 \n",
      "saving the latest model (epoch 190, total_iters 95000)\n",
      "saving the model at the end of epoch 190, iters 95000\n",
      "End of epoch 190 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 100, time: 0.058, data: 0.064) G_GAN: 2.715 G_L1: 10.039 D_real: 0.031 D_fake: 0.075 \n",
      "(epoch: 191, iters: 200, time: 0.210, data: 0.001) G_GAN: 1.218 G_L1: 6.003 D_real: 0.250 D_fake: 0.405 \n",
      "(epoch: 191, iters: 300, time: 0.059, data: 0.001) G_GAN: 1.172 G_L1: 10.183 D_real: 0.456 D_fake: 0.416 \n",
      "(epoch: 191, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.115 G_L1: 8.437 D_real: 0.190 D_fake: 0.589 \n",
      "(epoch: 191, iters: 500, time: 0.058, data: 0.001) G_GAN: 2.373 G_L1: 7.262 D_real: 1.076 D_fake: 0.105 \n",
      "End of epoch 191 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 100, time: 0.206, data: 0.062) G_GAN: 3.581 G_L1: 5.560 D_real: 0.048 D_fake: 0.033 \n",
      "(epoch: 192, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.195 G_L1: 7.298 D_real: 0.194 D_fake: 0.420 \n",
      "(epoch: 192, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.182 G_L1: 7.368 D_real: 1.261 D_fake: 0.430 \n",
      "(epoch: 192, iters: 400, time: 0.057, data: 0.001) G_GAN: 2.217 G_L1: 8.573 D_real: 0.107 D_fake: 0.137 \n",
      "(epoch: 192, iters: 500, time: 0.209, data: 0.001) G_GAN: 2.478 G_L1: 6.192 D_real: 1.037 D_fake: 0.074 \n",
      "End of epoch 192 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 100, time: 0.058, data: 0.066) G_GAN: 4.686 G_L1: 7.925 D_real: 0.139 D_fake: 0.010 \n",
      "(epoch: 193, iters: 200, time: 0.058, data: 0.001) G_GAN: 0.900 G_L1: 11.417 D_real: 0.124 D_fake: 0.649 \n",
      "(epoch: 193, iters: 300, time: 0.058, data: 0.001) G_GAN: 2.064 G_L1: 9.096 D_real: 0.013 D_fake: 0.161 \n",
      "(epoch: 193, iters: 400, time: 0.257, data: 0.001) G_GAN: 0.618 G_L1: 7.663 D_real: 0.368 D_fake: 0.904 \n",
      "(epoch: 193, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.610 G_L1: 6.685 D_real: 0.252 D_fake: 0.242 \n",
      "End of epoch 193 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 100, time: 0.058, data: 0.062) G_GAN: 1.550 G_L1: 6.751 D_real: 0.044 D_fake: 0.277 \n",
      "(epoch: 194, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.618 G_L1: 7.866 D_real: 0.137 D_fake: 0.273 \n",
      "(epoch: 194, iters: 300, time: 0.206, data: 0.001) G_GAN: 1.463 G_L1: 10.375 D_real: 0.397 D_fake: 0.294 \n",
      "(epoch: 194, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.986 G_L1: 6.090 D_real: 0.236 D_fake: 0.614 \n",
      "(epoch: 194, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.290 G_L1: 9.536 D_real: 0.044 D_fake: 0.406 \n",
      "End of epoch 194 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 100, time: 0.058, data: 0.063) G_GAN: 3.317 G_L1: 15.932 D_real: 0.044 D_fake: 0.040 \n",
      "(epoch: 195, iters: 200, time: 0.215, data: 0.001) G_GAN: 1.261 G_L1: 9.475 D_real: 0.122 D_fake: 0.380 \n",
      "(epoch: 195, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.336 G_L1: 7.404 D_real: 1.072 D_fake: 0.301 \n",
      "(epoch: 195, iters: 400, time: 0.057, data: 0.001) G_GAN: 1.738 G_L1: 6.071 D_real: 0.749 D_fake: 0.213 \n",
      "(epoch: 195, iters: 500, time: 0.058, data: 0.001) G_GAN: 4.040 G_L1: 6.888 D_real: 0.192 D_fake: 0.019 \n",
      "saving the model at the end of epoch 195, iters 97500\n",
      "End of epoch 195 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 100, time: 0.207, data: 0.063) G_GAN: 1.885 G_L1: 7.912 D_real: 0.089 D_fake: 0.185 \n",
      "(epoch: 196, iters: 200, time: 0.057, data: 0.001) G_GAN: 2.685 G_L1: 7.446 D_real: 0.073 D_fake: 0.077 \n",
      "(epoch: 196, iters: 300, time: 0.057, data: 0.001) G_GAN: 1.644 G_L1: 4.342 D_real: 1.304 D_fake: 0.238 \n",
      "(epoch: 196, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.652 G_L1: 0.016 D_real: 0.645 D_fake: 0.758 \n",
      "(epoch: 196, iters: 500, time: 0.250, data: 0.001) G_GAN: 0.476 G_L1: 7.426 D_real: 0.585 D_fake: 1.186 \n",
      "End of epoch 196 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 100, time: 0.058, data: 0.064) G_GAN: 0.540 G_L1: 7.149 D_real: 0.331 D_fake: 1.012 \n",
      "(epoch: 197, iters: 200, time: 0.057, data: 0.001) G_GAN: 0.822 G_L1: 3.488 D_real: 0.355 D_fake: 0.674 \n",
      "(epoch: 197, iters: 300, time: 0.058, data: 0.001) G_GAN: 0.530 G_L1: 5.036 D_real: 1.529 D_fake: 0.967 \n",
      "(epoch: 197, iters: 400, time: 0.211, data: 0.001) G_GAN: 2.155 G_L1: 10.397 D_real: 0.038 D_fake: 0.137 \n",
      "(epoch: 197, iters: 500, time: 0.058, data: 0.001) G_GAN: 2.834 G_L1: 5.915 D_real: 0.537 D_fake: 0.071 \n",
      "End of epoch 197 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 100, time: 0.057, data: 0.066) G_GAN: 1.774 G_L1: 10.014 D_real: 0.257 D_fake: 0.204 \n",
      "(epoch: 198, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.061 G_L1: 6.477 D_real: 0.142 D_fake: 0.475 \n",
      "(epoch: 198, iters: 300, time: 0.215, data: 0.001) G_GAN: 1.268 G_L1: 8.647 D_real: 0.007 D_fake: 0.399 \n",
      "(epoch: 198, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.091 G_L1: 6.738 D_real: 0.043 D_fake: 0.474 \n",
      "(epoch: 198, iters: 500, time: 0.058, data: 0.001) G_GAN: 1.903 G_L1: 7.424 D_real: 0.979 D_fake: 0.176 \n",
      "End of epoch 198 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 100, time: 0.057, data: 0.063) G_GAN: 2.970 G_L1: 5.582 D_real: 0.557 D_fake: 0.062 \n",
      "(epoch: 199, iters: 200, time: 0.254, data: 0.001) G_GAN: 3.621 G_L1: 8.676 D_real: 0.029 D_fake: 0.030 \n",
      "(epoch: 199, iters: 300, time: 0.058, data: 0.001) G_GAN: 1.288 G_L1: 8.576 D_real: 0.328 D_fake: 0.371 \n",
      "(epoch: 199, iters: 400, time: 0.058, data: 0.001) G_GAN: 0.288 G_L1: 6.271 D_real: 0.131 D_fake: 1.599 \n",
      "(epoch: 199, iters: 500, time: 0.058, data: 0.001) G_GAN: 3.039 G_L1: 9.623 D_real: 0.105 D_fake: 0.054 \n",
      "End of epoch 199 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 100, time: 0.217, data: 0.064) G_GAN: 0.636 G_L1: 7.619 D_real: 0.213 D_fake: 0.852 \n",
      "(epoch: 200, iters: 200, time: 0.057, data: 0.001) G_GAN: 1.847 G_L1: 9.072 D_real: 0.664 D_fake: 0.204 \n",
      "(epoch: 200, iters: 300, time: 0.058, data: 0.001) G_GAN: 2.233 G_L1: 4.056 D_real: 0.547 D_fake: 0.121 \n",
      "(epoch: 200, iters: 400, time: 0.058, data: 0.001) G_GAN: 1.798 G_L1: 8.158 D_real: 0.019 D_fake: 0.223 \n",
      "(epoch: 200, iters: 500, time: 0.213, data: 0.001) G_GAN: 2.587 G_L1: 11.427 D_real: 0.006 D_fake: 0.104 \n",
      "saving the latest model (epoch 200, total_iters 100000)\n",
      "saving the model at the end of epoch 200, iters 100000\n",
      "End of epoch 200 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot extrarealsyncolor/AB --model pix2pix --crop_size 128 --no_dropout --output_nc 1 --norm batch --checkpoints_dir apr25 --netG resnet_9blocks --preprocess resize_and_crop --name apr19realcrop256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: apr25                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: lp                            \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: resize256                     \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: results_apr25                 \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from apr25/resize256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['lp/Alabama.jpg']\n",
      "processing (0005)-th image... ['lp/Colorado.jpg']\n",
      "processing (0010)-th image... ['lp/Georgia.jpg']\n",
      "processing (0015)-th image... ['lp/Indiana.jpg']\n",
      "processing (0020)-th image... ['lp/Maine.jpg']\n",
      "processing (0025)-th image... ['lp/Mississippi.jpg']\n",
      "processing (0030)-th image... ['lp/NewHampshire.jpg']\n",
      "processing (0035)-th image... ['lp/NorthDakota.jpg']\n",
      "processing (0040)-th image... ['lp/PuertoRico.jpg']\n",
      "processing (0045)-th image... ['lp/Texas.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot lp --dataset_mode single --model test --results_dir results_apr25 --netG resnet_9blocks --preprocess resize_and_crop --name resize256 --norm batch --checkpoints_dir apr25 --output_nc 1 --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: apr25                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: lp                            \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: apr19256rea                   \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: results_apr25                 \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from apr25/apr19256rea/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['lp/Alabama.jpg']\n",
      "processing (0005)-th image... ['lp/Colorado.jpg']\n",
      "processing (0010)-th image... ['lp/Georgia.jpg']\n",
      "processing (0015)-th image... ['lp/Indiana.jpg']\n",
      "processing (0020)-th image... ['lp/Maine.jpg']\n",
      "processing (0025)-th image... ['lp/Mississippi.jpg']\n",
      "processing (0030)-th image... ['lp/NewHampshire.jpg']\n",
      "processing (0035)-th image... ['lp/NorthDakota.jpg']\n",
      "processing (0040)-th image... ['lp/PuertoRico.jpg']\n",
      "processing (0045)-th image... ['lp/Texas.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot lp --dataset_mode single --model test --results_dir results_apr25 --netG resnet_9blocks --preprocess resize_and_crop --name apr19256rea  --norm batch --checkpoints_dir apr25 --output_nc 1 --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: apr25                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: extracolor/AB                 \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: apr19256rea                   \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 417\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "[Network D] Total number of parameters : 2.767 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory apr25/apr19256rea/web...\n",
      "(epoch: 1, iters: 100, time: 0.158, data: 0.102) G_GAN: 2.025 G_L1: 16.834 D_real: 0.108 D_fake: 0.172 \n",
      "(epoch: 1, iters: 200, time: 0.161, data: 0.001) G_GAN: 1.864 G_L1: 20.537 D_real: 0.031 D_fake: 0.233 \n",
      "(epoch: 1, iters: 300, time: 0.162, data: 0.001) G_GAN: 1.857 G_L1: 13.378 D_real: 0.024 D_fake: 0.980 \n",
      "(epoch: 1, iters: 400, time: 0.254, data: 0.001) G_GAN: 1.172 G_L1: 7.944 D_real: 1.707 D_fake: 0.166 \n",
      "End of epoch 1 / 200 \t Time Taken: 43 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 83, time: 0.164, data: 0.001) G_GAN: 1.657 G_L1: 14.477 D_real: 0.788 D_fake: 0.131 \n",
      "(epoch: 2, iters: 183, time: 0.166, data: 0.001) G_GAN: 1.362 G_L1: 16.010 D_real: 0.034 D_fake: 1.610 \n",
      "(epoch: 2, iters: 283, time: 0.166, data: 0.001) G_GAN: 1.511 G_L1: 12.732 D_real: 0.192 D_fake: 0.448 \n",
      "(epoch: 2, iters: 383, time: 0.263, data: 0.001) G_GAN: 0.864 G_L1: 8.800 D_real: 0.911 D_fake: 0.590 \n",
      "End of epoch 2 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 66, time: 0.168, data: 0.001) G_GAN: 1.582 G_L1: 8.552 D_real: 1.455 D_fake: 0.150 \n",
      "(epoch: 3, iters: 166, time: 0.168, data: 0.001) G_GAN: 0.842 G_L1: 4.996 D_real: 0.843 D_fake: 0.233 \n",
      "(epoch: 3, iters: 266, time: 0.166, data: 0.001) G_GAN: 1.324 G_L1: 11.904 D_real: 0.078 D_fake: 0.317 \n",
      "(epoch: 3, iters: 366, time: 0.265, data: 0.001) G_GAN: 0.869 G_L1: 7.161 D_real: 1.749 D_fake: 0.404 \n",
      "End of epoch 3 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 49, time: 0.167, data: 0.001) G_GAN: 1.180 G_L1: 11.628 D_real: 0.087 D_fake: 0.561 \n",
      "(epoch: 4, iters: 149, time: 0.167, data: 0.001) G_GAN: 0.987 G_L1: 8.201 D_real: 0.295 D_fake: 0.704 \n",
      "(epoch: 4, iters: 249, time: 0.167, data: 0.001) G_GAN: 1.715 G_L1: 13.624 D_real: 0.155 D_fake: 0.226 \n",
      "(epoch: 4, iters: 349, time: 0.270, data: 0.001) G_GAN: 1.323 G_L1: 7.558 D_real: 0.280 D_fake: 0.324 \n",
      "End of epoch 4 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 32, time: 0.167, data: 0.001) G_GAN: 1.678 G_L1: 8.618 D_real: 0.249 D_fake: 0.342 \n",
      "(epoch: 5, iters: 132, time: 0.167, data: 0.001) G_GAN: 1.419 G_L1: 12.194 D_real: 0.011 D_fake: 0.727 \n",
      "(epoch: 5, iters: 232, time: 0.167, data: 0.001) G_GAN: 0.719 G_L1: 6.413 D_real: 0.688 D_fake: 0.611 \n",
      "(epoch: 5, iters: 332, time: 0.258, data: 0.001) G_GAN: 1.088 G_L1: 4.958 D_real: 0.688 D_fake: 0.400 \n",
      "saving the model at the end of epoch 5, iters 2085\n",
      "End of epoch 5 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 15, time: 0.167, data: 0.001) G_GAN: 1.079 G_L1: 8.451 D_real: 0.062 D_fake: 0.589 \n",
      "(epoch: 6, iters: 115, time: 0.167, data: 0.001) G_GAN: 0.888 G_L1: 7.498 D_real: 0.183 D_fake: 0.775 \n",
      "(epoch: 6, iters: 215, time: 0.167, data: 0.001) G_GAN: 1.073 G_L1: 7.432 D_real: 0.459 D_fake: 1.518 \n",
      "(epoch: 6, iters: 315, time: 0.270, data: 0.001) G_GAN: 1.284 G_L1: 4.568 D_real: 1.229 D_fake: 0.247 \n",
      "(epoch: 6, iters: 415, time: 0.166, data: 0.001) G_GAN: 1.452 G_L1: 12.497 D_real: 0.068 D_fake: 0.386 \n",
      "End of epoch 6 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 98, time: 0.168, data: 0.001) G_GAN: 1.004 G_L1: 6.303 D_real: 0.399 D_fake: 0.514 \n",
      "(epoch: 7, iters: 198, time: 0.168, data: 0.001) G_GAN: 0.936 G_L1: 9.627 D_real: 0.487 D_fake: 0.515 \n",
      "(epoch: 7, iters: 298, time: 0.264, data: 0.001) G_GAN: 0.819 G_L1: 6.416 D_real: 0.429 D_fake: 0.866 \n",
      "(epoch: 7, iters: 398, time: 0.167, data: 0.001) G_GAN: 1.327 G_L1: 14.847 D_real: 0.031 D_fake: 0.320 \n",
      "End of epoch 7 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 81, time: 0.168, data: 0.001) G_GAN: 0.916 G_L1: 8.778 D_real: 0.427 D_fake: 0.675 \n",
      "(epoch: 8, iters: 181, time: 0.167, data: 0.001) G_GAN: 0.795 G_L1: 5.446 D_real: 0.670 D_fake: 0.551 \n",
      "(epoch: 8, iters: 281, time: 0.278, data: 0.001) G_GAN: 1.221 G_L1: 15.551 D_real: 0.144 D_fake: 0.697 \n",
      "(epoch: 8, iters: 381, time: 0.167, data: 0.001) G_GAN: 0.941 G_L1: 6.790 D_real: 0.314 D_fake: 0.973 \n",
      "End of epoch 8 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 64, time: 0.166, data: 0.001) G_GAN: 1.261 G_L1: 13.154 D_real: 0.094 D_fake: 0.831 \n",
      "(epoch: 9, iters: 164, time: 0.167, data: 0.001) G_GAN: 0.668 G_L1: 9.109 D_real: 0.976 D_fake: 0.643 \n",
      "(epoch: 9, iters: 264, time: 0.266, data: 0.001) G_GAN: 0.790 G_L1: 6.620 D_real: 1.048 D_fake: 0.418 \n",
      "(epoch: 9, iters: 364, time: 0.168, data: 0.001) G_GAN: 1.064 G_L1: 1.211 D_real: 1.125 D_fake: 0.431 \n",
      "End of epoch 9 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 47, time: 0.167, data: 0.001) G_GAN: 0.718 G_L1: 7.346 D_real: 0.232 D_fake: 1.009 \n",
      "(epoch: 10, iters: 147, time: 0.168, data: 0.001) G_GAN: 1.450 G_L1: 7.645 D_real: 1.882 D_fake: 0.264 \n",
      "(epoch: 10, iters: 247, time: 0.274, data: 0.001) G_GAN: 1.179 G_L1: 8.509 D_real: 0.844 D_fake: 0.271 \n",
      "(epoch: 10, iters: 347, time: 0.168, data: 0.001) G_GAN: 0.934 G_L1: 5.283 D_real: 1.004 D_fake: 0.433 \n",
      "saving the model at the end of epoch 10, iters 4170\n",
      "End of epoch 10 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 30, time: 0.169, data: 0.001) G_GAN: 0.870 G_L1: 12.813 D_real: 0.121 D_fake: 0.658 \n",
      "(epoch: 11, iters: 130, time: 0.168, data: 0.001) G_GAN: 0.740 G_L1: 7.266 D_real: 0.545 D_fake: 0.781 \n",
      "(epoch: 11, iters: 230, time: 0.269, data: 0.001) G_GAN: 0.715 G_L1: 7.826 D_real: 0.288 D_fake: 0.959 \n",
      "(epoch: 11, iters: 330, time: 0.167, data: 0.001) G_GAN: 1.146 G_L1: 9.235 D_real: 0.247 D_fake: 0.476 \n",
      "End of epoch 11 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 13, time: 0.166, data: 0.001) G_GAN: 0.920 G_L1: 5.852 D_real: 0.883 D_fake: 0.473 \n",
      "(epoch: 12, iters: 113, time: 0.167, data: 0.001) G_GAN: 1.017 G_L1: 7.802 D_real: 0.388 D_fake: 0.476 \n",
      "(epoch: 12, iters: 213, time: 0.272, data: 0.001) G_GAN: 1.141 G_L1: 5.514 D_real: 1.449 D_fake: 0.280 \n",
      "(epoch: 12, iters: 313, time: 0.167, data: 0.001) G_GAN: 0.863 G_L1: 11.854 D_real: 0.017 D_fake: 1.042 \n",
      "(epoch: 12, iters: 413, time: 0.168, data: 0.001) G_GAN: 1.192 G_L1: 12.005 D_real: 0.035 D_fake: 0.759 \n",
      "saving the latest model (epoch 12, total_iters 5000)\n",
      "End of epoch 12 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 96, time: 0.168, data: 0.001) G_GAN: 0.938 G_L1: 3.224 D_real: 1.073 D_fake: 0.366 \n",
      "(epoch: 13, iters: 196, time: 0.285, data: 0.001) G_GAN: 1.436 G_L1: 6.411 D_real: 1.613 D_fake: 0.184 \n",
      "(epoch: 13, iters: 296, time: 0.166, data: 0.001) G_GAN: 0.867 G_L1: 7.713 D_real: 0.473 D_fake: 0.473 \n",
      "(epoch: 13, iters: 396, time: 0.166, data: 0.001) G_GAN: 0.730 G_L1: 6.628 D_real: 0.607 D_fake: 0.621 \n",
      "End of epoch 13 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 79, time: 0.167, data: 0.001) G_GAN: 0.774 G_L1: 7.961 D_real: 0.467 D_fake: 0.655 \n",
      "(epoch: 14, iters: 179, time: 0.279, data: 0.001) G_GAN: 0.905 G_L1: 14.828 D_real: 0.607 D_fake: 0.445 \n",
      "(epoch: 14, iters: 279, time: 0.166, data: 0.001) G_GAN: 1.141 G_L1: 6.398 D_real: 1.312 D_fake: 0.364 \n",
      "(epoch: 14, iters: 379, time: 0.168, data: 0.001) G_GAN: 0.658 G_L1: 1.283 D_real: 0.686 D_fake: 0.741 \n",
      "End of epoch 14 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 62, time: 0.167, data: 0.001) G_GAN: 0.885 G_L1: 0.228 D_real: 0.991 D_fake: 0.474 \n",
      "(epoch: 15, iters: 162, time: 0.275, data: 0.001) G_GAN: 0.621 G_L1: 4.248 D_real: 0.783 D_fake: 0.769 \n",
      "(epoch: 15, iters: 262, time: 0.167, data: 0.001) G_GAN: 0.845 G_L1: 7.224 D_real: 0.660 D_fake: 0.613 \n",
      "(epoch: 15, iters: 362, time: 0.168, data: 0.001) G_GAN: 0.879 G_L1: 5.563 D_real: 0.286 D_fake: 1.030 \n",
      "saving the model at the end of epoch 15, iters 6255\n",
      "End of epoch 15 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 45, time: 0.167, data: 0.001) G_GAN: 0.942 G_L1: 5.961 D_real: 0.583 D_fake: 0.432 \n",
      "(epoch: 16, iters: 145, time: 0.280, data: 0.001) G_GAN: 1.126 G_L1: 12.873 D_real: 0.016 D_fake: 1.101 \n",
      "(epoch: 16, iters: 245, time: 0.167, data: 0.001) G_GAN: 1.260 G_L1: 9.749 D_real: 0.262 D_fake: 0.298 \n",
      "(epoch: 16, iters: 345, time: 0.167, data: 0.001) G_GAN: 0.980 G_L1: 7.503 D_real: 0.971 D_fake: 0.341 \n",
      "End of epoch 16 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 28, time: 0.167, data: 0.001) G_GAN: 0.775 G_L1: 6.234 D_real: 0.651 D_fake: 0.580 \n",
      "(epoch: 17, iters: 128, time: 0.272, data: 0.001) G_GAN: 1.039 G_L1: 8.376 D_real: 0.178 D_fake: 1.090 \n",
      "(epoch: 17, iters: 228, time: 0.168, data: 0.001) G_GAN: 1.030 G_L1: 6.156 D_real: 0.297 D_fake: 0.882 \n",
      "(epoch: 17, iters: 328, time: 0.167, data: 0.001) G_GAN: 1.125 G_L1: 17.818 D_real: 0.024 D_fake: 1.003 \n",
      "End of epoch 17 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 11, time: 0.167, data: 0.001) G_GAN: 0.841 G_L1: 5.944 D_real: 0.677 D_fake: 0.841 \n",
      "(epoch: 18, iters: 111, time: 0.286, data: 0.001) G_GAN: 1.066 G_L1: 7.543 D_real: 1.624 D_fake: 0.258 \n",
      "(epoch: 18, iters: 211, time: 0.166, data: 0.001) G_GAN: 1.456 G_L1: 11.864 D_real: 0.016 D_fake: 0.442 \n",
      "(epoch: 18, iters: 311, time: 0.167, data: 0.001) G_GAN: 1.070 G_L1: 6.105 D_real: 1.356 D_fake: 0.298 \n",
      "(epoch: 18, iters: 411, time: 0.167, data: 0.001) G_GAN: 0.930 G_L1: 6.840 D_real: 0.932 D_fake: 0.338 \n",
      "End of epoch 18 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 94, time: 0.289, data: 0.001) G_GAN: 1.115 G_L1: 9.365 D_real: 0.398 D_fake: 0.371 \n",
      "(epoch: 19, iters: 194, time: 0.168, data: 0.001) G_GAN: 1.143 G_L1: 6.920 D_real: 1.441 D_fake: 0.240 \n",
      "(epoch: 19, iters: 294, time: 0.168, data: 0.001) G_GAN: 0.869 G_L1: 6.809 D_real: 0.337 D_fake: 0.887 \n",
      "(epoch: 19, iters: 394, time: 0.167, data: 0.001) G_GAN: 0.933 G_L1: 6.246 D_real: 0.609 D_fake: 0.337 \n",
      "End of epoch 19 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 77, time: 0.287, data: 0.001) G_GAN: 0.964 G_L1: 6.620 D_real: 1.532 D_fake: 0.328 \n",
      "(epoch: 20, iters: 177, time: 0.166, data: 0.001) G_GAN: 0.927 G_L1: 6.466 D_real: 0.458 D_fake: 0.592 \n",
      "(epoch: 20, iters: 277, time: 0.168, data: 0.001) G_GAN: 1.087 G_L1: 11.152 D_real: 0.081 D_fake: 0.784 \n",
      "(epoch: 20, iters: 377, time: 0.168, data: 0.001) G_GAN: 0.828 G_L1: 5.316 D_real: 0.371 D_fake: 0.697 \n",
      "saving the model at the end of epoch 20, iters 8340\n",
      "End of epoch 20 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 60, time: 0.290, data: 0.001) G_GAN: 0.865 G_L1: 7.663 D_real: 0.411 D_fake: 0.560 \n",
      "(epoch: 21, iters: 160, time: 0.167, data: 0.001) G_GAN: 1.552 G_L1: 7.575 D_real: 0.964 D_fake: 0.198 \n",
      "(epoch: 21, iters: 260, time: 0.168, data: 0.001) G_GAN: 1.047 G_L1: 5.021 D_real: 1.056 D_fake: 0.382 \n",
      "(epoch: 21, iters: 360, time: 0.167, data: 0.001) G_GAN: 0.768 G_L1: 5.323 D_real: 0.761 D_fake: 0.681 \n",
      "End of epoch 21 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 43, time: 0.296, data: 0.001) G_GAN: 0.791 G_L1: 8.365 D_real: 0.559 D_fake: 1.490 \n",
      "(epoch: 22, iters: 143, time: 0.167, data: 0.001) G_GAN: 0.829 G_L1: 6.259 D_real: 0.745 D_fake: 0.583 \n",
      "(epoch: 22, iters: 243, time: 0.167, data: 0.001) G_GAN: 0.925 G_L1: 9.198 D_real: 0.093 D_fake: 0.708 \n",
      "(epoch: 22, iters: 343, time: 0.166, data: 0.001) G_GAN: 1.028 G_L1: 9.355 D_real: 0.580 D_fake: 0.402 \n",
      "End of epoch 22 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 26, time: 0.279, data: 0.001) G_GAN: 0.718 G_L1: 4.677 D_real: 0.970 D_fake: 0.508 \n",
      "(epoch: 23, iters: 126, time: 0.167, data: 0.001) G_GAN: 1.054 G_L1: 11.034 D_real: 0.124 D_fake: 1.052 \n",
      "(epoch: 23, iters: 226, time: 0.168, data: 0.001) G_GAN: 0.721 G_L1: 0.226 D_real: 0.706 D_fake: 0.682 \n",
      "(epoch: 23, iters: 326, time: 0.168, data: 0.001) G_GAN: 0.911 G_L1: 8.433 D_real: 0.556 D_fake: 0.672 \n",
      "End of epoch 23 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 9, time: 0.307, data: 0.001) G_GAN: 1.092 G_L1: 10.479 D_real: 0.100 D_fake: 1.139 \n",
      "(epoch: 24, iters: 109, time: 0.167, data: 0.001) G_GAN: 0.882 G_L1: 7.325 D_real: 0.192 D_fake: 0.965 \n",
      "(epoch: 24, iters: 209, time: 0.168, data: 0.001) G_GAN: 1.074 G_L1: 2.791 D_real: 0.809 D_fake: 0.441 \n",
      "(epoch: 24, iters: 309, time: 0.167, data: 0.001) G_GAN: 1.328 G_L1: 11.638 D_real: 0.242 D_fake: 0.379 \n",
      "(epoch: 24, iters: 409, time: 0.299, data: 0.001) G_GAN: 1.040 G_L1: 10.473 D_real: 0.802 D_fake: 0.347 \n",
      "saving the latest model (epoch 24, total_iters 10000)\n",
      "End of epoch 24 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 92, time: 0.166, data: 0.002) G_GAN: 1.838 G_L1: 10.985 D_real: 0.065 D_fake: 0.962 \n",
      "(epoch: 25, iters: 192, time: 0.167, data: 0.001) G_GAN: 1.104 G_L1: 7.142 D_real: 0.260 D_fake: 0.463 \n",
      "(epoch: 25, iters: 292, time: 0.168, data: 0.001) G_GAN: 0.649 G_L1: 7.287 D_real: 0.500 D_fake: 0.932 \n",
      "(epoch: 25, iters: 392, time: 0.270, data: 0.001) G_GAN: 0.881 G_L1: 5.021 D_real: 0.454 D_fake: 0.585 \n",
      "saving the model at the end of epoch 25, iters 10425\n",
      "End of epoch 25 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 75, time: 0.168, data: 0.001) G_GAN: 0.844 G_L1: 12.921 D_real: 0.508 D_fake: 0.399 \n",
      "(epoch: 26, iters: 175, time: 0.167, data: 0.001) G_GAN: 0.829 G_L1: 3.855 D_real: 0.528 D_fake: 0.729 \n",
      "(epoch: 26, iters: 275, time: 0.169, data: 0.001) G_GAN: 1.113 G_L1: 3.496 D_real: 1.228 D_fake: 0.379 \n",
      "(epoch: 26, iters: 375, time: 0.285, data: 0.001) G_GAN: 0.774 G_L1: 6.875 D_real: 0.714 D_fake: 0.521 \n",
      "End of epoch 26 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 58, time: 0.166, data: 0.001) G_GAN: 0.934 G_L1: 5.959 D_real: 0.952 D_fake: 0.457 \n",
      "(epoch: 27, iters: 158, time: 0.166, data: 0.001) G_GAN: 0.941 G_L1: 5.618 D_real: 0.944 D_fake: 0.378 \n",
      "(epoch: 27, iters: 258, time: 0.168, data: 0.001) G_GAN: 1.081 G_L1: 5.671 D_real: 1.347 D_fake: 0.272 \n",
      "(epoch: 27, iters: 358, time: 0.304, data: 0.001) G_GAN: 1.039 G_L1: 10.939 D_real: 0.144 D_fake: 0.973 \n",
      "End of epoch 27 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 41, time: 0.167, data: 0.001) G_GAN: 0.718 G_L1: 7.785 D_real: 1.099 D_fake: 0.492 \n",
      "(epoch: 28, iters: 141, time: 0.166, data: 0.001) G_GAN: 1.001 G_L1: 4.624 D_real: 1.441 D_fake: 0.285 \n",
      "(epoch: 28, iters: 241, time: 0.168, data: 0.001) G_GAN: 0.964 G_L1: 5.381 D_real: 1.125 D_fake: 0.389 \n",
      "(epoch: 28, iters: 341, time: 0.313, data: 0.001) G_GAN: 1.095 G_L1: 10.191 D_real: 0.114 D_fake: 0.898 \n",
      "End of epoch 28 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 24, time: 0.169, data: 0.001) G_GAN: 0.682 G_L1: 5.654 D_real: 0.494 D_fake: 0.771 \n",
      "(epoch: 29, iters: 124, time: 0.168, data: 0.001) G_GAN: 0.770 G_L1: 6.887 D_real: 0.911 D_fake: 0.559 \n",
      "(epoch: 29, iters: 224, time: 0.168, data: 0.001) G_GAN: 0.841 G_L1: 5.073 D_real: 0.645 D_fake: 0.520 \n",
      "(epoch: 29, iters: 324, time: 0.285, data: 0.001) G_GAN: 0.947 G_L1: 4.138 D_real: 1.001 D_fake: 0.431 \n",
      "End of epoch 29 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 7, time: 0.168, data: 0.001) G_GAN: 1.068 G_L1: 5.648 D_real: 1.332 D_fake: 0.320 \n",
      "(epoch: 30, iters: 107, time: 0.167, data: 0.000) G_GAN: 1.147 G_L1: 15.525 D_real: 0.093 D_fake: 0.847 \n",
      "(epoch: 30, iters: 207, time: 0.168, data: 0.001) G_GAN: 1.031 G_L1: 9.032 D_real: 0.630 D_fake: 0.450 \n",
      "(epoch: 30, iters: 307, time: 0.275, data: 0.001) G_GAN: 0.747 G_L1: 4.551 D_real: 0.451 D_fake: 0.720 \n",
      "(epoch: 30, iters: 407, time: 0.168, data: 0.001) G_GAN: 0.831 G_L1: 7.508 D_real: 0.145 D_fake: 0.942 \n",
      "saving the model at the end of epoch 30, iters 12510\n",
      "End of epoch 30 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 90, time: 0.167, data: 0.001) G_GAN: 0.917 G_L1: 6.579 D_real: 0.112 D_fake: 1.219 \n",
      "(epoch: 31, iters: 190, time: 0.167, data: 0.001) G_GAN: 0.839 G_L1: 6.815 D_real: 0.879 D_fake: 0.350 \n",
      "(epoch: 31, iters: 290, time: 0.295, data: 0.001) G_GAN: 0.950 G_L1: 7.478 D_real: 0.975 D_fake: 0.318 \n",
      "(epoch: 31, iters: 390, time: 0.167, data: 0.001) G_GAN: 0.733 G_L1: 0.858 D_real: 0.690 D_fake: 0.704 \n",
      "End of epoch 31 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 73, time: 0.167, data: 0.001) G_GAN: 0.764 G_L1: 4.617 D_real: 1.832 D_fake: 0.381 \n",
      "(epoch: 32, iters: 173, time: 0.166, data: 0.001) G_GAN: 0.922 G_L1: 19.796 D_real: 0.168 D_fake: 0.696 \n",
      "(epoch: 32, iters: 273, time: 0.297, data: 0.001) G_GAN: 0.914 G_L1: 7.362 D_real: 0.711 D_fake: 0.518 \n",
      "(epoch: 32, iters: 373, time: 0.167, data: 0.001) G_GAN: 0.996 G_L1: 6.785 D_real: 1.133 D_fake: 0.239 \n",
      "End of epoch 32 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 56, time: 0.166, data: 0.001) G_GAN: 1.532 G_L1: 8.715 D_real: 0.054 D_fake: 0.293 \n",
      "(epoch: 33, iters: 156, time: 0.167, data: 0.001) G_GAN: 1.212 G_L1: 9.726 D_real: 0.453 D_fake: 0.309 \n",
      "(epoch: 33, iters: 256, time: 0.294, data: 0.001) G_GAN: 0.825 G_L1: 5.177 D_real: 0.954 D_fake: 0.450 \n",
      "(epoch: 33, iters: 356, time: 0.167, data: 0.001) G_GAN: 0.728 G_L1: 4.171 D_real: 0.740 D_fake: 0.666 \n",
      "End of epoch 33 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 39, time: 0.167, data: 0.001) G_GAN: 0.735 G_L1: 5.617 D_real: 0.462 D_fake: 0.925 \n",
      "(epoch: 34, iters: 139, time: 0.168, data: 0.001) G_GAN: 1.100 G_L1: 9.732 D_real: 0.062 D_fake: 1.103 \n",
      "(epoch: 34, iters: 239, time: 0.294, data: 0.001) G_GAN: 0.879 G_L1: 5.207 D_real: 0.459 D_fake: 0.752 \n",
      "(epoch: 34, iters: 339, time: 0.168, data: 0.001) G_GAN: 0.999 G_L1: 7.514 D_real: 0.264 D_fake: 0.795 \n",
      "End of epoch 34 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 22, time: 0.167, data: 0.001) G_GAN: 0.788 G_L1: 5.568 D_real: 0.356 D_fake: 0.806 \n",
      "(epoch: 35, iters: 122, time: 0.168, data: 0.001) G_GAN: 0.980 G_L1: 6.463 D_real: 0.561 D_fake: 0.582 \n",
      "(epoch: 35, iters: 222, time: 0.314, data: 0.001) G_GAN: 0.703 G_L1: 4.396 D_real: 0.614 D_fake: 0.792 \n",
      "(epoch: 35, iters: 322, time: 0.167, data: 0.001) G_GAN: 1.507 G_L1: 10.681 D_real: 0.219 D_fake: 0.267 \n",
      "saving the model at the end of epoch 35, iters 14595\n",
      "End of epoch 35 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 5, time: 0.165, data: 0.001) G_GAN: 0.793 G_L1: 6.312 D_real: 0.408 D_fake: 0.947 \n",
      "(epoch: 36, iters: 105, time: 0.167, data: 0.000) G_GAN: 0.750 G_L1: 3.182 D_real: 0.523 D_fake: 0.688 \n",
      "(epoch: 36, iters: 205, time: 0.293, data: 0.001) G_GAN: 1.094 G_L1: 4.344 D_real: 1.792 D_fake: 0.248 \n",
      "(epoch: 36, iters: 305, time: 0.185, data: 0.001) G_GAN: 1.296 G_L1: 7.772 D_real: 0.300 D_fake: 0.522 \n",
      "(epoch: 36, iters: 405, time: 0.166, data: 0.001) G_GAN: 0.893 G_L1: 5.875 D_real: 0.648 D_fake: 0.501 \n",
      "saving the latest model (epoch 36, total_iters 15000)\n",
      "End of epoch 36 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 88, time: 0.166, data: 0.001) G_GAN: 0.943 G_L1: 8.658 D_real: 0.324 D_fake: 0.541 \n",
      "(epoch: 37, iters: 188, time: 0.336, data: 0.001) G_GAN: 0.949 G_L1: 6.994 D_real: 0.939 D_fake: 0.381 \n",
      "(epoch: 37, iters: 288, time: 0.167, data: 0.001) G_GAN: 0.822 G_L1: 0.135 D_real: 0.806 D_fake: 0.599 \n",
      "(epoch: 37, iters: 388, time: 0.167, data: 0.001) G_GAN: 0.802 G_L1: 4.728 D_real: 1.179 D_fake: 0.373 \n",
      "End of epoch 37 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 71, time: 0.167, data: 0.001) G_GAN: 0.785 G_L1: 6.498 D_real: 0.426 D_fake: 0.684 \n",
      "(epoch: 38, iters: 171, time: 0.311, data: 0.001) G_GAN: 0.805 G_L1: 5.123 D_real: 0.723 D_fake: 0.613 \n",
      "(epoch: 38, iters: 271, time: 0.167, data: 0.001) G_GAN: 1.318 G_L1: 6.303 D_real: 0.574 D_fake: 0.281 \n",
      "(epoch: 38, iters: 371, time: 0.168, data: 0.001) G_GAN: 1.295 G_L1: 14.543 D_real: 0.149 D_fake: 0.554 \n",
      "End of epoch 38 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 54, time: 0.168, data: 0.001) G_GAN: 0.861 G_L1: 7.756 D_real: 0.683 D_fake: 0.437 \n",
      "(epoch: 39, iters: 154, time: 0.306, data: 0.001) G_GAN: 0.960 G_L1: 6.488 D_real: 0.160 D_fake: 1.373 \n",
      "(epoch: 39, iters: 254, time: 0.167, data: 0.001) G_GAN: 0.991 G_L1: 6.950 D_real: 0.425 D_fake: 0.485 \n",
      "(epoch: 39, iters: 354, time: 0.167, data: 0.001) G_GAN: 0.807 G_L1: 6.739 D_real: 0.783 D_fake: 0.583 \n",
      "End of epoch 39 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 37, time: 0.168, data: 0.001) G_GAN: 1.341 G_L1: 13.787 D_real: 1.213 D_fake: 0.163 \n",
      "(epoch: 40, iters: 137, time: 0.319, data: 0.001) G_GAN: 1.442 G_L1: 9.788 D_real: 0.037 D_fake: 1.587 \n",
      "(epoch: 40, iters: 237, time: 0.168, data: 0.001) G_GAN: 0.763 G_L1: 6.214 D_real: 1.151 D_fake: 0.418 \n",
      "(epoch: 40, iters: 337, time: 0.167, data: 0.001) G_GAN: 0.784 G_L1: 5.662 D_real: 1.040 D_fake: 0.397 \n",
      "saving the model at the end of epoch 40, iters 16680\n",
      "End of epoch 40 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 20, time: 0.168, data: 0.001) G_GAN: 0.896 G_L1: 9.546 D_real: 0.305 D_fake: 1.035 \n",
      "(epoch: 41, iters: 120, time: 0.318, data: 0.001) G_GAN: 0.756 G_L1: 5.200 D_real: 0.325 D_fake: 1.051 \n",
      "(epoch: 41, iters: 220, time: 0.167, data: 0.001) G_GAN: 0.981 G_L1: 6.265 D_real: 0.453 D_fake: 0.714 \n",
      "(epoch: 41, iters: 320, time: 0.168, data: 0.001) G_GAN: 0.596 G_L1: 4.972 D_real: 1.012 D_fake: 0.357 \n",
      "End of epoch 41 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 3, time: 0.168, data: 0.001) G_GAN: 0.787 G_L1: 4.268 D_real: 0.664 D_fake: 0.526 \n",
      "(epoch: 42, iters: 103, time: 0.316, data: 0.001) G_GAN: 0.900 G_L1: 5.821 D_real: 0.539 D_fake: 0.605 \n",
      "(epoch: 42, iters: 203, time: 0.167, data: 0.001) G_GAN: 0.953 G_L1: 5.043 D_real: 0.696 D_fake: 0.535 \n",
      "(epoch: 42, iters: 303, time: 0.167, data: 0.001) G_GAN: 0.633 G_L1: 7.445 D_real: 0.978 D_fake: 0.457 \n",
      "(epoch: 42, iters: 403, time: 0.167, data: 0.001) G_GAN: 0.908 G_L1: 8.591 D_real: 0.429 D_fake: 0.819 \n",
      "End of epoch 42 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 86, time: 0.293, data: 0.001) G_GAN: 0.699 G_L1: 0.074 D_real: 0.702 D_fake: 0.706 \n",
      "(epoch: 43, iters: 186, time: 0.167, data: 0.001) G_GAN: 0.882 G_L1: 7.343 D_real: 0.575 D_fake: 0.555 \n",
      "(epoch: 43, iters: 286, time: 0.168, data: 0.001) G_GAN: 0.727 G_L1: 3.091 D_real: 0.634 D_fake: 0.696 \n",
      "(epoch: 43, iters: 386, time: 0.168, data: 0.001) G_GAN: 1.278 G_L1: 7.253 D_real: 0.665 D_fake: 0.252 \n",
      "End of epoch 43 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 69, time: 0.328, data: 0.001) G_GAN: 1.085 G_L1: 9.577 D_real: 0.256 D_fake: 0.536 \n",
      "(epoch: 44, iters: 169, time: 0.168, data: 0.001) G_GAN: 1.633 G_L1: 7.919 D_real: 0.373 D_fake: 0.189 \n",
      "(epoch: 44, iters: 269, time: 0.167, data: 0.001) G_GAN: 0.974 G_L1: 7.823 D_real: 0.385 D_fake: 0.582 \n",
      "(epoch: 44, iters: 369, time: 0.168, data: 0.001) G_GAN: 0.717 G_L1: 5.836 D_real: 1.291 D_fake: 0.363 \n",
      "End of epoch 44 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 52, time: 0.333, data: 0.001) G_GAN: 0.959 G_L1: 7.032 D_real: 0.732 D_fake: 0.405 \n",
      "(epoch: 45, iters: 152, time: 0.166, data: 0.001) G_GAN: 0.806 G_L1: 5.178 D_real: 1.350 D_fake: 0.332 \n",
      "(epoch: 45, iters: 252, time: 0.168, data: 0.001) G_GAN: 0.757 G_L1: 4.315 D_real: 0.453 D_fake: 0.699 \n",
      "(epoch: 45, iters: 352, time: 0.169, data: 0.001) G_GAN: 1.203 G_L1: 13.334 D_real: 0.297 D_fake: 0.382 \n",
      "saving the model at the end of epoch 45, iters 18765\n",
      "End of epoch 45 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 35, time: 0.300, data: 0.001) G_GAN: 0.723 G_L1: 5.670 D_real: 0.626 D_fake: 0.584 \n",
      "(epoch: 46, iters: 135, time: 0.168, data: 0.001) G_GAN: 1.087 G_L1: 5.070 D_real: 0.861 D_fake: 0.408 \n",
      "(epoch: 46, iters: 235, time: 0.168, data: 0.001) G_GAN: 1.451 G_L1: 9.961 D_real: 0.129 D_fake: 0.402 \n",
      "(epoch: 46, iters: 335, time: 0.168, data: 0.001) G_GAN: 0.970 G_L1: 5.073 D_real: 1.045 D_fake: 0.325 \n",
      "End of epoch 46 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 18, time: 0.314, data: 0.001) G_GAN: 0.698 G_L1: 4.735 D_real: 0.718 D_fake: 0.597 \n",
      "(epoch: 47, iters: 118, time: 0.167, data: 0.001) G_GAN: 0.642 G_L1: 6.598 D_real: 0.701 D_fake: 0.776 \n",
      "(epoch: 47, iters: 218, time: 0.167, data: 0.001) G_GAN: 1.230 G_L1: 9.423 D_real: 0.206 D_fake: 0.722 \n",
      "(epoch: 47, iters: 318, time: 0.168, data: 0.001) G_GAN: 1.025 G_L1: 5.795 D_real: 0.753 D_fake: 0.424 \n",
      "End of epoch 47 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 1, time: 0.262, data: 0.001) G_GAN: 1.898 G_L1: 8.518 D_real: 0.054 D_fake: 0.401 \n",
      "(epoch: 48, iters: 101, time: 0.168, data: 0.000) G_GAN: 0.965 G_L1: 6.832 D_real: 0.670 D_fake: 0.461 \n",
      "(epoch: 48, iters: 201, time: 0.168, data: 0.001) G_GAN: 0.835 G_L1: 4.247 D_real: 0.576 D_fake: 0.368 \n",
      "(epoch: 48, iters: 301, time: 0.167, data: 0.001) G_GAN: 0.644 G_L1: 5.462 D_real: 0.567 D_fake: 0.991 \n",
      "(epoch: 48, iters: 401, time: 0.322, data: 0.001) G_GAN: 1.036 G_L1: 7.879 D_real: 0.273 D_fake: 0.559 \n",
      "saving the latest model (epoch 48, total_iters 20000)\n",
      "End of epoch 48 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 84, time: 0.167, data: 0.001) G_GAN: 1.099 G_L1: 5.215 D_real: 0.845 D_fake: 0.315 \n",
      "(epoch: 49, iters: 184, time: 0.167, data: 0.001) G_GAN: 0.891 G_L1: 6.508 D_real: 0.578 D_fake: 0.559 \n",
      "(epoch: 49, iters: 284, time: 0.168, data: 0.001) G_GAN: 0.821 G_L1: 5.810 D_real: 0.633 D_fake: 0.528 \n",
      "(epoch: 49, iters: 384, time: 0.317, data: 0.001) G_GAN: 0.863 G_L1: 6.624 D_real: 0.543 D_fake: 0.487 \n",
      "End of epoch 49 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 67, time: 0.168, data: 0.001) G_GAN: 1.094 G_L1: 9.116 D_real: 0.299 D_fake: 0.817 \n",
      "(epoch: 50, iters: 167, time: 0.167, data: 0.001) G_GAN: 0.790 G_L1: 5.383 D_real: 0.743 D_fake: 0.514 \n",
      "(epoch: 50, iters: 267, time: 0.166, data: 0.001) G_GAN: 0.861 G_L1: 5.562 D_real: 1.065 D_fake: 0.537 \n",
      "(epoch: 50, iters: 367, time: 0.335, data: 0.001) G_GAN: 1.077 G_L1: 6.727 D_real: 0.249 D_fake: 1.166 \n",
      "saving the model at the end of epoch 50, iters 20850\n",
      "End of epoch 50 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 50, time: 0.167, data: 0.001) G_GAN: 1.427 G_L1: 7.111 D_real: 0.291 D_fake: 0.297 \n",
      "(epoch: 51, iters: 150, time: 0.166, data: 0.001) G_GAN: 1.022 G_L1: 7.655 D_real: 0.364 D_fake: 0.987 \n",
      "(epoch: 51, iters: 250, time: 0.167, data: 0.001) G_GAN: 1.006 G_L1: 6.246 D_real: 1.063 D_fake: 0.333 \n",
      "(epoch: 51, iters: 350, time: 0.339, data: 0.001) G_GAN: 1.289 G_L1: 5.624 D_real: 0.359 D_fake: 0.431 \n",
      "End of epoch 51 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 33, time: 0.169, data: 0.001) G_GAN: 1.347 G_L1: 9.424 D_real: 0.314 D_fake: 0.726 \n",
      "(epoch: 52, iters: 133, time: 0.168, data: 0.002) G_GAN: 0.860 G_L1: 6.756 D_real: 0.424 D_fake: 0.974 \n",
      "(epoch: 52, iters: 233, time: 0.168, data: 0.001) G_GAN: 1.160 G_L1: 9.895 D_real: 0.173 D_fake: 1.421 \n",
      "(epoch: 52, iters: 333, time: 0.353, data: 0.001) G_GAN: 0.785 G_L1: 4.408 D_real: 0.618 D_fake: 0.751 \n",
      "End of epoch 52 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 16, time: 0.167, data: 0.001) G_GAN: 1.162 G_L1: 3.933 D_real: 0.741 D_fake: 0.354 \n",
      "(epoch: 53, iters: 116, time: 0.166, data: 0.001) G_GAN: 0.936 G_L1: 3.707 D_real: 1.303 D_fake: 0.319 \n",
      "(epoch: 53, iters: 216, time: 0.168, data: 0.001) G_GAN: 0.851 G_L1: 7.573 D_real: 0.587 D_fake: 0.640 \n",
      "(epoch: 53, iters: 316, time: 0.320, data: 0.001) G_GAN: 0.906 G_L1: 6.945 D_real: 0.696 D_fake: 0.518 \n",
      "(epoch: 53, iters: 416, time: 0.167, data: 0.001) G_GAN: 0.811 G_L1: 6.793 D_real: 0.661 D_fake: 0.491 \n",
      "End of epoch 53 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 99, time: 0.168, data: 0.001) G_GAN: 0.835 G_L1: 0.061 D_real: 0.889 D_fake: 0.548 \n",
      "(epoch: 54, iters: 199, time: 0.168, data: 0.002) G_GAN: 0.701 G_L1: 1.892 D_real: 0.745 D_fake: 0.719 \n",
      "(epoch: 54, iters: 299, time: 0.310, data: 0.001) G_GAN: 0.712 G_L1: 1.938 D_real: 0.644 D_fake: 0.644 \n",
      "(epoch: 54, iters: 399, time: 0.168, data: 0.001) G_GAN: 0.799 G_L1: 5.115 D_real: 0.665 D_fake: 0.536 \n",
      "End of epoch 54 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 82, time: 0.166, data: 0.001) G_GAN: 1.005 G_L1: 5.524 D_real: 0.866 D_fake: 0.394 \n",
      "(epoch: 55, iters: 182, time: 0.168, data: 0.001) G_GAN: 0.743 G_L1: 4.998 D_real: 0.968 D_fake: 0.373 \n",
      "(epoch: 55, iters: 282, time: 0.325, data: 0.001) G_GAN: 0.648 G_L1: 5.582 D_real: 0.404 D_fake: 1.221 \n",
      "(epoch: 55, iters: 382, time: 0.167, data: 0.001) G_GAN: 0.962 G_L1: 5.076 D_real: 0.607 D_fake: 0.376 \n",
      "saving the model at the end of epoch 55, iters 22935\n",
      "End of epoch 55 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 65, time: 0.167, data: 0.001) G_GAN: 1.095 G_L1: 7.469 D_real: 0.624 D_fake: 0.328 \n",
      "(epoch: 56, iters: 165, time: 0.167, data: 0.001) G_GAN: 0.866 G_L1: 4.245 D_real: 1.193 D_fake: 0.442 \n",
      "(epoch: 56, iters: 265, time: 0.335, data: 0.001) G_GAN: 1.197 G_L1: 4.541 D_real: 0.929 D_fake: 0.345 \n",
      "(epoch: 56, iters: 365, time: 0.166, data: 0.001) G_GAN: 0.872 G_L1: 5.870 D_real: 0.465 D_fake: 0.601 \n",
      "End of epoch 56 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 48, time: 0.168, data: 0.001) G_GAN: 0.945 G_L1: 1.706 D_real: 0.936 D_fake: 0.393 \n",
      "(epoch: 57, iters: 148, time: 0.168, data: 0.001) G_GAN: 0.979 G_L1: 8.335 D_real: 0.698 D_fake: 0.428 \n",
      "(epoch: 57, iters: 248, time: 0.304, data: 0.001) G_GAN: 0.749 G_L1: 0.066 D_real: 0.812 D_fake: 0.599 \n",
      "(epoch: 57, iters: 348, time: 0.167, data: 0.001) G_GAN: 0.691 G_L1: 2.721 D_real: 0.695 D_fake: 0.715 \n",
      "End of epoch 57 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 31, time: 0.168, data: 0.001) G_GAN: 0.985 G_L1: 7.790 D_real: 0.744 D_fake: 0.370 \n",
      "(epoch: 58, iters: 131, time: 0.168, data: 0.001) G_GAN: 0.897 G_L1: 6.794 D_real: 0.364 D_fake: 0.906 \n",
      "(epoch: 58, iters: 231, time: 0.334, data: 0.001) G_GAN: 1.340 G_L1: 9.678 D_real: 0.116 D_fake: 1.860 \n",
      "(epoch: 58, iters: 331, time: 0.167, data: 0.001) G_GAN: 1.437 G_L1: 5.973 D_real: 0.450 D_fake: 0.268 \n",
      "End of epoch 58 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 14, time: 0.166, data: 0.001) G_GAN: 0.892 G_L1: 6.125 D_real: 0.459 D_fake: 0.950 \n",
      "(epoch: 59, iters: 114, time: 0.167, data: 0.001) G_GAN: 0.925 G_L1: 8.893 D_real: 0.229 D_fake: 0.690 \n",
      "(epoch: 59, iters: 214, time: 0.304, data: 0.001) G_GAN: 0.728 G_L1: 0.056 D_real: 0.756 D_fake: 0.647 \n",
      "(epoch: 59, iters: 314, time: 0.166, data: 0.001) G_GAN: 0.894 G_L1: 3.467 D_real: 0.809 D_fake: 0.504 \n",
      "(epoch: 59, iters: 414, time: 0.168, data: 0.001) G_GAN: 0.706 G_L1: 4.615 D_real: 0.685 D_fake: 0.696 \n",
      "End of epoch 59 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 97, time: 0.168, data: 0.001) G_GAN: 0.536 G_L1: 8.063 D_real: 1.406 D_fake: 0.527 \n",
      "(epoch: 60, iters: 197, time: 0.335, data: 0.001) G_GAN: 0.880 G_L1: 6.544 D_real: 0.517 D_fake: 0.658 \n",
      "(epoch: 60, iters: 297, time: 0.168, data: 0.001) G_GAN: 1.105 G_L1: 7.985 D_real: 1.540 D_fake: 0.099 \n",
      "(epoch: 60, iters: 397, time: 0.167, data: 0.001) G_GAN: 0.807 G_L1: 4.199 D_real: 0.372 D_fake: 0.736 \n",
      "saving the latest model (epoch 60, total_iters 25000)\n",
      "saving the model at the end of epoch 60, iters 25020\n",
      "End of epoch 60 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 80, time: 0.168, data: 0.001) G_GAN: 0.923 G_L1: 8.938 D_real: 0.407 D_fake: 0.847 \n",
      "(epoch: 61, iters: 180, time: 0.353, data: 0.001) G_GAN: 0.870 G_L1: 20.864 D_real: 0.460 D_fake: 1.169 \n",
      "(epoch: 61, iters: 280, time: 0.167, data: 0.001) G_GAN: 0.910 G_L1: 6.200 D_real: 0.350 D_fake: 0.780 \n",
      "(epoch: 61, iters: 380, time: 0.168, data: 0.001) G_GAN: 1.220 G_L1: 10.150 D_real: 0.788 D_fake: 0.444 \n",
      "End of epoch 61 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 63, time: 0.168, data: 0.001) G_GAN: 0.779 G_L1: 4.837 D_real: 0.529 D_fake: 0.889 \n",
      "(epoch: 62, iters: 163, time: 0.338, data: 0.001) G_GAN: 1.370 G_L1: 9.925 D_real: 0.062 D_fake: 0.965 \n",
      "(epoch: 62, iters: 263, time: 0.168, data: 0.001) G_GAN: 1.657 G_L1: 8.267 D_real: 0.302 D_fake: 0.232 \n",
      "(epoch: 62, iters: 363, time: 0.168, data: 0.001) G_GAN: 0.945 G_L1: 5.211 D_real: 0.566 D_fake: 0.549 \n",
      "End of epoch 62 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 46, time: 0.167, data: 0.001) G_GAN: 1.089 G_L1: 9.012 D_real: 0.667 D_fake: 0.322 \n",
      "(epoch: 63, iters: 146, time: 0.329, data: 0.001) G_GAN: 1.401 G_L1: 3.752 D_real: 0.815 D_fake: 0.288 \n",
      "(epoch: 63, iters: 246, time: 0.167, data: 0.001) G_GAN: 1.140 G_L1: 6.384 D_real: 0.260 D_fake: 0.437 \n",
      "(epoch: 63, iters: 346, time: 0.167, data: 0.001) G_GAN: 0.847 G_L1: 1.186 D_real: 0.941 D_fake: 0.521 \n",
      "End of epoch 63 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 29, time: 0.168, data: 0.001) G_GAN: 1.166 G_L1: 7.026 D_real: 0.657 D_fake: 0.346 \n",
      "(epoch: 64, iters: 129, time: 0.347, data: 0.001) G_GAN: 0.793 G_L1: 6.179 D_real: 0.677 D_fake: 0.566 \n",
      "(epoch: 64, iters: 229, time: 0.168, data: 0.001) G_GAN: 0.864 G_L1: 6.090 D_real: 1.034 D_fake: 0.380 \n",
      "(epoch: 64, iters: 329, time: 0.168, data: 0.001) G_GAN: 1.685 G_L1: 8.807 D_real: 0.223 D_fake: 0.214 \n",
      "End of epoch 64 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 12, time: 0.167, data: 0.001) G_GAN: 0.816 G_L1: 5.757 D_real: 1.049 D_fake: 0.459 \n",
      "(epoch: 65, iters: 112, time: 0.384, data: 0.001) G_GAN: 1.237 G_L1: 6.146 D_real: 0.859 D_fake: 0.275 \n",
      "(epoch: 65, iters: 212, time: 0.167, data: 0.001) G_GAN: 0.730 G_L1: 1.649 D_real: 0.362 D_fake: 0.761 \n",
      "(epoch: 65, iters: 312, time: 0.167, data: 0.001) G_GAN: 0.746 G_L1: 7.524 D_real: 0.402 D_fake: 0.739 \n",
      "(epoch: 65, iters: 412, time: 0.167, data: 0.001) G_GAN: 0.779 G_L1: 6.302 D_real: 0.505 D_fake: 0.771 \n",
      "saving the model at the end of epoch 65, iters 27105\n",
      "End of epoch 65 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 95, time: 0.344, data: 0.001) G_GAN: 2.384 G_L1: 7.993 D_real: 0.234 D_fake: 0.088 \n",
      "(epoch: 66, iters: 195, time: 0.168, data: 0.002) G_GAN: 0.825 G_L1: 4.718 D_real: 0.672 D_fake: 0.724 \n",
      "(epoch: 66, iters: 295, time: 0.167, data: 0.001) G_GAN: 0.873 G_L1: 0.037 D_real: 1.034 D_fake: 0.460 \n",
      "(epoch: 66, iters: 395, time: 0.167, data: 0.001) G_GAN: 1.400 G_L1: 8.576 D_real: 0.239 D_fake: 0.451 \n",
      "End of epoch 66 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 78, time: 0.320, data: 0.001) G_GAN: 0.868 G_L1: 3.778 D_real: 0.652 D_fake: 0.534 \n",
      "(epoch: 67, iters: 178, time: 0.166, data: 0.001) G_GAN: 1.515 G_L1: 6.664 D_real: 0.838 D_fake: 0.093 \n",
      "(epoch: 67, iters: 278, time: 0.168, data: 0.001) G_GAN: 1.098 G_L1: 6.717 D_real: 0.973 D_fake: 0.271 \n",
      "(epoch: 67, iters: 378, time: 0.167, data: 0.001) G_GAN: 0.890 G_L1: 4.864 D_real: 0.986 D_fake: 0.284 \n",
      "End of epoch 67 / 200 \t Time Taken: 44 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 61, time: 0.365, data: 0.001) G_GAN: 1.099 G_L1: 7.397 D_real: 0.721 D_fake: 0.313 \n",
      "(epoch: 68, iters: 161, time: 0.166, data: 0.001) G_GAN: 0.817 G_L1: 7.739 D_real: 0.555 D_fake: 0.616 \n",
      "(epoch: 68, iters: 261, time: 0.166, data: 0.001) G_GAN: 1.423 G_L1: 9.161 D_real: 0.158 D_fake: 0.428 \n",
      "(epoch: 68, iters: 361, time: 0.169, data: 0.001) G_GAN: 1.514 G_L1: 7.859 D_real: 0.203 D_fake: 0.412 \n",
      "End of epoch 68 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 44, time: 0.346, data: 0.001) G_GAN: 1.230 G_L1: 6.179 D_real: 0.509 D_fake: 0.269 \n",
      "(epoch: 69, iters: 144, time: 0.167, data: 0.001) G_GAN: 1.177 G_L1: 8.318 D_real: 0.467 D_fake: 0.375 \n",
      "(epoch: 69, iters: 244, time: 0.168, data: 0.001) G_GAN: 0.691 G_L1: 6.325 D_real: 1.227 D_fake: 0.505 \n",
      "(epoch: 69, iters: 344, time: 0.168, data: 0.001) G_GAN: 0.931 G_L1: 5.298 D_real: 0.232 D_fake: 1.043 \n",
      "End of epoch 69 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 27, time: 0.339, data: 0.001) G_GAN: 0.973 G_L1: 4.815 D_real: 0.281 D_fake: 0.795 \n",
      "(epoch: 70, iters: 127, time: 0.167, data: 0.002) G_GAN: 0.984 G_L1: 4.958 D_real: 0.625 D_fake: 0.664 \n",
      "(epoch: 70, iters: 227, time: 0.167, data: 0.001) G_GAN: 0.920 G_L1: 5.100 D_real: 0.316 D_fake: 1.011 \n",
      "(epoch: 70, iters: 327, time: 0.166, data: 0.001) G_GAN: 0.891 G_L1: 4.593 D_real: 0.712 D_fake: 0.410 \n",
      "saving the model at the end of epoch 70, iters 29190\n",
      "End of epoch 70 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 10, time: 0.346, data: 0.001) G_GAN: 1.111 G_L1: 7.066 D_real: 0.935 D_fake: 0.378 \n",
      "(epoch: 71, iters: 110, time: 0.166, data: 0.001) G_GAN: 0.909 G_L1: 6.424 D_real: 0.673 D_fake: 0.706 \n",
      "(epoch: 71, iters: 210, time: 0.167, data: 0.001) G_GAN: 1.110 G_L1: 4.445 D_real: 1.385 D_fake: 0.244 \n",
      "(epoch: 71, iters: 310, time: 0.166, data: 0.001) G_GAN: 0.941 G_L1: 3.400 D_real: 0.784 D_fake: 0.494 \n",
      "(epoch: 71, iters: 410, time: 0.336, data: 0.001) G_GAN: 1.309 G_L1: 8.517 D_real: 0.130 D_fake: 0.705 \n",
      "End of epoch 71 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 93, time: 0.167, data: 0.001) G_GAN: 1.084 G_L1: 5.168 D_real: 0.281 D_fake: 0.992 \n",
      "(epoch: 72, iters: 193, time: 0.166, data: 0.001) G_GAN: 1.129 G_L1: 8.724 D_real: 0.357 D_fake: 0.526 \n",
      "(epoch: 72, iters: 293, time: 0.168, data: 0.001) G_GAN: 1.080 G_L1: 4.844 D_real: 0.505 D_fake: 0.461 \n",
      "(epoch: 72, iters: 393, time: 0.330, data: 0.001) G_GAN: 1.720 G_L1: 3.354 D_real: 0.988 D_fake: 0.103 \n",
      "saving the latest model (epoch 72, total_iters 30000)\n",
      "End of epoch 72 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 76, time: 0.168, data: 0.001) G_GAN: 0.764 G_L1: 4.563 D_real: 1.233 D_fake: 0.567 \n",
      "(epoch: 73, iters: 176, time: 0.167, data: 0.001) G_GAN: 1.202 G_L1: 6.482 D_real: 0.101 D_fake: 0.963 \n",
      "(epoch: 73, iters: 276, time: 0.167, data: 0.001) G_GAN: 0.825 G_L1: 5.182 D_real: 0.321 D_fake: 0.903 \n",
      "(epoch: 73, iters: 376, time: 0.346, data: 0.001) G_GAN: 1.083 G_L1: 6.515 D_real: 0.229 D_fake: 1.403 \n",
      "End of epoch 73 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 59, time: 0.167, data: 0.001) G_GAN: 1.243 G_L1: 6.875 D_real: 0.263 D_fake: 1.216 \n",
      "(epoch: 74, iters: 159, time: 0.167, data: 0.001) G_GAN: 1.394 G_L1: 8.678 D_real: 0.382 D_fake: 0.384 \n",
      "(epoch: 74, iters: 259, time: 0.167, data: 0.001) G_GAN: 0.960 G_L1: 8.855 D_real: 0.333 D_fake: 0.656 \n",
      "(epoch: 74, iters: 359, time: 0.395, data: 0.001) G_GAN: 0.873 G_L1: 6.045 D_real: 0.973 D_fake: 0.441 \n",
      "End of epoch 74 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 42, time: 0.167, data: 0.001) G_GAN: 0.718 G_L1: 1.324 D_real: 0.523 D_fake: 0.760 \n",
      "(epoch: 75, iters: 142, time: 0.167, data: 0.001) G_GAN: 0.861 G_L1: 4.962 D_real: 0.586 D_fake: 0.565 \n",
      "(epoch: 75, iters: 242, time: 0.167, data: 0.001) G_GAN: 1.145 G_L1: 7.209 D_real: 0.560 D_fake: 0.296 \n",
      "(epoch: 75, iters: 342, time: 0.353, data: 0.001) G_GAN: 1.335 G_L1: 8.590 D_real: 0.245 D_fake: 0.889 \n",
      "saving the model at the end of epoch 75, iters 31275\n",
      "End of epoch 75 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 25, time: 0.168, data: 0.001) G_GAN: 1.027 G_L1: 8.661 D_real: 0.192 D_fake: 0.798 \n",
      "(epoch: 76, iters: 125, time: 0.167, data: 0.001) G_GAN: 0.759 G_L1: 5.123 D_real: 0.289 D_fake: 1.366 \n",
      "(epoch: 76, iters: 225, time: 0.168, data: 0.001) G_GAN: 1.134 G_L1: 6.156 D_real: 0.808 D_fake: 0.432 \n",
      "(epoch: 76, iters: 325, time: 0.345, data: 0.001) G_GAN: 0.912 G_L1: 3.086 D_real: 0.294 D_fake: 0.784 \n",
      "End of epoch 76 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 8, time: 0.169, data: 0.001) G_GAN: 1.345 G_L1: 8.290 D_real: 0.656 D_fake: 0.421 \n",
      "(epoch: 77, iters: 108, time: 0.168, data: 0.001) G_GAN: 1.361 G_L1: 8.752 D_real: 0.130 D_fake: 0.574 \n",
      "(epoch: 77, iters: 208, time: 0.166, data: 0.001) G_GAN: 0.621 G_L1: 1.589 D_real: 0.465 D_fake: 0.898 \n",
      "(epoch: 77, iters: 308, time: 0.380, data: 0.001) G_GAN: 1.424 G_L1: 9.345 D_real: 0.220 D_fake: 0.697 \n",
      "(epoch: 77, iters: 408, time: 0.168, data: 0.001) G_GAN: 0.977 G_L1: 6.978 D_real: 1.067 D_fake: 0.319 \n",
      "End of epoch 77 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 91, time: 0.167, data: 0.001) G_GAN: 1.693 G_L1: 4.118 D_real: 0.980 D_fake: 0.129 \n",
      "(epoch: 78, iters: 191, time: 0.169, data: 0.001) G_GAN: 1.182 G_L1: 8.059 D_real: 0.607 D_fake: 0.405 \n",
      "(epoch: 78, iters: 291, time: 0.334, data: 0.001) G_GAN: 0.592 G_L1: 0.113 D_real: 0.645 D_fake: 0.812 \n",
      "(epoch: 78, iters: 391, time: 0.167, data: 0.001) G_GAN: 1.650 G_L1: 7.718 D_real: 0.082 D_fake: 0.277 \n",
      "End of epoch 78 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 74, time: 0.168, data: 0.001) G_GAN: 0.831 G_L1: 5.141 D_real: 0.940 D_fake: 0.443 \n",
      "(epoch: 79, iters: 174, time: 0.167, data: 0.001) G_GAN: 1.027 G_L1: 4.202 D_real: 1.445 D_fake: 0.244 \n",
      "(epoch: 79, iters: 274, time: 0.378, data: 0.001) G_GAN: 1.011 G_L1: 6.961 D_real: 0.971 D_fake: 0.235 \n",
      "(epoch: 79, iters: 374, time: 0.167, data: 0.001) G_GAN: 0.871 G_L1: 7.967 D_real: 1.152 D_fake: 0.609 \n",
      "End of epoch 79 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 57, time: 0.167, data: 0.001) G_GAN: 1.290 G_L1: 6.673 D_real: 0.479 D_fake: 0.386 \n",
      "(epoch: 80, iters: 157, time: 0.168, data: 0.001) G_GAN: 1.201 G_L1: 5.040 D_real: 0.882 D_fake: 0.200 \n",
      "(epoch: 80, iters: 257, time: 0.361, data: 0.001) G_GAN: 1.356 G_L1: 6.685 D_real: 0.602 D_fake: 0.363 \n",
      "(epoch: 80, iters: 357, time: 0.168, data: 0.001) G_GAN: 1.066 G_L1: 7.218 D_real: 0.299 D_fake: 0.566 \n",
      "saving the model at the end of epoch 80, iters 33360\n",
      "End of epoch 80 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 40, time: 0.167, data: 0.001) G_GAN: 1.040 G_L1: 4.746 D_real: 0.553 D_fake: 0.621 \n",
      "(epoch: 81, iters: 140, time: 0.167, data: 0.001) G_GAN: 1.338 G_L1: 7.409 D_real: 0.278 D_fake: 0.804 \n",
      "(epoch: 81, iters: 240, time: 0.356, data: 0.001) G_GAN: 1.421 G_L1: 8.701 D_real: 0.022 D_fake: 0.551 \n",
      "(epoch: 81, iters: 340, time: 0.166, data: 0.001) G_GAN: 1.086 G_L1: 7.246 D_real: 0.417 D_fake: 0.477 \n",
      "End of epoch 81 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 23, time: 0.167, data: 0.001) G_GAN: 0.967 G_L1: 3.830 D_real: 1.566 D_fake: 0.166 \n",
      "(epoch: 82, iters: 123, time: 0.167, data: 0.001) G_GAN: 0.786 G_L1: 5.852 D_real: 0.776 D_fake: 0.327 \n",
      "(epoch: 82, iters: 223, time: 0.366, data: 0.001) G_GAN: 1.769 G_L1: 4.674 D_real: 1.050 D_fake: 0.105 \n",
      "(epoch: 82, iters: 323, time: 0.168, data: 0.001) G_GAN: 1.308 G_L1: 7.284 D_real: 0.374 D_fake: 0.456 \n",
      "End of epoch 82 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 6, time: 0.169, data: 0.001) G_GAN: 1.364 G_L1: 4.882 D_real: 0.406 D_fake: 0.287 \n",
      "(epoch: 83, iters: 106, time: 0.167, data: 0.000) G_GAN: 0.646 G_L1: 4.908 D_real: 0.618 D_fake: 0.929 \n",
      "(epoch: 83, iters: 206, time: 0.383, data: 0.001) G_GAN: 0.758 G_L1: 3.218 D_real: 0.299 D_fake: 0.889 \n",
      "(epoch: 83, iters: 306, time: 0.168, data: 0.001) G_GAN: 1.148 G_L1: 6.153 D_real: 0.441 D_fake: 0.497 \n",
      "(epoch: 83, iters: 406, time: 0.169, data: 0.001) G_GAN: 0.864 G_L1: 5.114 D_real: 0.671 D_fake: 0.511 \n",
      "End of epoch 83 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 89, time: 0.168, data: 0.001) G_GAN: 1.081 G_L1: 6.848 D_real: 0.377 D_fake: 1.580 \n",
      "(epoch: 84, iters: 189, time: 0.346, data: 0.001) G_GAN: 1.578 G_L1: 6.356 D_real: 0.058 D_fake: 1.001 \n",
      "(epoch: 84, iters: 289, time: 0.167, data: 0.001) G_GAN: 1.215 G_L1: 7.055 D_real: 0.538 D_fake: 0.375 \n",
      "(epoch: 84, iters: 389, time: 0.166, data: 0.001) G_GAN: 0.674 G_L1: 6.777 D_real: 0.968 D_fake: 0.531 \n",
      "saving the latest model (epoch 84, total_iters 35000)\n",
      "End of epoch 84 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 72, time: 0.167, data: 0.001) G_GAN: 1.208 G_L1: 5.175 D_real: 0.358 D_fake: 0.518 \n",
      "(epoch: 85, iters: 172, time: 0.378, data: 0.001) G_GAN: 1.438 G_L1: 6.515 D_real: 0.192 D_fake: 1.323 \n",
      "(epoch: 85, iters: 272, time: 0.167, data: 0.001) G_GAN: 0.928 G_L1: 6.228 D_real: 0.905 D_fake: 0.349 \n",
      "(epoch: 85, iters: 372, time: 0.166, data: 0.001) G_GAN: 1.051 G_L1: 0.924 D_real: 0.560 D_fake: 0.615 \n",
      "saving the model at the end of epoch 85, iters 35445\n",
      "End of epoch 85 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 55, time: 0.168, data: 0.001) G_GAN: 0.942 G_L1: 1.546 D_real: 0.735 D_fake: 0.594 \n",
      "(epoch: 86, iters: 155, time: 0.370, data: 0.001) G_GAN: 1.510 G_L1: 4.891 D_real: 1.436 D_fake: 0.119 \n",
      "(epoch: 86, iters: 255, time: 0.168, data: 0.001) G_GAN: 0.861 G_L1: 7.165 D_real: 0.667 D_fake: 0.461 \n",
      "(epoch: 86, iters: 355, time: 0.168, data: 0.001) G_GAN: 1.650 G_L1: 17.542 D_real: 0.364 D_fake: 0.346 \n",
      "End of epoch 86 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 38, time: 0.168, data: 0.001) G_GAN: 1.476 G_L1: 8.893 D_real: 0.604 D_fake: 0.258 \n",
      "(epoch: 87, iters: 138, time: 0.362, data: 0.001) G_GAN: 0.954 G_L1: 4.043 D_real: 0.556 D_fake: 0.693 \n",
      "(epoch: 87, iters: 238, time: 0.168, data: 0.001) G_GAN: 1.078 G_L1: 6.404 D_real: 0.756 D_fake: 0.336 \n",
      "(epoch: 87, iters: 338, time: 0.167, data: 0.001) G_GAN: 0.754 G_L1: 6.067 D_real: 0.841 D_fake: 0.614 \n",
      "End of epoch 87 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 21, time: 0.168, data: 0.001) G_GAN: 0.970 G_L1: 5.806 D_real: 1.698 D_fake: 0.185 \n",
      "(epoch: 88, iters: 121, time: 0.372, data: 0.001) G_GAN: 1.154 G_L1: 5.022 D_real: 0.806 D_fake: 0.192 \n",
      "(epoch: 88, iters: 221, time: 0.167, data: 0.001) G_GAN: 1.184 G_L1: 6.642 D_real: 0.837 D_fake: 0.259 \n",
      "(epoch: 88, iters: 321, time: 0.168, data: 0.001) G_GAN: 1.531 G_L1: 3.736 D_real: 0.517 D_fake: 0.334 \n",
      "End of epoch 88 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 4, time: 0.167, data: 0.001) G_GAN: 0.802 G_L1: 9.020 D_real: 0.602 D_fake: 0.692 \n",
      "(epoch: 89, iters: 104, time: 0.383, data: 0.002) G_GAN: 1.349 G_L1: 8.190 D_real: 0.266 D_fake: 0.353 \n",
      "(epoch: 89, iters: 204, time: 0.168, data: 0.001) G_GAN: 1.771 G_L1: 10.170 D_real: 0.225 D_fake: 0.240 \n",
      "(epoch: 89, iters: 304, time: 0.168, data: 0.001) G_GAN: 0.927 G_L1: 4.702 D_real: 1.536 D_fake: 0.279 \n",
      "(epoch: 89, iters: 404, time: 0.168, data: 0.001) G_GAN: 1.105 G_L1: 5.964 D_real: 0.517 D_fake: 1.012 \n",
      "End of epoch 89 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 87, time: 0.372, data: 0.001) G_GAN: 0.897 G_L1: 4.794 D_real: 0.605 D_fake: 0.792 \n",
      "(epoch: 90, iters: 187, time: 0.166, data: 0.001) G_GAN: 0.917 G_L1: 4.430 D_real: 1.450 D_fake: 0.340 \n",
      "(epoch: 90, iters: 287, time: 0.167, data: 0.001) G_GAN: 0.891 G_L1: 7.952 D_real: 0.689 D_fake: 0.725 \n",
      "(epoch: 90, iters: 387, time: 0.166, data: 0.001) G_GAN: 0.866 G_L1: 6.840 D_real: 0.434 D_fake: 0.710 \n",
      "saving the model at the end of epoch 90, iters 37530\n",
      "End of epoch 90 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 70, time: 0.433, data: 0.001) G_GAN: 1.546 G_L1: 6.799 D_real: 0.521 D_fake: 0.253 \n",
      "(epoch: 91, iters: 170, time: 0.167, data: 0.001) G_GAN: 1.464 G_L1: 4.250 D_real: 0.273 D_fake: 0.692 \n",
      "(epoch: 91, iters: 270, time: 0.166, data: 0.001) G_GAN: 1.271 G_L1: 5.987 D_real: 0.317 D_fake: 0.819 \n",
      "(epoch: 91, iters: 370, time: 0.168, data: 0.001) G_GAN: 1.174 G_L1: 7.409 D_real: 0.331 D_fake: 0.574 \n",
      "End of epoch 91 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 53, time: 0.359, data: 0.001) G_GAN: 1.126 G_L1: 2.776 D_real: 0.761 D_fake: 0.348 \n",
      "(epoch: 92, iters: 153, time: 0.168, data: 0.001) G_GAN: 1.537 G_L1: 4.912 D_real: 0.795 D_fake: 0.214 \n",
      "(epoch: 92, iters: 253, time: 0.167, data: 0.002) G_GAN: 0.659 G_L1: 6.257 D_real: 1.304 D_fake: 0.438 \n",
      "(epoch: 92, iters: 353, time: 0.168, data: 0.001) G_GAN: 1.135 G_L1: 6.227 D_real: 0.342 D_fake: 0.472 \n",
      "End of epoch 92 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 36, time: 0.380, data: 0.001) G_GAN: 1.394 G_L1: 7.305 D_real: 0.340 D_fake: 1.917 \n",
      "(epoch: 93, iters: 136, time: 0.168, data: 0.001) G_GAN: 1.595 G_L1: 6.286 D_real: 0.081 D_fake: 0.508 \n",
      "(epoch: 93, iters: 236, time: 0.168, data: 0.002) G_GAN: 0.617 G_L1: 5.856 D_real: 0.584 D_fake: 1.362 \n",
      "(epoch: 93, iters: 336, time: 0.167, data: 0.001) G_GAN: 0.923 G_L1: 6.662 D_real: 0.255 D_fake: 1.267 \n",
      "End of epoch 93 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 19, time: 0.369, data: 0.001) G_GAN: 1.610 G_L1: 4.974 D_real: 1.234 D_fake: 0.211 \n",
      "(epoch: 94, iters: 119, time: 0.167, data: 0.001) G_GAN: 1.066 G_L1: 7.602 D_real: 0.995 D_fake: 0.179 \n",
      "(epoch: 94, iters: 219, time: 0.167, data: 0.001) G_GAN: 1.157 G_L1: 5.775 D_real: 1.318 D_fake: 0.240 \n",
      "(epoch: 94, iters: 319, time: 0.168, data: 0.001) G_GAN: 1.258 G_L1: 10.424 D_real: 0.482 D_fake: 1.271 \n",
      "End of epoch 94 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 2, time: 0.391, data: 0.002) G_GAN: 1.118 G_L1: 3.936 D_real: 0.637 D_fake: 0.355 \n",
      "(epoch: 95, iters: 102, time: 0.168, data: 0.000) G_GAN: 1.043 G_L1: 5.029 D_real: 0.712 D_fake: 0.232 \n",
      "(epoch: 95, iters: 202, time: 0.167, data: 0.001) G_GAN: 1.189 G_L1: 6.380 D_real: 0.635 D_fake: 0.265 \n",
      "(epoch: 95, iters: 302, time: 0.168, data: 0.001) G_GAN: 1.372 G_L1: 4.815 D_real: 0.588 D_fake: 0.174 \n",
      "(epoch: 95, iters: 402, time: 0.378, data: 0.001) G_GAN: 1.592 G_L1: 4.332 D_real: 0.674 D_fake: 0.280 \n",
      "saving the model at the end of epoch 95, iters 39615\n",
      "End of epoch 95 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 85, time: 0.167, data: 0.001) G_GAN: 0.822 G_L1: 4.465 D_real: 1.099 D_fake: 0.526 \n",
      "(epoch: 96, iters: 185, time: 0.167, data: 0.001) G_GAN: 0.709 G_L1: 3.868 D_real: 0.486 D_fake: 0.771 \n",
      "(epoch: 96, iters: 285, time: 0.167, data: 0.001) G_GAN: 1.182 G_L1: 6.131 D_real: 0.490 D_fake: 0.700 \n",
      "(epoch: 96, iters: 385, time: 0.348, data: 0.001) G_GAN: 0.732 G_L1: 0.063 D_real: 0.596 D_fake: 0.855 \n",
      "saving the latest model (epoch 96, total_iters 40000)\n",
      "End of epoch 96 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 68, time: 0.167, data: 0.001) G_GAN: 1.352 G_L1: 4.604 D_real: 0.281 D_fake: 0.815 \n",
      "(epoch: 97, iters: 168, time: 0.166, data: 0.001) G_GAN: 0.988 G_L1: 4.911 D_real: 0.636 D_fake: 0.436 \n",
      "(epoch: 97, iters: 268, time: 0.167, data: 0.001) G_GAN: 0.921 G_L1: 4.937 D_real: 0.697 D_fake: 0.414 \n",
      "(epoch: 97, iters: 368, time: 0.390, data: 0.001) G_GAN: 0.996 G_L1: 3.996 D_real: 1.220 D_fake: 0.261 \n",
      "End of epoch 97 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 51, time: 0.168, data: 0.002) G_GAN: 1.092 G_L1: 6.307 D_real: 0.466 D_fake: 0.325 \n",
      "(epoch: 98, iters: 151, time: 0.167, data: 0.001) G_GAN: 0.712 G_L1: 0.402 D_real: 0.905 D_fake: 0.526 \n",
      "(epoch: 98, iters: 251, time: 0.166, data: 0.001) G_GAN: 1.088 G_L1: 5.599 D_real: 0.339 D_fake: 0.956 \n",
      "(epoch: 98, iters: 351, time: 0.423, data: 0.001) G_GAN: 0.779 G_L1: 5.947 D_real: 0.730 D_fake: 1.185 \n",
      "End of epoch 98 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 34, time: 0.168, data: 0.001) G_GAN: 0.679 G_L1: 0.988 D_real: 0.478 D_fake: 1.101 \n",
      "(epoch: 99, iters: 134, time: 0.168, data: 0.001) G_GAN: 2.070 G_L1: 7.225 D_real: 1.005 D_fake: 0.108 \n",
      "(epoch: 99, iters: 234, time: 0.168, data: 0.001) G_GAN: 0.757 G_L1: 0.019 D_real: 0.824 D_fake: 0.608 \n",
      "(epoch: 99, iters: 334, time: 0.386, data: 0.001) G_GAN: 0.498 G_L1: 5.455 D_real: 1.353 D_fake: 0.666 \n",
      "End of epoch 99 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 17, time: 0.166, data: 0.001) G_GAN: 1.003 G_L1: 5.278 D_real: 0.366 D_fake: 0.599 \n",
      "(epoch: 100, iters: 117, time: 0.166, data: 0.001) G_GAN: 1.201 G_L1: 9.702 D_real: 0.641 D_fake: 0.267 \n",
      "(epoch: 100, iters: 217, time: 0.170, data: 0.001) G_GAN: 1.157 G_L1: 8.252 D_real: 0.029 D_fake: 1.774 \n",
      "(epoch: 100, iters: 317, time: 0.388, data: 0.002) G_GAN: 1.232 G_L1: 6.251 D_real: 0.303 D_fake: 0.478 \n",
      "(epoch: 100, iters: 417, time: 0.166, data: 0.001) G_GAN: 1.046 G_L1: 6.657 D_real: 0.480 D_fake: 0.503 \n",
      "saving the model at the end of epoch 100, iters 41700\n",
      "End of epoch 100 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.167, data: 0.068) G_GAN: 0.961 G_L1: 3.184 D_real: 0.772 D_fake: 0.435 \n",
      "(epoch: 101, iters: 200, time: 0.167, data: 0.002) G_GAN: 1.573 G_L1: 6.448 D_real: 0.064 D_fake: 1.935 \n",
      "(epoch: 101, iters: 300, time: 0.394, data: 0.001) G_GAN: 1.366 G_L1: 4.350 D_real: 0.205 D_fake: 1.150 \n",
      "(epoch: 101, iters: 400, time: 0.167, data: 0.001) G_GAN: 1.591 G_L1: 6.841 D_real: 0.063 D_fake: 1.334 \n",
      "End of epoch 101 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 83, time: 0.167, data: 0.001) G_GAN: 1.660 G_L1: 4.185 D_real: 0.797 D_fake: 0.156 \n",
      "(epoch: 102, iters: 183, time: 0.168, data: 0.001) G_GAN: 1.610 G_L1: 5.768 D_real: 0.098 D_fake: 0.338 \n",
      "(epoch: 102, iters: 283, time: 0.391, data: 0.001) G_GAN: 1.390 G_L1: 8.846 D_real: 0.226 D_fake: 0.973 \n",
      "(epoch: 102, iters: 383, time: 0.168, data: 0.001) G_GAN: 0.951 G_L1: 6.540 D_real: 0.948 D_fake: 0.924 \n",
      "End of epoch 102 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 66, time: 0.168, data: 0.001) G_GAN: 0.817 G_L1: 4.839 D_real: 0.761 D_fake: 0.900 \n",
      "(epoch: 103, iters: 166, time: 0.168, data: 0.001) G_GAN: 0.838 G_L1: 6.418 D_real: 0.394 D_fake: 1.090 \n",
      "(epoch: 103, iters: 266, time: 0.348, data: 0.001) G_GAN: 1.055 G_L1: 1.151 D_real: 0.532 D_fake: 0.520 \n",
      "(epoch: 103, iters: 366, time: 0.168, data: 0.001) G_GAN: 0.812 G_L1: 3.046 D_real: 0.662 D_fake: 0.787 \n",
      "End of epoch 103 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 49, time: 0.167, data: 0.001) G_GAN: 1.794 G_L1: 7.154 D_real: 0.531 D_fake: 0.132 \n",
      "(epoch: 104, iters: 149, time: 0.167, data: 0.001) G_GAN: 0.698 G_L1: 0.045 D_real: 0.850 D_fake: 0.602 \n",
      "(epoch: 104, iters: 249, time: 0.395, data: 0.001) G_GAN: 1.229 G_L1: 7.392 D_real: 0.377 D_fake: 0.327 \n",
      "(epoch: 104, iters: 349, time: 0.168, data: 0.001) G_GAN: 1.363 G_L1: 6.033 D_real: 0.762 D_fake: 0.160 \n",
      "End of epoch 104 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 32, time: 0.167, data: 0.001) G_GAN: 1.326 G_L1: 8.173 D_real: 0.761 D_fake: 0.252 \n",
      "(epoch: 105, iters: 132, time: 0.168, data: 0.001) G_GAN: 1.235 G_L1: 3.833 D_real: 1.363 D_fake: 0.192 \n",
      "(epoch: 105, iters: 232, time: 0.406, data: 0.001) G_GAN: 1.286 G_L1: 2.249 D_real: 0.468 D_fake: 0.587 \n",
      "(epoch: 105, iters: 332, time: 0.168, data: 0.001) G_GAN: 1.395 G_L1: 5.498 D_real: 0.615 D_fake: 0.295 \n",
      "saving the model at the end of epoch 105, iters 43785\n",
      "End of epoch 105 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 15, time: 0.168, data: 0.001) G_GAN: 1.306 G_L1: 5.948 D_real: 0.522 D_fake: 0.369 \n",
      "(epoch: 106, iters: 115, time: 0.168, data: 0.001) G_GAN: 0.995 G_L1: 4.062 D_real: 1.284 D_fake: 0.476 \n",
      "(epoch: 106, iters: 215, time: 0.414, data: 0.001) G_GAN: 2.050 G_L1: 5.426 D_real: 0.161 D_fake: 1.436 \n",
      "(epoch: 106, iters: 315, time: 0.167, data: 0.001) G_GAN: 0.978 G_L1: 5.722 D_real: 0.482 D_fake: 0.619 \n",
      "(epoch: 106, iters: 415, time: 0.167, data: 0.001) G_GAN: 1.275 G_L1: 6.298 D_real: 1.336 D_fake: 0.213 \n",
      "End of epoch 106 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 98, time: 0.167, data: 0.001) G_GAN: 0.989 G_L1: 7.112 D_real: 0.358 D_fake: 0.697 \n",
      "(epoch: 107, iters: 198, time: 0.409, data: 0.001) G_GAN: 1.188 G_L1: 5.348 D_real: 0.639 D_fake: 0.695 \n",
      "(epoch: 107, iters: 298, time: 0.167, data: 0.001) G_GAN: 1.302 G_L1: 5.018 D_real: 0.221 D_fake: 0.785 \n",
      "(epoch: 107, iters: 398, time: 0.168, data: 0.001) G_GAN: 1.340 G_L1: 6.818 D_real: 0.079 D_fake: 0.907 \n",
      "End of epoch 107 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 81, time: 0.167, data: 0.001) G_GAN: 0.826 G_L1: 4.860 D_real: 1.358 D_fake: 0.349 \n",
      "(epoch: 108, iters: 181, time: 0.405, data: 0.001) G_GAN: 1.094 G_L1: 7.358 D_real: 0.276 D_fake: 0.646 \n",
      "(epoch: 108, iters: 281, time: 0.168, data: 0.001) G_GAN: 0.970 G_L1: 5.278 D_real: 0.406 D_fake: 0.464 \n",
      "(epoch: 108, iters: 381, time: 0.167, data: 0.001) G_GAN: 1.123 G_L1: 5.832 D_real: 0.416 D_fake: 1.142 \n",
      "saving the latest model (epoch 108, total_iters 45000)\n",
      "End of epoch 108 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 64, time: 0.168, data: 0.001) G_GAN: 0.815 G_L1: 7.796 D_real: 0.448 D_fake: 1.393 \n",
      "(epoch: 109, iters: 164, time: 0.384, data: 0.001) G_GAN: 1.205 G_L1: 2.505 D_real: 0.980 D_fake: 0.216 \n",
      "(epoch: 109, iters: 264, time: 0.167, data: 0.001) G_GAN: 0.677 G_L1: 8.920 D_real: 0.481 D_fake: 1.411 \n",
      "(epoch: 109, iters: 364, time: 0.168, data: 0.001) G_GAN: 0.785 G_L1: 4.738 D_real: 0.372 D_fake: 0.940 \n",
      "End of epoch 109 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 47, time: 0.167, data: 0.001) G_GAN: 1.446 G_L1: 5.593 D_real: 1.320 D_fake: 0.118 \n",
      "(epoch: 110, iters: 147, time: 0.405, data: 0.001) G_GAN: 1.225 G_L1: 5.818 D_real: 1.603 D_fake: 0.325 \n",
      "(epoch: 110, iters: 247, time: 0.168, data: 0.001) G_GAN: 0.585 G_L1: 8.749 D_real: 0.083 D_fake: 3.456 \n",
      "(epoch: 110, iters: 347, time: 0.168, data: 0.001) G_GAN: 3.041 G_L1: 7.800 D_real: 0.248 D_fake: 0.040 \n",
      "saving the model at the end of epoch 110, iters 45870\n",
      "End of epoch 110 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 30, time: 0.168, data: 0.001) G_GAN: 0.504 G_L1: 8.990 D_real: 0.085 D_fake: 3.071 \n",
      "(epoch: 111, iters: 130, time: 0.406, data: 0.001) G_GAN: 1.401 G_L1: 5.389 D_real: 0.322 D_fake: 0.544 \n",
      "(epoch: 111, iters: 230, time: 0.167, data: 0.001) G_GAN: 1.030 G_L1: 1.332 D_real: 0.449 D_fake: 0.678 \n",
      "(epoch: 111, iters: 330, time: 0.167, data: 0.001) G_GAN: 0.924 G_L1: 6.595 D_real: 0.897 D_fake: 0.640 \n",
      "End of epoch 111 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 13, time: 0.167, data: 0.001) G_GAN: 1.817 G_L1: 4.158 D_real: 0.337 D_fake: 0.571 \n",
      "(epoch: 112, iters: 113, time: 0.391, data: 0.001) G_GAN: 0.725 G_L1: 1.053 D_real: 0.267 D_fake: 1.041 \n",
      "(epoch: 112, iters: 213, time: 0.168, data: 0.001) G_GAN: 1.416 G_L1: 4.483 D_real: 0.306 D_fake: 0.628 \n",
      "(epoch: 112, iters: 313, time: 0.167, data: 0.001) G_GAN: 2.073 G_L1: 9.200 D_real: 0.219 D_fake: 0.527 \n",
      "(epoch: 112, iters: 413, time: 0.168, data: 0.001) G_GAN: 0.753 G_L1: 3.456 D_real: 0.893 D_fake: 0.772 \n",
      "End of epoch 112 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 96, time: 0.381, data: 0.001) G_GAN: 0.847 G_L1: 3.103 D_real: 0.646 D_fake: 0.379 \n",
      "(epoch: 113, iters: 196, time: 0.167, data: 0.001) G_GAN: 2.166 G_L1: 4.785 D_real: 0.159 D_fake: 0.169 \n",
      "(epoch: 113, iters: 296, time: 0.167, data: 0.001) G_GAN: 1.133 G_L1: 5.175 D_real: 1.115 D_fake: 0.250 \n",
      "(epoch: 113, iters: 396, time: 0.168, data: 0.001) G_GAN: 1.224 G_L1: 10.371 D_real: 0.280 D_fake: 1.185 \n",
      "End of epoch 113 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 79, time: 0.401, data: 0.001) G_GAN: 1.038 G_L1: 7.631 D_real: 0.230 D_fake: 0.901 \n",
      "(epoch: 114, iters: 179, time: 0.168, data: 0.001) G_GAN: 0.793 G_L1: 5.542 D_real: 1.384 D_fake: 0.286 \n",
      "(epoch: 114, iters: 279, time: 0.168, data: 0.001) G_GAN: 0.874 G_L1: 4.406 D_real: 0.948 D_fake: 0.543 \n",
      "(epoch: 114, iters: 379, time: 0.168, data: 0.001) G_GAN: 1.748 G_L1: 4.576 D_real: 0.300 D_fake: 0.241 \n",
      "End of epoch 114 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 62, time: 0.389, data: 0.001) G_GAN: 1.072 G_L1: 6.605 D_real: 0.648 D_fake: 0.526 \n",
      "(epoch: 115, iters: 162, time: 0.168, data: 0.001) G_GAN: 1.977 G_L1: 5.202 D_real: 0.293 D_fake: 0.202 \n",
      "(epoch: 115, iters: 262, time: 0.169, data: 0.001) G_GAN: 1.068 G_L1: 5.777 D_real: 0.803 D_fake: 0.292 \n",
      "(epoch: 115, iters: 362, time: 0.169, data: 0.001) G_GAN: 1.261 G_L1: 5.024 D_real: 0.362 D_fake: 0.481 \n",
      "saving the model at the end of epoch 115, iters 47955\n",
      "End of epoch 115 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 45, time: 0.409, data: 0.001) G_GAN: 0.805 G_L1: 3.627 D_real: 1.842 D_fake: 0.309 \n",
      "(epoch: 116, iters: 145, time: 0.168, data: 0.001) G_GAN: 0.919 G_L1: 6.732 D_real: 0.823 D_fake: 0.562 \n",
      "(epoch: 116, iters: 245, time: 0.167, data: 0.001) G_GAN: 1.170 G_L1: 6.097 D_real: 1.361 D_fake: 0.158 \n",
      "(epoch: 116, iters: 345, time: 0.168, data: 0.001) G_GAN: 0.621 G_L1: 3.899 D_real: 0.873 D_fake: 0.682 \n",
      "End of epoch 116 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 28, time: 0.408, data: 0.001) G_GAN: 0.838 G_L1: 9.051 D_real: 0.199 D_fake: 1.698 \n",
      "(epoch: 117, iters: 128, time: 0.167, data: 0.001) G_GAN: 1.607 G_L1: 3.148 D_real: 0.379 D_fake: 0.684 \n",
      "(epoch: 117, iters: 228, time: 0.168, data: 0.001) G_GAN: 1.736 G_L1: 7.843 D_real: 0.137 D_fake: 0.695 \n",
      "(epoch: 117, iters: 328, time: 0.167, data: 0.001) G_GAN: 1.134 G_L1: 4.971 D_real: 0.631 D_fake: 0.181 \n",
      "End of epoch 117 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 11, time: 0.449, data: 0.001) G_GAN: 1.498 G_L1: 5.123 D_real: 1.220 D_fake: 0.160 \n",
      "(epoch: 118, iters: 111, time: 0.168, data: 0.001) G_GAN: 0.667 G_L1: 0.040 D_real: 1.291 D_fake: 0.349 \n",
      "(epoch: 118, iters: 211, time: 0.168, data: 0.001) G_GAN: 2.336 G_L1: 6.708 D_real: 0.659 D_fake: 0.097 \n",
      "(epoch: 118, iters: 311, time: 0.167, data: 0.001) G_GAN: 1.405 G_L1: 3.798 D_real: 0.567 D_fake: 0.314 \n",
      "(epoch: 118, iters: 411, time: 0.402, data: 0.001) G_GAN: 1.476 G_L1: 5.180 D_real: 0.093 D_fake: 0.660 \n",
      "End of epoch 118 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 94, time: 0.167, data: 0.001) G_GAN: 0.843 G_L1: 3.978 D_real: 1.064 D_fake: 0.479 \n",
      "(epoch: 119, iters: 194, time: 0.167, data: 0.001) G_GAN: 1.133 G_L1: 6.068 D_real: 0.202 D_fake: 0.782 \n",
      "(epoch: 119, iters: 294, time: 0.166, data: 0.001) G_GAN: 1.104 G_L1: 6.793 D_real: 0.551 D_fake: 0.392 \n",
      "(epoch: 119, iters: 394, time: 0.398, data: 0.001) G_GAN: 0.992 G_L1: 2.666 D_real: 1.249 D_fake: 0.252 \n",
      "End of epoch 119 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 77, time: 0.168, data: 0.001) G_GAN: 1.202 G_L1: 6.287 D_real: 0.686 D_fake: 0.545 \n",
      "(epoch: 120, iters: 177, time: 0.168, data: 0.001) G_GAN: 0.906 G_L1: 3.533 D_real: 1.061 D_fake: 0.389 \n",
      "(epoch: 120, iters: 277, time: 0.168, data: 0.001) G_GAN: 1.427 G_L1: 4.751 D_real: 1.535 D_fake: 0.130 \n",
      "(epoch: 120, iters: 377, time: 0.411, data: 0.001) G_GAN: 1.223 G_L1: 6.809 D_real: 0.314 D_fake: 0.585 \n",
      "saving the latest model (epoch 120, total_iters 50000)\n",
      "saving the model at the end of epoch 120, iters 50040\n",
      "End of epoch 120 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 60, time: 0.167, data: 0.001) G_GAN: 0.924 G_L1: 7.635 D_real: 0.010 D_fake: 1.414 \n",
      "(epoch: 121, iters: 160, time: 0.167, data: 0.001) G_GAN: 1.047 G_L1: 7.290 D_real: 0.199 D_fake: 0.524 \n",
      "(epoch: 121, iters: 260, time: 0.168, data: 0.001) G_GAN: 1.603 G_L1: 9.701 D_real: 0.417 D_fake: 0.284 \n",
      "(epoch: 121, iters: 360, time: 0.428, data: 0.001) G_GAN: 1.296 G_L1: 5.484 D_real: 0.451 D_fake: 0.389 \n",
      "End of epoch 121 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 43, time: 0.168, data: 0.001) G_GAN: 0.760 G_L1: 2.401 D_real: 1.159 D_fake: 0.324 \n",
      "(epoch: 122, iters: 143, time: 0.168, data: 0.002) G_GAN: 2.271 G_L1: 6.171 D_real: 0.139 D_fake: 0.135 \n",
      "(epoch: 122, iters: 243, time: 0.168, data: 0.001) G_GAN: 0.876 G_L1: 3.819 D_real: 0.964 D_fake: 0.544 \n",
      "(epoch: 122, iters: 343, time: 0.414, data: 0.001) G_GAN: 1.733 G_L1: 5.199 D_real: 0.219 D_fake: 0.544 \n",
      "End of epoch 122 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 26, time: 0.168, data: 0.001) G_GAN: 1.541 G_L1: 5.436 D_real: 0.089 D_fake: 0.503 \n",
      "(epoch: 123, iters: 126, time: 0.167, data: 0.001) G_GAN: 1.031 G_L1: 4.720 D_real: 1.045 D_fake: 0.286 \n",
      "(epoch: 123, iters: 226, time: 0.168, data: 0.001) G_GAN: 0.760 G_L1: 6.010 D_real: 0.542 D_fake: 0.891 \n",
      "(epoch: 123, iters: 326, time: 0.474, data: 0.001) G_GAN: 1.965 G_L1: 6.229 D_real: 0.060 D_fake: 1.045 \n",
      "End of epoch 123 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 9, time: 0.170, data: 0.001) G_GAN: 1.436 G_L1: 6.908 D_real: 0.492 D_fake: 0.246 \n",
      "(epoch: 124, iters: 109, time: 0.168, data: 0.001) G_GAN: 2.173 G_L1: 6.559 D_real: 0.961 D_fake: 0.090 \n",
      "(epoch: 124, iters: 209, time: 0.167, data: 0.001) G_GAN: 0.931 G_L1: 3.952 D_real: 1.043 D_fake: 0.370 \n",
      "(epoch: 124, iters: 309, time: 0.422, data: 0.001) G_GAN: 0.768 G_L1: 5.624 D_real: 0.643 D_fake: 0.805 \n",
      "(epoch: 124, iters: 409, time: 0.167, data: 0.001) G_GAN: 1.009 G_L1: 6.041 D_real: 0.294 D_fake: 0.738 \n",
      "End of epoch 124 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 92, time: 0.168, data: 0.001) G_GAN: 0.622 G_L1: 4.180 D_real: 0.730 D_fake: 0.892 \n",
      "(epoch: 125, iters: 192, time: 0.168, data: 0.001) G_GAN: 0.979 G_L1: 7.100 D_real: 0.085 D_fake: 0.985 \n",
      "(epoch: 125, iters: 292, time: 0.428, data: 0.001) G_GAN: 1.007 G_L1: 6.309 D_real: 0.569 D_fake: 0.475 \n",
      "(epoch: 125, iters: 392, time: 0.168, data: 0.001) G_GAN: 1.503 G_L1: 5.306 D_real: 0.140 D_fake: 2.099 \n",
      "saving the model at the end of epoch 125, iters 52125\n",
      "End of epoch 125 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 75, time: 0.169, data: 0.001) G_GAN: 0.739 G_L1: 0.036 D_real: 0.789 D_fake: 0.629 \n",
      "(epoch: 126, iters: 175, time: 0.168, data: 0.001) G_GAN: 0.934 G_L1: 5.250 D_real: 0.756 D_fake: 0.298 \n",
      "(epoch: 126, iters: 275, time: 0.418, data: 0.001) G_GAN: 0.875 G_L1: 3.929 D_real: 1.493 D_fake: 0.241 \n",
      "(epoch: 126, iters: 375, time: 0.168, data: 0.001) G_GAN: 1.797 G_L1: 3.466 D_real: 0.311 D_fake: 0.332 \n",
      "End of epoch 126 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 58, time: 0.169, data: 0.001) G_GAN: 1.187 G_L1: 6.759 D_real: 1.667 D_fake: 0.134 \n",
      "(epoch: 127, iters: 158, time: 0.168, data: 0.001) G_GAN: 0.994 G_L1: 5.658 D_real: 0.707 D_fake: 0.495 \n",
      "(epoch: 127, iters: 258, time: 0.406, data: 0.001) G_GAN: 1.626 G_L1: 3.420 D_real: 0.403 D_fake: 0.499 \n",
      "(epoch: 127, iters: 358, time: 0.168, data: 0.001) G_GAN: 0.997 G_L1: 8.333 D_real: 0.230 D_fake: 0.788 \n",
      "End of epoch 127 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 41, time: 0.168, data: 0.001) G_GAN: 1.293 G_L1: 5.193 D_real: 0.354 D_fake: 0.408 \n",
      "(epoch: 128, iters: 141, time: 0.168, data: 0.001) G_GAN: 0.673 G_L1: 6.033 D_real: 0.586 D_fake: 0.894 \n",
      "(epoch: 128, iters: 241, time: 0.435, data: 0.001) G_GAN: 1.233 G_L1: 6.966 D_real: 0.790 D_fake: 0.271 \n",
      "(epoch: 128, iters: 341, time: 0.167, data: 0.001) G_GAN: 0.901 G_L1: 8.302 D_real: 0.971 D_fake: 0.392 \n",
      "End of epoch 128 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 24, time: 0.169, data: 0.001) G_GAN: 0.847 G_L1: 6.596 D_real: 0.450 D_fake: 0.575 \n",
      "(epoch: 129, iters: 124, time: 0.168, data: 0.001) G_GAN: 1.251 G_L1: 5.694 D_real: 0.915 D_fake: 0.296 \n",
      "(epoch: 129, iters: 224, time: 0.461, data: 0.001) G_GAN: 1.314 G_L1: 5.517 D_real: 0.330 D_fake: 0.433 \n",
      "(epoch: 129, iters: 324, time: 0.168, data: 0.001) G_GAN: 1.560 G_L1: 5.573 D_real: 0.727 D_fake: 0.287 \n",
      "End of epoch 129 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 7, time: 0.168, data: 0.001) G_GAN: 0.896 G_L1: 5.813 D_real: 0.553 D_fake: 0.496 \n",
      "(epoch: 130, iters: 107, time: 0.168, data: 0.001) G_GAN: 0.792 G_L1: 1.333 D_real: 1.076 D_fake: 0.301 \n",
      "(epoch: 130, iters: 207, time: 0.427, data: 0.001) G_GAN: 0.850 G_L1: 4.094 D_real: 0.617 D_fake: 0.651 \n",
      "(epoch: 130, iters: 307, time: 0.167, data: 0.001) G_GAN: 1.160 G_L1: 7.553 D_real: 0.185 D_fake: 1.362 \n",
      "(epoch: 130, iters: 407, time: 0.167, data: 0.001) G_GAN: 0.969 G_L1: 4.419 D_real: 0.700 D_fake: 0.487 \n",
      "saving the model at the end of epoch 130, iters 54210\n",
      "End of epoch 130 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 90, time: 0.168, data: 0.001) G_GAN: 1.247 G_L1: 6.073 D_real: 0.333 D_fake: 0.648 \n",
      "(epoch: 131, iters: 190, time: 0.445, data: 0.001) G_GAN: 0.695 G_L1: 5.872 D_real: 1.166 D_fake: 0.514 \n",
      "(epoch: 131, iters: 290, time: 0.168, data: 0.001) G_GAN: 0.774 G_L1: 7.795 D_real: 0.620 D_fake: 0.978 \n",
      "(epoch: 131, iters: 390, time: 0.167, data: 0.001) G_GAN: 1.243 G_L1: 6.069 D_real: 0.368 D_fake: 0.609 \n",
      "End of epoch 131 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 73, time: 0.167, data: 0.001) G_GAN: 0.931 G_L1: 0.027 D_real: 1.266 D_fake: 0.344 \n",
      "(epoch: 132, iters: 173, time: 0.414, data: 0.001) G_GAN: 0.753 G_L1: 2.980 D_real: 1.145 D_fake: 0.502 \n",
      "(epoch: 132, iters: 273, time: 0.168, data: 0.001) G_GAN: 0.997 G_L1: 5.685 D_real: 0.713 D_fake: 0.587 \n",
      "(epoch: 132, iters: 373, time: 0.168, data: 0.002) G_GAN: 0.735 G_L1: 5.500 D_real: 0.466 D_fake: 1.129 \n",
      "saving the latest model (epoch 132, total_iters 55000)\n",
      "End of epoch 132 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 56, time: 0.168, data: 0.001) G_GAN: 1.747 G_L1: 2.745 D_real: 0.261 D_fake: 0.761 \n",
      "(epoch: 133, iters: 156, time: 0.424, data: 0.001) G_GAN: 0.996 G_L1: 4.784 D_real: 1.242 D_fake: 0.251 \n",
      "(epoch: 133, iters: 256, time: 0.168, data: 0.001) G_GAN: 0.784 G_L1: 5.917 D_real: 0.410 D_fake: 0.708 \n",
      "(epoch: 133, iters: 356, time: 0.167, data: 0.001) G_GAN: 0.881 G_L1: 0.027 D_real: 0.620 D_fake: 0.821 \n",
      "End of epoch 133 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 39, time: 0.167, data: 0.001) G_GAN: 0.882 G_L1: 4.937 D_real: 0.901 D_fake: 0.390 \n",
      "(epoch: 134, iters: 139, time: 0.436, data: 0.002) G_GAN: 0.911 G_L1: 8.150 D_real: 0.601 D_fake: 0.728 \n",
      "(epoch: 134, iters: 239, time: 0.168, data: 0.001) G_GAN: 2.487 G_L1: 6.731 D_real: 0.370 D_fake: 0.074 \n",
      "(epoch: 134, iters: 339, time: 0.167, data: 0.001) G_GAN: 1.342 G_L1: 6.226 D_real: 0.113 D_fake: 0.955 \n",
      "End of epoch 134 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 22, time: 0.168, data: 0.001) G_GAN: 0.926 G_L1: 3.113 D_real: 0.474 D_fake: 0.463 \n",
      "(epoch: 135, iters: 122, time: 0.475, data: 0.001) G_GAN: 1.169 G_L1: 4.245 D_real: 1.209 D_fake: 0.302 \n",
      "(epoch: 135, iters: 222, time: 0.167, data: 0.001) G_GAN: 1.232 G_L1: 4.402 D_real: 0.347 D_fake: 0.340 \n",
      "(epoch: 135, iters: 322, time: 0.168, data: 0.001) G_GAN: 1.653 G_L1: 5.431 D_real: 0.728 D_fake: 0.172 \n",
      "saving the model at the end of epoch 135, iters 56295\n",
      "End of epoch 135 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 5, time: 0.168, data: 0.001) G_GAN: 0.959 G_L1: 4.549 D_real: 0.367 D_fake: 0.713 \n",
      "(epoch: 136, iters: 105, time: 0.430, data: 0.002) G_GAN: 0.989 G_L1: 4.175 D_real: 0.415 D_fake: 0.780 \n",
      "(epoch: 136, iters: 205, time: 0.168, data: 0.001) G_GAN: 0.767 G_L1: 2.338 D_real: 1.113 D_fake: 0.223 \n",
      "(epoch: 136, iters: 305, time: 0.167, data: 0.001) G_GAN: 1.062 G_L1: 5.340 D_real: 0.711 D_fake: 0.405 \n",
      "(epoch: 136, iters: 405, time: 0.166, data: 0.001) G_GAN: 1.252 G_L1: 4.406 D_real: 0.193 D_fake: 0.657 \n",
      "End of epoch 136 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 88, time: 0.441, data: 0.001) G_GAN: 1.164 G_L1: 6.461 D_real: 0.888 D_fake: 0.356 \n",
      "(epoch: 137, iters: 188, time: 0.168, data: 0.001) G_GAN: 1.063 G_L1: 8.935 D_real: 0.368 D_fake: 0.658 \n",
      "(epoch: 137, iters: 288, time: 0.168, data: 0.001) G_GAN: 1.449 G_L1: 6.477 D_real: 0.660 D_fake: 0.264 \n",
      "(epoch: 137, iters: 388, time: 0.167, data: 0.001) G_GAN: 0.819 G_L1: 5.926 D_real: 0.472 D_fake: 0.845 \n",
      "End of epoch 137 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 71, time: 0.447, data: 0.001) G_GAN: 1.952 G_L1: 6.335 D_real: 0.465 D_fake: 0.176 \n",
      "(epoch: 138, iters: 171, time: 0.167, data: 0.001) G_GAN: 1.030 G_L1: 6.275 D_real: 0.183 D_fake: 0.863 \n",
      "(epoch: 138, iters: 271, time: 0.168, data: 0.001) G_GAN: 1.021 G_L1: 6.775 D_real: 0.335 D_fake: 0.870 \n",
      "(epoch: 138, iters: 371, time: 0.167, data: 0.001) G_GAN: 0.887 G_L1: 4.747 D_real: 0.762 D_fake: 0.562 \n",
      "End of epoch 138 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 54, time: 0.415, data: 0.001) G_GAN: 0.976 G_L1: 3.049 D_real: 0.811 D_fake: 0.390 \n",
      "(epoch: 139, iters: 154, time: 0.167, data: 0.001) G_GAN: 1.194 G_L1: 5.619 D_real: 1.351 D_fake: 0.188 \n",
      "(epoch: 139, iters: 254, time: 0.167, data: 0.001) G_GAN: 1.418 G_L1: 6.966 D_real: 0.102 D_fake: 0.512 \n",
      "(epoch: 139, iters: 354, time: 0.167, data: 0.001) G_GAN: 0.766 G_L1: 1.480 D_real: 0.557 D_fake: 0.474 \n",
      "End of epoch 139 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 37, time: 0.476, data: 0.001) G_GAN: 1.364 G_L1: 5.234 D_real: 0.855 D_fake: 0.240 \n",
      "(epoch: 140, iters: 137, time: 0.168, data: 0.001) G_GAN: 0.865 G_L1: 7.815 D_real: 0.427 D_fake: 0.634 \n",
      "(epoch: 140, iters: 237, time: 0.167, data: 0.001) G_GAN: 0.912 G_L1: 4.645 D_real: 0.690 D_fake: 0.650 \n",
      "(epoch: 140, iters: 337, time: 0.168, data: 0.001) G_GAN: 1.671 G_L1: 4.094 D_real: 0.124 D_fake: 0.291 \n",
      "saving the model at the end of epoch 140, iters 58380\n",
      "End of epoch 140 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 20, time: 0.428, data: 0.001) G_GAN: 1.661 G_L1: 3.987 D_real: 0.129 D_fake: 1.650 \n",
      "(epoch: 141, iters: 120, time: 0.167, data: 0.001) G_GAN: 1.176 G_L1: 4.951 D_real: 0.618 D_fake: 0.341 \n",
      "(epoch: 141, iters: 220, time: 0.168, data: 0.001) G_GAN: 1.656 G_L1: 1.561 D_real: 0.973 D_fake: 0.505 \n",
      "(epoch: 141, iters: 320, time: 0.168, data: 0.001) G_GAN: 0.920 G_L1: 5.705 D_real: 0.411 D_fake: 0.582 \n",
      "End of epoch 141 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 3, time: 0.459, data: 0.001) G_GAN: 1.224 G_L1: 8.611 D_real: 0.092 D_fake: 0.541 \n",
      "(epoch: 142, iters: 103, time: 0.167, data: 0.000) G_GAN: 1.918 G_L1: 4.719 D_real: 1.278 D_fake: 0.123 \n",
      "(epoch: 142, iters: 203, time: 0.168, data: 0.001) G_GAN: 0.742 G_L1: 6.543 D_real: 0.150 D_fake: 1.237 \n",
      "(epoch: 142, iters: 303, time: 0.167, data: 0.001) G_GAN: 0.752 G_L1: 0.028 D_real: 0.674 D_fake: 0.743 \n",
      "(epoch: 142, iters: 403, time: 0.420, data: 0.001) G_GAN: 1.969 G_L1: 3.809 D_real: 0.099 D_fake: 0.309 \n",
      "End of epoch 142 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 86, time: 0.168, data: 0.001) G_GAN: 0.745 G_L1: 4.717 D_real: 0.561 D_fake: 0.677 \n",
      "(epoch: 143, iters: 186, time: 0.167, data: 0.001) G_GAN: 1.213 G_L1: 3.486 D_real: 0.751 D_fake: 0.516 \n",
      "(epoch: 143, iters: 286, time: 0.167, data: 0.001) G_GAN: 0.838 G_L1: 2.290 D_real: 1.510 D_fake: 0.067 \n",
      "(epoch: 143, iters: 386, time: 0.435, data: 0.001) G_GAN: 1.933 G_L1: 3.925 D_real: 0.447 D_fake: 0.112 \n",
      "End of epoch 143 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 69, time: 0.168, data: 0.001) G_GAN: 0.681 G_L1: 5.725 D_real: 0.476 D_fake: 1.127 \n",
      "(epoch: 144, iters: 169, time: 0.168, data: 0.001) G_GAN: 2.626 G_L1: 5.046 D_real: 0.831 D_fake: 0.062 \n",
      "(epoch: 144, iters: 269, time: 0.168, data: 0.001) G_GAN: 0.740 G_L1: 6.121 D_real: 0.299 D_fake: 0.925 \n",
      "(epoch: 144, iters: 369, time: 0.539, data: 0.001) G_GAN: 2.034 G_L1: 4.088 D_real: 0.448 D_fake: 0.249 \n",
      "saving the latest model (epoch 144, total_iters 60000)\n",
      "End of epoch 144 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 52, time: 0.167, data: 0.001) G_GAN: 1.734 G_L1: 4.443 D_real: 0.650 D_fake: 0.099 \n",
      "(epoch: 145, iters: 152, time: 0.167, data: 0.001) G_GAN: 1.356 G_L1: 5.867 D_real: 1.192 D_fake: 0.173 \n",
      "(epoch: 145, iters: 252, time: 0.168, data: 0.001) G_GAN: 0.952 G_L1: 4.492 D_real: 0.727 D_fake: 0.606 \n",
      "(epoch: 145, iters: 352, time: 0.449, data: 0.001) G_GAN: 1.735 G_L1: 5.987 D_real: 0.908 D_fake: 0.143 \n",
      "saving the model at the end of epoch 145, iters 60465\n",
      "End of epoch 145 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 35, time: 0.168, data: 0.001) G_GAN: 1.220 G_L1: 5.081 D_real: 0.707 D_fake: 0.321 \n",
      "(epoch: 146, iters: 135, time: 0.167, data: 0.001) G_GAN: 1.097 G_L1: 5.050 D_real: 1.361 D_fake: 0.274 \n",
      "(epoch: 146, iters: 235, time: 0.169, data: 0.001) G_GAN: 0.709 G_L1: 4.443 D_real: 0.701 D_fake: 0.812 \n",
      "(epoch: 146, iters: 335, time: 0.445, data: 0.001) G_GAN: 1.576 G_L1: 5.666 D_real: 0.500 D_fake: 0.213 \n",
      "End of epoch 146 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 18, time: 0.168, data: 0.001) G_GAN: 0.938 G_L1: 5.335 D_real: 0.346 D_fake: 0.578 \n",
      "(epoch: 147, iters: 118, time: 0.168, data: 0.001) G_GAN: 1.066 G_L1: 7.563 D_real: 0.522 D_fake: 0.564 \n",
      "(epoch: 147, iters: 218, time: 0.167, data: 0.001) G_GAN: 1.326 G_L1: 5.703 D_real: 0.382 D_fake: 0.892 \n",
      "(epoch: 147, iters: 318, time: 0.456, data: 0.001) G_GAN: 1.149 G_L1: 5.739 D_real: 0.453 D_fake: 0.341 \n",
      "End of epoch 147 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 1, time: 0.102, data: 0.001) G_GAN: 1.021 G_L1: 7.122 D_real: 0.445 D_fake: 0.557 \n",
      "(epoch: 148, iters: 101, time: 0.168, data: 0.000) G_GAN: 1.087 G_L1: 6.373 D_real: 0.503 D_fake: 0.524 \n",
      "(epoch: 148, iters: 201, time: 0.168, data: 0.001) G_GAN: 0.988 G_L1: 5.704 D_real: 0.674 D_fake: 0.553 \n",
      "(epoch: 148, iters: 301, time: 0.469, data: 0.001) G_GAN: 1.135 G_L1: 7.196 D_real: 0.644 D_fake: 0.319 \n",
      "(epoch: 148, iters: 401, time: 0.167, data: 0.001) G_GAN: 1.002 G_L1: 5.080 D_real: 0.252 D_fake: 0.819 \n",
      "End of epoch 148 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 84, time: 0.168, data: 0.001) G_GAN: 1.021 G_L1: 5.312 D_real: 0.582 D_fake: 0.664 \n",
      "(epoch: 149, iters: 184, time: 0.167, data: 0.001) G_GAN: 0.969 G_L1: 3.020 D_real: 1.355 D_fake: 0.372 \n",
      "(epoch: 149, iters: 284, time: 0.514, data: 0.001) G_GAN: 1.067 G_L1: 5.964 D_real: 0.239 D_fake: 0.639 \n",
      "(epoch: 149, iters: 384, time: 0.168, data: 0.001) G_GAN: 1.747 G_L1: 3.572 D_real: 0.682 D_fake: 0.208 \n",
      "End of epoch 149 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 67, time: 0.168, data: 0.001) G_GAN: 2.566 G_L1: 5.277 D_real: 0.197 D_fake: 1.393 \n",
      "(epoch: 150, iters: 167, time: 0.167, data: 0.001) G_GAN: 1.409 G_L1: 4.683 D_real: 0.464 D_fake: 0.270 \n",
      "(epoch: 150, iters: 267, time: 0.450, data: 0.001) G_GAN: 1.214 G_L1: 5.831 D_real: 0.510 D_fake: 0.501 \n",
      "(epoch: 150, iters: 367, time: 0.167, data: 0.001) G_GAN: 1.518 G_L1: 3.642 D_real: 0.230 D_fake: 0.514 \n",
      "saving the model at the end of epoch 150, iters 62550\n",
      "End of epoch 150 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 50, time: 0.168, data: 0.001) G_GAN: 1.598 G_L1: 3.439 D_real: 0.367 D_fake: 0.558 \n",
      "(epoch: 151, iters: 150, time: 0.167, data: 0.001) G_GAN: 1.083 G_L1: 4.683 D_real: 0.834 D_fake: 0.343 \n",
      "(epoch: 151, iters: 250, time: 0.476, data: 0.001) G_GAN: 1.127 G_L1: 6.422 D_real: 0.382 D_fake: 0.700 \n",
      "(epoch: 151, iters: 350, time: 0.168, data: 0.001) G_GAN: 0.617 G_L1: 5.910 D_real: 1.353 D_fake: 0.161 \n",
      "End of epoch 151 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 33, time: 0.167, data: 0.001) G_GAN: 2.363 G_L1: 4.866 D_real: 0.478 D_fake: 0.105 \n",
      "(epoch: 152, iters: 133, time: 0.168, data: 0.001) G_GAN: 1.023 G_L1: 6.744 D_real: 0.376 D_fake: 0.912 \n",
      "(epoch: 152, iters: 233, time: 0.449, data: 0.001) G_GAN: 0.885 G_L1: 6.412 D_real: 0.934 D_fake: 0.532 \n",
      "(epoch: 152, iters: 333, time: 0.168, data: 0.001) G_GAN: 1.491 G_L1: 4.349 D_real: 1.024 D_fake: 0.157 \n",
      "End of epoch 152 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 16, time: 0.168, data: 0.001) G_GAN: 0.817 G_L1: 4.313 D_real: 0.893 D_fake: 0.457 \n",
      "(epoch: 153, iters: 116, time: 0.168, data: 0.001) G_GAN: 0.744 G_L1: 5.113 D_real: 0.345 D_fake: 0.869 \n",
      "(epoch: 153, iters: 216, time: 0.470, data: 0.001) G_GAN: 1.478 G_L1: 4.384 D_real: 0.237 D_fake: 0.276 \n",
      "(epoch: 153, iters: 316, time: 0.168, data: 0.001) G_GAN: 1.501 G_L1: 4.679 D_real: 0.415 D_fake: 0.314 \n",
      "(epoch: 153, iters: 416, time: 0.168, data: 0.001) G_GAN: 0.890 G_L1: 6.262 D_real: 0.353 D_fake: 0.647 \n",
      "End of epoch 153 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 99, time: 0.167, data: 0.001) G_GAN: 0.859 G_L1: 5.429 D_real: 0.813 D_fake: 0.505 \n",
      "(epoch: 154, iters: 199, time: 0.500, data: 0.001) G_GAN: 0.996 G_L1: 5.772 D_real: 0.328 D_fake: 1.044 \n",
      "(epoch: 154, iters: 299, time: 0.167, data: 0.001) G_GAN: 2.322 G_L1: 4.723 D_real: 0.139 D_fake: 0.435 \n",
      "(epoch: 154, iters: 399, time: 0.167, data: 0.001) G_GAN: 0.692 G_L1: 3.918 D_real: 0.575 D_fake: 0.905 \n",
      "End of epoch 154 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 82, time: 0.168, data: 0.001) G_GAN: 1.220 G_L1: 5.917 D_real: 0.292 D_fake: 0.412 \n",
      "(epoch: 155, iters: 182, time: 0.490, data: 0.002) G_GAN: 1.501 G_L1: 7.440 D_real: 0.951 D_fake: 0.816 \n",
      "(epoch: 155, iters: 282, time: 0.167, data: 0.001) G_GAN: 0.750 G_L1: 7.291 D_real: 0.333 D_fake: 1.040 \n",
      "(epoch: 155, iters: 382, time: 0.168, data: 0.001) G_GAN: 0.770 G_L1: 0.024 D_real: 0.843 D_fake: 0.600 \n",
      "saving the model at the end of epoch 155, iters 64635\n",
      "End of epoch 155 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 65, time: 0.168, data: 0.001) G_GAN: 0.737 G_L1: 7.370 D_real: 1.016 D_fake: 0.593 \n",
      "(epoch: 156, iters: 165, time: 0.451, data: 0.001) G_GAN: 1.009 G_L1: 3.715 D_real: 0.473 D_fake: 0.525 \n",
      "(epoch: 156, iters: 265, time: 0.169, data: 0.001) G_GAN: 1.301 G_L1: 5.624 D_real: 0.511 D_fake: 0.361 \n",
      "(epoch: 156, iters: 365, time: 0.168, data: 0.001) G_GAN: 1.408 G_L1: 1.245 D_real: 0.131 D_fake: 0.649 \n",
      "saving the latest model (epoch 156, total_iters 65000)\n",
      "End of epoch 156 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 48, time: 0.168, data: 0.001) G_GAN: 1.336 G_L1: 5.560 D_real: 0.321 D_fake: 0.452 \n",
      "(epoch: 157, iters: 148, time: 0.460, data: 0.001) G_GAN: 0.980 G_L1: 4.389 D_real: 0.575 D_fake: 0.401 \n",
      "(epoch: 157, iters: 248, time: 0.168, data: 0.001) G_GAN: 0.987 G_L1: 5.629 D_real: 0.911 D_fake: 0.466 \n",
      "(epoch: 157, iters: 348, time: 0.168, data: 0.001) G_GAN: 0.752 G_L1: 5.262 D_real: 0.380 D_fake: 1.095 \n",
      "End of epoch 157 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 31, time: 0.168, data: 0.001) G_GAN: 1.022 G_L1: 6.664 D_real: 0.448 D_fake: 0.558 \n",
      "(epoch: 158, iters: 131, time: 0.449, data: 0.001) G_GAN: 0.983 G_L1: 4.148 D_real: 0.669 D_fake: 0.462 \n",
      "(epoch: 158, iters: 231, time: 0.168, data: 0.001) G_GAN: 0.908 G_L1: 3.711 D_real: 0.826 D_fake: 0.490 \n",
      "(epoch: 158, iters: 331, time: 0.168, data: 0.001) G_GAN: 0.924 G_L1: 5.512 D_real: 0.415 D_fake: 0.810 \n",
      "End of epoch 158 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 14, time: 0.167, data: 0.001) G_GAN: 0.805 G_L1: 5.846 D_real: 0.524 D_fake: 0.863 \n",
      "(epoch: 159, iters: 114, time: 0.506, data: 0.001) G_GAN: 1.183 G_L1: 6.250 D_real: 0.330 D_fake: 0.547 \n",
      "(epoch: 159, iters: 214, time: 0.168, data: 0.001) G_GAN: 1.814 G_L1: 5.221 D_real: 0.036 D_fake: 0.448 \n",
      "(epoch: 159, iters: 314, time: 0.169, data: 0.001) G_GAN: 1.127 G_L1: 6.548 D_real: 0.312 D_fake: 0.559 \n",
      "(epoch: 159, iters: 414, time: 0.168, data: 0.001) G_GAN: 0.979 G_L1: 5.490 D_real: 0.049 D_fake: 1.486 \n",
      "End of epoch 159 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 97, time: 0.468, data: 0.001) G_GAN: 0.821 G_L1: 4.191 D_real: 0.694 D_fake: 0.524 \n",
      "(epoch: 160, iters: 197, time: 0.167, data: 0.001) G_GAN: 1.384 G_L1: 5.445 D_real: 0.191 D_fake: 0.383 \n",
      "(epoch: 160, iters: 297, time: 0.167, data: 0.001) G_GAN: 0.644 G_L1: 0.020 D_real: 0.610 D_fake: 0.833 \n",
      "(epoch: 160, iters: 397, time: 0.167, data: 0.001) G_GAN: 1.876 G_L1: 3.902 D_real: 0.373 D_fake: 0.626 \n",
      "saving the model at the end of epoch 160, iters 66720\n",
      "End of epoch 160 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 80, time: 0.491, data: 0.001) G_GAN: 0.898 G_L1: 8.873 D_real: 0.256 D_fake: 0.826 \n",
      "(epoch: 161, iters: 180, time: 0.167, data: 0.001) G_GAN: 1.080 G_L1: 5.939 D_real: 0.165 D_fake: 0.593 \n",
      "(epoch: 161, iters: 280, time: 0.167, data: 0.001) G_GAN: 0.872 G_L1: 2.074 D_real: 1.097 D_fake: 0.338 \n",
      "(epoch: 161, iters: 380, time: 0.167, data: 0.001) G_GAN: 1.282 G_L1: 3.864 D_real: 0.751 D_fake: 0.820 \n",
      "End of epoch 161 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 63, time: 0.482, data: 0.001) G_GAN: 1.287 G_L1: 5.560 D_real: 0.077 D_fake: 0.600 \n",
      "(epoch: 162, iters: 163, time: 0.168, data: 0.001) G_GAN: 0.734 G_L1: 7.311 D_real: 0.902 D_fake: 0.793 \n",
      "(epoch: 162, iters: 263, time: 0.167, data: 0.001) G_GAN: 0.760 G_L1: 4.421 D_real: 0.431 D_fake: 0.975 \n",
      "(epoch: 162, iters: 363, time: 0.167, data: 0.001) G_GAN: 1.122 G_L1: 4.789 D_real: 0.842 D_fake: 0.231 \n",
      "End of epoch 162 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 46, time: 0.491, data: 0.001) G_GAN: 2.213 G_L1: 3.731 D_real: 0.374 D_fake: 0.234 \n",
      "(epoch: 163, iters: 146, time: 0.167, data: 0.001) G_GAN: 1.198 G_L1: 3.876 D_real: 0.809 D_fake: 0.339 \n",
      "(epoch: 163, iters: 246, time: 0.168, data: 0.001) G_GAN: 1.329 G_L1: 7.084 D_real: 0.350 D_fake: 0.417 \n",
      "(epoch: 163, iters: 346, time: 0.168, data: 0.001) G_GAN: 0.948 G_L1: 6.081 D_real: 0.722 D_fake: 0.453 \n",
      "End of epoch 163 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 29, time: 0.499, data: 0.001) G_GAN: 0.917 G_L1: 6.365 D_real: 0.389 D_fake: 1.272 \n",
      "(epoch: 164, iters: 129, time: 0.166, data: 0.001) G_GAN: 1.419 G_L1: 5.625 D_real: 0.792 D_fake: 0.406 \n",
      "(epoch: 164, iters: 229, time: 0.166, data: 0.001) G_GAN: 0.843 G_L1: 4.080 D_real: 0.889 D_fake: 0.598 \n",
      "(epoch: 164, iters: 329, time: 0.168, data: 0.001) G_GAN: 1.689 G_L1: 4.941 D_real: 0.254 D_fake: 0.298 \n",
      "End of epoch 164 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 12, time: 0.480, data: 0.001) G_GAN: 0.717 G_L1: 5.073 D_real: 0.729 D_fake: 0.718 \n",
      "(epoch: 165, iters: 112, time: 0.167, data: 0.001) G_GAN: 1.173 G_L1: 6.043 D_real: 0.206 D_fake: 0.552 \n",
      "(epoch: 165, iters: 212, time: 0.168, data: 0.001) G_GAN: 2.737 G_L1: 4.945 D_real: 0.162 D_fake: 0.660 \n",
      "(epoch: 165, iters: 312, time: 0.167, data: 0.001) G_GAN: 0.950 G_L1: 6.000 D_real: 0.599 D_fake: 0.559 \n",
      "(epoch: 165, iters: 412, time: 0.462, data: 0.001) G_GAN: 2.174 G_L1: 9.485 D_real: 0.033 D_fake: 0.181 \n",
      "saving the model at the end of epoch 165, iters 68805\n",
      "End of epoch 165 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 95, time: 0.168, data: 0.001) G_GAN: 0.725 G_L1: 5.438 D_real: 0.690 D_fake: 0.686 \n",
      "(epoch: 166, iters: 195, time: 0.167, data: 0.001) G_GAN: 1.322 G_L1: 5.280 D_real: 0.027 D_fake: 0.507 \n",
      "(epoch: 166, iters: 295, time: 0.168, data: 0.001) G_GAN: 1.282 G_L1: 4.847 D_real: 0.290 D_fake: 0.639 \n",
      "(epoch: 166, iters: 395, time: 0.478, data: 0.001) G_GAN: 1.156 G_L1: 5.745 D_real: 0.750 D_fake: 0.307 \n",
      "End of epoch 166 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 78, time: 0.168, data: 0.001) G_GAN: 0.841 G_L1: 3.116 D_real: 0.546 D_fake: 0.754 \n",
      "(epoch: 167, iters: 178, time: 0.167, data: 0.001) G_GAN: 0.921 G_L1: 4.926 D_real: 0.154 D_fake: 1.021 \n",
      "(epoch: 167, iters: 278, time: 0.168, data: 0.001) G_GAN: 0.829 G_L1: 2.683 D_real: 0.189 D_fake: 1.418 \n",
      "(epoch: 167, iters: 378, time: 0.507, data: 0.001) G_GAN: 1.812 G_L1: 3.211 D_real: 0.218 D_fake: 0.529 \n",
      "End of epoch 167 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 61, time: 0.168, data: 0.001) G_GAN: 0.772 G_L1: 5.067 D_real: 0.526 D_fake: 0.812 \n",
      "(epoch: 168, iters: 161, time: 0.169, data: 0.001) G_GAN: 1.151 G_L1: 4.897 D_real: 1.042 D_fake: 0.305 \n",
      "(epoch: 168, iters: 261, time: 0.168, data: 0.001) G_GAN: 1.593 G_L1: 3.963 D_real: 0.227 D_fake: 0.277 \n",
      "(epoch: 168, iters: 361, time: 0.475, data: 0.001) G_GAN: 1.300 G_L1: 7.374 D_real: 0.080 D_fake: 0.565 \n",
      "saving the latest model (epoch 168, total_iters 70000)\n",
      "End of epoch 168 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 44, time: 0.166, data: 0.001) G_GAN: 1.368 G_L1: 5.263 D_real: 0.424 D_fake: 0.284 \n",
      "(epoch: 169, iters: 144, time: 0.168, data: 0.001) G_GAN: 1.156 G_L1: 4.076 D_real: 0.389 D_fake: 0.480 \n",
      "(epoch: 169, iters: 244, time: 0.167, data: 0.001) G_GAN: 1.546 G_L1: 4.698 D_real: 0.388 D_fake: 0.265 \n",
      "(epoch: 169, iters: 344, time: 0.456, data: 0.001) G_GAN: 1.502 G_L1: 4.009 D_real: 0.470 D_fake: 0.225 \n",
      "End of epoch 169 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 27, time: 0.168, data: 0.001) G_GAN: 1.077 G_L1: 3.600 D_real: 0.560 D_fake: 0.529 \n",
      "(epoch: 170, iters: 127, time: 0.167, data: 0.001) G_GAN: 0.729 G_L1: 4.368 D_real: 0.574 D_fake: 0.811 \n",
      "(epoch: 170, iters: 227, time: 0.168, data: 0.001) G_GAN: 0.916 G_L1: 6.644 D_real: 0.373 D_fake: 0.689 \n",
      "(epoch: 170, iters: 327, time: 0.475, data: 0.001) G_GAN: 0.992 G_L1: 3.382 D_real: 0.535 D_fake: 0.460 \n",
      "saving the model at the end of epoch 170, iters 70890\n",
      "End of epoch 170 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 10, time: 0.169, data: 0.001) G_GAN: 1.539 G_L1: 4.122 D_real: 0.077 D_fake: 0.326 \n",
      "(epoch: 171, iters: 110, time: 0.168, data: 0.001) G_GAN: 1.062 G_L1: 3.667 D_real: 0.859 D_fake: 0.436 \n",
      "(epoch: 171, iters: 210, time: 0.168, data: 0.001) G_GAN: 0.932 G_L1: 3.873 D_real: 0.446 D_fake: 0.610 \n",
      "(epoch: 171, iters: 310, time: 0.509, data: 0.001) G_GAN: 1.360 G_L1: 3.350 D_real: 0.503 D_fake: 0.440 \n",
      "(epoch: 171, iters: 410, time: 0.167, data: 0.001) G_GAN: 0.821 G_L1: 5.050 D_real: 0.626 D_fake: 0.602 \n",
      "End of epoch 171 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 93, time: 0.167, data: 0.001) G_GAN: 1.210 G_L1: 6.143 D_real: 0.541 D_fake: 0.398 \n",
      "(epoch: 172, iters: 193, time: 0.167, data: 0.001) G_GAN: 0.738 G_L1: 4.207 D_real: 0.981 D_fake: 0.694 \n",
      "(epoch: 172, iters: 293, time: 0.492, data: 0.001) G_GAN: 1.494 G_L1: 7.038 D_real: 0.160 D_fake: 0.397 \n",
      "(epoch: 172, iters: 393, time: 0.167, data: 0.001) G_GAN: 0.749 G_L1: 0.016 D_real: 0.783 D_fake: 0.641 \n",
      "End of epoch 172 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 76, time: 0.168, data: 0.001) G_GAN: 1.016 G_L1: 6.030 D_real: 0.196 D_fake: 0.798 \n",
      "(epoch: 173, iters: 176, time: 0.167, data: 0.001) G_GAN: 0.918 G_L1: 6.080 D_real: 0.432 D_fake: 0.656 \n",
      "(epoch: 173, iters: 276, time: 0.477, data: 0.001) G_GAN: 1.059 G_L1: 2.078 D_real: 0.716 D_fake: 0.467 \n",
      "(epoch: 173, iters: 376, time: 0.168, data: 0.001) G_GAN: 1.228 G_L1: 3.605 D_real: 1.269 D_fake: 0.291 \n",
      "End of epoch 173 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 59, time: 0.168, data: 0.001) G_GAN: 1.156 G_L1: 8.661 D_real: 0.580 D_fake: 0.327 \n",
      "(epoch: 174, iters: 159, time: 0.166, data: 0.001) G_GAN: 1.035 G_L1: 3.782 D_real: 1.467 D_fake: 0.266 \n",
      "(epoch: 174, iters: 259, time: 0.477, data: 0.001) G_GAN: 1.030 G_L1: 3.730 D_real: 0.509 D_fake: 0.714 \n",
      "(epoch: 174, iters: 359, time: 0.167, data: 0.001) G_GAN: 1.369 G_L1: 8.293 D_real: 0.219 D_fake: 0.461 \n",
      "End of epoch 174 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 42, time: 0.168, data: 0.001) G_GAN: 1.369 G_L1: 9.540 D_real: 0.071 D_fake: 0.382 \n",
      "(epoch: 175, iters: 142, time: 0.167, data: 0.001) G_GAN: 0.678 G_L1: 4.117 D_real: 0.525 D_fake: 0.888 \n",
      "(epoch: 175, iters: 242, time: 0.515, data: 0.001) G_GAN: 1.217 G_L1: 5.551 D_real: 0.576 D_fake: 0.292 \n",
      "(epoch: 175, iters: 342, time: 0.167, data: 0.001) G_GAN: 0.914 G_L1: 5.260 D_real: 0.889 D_fake: 0.531 \n",
      "saving the model at the end of epoch 175, iters 72975\n",
      "End of epoch 175 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 25, time: 0.166, data: 0.001) G_GAN: 1.196 G_L1: 5.176 D_real: 0.514 D_fake: 0.355 \n",
      "(epoch: 176, iters: 125, time: 0.168, data: 0.001) G_GAN: 1.264 G_L1: 3.919 D_real: 0.840 D_fake: 0.337 \n",
      "(epoch: 176, iters: 225, time: 0.469, data: 0.001) G_GAN: 1.002 G_L1: 4.567 D_real: 0.766 D_fake: 0.471 \n",
      "(epoch: 176, iters: 325, time: 0.168, data: 0.001) G_GAN: 1.709 G_L1: 5.170 D_real: 0.054 D_fake: 0.271 \n",
      "End of epoch 176 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 8, time: 0.169, data: 0.001) G_GAN: 2.000 G_L1: 2.608 D_real: 0.275 D_fake: 0.373 \n",
      "(epoch: 177, iters: 108, time: 0.168, data: 0.001) G_GAN: 1.000 G_L1: 5.010 D_real: 0.682 D_fake: 0.476 \n",
      "(epoch: 177, iters: 208, time: 0.483, data: 0.001) G_GAN: 0.709 G_L1: 4.265 D_real: 0.538 D_fake: 0.746 \n",
      "(epoch: 177, iters: 308, time: 0.168, data: 0.001) G_GAN: 0.771 G_L1: 5.327 D_real: 0.272 D_fake: 1.342 \n",
      "(epoch: 177, iters: 408, time: 0.168, data: 0.001) G_GAN: 0.835 G_L1: 5.190 D_real: 0.551 D_fake: 0.711 \n",
      "End of epoch 177 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 91, time: 0.168, data: 0.001) G_GAN: 1.034 G_L1: 5.533 D_real: 0.590 D_fake: 0.482 \n",
      "(epoch: 178, iters: 191, time: 0.507, data: 0.001) G_GAN: 1.148 G_L1: 4.810 D_real: 0.442 D_fake: 0.448 \n",
      "(epoch: 178, iters: 291, time: 0.168, data: 0.001) G_GAN: 0.890 G_L1: 2.429 D_real: 0.618 D_fake: 0.545 \n",
      "(epoch: 178, iters: 391, time: 0.168, data: 0.001) G_GAN: 0.858 G_L1: 3.770 D_real: 0.580 D_fake: 0.623 \n",
      "End of epoch 178 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 74, time: 0.168, data: 0.001) G_GAN: 0.858 G_L1: 5.322 D_real: 0.483 D_fake: 0.789 \n",
      "(epoch: 179, iters: 174, time: 0.544, data: 0.001) G_GAN: 1.111 G_L1: 3.875 D_real: 0.801 D_fake: 0.423 \n",
      "(epoch: 179, iters: 274, time: 0.168, data: 0.001) G_GAN: 1.217 G_L1: 5.642 D_real: 0.612 D_fake: 0.357 \n",
      "(epoch: 179, iters: 374, time: 0.168, data: 0.001) G_GAN: 1.207 G_L1: 6.541 D_real: 0.405 D_fake: 0.754 \n",
      "End of epoch 179 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000416\n",
      "(epoch: 180, iters: 57, time: 0.168, data: 0.001) G_GAN: 0.830 G_L1: 5.674 D_real: 0.178 D_fake: 0.758 \n",
      "(epoch: 180, iters: 157, time: 0.525, data: 0.001) G_GAN: 0.771 G_L1: 6.920 D_real: 0.640 D_fake: 0.777 \n",
      "(epoch: 180, iters: 257, time: 0.167, data: 0.001) G_GAN: 1.197 G_L1: 4.070 D_real: 0.747 D_fake: 0.347 \n",
      "(epoch: 180, iters: 357, time: 0.167, data: 0.001) G_GAN: 1.120 G_L1: 6.137 D_real: 0.866 D_fake: 0.395 \n",
      "saving the latest model (epoch 180, total_iters 75000)\n",
      "saving the model at the end of epoch 180, iters 75060\n",
      "End of epoch 180 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 40, time: 0.168, data: 0.001) G_GAN: 1.317 G_L1: 3.769 D_real: 0.284 D_fake: 0.353 \n",
      "(epoch: 181, iters: 140, time: 0.478, data: 0.001) G_GAN: 0.865 G_L1: 3.289 D_real: 1.297 D_fake: 0.820 \n",
      "(epoch: 181, iters: 240, time: 0.168, data: 0.001) G_GAN: 0.906 G_L1: 4.634 D_real: 0.198 D_fake: 0.998 \n",
      "(epoch: 181, iters: 340, time: 0.167, data: 0.001) G_GAN: 1.284 G_L1: 3.485 D_real: 1.320 D_fake: 0.245 \n",
      "End of epoch 181 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 23, time: 0.168, data: 0.001) G_GAN: 0.771 G_L1: 4.090 D_real: 0.848 D_fake: 0.667 \n",
      "(epoch: 182, iters: 123, time: 0.485, data: 0.001) G_GAN: 0.712 G_L1: 4.902 D_real: 0.722 D_fake: 0.695 \n",
      "(epoch: 182, iters: 223, time: 0.168, data: 0.001) G_GAN: 0.451 G_L1: 5.190 D_real: 0.469 D_fake: 1.430 \n",
      "(epoch: 182, iters: 323, time: 0.170, data: 0.001) G_GAN: 0.958 G_L1: 4.304 D_real: 1.053 D_fake: 0.477 \n",
      "End of epoch 182 / 200 \t Time Taken: 46 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 6, time: 0.171, data: 0.001) G_GAN: 1.050 G_L1: 1.212 D_real: 0.652 D_fake: 0.444 \n",
      "(epoch: 183, iters: 106, time: 0.553, data: 0.000) G_GAN: 1.155 G_L1: 5.765 D_real: 0.406 D_fake: 0.458 \n",
      "(epoch: 183, iters: 206, time: 0.172, data: 0.001) G_GAN: 0.657 G_L1: 3.860 D_real: 0.412 D_fake: 0.913 \n",
      "(epoch: 183, iters: 306, time: 0.172, data: 0.001) G_GAN: 1.255 G_L1: 1.320 D_real: 0.588 D_fake: 0.372 \n",
      "(epoch: 183, iters: 406, time: 0.171, data: 0.001) G_GAN: 0.595 G_L1: 3.484 D_real: 0.441 D_fake: 1.027 \n",
      "End of epoch 183 / 200 \t Time Taken: 46 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 89, time: 0.506, data: 0.001) G_GAN: 0.767 G_L1: 4.551 D_real: 0.705 D_fake: 0.653 \n",
      "(epoch: 184, iters: 189, time: 0.190, data: 0.001) G_GAN: 0.724 G_L1: 0.073 D_real: 0.826 D_fake: 0.608 \n",
      "(epoch: 184, iters: 289, time: 0.167, data: 0.001) G_GAN: 1.006 G_L1: 4.492 D_real: 1.042 D_fake: 0.374 \n",
      "(epoch: 184, iters: 389, time: 0.167, data: 0.001) G_GAN: 0.576 G_L1: 6.842 D_real: 0.314 D_fake: 1.118 \n",
      "End of epoch 184 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 72, time: 0.490, data: 0.001) G_GAN: 0.988 G_L1: 3.961 D_real: 0.767 D_fake: 0.495 \n",
      "(epoch: 185, iters: 172, time: 0.167, data: 0.001) G_GAN: 1.415 G_L1: 4.187 D_real: 0.568 D_fake: 0.331 \n",
      "(epoch: 185, iters: 272, time: 0.168, data: 0.001) G_GAN: 0.802 G_L1: 3.059 D_real: 0.458 D_fake: 0.732 \n",
      "(epoch: 185, iters: 372, time: 0.166, data: 0.001) G_GAN: 0.708 G_L1: 0.021 D_real: 0.704 D_fake: 0.699 \n",
      "saving the model at the end of epoch 185, iters 77145\n",
      "End of epoch 185 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 55, time: 0.502, data: 0.001) G_GAN: 1.052 G_L1: 4.353 D_real: 0.644 D_fake: 0.453 \n",
      "(epoch: 186, iters: 155, time: 0.168, data: 0.001) G_GAN: 1.383 G_L1: 6.784 D_real: 0.235 D_fake: 0.345 \n",
      "(epoch: 186, iters: 255, time: 0.166, data: 0.001) G_GAN: 0.858 G_L1: 6.287 D_real: 0.450 D_fake: 0.778 \n",
      "(epoch: 186, iters: 355, time: 0.167, data: 0.001) G_GAN: 0.877 G_L1: 3.103 D_real: 0.774 D_fake: 0.565 \n",
      "End of epoch 186 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 38, time: 0.527, data: 0.001) G_GAN: 1.205 G_L1: 4.534 D_real: 0.803 D_fake: 0.335 \n",
      "(epoch: 187, iters: 138, time: 0.167, data: 0.001) G_GAN: 1.033 G_L1: 5.614 D_real: 0.509 D_fake: 0.499 \n",
      "(epoch: 187, iters: 238, time: 0.167, data: 0.001) G_GAN: 0.695 G_L1: 3.941 D_real: 0.903 D_fake: 0.852 \n",
      "(epoch: 187, iters: 338, time: 0.167, data: 0.001) G_GAN: 1.040 G_L1: 6.460 D_real: 0.451 D_fake: 0.532 \n",
      "End of epoch 187 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 21, time: 0.518, data: 0.001) G_GAN: 0.831 G_L1: 6.254 D_real: 0.687 D_fake: 0.602 \n",
      "(epoch: 188, iters: 121, time: 0.167, data: 0.001) G_GAN: 0.765 G_L1: 3.678 D_real: 0.185 D_fake: 0.858 \n",
      "(epoch: 188, iters: 221, time: 0.166, data: 0.001) G_GAN: 0.986 G_L1: 5.549 D_real: 0.691 D_fake: 0.486 \n",
      "(epoch: 188, iters: 321, time: 0.167, data: 0.001) G_GAN: 1.953 G_L1: 3.487 D_real: 1.545 D_fake: 0.151 \n",
      "End of epoch 188 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 4, time: 0.508, data: 0.001) G_GAN: 0.780 G_L1: 3.280 D_real: 0.903 D_fake: 0.668 \n",
      "(epoch: 189, iters: 104, time: 0.167, data: 0.002) G_GAN: 0.841 G_L1: 3.442 D_real: 0.779 D_fake: 0.662 \n",
      "(epoch: 189, iters: 204, time: 0.167, data: 0.001) G_GAN: 2.290 G_L1: 4.943 D_real: 0.186 D_fake: 0.141 \n",
      "(epoch: 189, iters: 304, time: 0.166, data: 0.001) G_GAN: 1.043 G_L1: 4.740 D_real: 0.411 D_fake: 0.822 \n",
      "(epoch: 189, iters: 404, time: 0.487, data: 0.001) G_GAN: 0.922 G_L1: 4.429 D_real: 0.790 D_fake: 0.511 \n",
      "End of epoch 189 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 87, time: 0.167, data: 0.001) G_GAN: 0.564 G_L1: 3.614 D_real: 0.939 D_fake: 0.982 \n",
      "(epoch: 190, iters: 187, time: 0.167, data: 0.001) G_GAN: 0.842 G_L1: 1.221 D_real: 0.998 D_fake: 0.583 \n",
      "(epoch: 190, iters: 287, time: 0.166, data: 0.001) G_GAN: 1.375 G_L1: 3.812 D_real: 0.520 D_fake: 0.339 \n",
      "(epoch: 190, iters: 387, time: 0.535, data: 0.001) G_GAN: 0.638 G_L1: 6.621 D_real: 0.385 D_fake: 0.905 \n",
      "saving the model at the end of epoch 190, iters 79230\n",
      "End of epoch 190 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 70, time: 0.168, data: 0.001) G_GAN: 1.067 G_L1: 3.936 D_real: 0.671 D_fake: 0.449 \n",
      "(epoch: 191, iters: 170, time: 0.167, data: 0.001) G_GAN: 0.954 G_L1: 5.412 D_real: 0.789 D_fake: 0.582 \n",
      "(epoch: 191, iters: 270, time: 0.168, data: 0.001) G_GAN: 0.816 G_L1: 8.044 D_real: 0.353 D_fake: 0.797 \n",
      "(epoch: 191, iters: 370, time: 0.505, data: 0.001) G_GAN: 1.077 G_L1: 6.893 D_real: 0.643 D_fake: 0.453 \n",
      "End of epoch 191 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 53, time: 0.167, data: 0.001) G_GAN: 0.961 G_L1: 5.503 D_real: 0.433 D_fake: 0.596 \n",
      "(epoch: 192, iters: 153, time: 0.168, data: 0.001) G_GAN: 1.205 G_L1: 5.023 D_real: 0.341 D_fake: 0.423 \n",
      "(epoch: 192, iters: 253, time: 0.167, data: 0.001) G_GAN: 1.022 G_L1: 3.432 D_real: 1.149 D_fake: 0.429 \n",
      "(epoch: 192, iters: 353, time: 0.496, data: 0.001) G_GAN: 1.127 G_L1: 3.029 D_real: 0.912 D_fake: 0.382 \n",
      "saving the latest model (epoch 192, total_iters 80000)\n",
      "End of epoch 192 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 36, time: 0.167, data: 0.001) G_GAN: 0.698 G_L1: 4.206 D_real: 0.701 D_fake: 0.806 \n",
      "(epoch: 193, iters: 136, time: 0.168, data: 0.001) G_GAN: 1.200 G_L1: 4.226 D_real: 0.784 D_fake: 0.372 \n",
      "(epoch: 193, iters: 236, time: 0.167, data: 0.001) G_GAN: 0.836 G_L1: 5.091 D_real: 0.806 D_fake: 0.598 \n",
      "(epoch: 193, iters: 336, time: 0.510, data: 0.001) G_GAN: 1.325 G_L1: 4.984 D_real: 0.215 D_fake: 0.360 \n",
      "End of epoch 193 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 19, time: 0.166, data: 0.001) G_GAN: 0.977 G_L1: 5.703 D_real: 0.568 D_fake: 0.518 \n",
      "(epoch: 194, iters: 119, time: 0.168, data: 0.001) G_GAN: 0.845 G_L1: 6.059 D_real: 0.471 D_fake: 0.659 \n",
      "(epoch: 194, iters: 219, time: 0.167, data: 0.001) G_GAN: 0.787 G_L1: 3.727 D_real: 0.704 D_fake: 0.653 \n",
      "(epoch: 194, iters: 319, time: 0.545, data: 0.001) G_GAN: 0.985 G_L1: 5.174 D_real: 0.464 D_fake: 0.534 \n",
      "End of epoch 194 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 2, time: 0.165, data: 0.001) G_GAN: 0.844 G_L1: 3.775 D_real: 0.843 D_fake: 0.595 \n",
      "(epoch: 195, iters: 102, time: 0.166, data: 0.000) G_GAN: 0.949 G_L1: 5.804 D_real: 0.232 D_fake: 0.574 \n",
      "(epoch: 195, iters: 202, time: 0.166, data: 0.001) G_GAN: 1.277 G_L1: 7.349 D_real: 0.388 D_fake: 0.354 \n",
      "(epoch: 195, iters: 302, time: 0.509, data: 0.001) G_GAN: 1.268 G_L1: 3.698 D_real: 0.350 D_fake: 0.394 \n",
      "(epoch: 195, iters: 402, time: 0.166, data: 0.001) G_GAN: 0.713 G_L1: 5.314 D_real: 0.506 D_fake: 0.765 \n",
      "saving the model at the end of epoch 195, iters 81315\n",
      "End of epoch 195 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 85, time: 0.165, data: 0.001) G_GAN: 0.680 G_L1: 1.617 D_real: 0.363 D_fake: 0.785 \n",
      "(epoch: 196, iters: 185, time: 0.167, data: 0.001) G_GAN: 0.767 G_L1: 0.042 D_real: 0.775 D_fake: 0.634 \n",
      "(epoch: 196, iters: 285, time: 0.494, data: 0.001) G_GAN: 0.761 G_L1: 3.985 D_real: 0.518 D_fake: 0.687 \n",
      "(epoch: 196, iters: 385, time: 0.166, data: 0.001) G_GAN: 1.045 G_L1: 4.575 D_real: 1.303 D_fake: 0.463 \n",
      "End of epoch 196 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 68, time: 0.166, data: 0.001) G_GAN: 1.245 G_L1: 3.764 D_real: 0.884 D_fake: 0.363 \n",
      "(epoch: 197, iters: 168, time: 0.167, data: 0.001) G_GAN: 0.986 G_L1: 4.960 D_real: 0.663 D_fake: 0.505 \n",
      "(epoch: 197, iters: 268, time: 0.521, data: 0.001) G_GAN: 0.914 G_L1: 5.452 D_real: 0.551 D_fake: 0.573 \n",
      "(epoch: 197, iters: 368, time: 0.167, data: 0.001) G_GAN: 0.631 G_L1: 3.901 D_real: 0.490 D_fake: 0.856 \n",
      "End of epoch 197 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 51, time: 0.167, data: 0.001) G_GAN: 0.922 G_L1: 3.715 D_real: 1.076 D_fake: 0.550 \n",
      "(epoch: 198, iters: 151, time: 0.167, data: 0.001) G_GAN: 0.511 G_L1: 4.597 D_real: 0.555 D_fake: 1.007 \n",
      "(epoch: 198, iters: 251, time: 0.561, data: 0.001) G_GAN: 0.916 G_L1: 4.922 D_real: 0.474 D_fake: 0.565 \n",
      "(epoch: 198, iters: 351, time: 0.167, data: 0.001) G_GAN: 1.104 G_L1: 5.043 D_real: 0.964 D_fake: 0.448 \n",
      "End of epoch 198 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 34, time: 0.167, data: 0.001) G_GAN: 0.917 G_L1: 3.172 D_real: 0.709 D_fake: 0.546 \n",
      "(epoch: 199, iters: 134, time: 0.166, data: 0.001) G_GAN: 0.667 G_L1: 4.432 D_real: 0.589 D_fake: 0.773 \n",
      "(epoch: 199, iters: 234, time: 0.498, data: 0.001) G_GAN: 0.662 G_L1: 0.924 D_real: 0.441 D_fake: 0.775 \n",
      "(epoch: 199, iters: 334, time: 0.166, data: 0.001) G_GAN: 0.722 G_L1: 2.685 D_real: 0.502 D_fake: 0.725 \n",
      "End of epoch 199 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 17, time: 0.168, data: 0.001) G_GAN: 0.615 G_L1: 6.349 D_real: 0.467 D_fake: 0.854 \n",
      "(epoch: 200, iters: 117, time: 0.167, data: 0.001) G_GAN: 1.378 G_L1: 6.441 D_real: 0.370 D_fake: 0.321 \n",
      "(epoch: 200, iters: 217, time: 0.509, data: 0.001) G_GAN: 0.705 G_L1: 6.948 D_real: 0.544 D_fake: 0.775 \n",
      "(epoch: 200, iters: 317, time: 0.167, data: 0.001) G_GAN: 0.629 G_L1: 6.817 D_real: 0.816 D_fake: 0.824 \n",
      "(epoch: 200, iters: 417, time: 0.166, data: 0.001) G_GAN: 1.015 G_L1: 4.756 D_real: 0.577 D_fake: 0.470 \n",
      "saving the model at the end of epoch 200, iters 83400\n",
      "End of epoch 200 / 200 \t Time Taken: 45 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot extracolor/AB --model pix2pix --crop_size 256 --no_dropout --output_nc 1 --norm batch --checkpoints_dir apr25 --netG resnet_9blocks --preprocess resize_and_crop --name apr19256rea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: apr25                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 128                           \t[default: 256]\n",
      "                 dataroot: extracolor/AB                 \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: apr19256_REAL                 \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: crop                          \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 417\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "[Network D] Total number of parameters : 2.767 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory apr25/apr19256_REAL/web...\n",
      "(epoch: 1, iters: 100, time: 0.086, data: 0.098) G_GAN: 1.328 G_L1: 5.766 D_real: 0.376 D_fake: 0.319 \n",
      "(epoch: 1, iters: 200, time: 0.055, data: 0.001) G_GAN: 0.903 G_L1: 10.471 D_real: 0.556 D_fake: 0.876 \n",
      "(epoch: 1, iters: 300, time: 0.056, data: 0.001) G_GAN: 1.878 G_L1: 14.111 D_real: 0.107 D_fake: 0.218 \n",
      "(epoch: 1, iters: 400, time: 0.083, data: 0.001) G_GAN: 1.445 G_L1: 14.510 D_real: 0.062 D_fake: 0.901 \n",
      "End of epoch 1 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 83, time: 0.056, data: 0.001) G_GAN: 1.364 G_L1: 15.530 D_real: 0.025 D_fake: 0.426 \n",
      "(epoch: 2, iters: 183, time: 0.056, data: 0.001) G_GAN: 1.531 G_L1: 8.070 D_real: 0.093 D_fake: 0.369 \n",
      "(epoch: 2, iters: 283, time: 0.055, data: 0.001) G_GAN: 2.000 G_L1: 19.001 D_real: 0.494 D_fake: 0.149 \n",
      "(epoch: 2, iters: 383, time: 0.083, data: 0.001) G_GAN: 1.048 G_L1: 10.247 D_real: 0.257 D_fake: 0.582 \n",
      "End of epoch 2 / 200 \t Time Taken: 15 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 66, time: 0.059, data: 0.001) G_GAN: 0.744 G_L1: 10.224 D_real: 0.356 D_fake: 1.029 \n",
      "(epoch: 3, iters: 166, time: 0.057, data: 0.001) G_GAN: 1.169 G_L1: 9.443 D_real: 0.662 D_fake: 0.254 \n",
      "(epoch: 3, iters: 266, time: 0.059, data: 0.001) G_GAN: 0.843 G_L1: 13.071 D_real: 0.282 D_fake: 0.729 \n",
      "(epoch: 3, iters: 366, time: 0.096, data: 0.001) G_GAN: 1.206 G_L1: 15.108 D_real: 1.595 D_fake: 0.220 \n",
      "End of epoch 3 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 49, time: 0.058, data: 0.001) G_GAN: 1.387 G_L1: 17.947 D_real: 0.023 D_fake: 0.350 \n",
      "(epoch: 4, iters: 149, time: 0.056, data: 0.001) G_GAN: 1.484 G_L1: 12.064 D_real: 0.063 D_fake: 0.304 \n",
      "(epoch: 4, iters: 249, time: 0.057, data: 0.001) G_GAN: 0.582 G_L1: 9.087 D_real: 1.302 D_fake: 1.317 \n",
      "(epoch: 4, iters: 349, time: 0.081, data: 0.001) G_GAN: 1.758 G_L1: 16.037 D_real: 0.036 D_fake: 0.890 \n",
      "End of epoch 4 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 32, time: 0.057, data: 0.001) G_GAN: 1.350 G_L1: 17.653 D_real: 0.011 D_fake: 0.304 \n",
      "(epoch: 5, iters: 132, time: 0.056, data: 0.001) G_GAN: 1.104 G_L1: 11.442 D_real: 0.272 D_fake: 0.483 \n",
      "(epoch: 5, iters: 232, time: 0.057, data: 0.001) G_GAN: 0.964 G_L1: 9.492 D_real: 0.450 D_fake: 0.521 \n",
      "(epoch: 5, iters: 332, time: 0.114, data: 0.001) G_GAN: 0.725 G_L1: 8.777 D_real: 0.724 D_fake: 1.028 \n",
      "saving the model at the end of epoch 5, iters 2085\n",
      "End of epoch 5 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 15, time: 0.058, data: 0.001) G_GAN: 1.159 G_L1: 15.083 D_real: 0.023 D_fake: 0.563 \n",
      "(epoch: 6, iters: 115, time: 0.057, data: 0.001) G_GAN: 1.276 G_L1: 13.854 D_real: 0.218 D_fake: 0.533 \n",
      "(epoch: 6, iters: 215, time: 0.066, data: 0.001) G_GAN: 2.040 G_L1: 26.136 D_real: 0.016 D_fake: 0.242 \n",
      "(epoch: 6, iters: 315, time: 0.108, data: 0.001) G_GAN: 1.124 G_L1: 12.189 D_real: 0.211 D_fake: 1.329 \n",
      "(epoch: 6, iters: 415, time: 0.059, data: 0.001) G_GAN: 0.910 G_L1: 12.997 D_real: 0.044 D_fake: 1.038 \n",
      "End of epoch 6 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 98, time: 0.057, data: 0.001) G_GAN: 1.379 G_L1: 5.193 D_real: 0.457 D_fake: 0.260 \n",
      "(epoch: 7, iters: 198, time: 0.058, data: 0.001) G_GAN: 0.961 G_L1: 15.310 D_real: 0.255 D_fake: 0.784 \n",
      "(epoch: 7, iters: 298, time: 0.087, data: 0.001) G_GAN: 0.946 G_L1: 12.784 D_real: 0.295 D_fake: 0.573 \n",
      "(epoch: 7, iters: 398, time: 0.058, data: 0.001) G_GAN: 1.246 G_L1: 7.511 D_real: 0.719 D_fake: 0.356 \n",
      "End of epoch 7 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 81, time: 0.057, data: 0.001) G_GAN: 0.820 G_L1: 9.598 D_real: 1.399 D_fake: 0.305 \n",
      "(epoch: 8, iters: 181, time: 0.057, data: 0.001) G_GAN: 1.496 G_L1: 8.090 D_real: 0.331 D_fake: 0.234 \n",
      "(epoch: 8, iters: 281, time: 0.087, data: 0.001) G_GAN: 1.158 G_L1: 1.504 D_real: 1.450 D_fake: 0.345 \n",
      "(epoch: 8, iters: 381, time: 0.057, data: 0.001) G_GAN: 0.913 G_L1: 0.833 D_real: 1.137 D_fake: 0.390 \n",
      "End of epoch 8 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 64, time: 0.058, data: 0.001) G_GAN: 1.032 G_L1: 2.594 D_real: 0.747 D_fake: 0.420 \n",
      "(epoch: 9, iters: 164, time: 0.058, data: 0.001) G_GAN: 0.671 G_L1: 11.485 D_real: 0.796 D_fake: 1.214 \n",
      "(epoch: 9, iters: 264, time: 0.086, data: 0.001) G_GAN: 0.438 G_L1: 5.732 D_real: 1.273 D_fake: 0.249 \n",
      "(epoch: 9, iters: 364, time: 0.058, data: 0.001) G_GAN: 1.771 G_L1: 8.108 D_real: 0.046 D_fake: 0.227 \n",
      "End of epoch 9 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 47, time: 0.057, data: 0.001) G_GAN: 1.609 G_L1: 11.150 D_real: 0.230 D_fake: 0.246 \n",
      "(epoch: 10, iters: 147, time: 0.058, data: 0.001) G_GAN: 1.174 G_L1: 11.252 D_real: 0.005 D_fake: 0.716 \n",
      "(epoch: 10, iters: 247, time: 0.084, data: 0.001) G_GAN: 0.819 G_L1: 0.696 D_real: 0.820 D_fake: 0.594 \n",
      "(epoch: 10, iters: 347, time: 0.059, data: 0.001) G_GAN: 1.224 G_L1: 2.101 D_real: 1.210 D_fake: 0.317 \n",
      "saving the model at the end of epoch 10, iters 4170\n",
      "End of epoch 10 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 30, time: 0.058, data: 0.001) G_GAN: 1.438 G_L1: 9.902 D_real: 0.016 D_fake: 0.489 \n",
      "(epoch: 11, iters: 130, time: 0.057, data: 0.001) G_GAN: 0.999 G_L1: 11.329 D_real: 0.967 D_fake: 0.232 \n",
      "(epoch: 11, iters: 230, time: 0.090, data: 0.001) G_GAN: 1.933 G_L1: 9.082 D_real: 0.098 D_fake: 0.170 \n",
      "(epoch: 11, iters: 330, time: 0.058, data: 0.001) G_GAN: 0.853 G_L1: 7.741 D_real: 0.323 D_fake: 0.597 \n",
      "End of epoch 11 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 13, time: 0.058, data: 0.001) G_GAN: 1.796 G_L1: 8.471 D_real: 0.165 D_fake: 0.164 \n",
      "(epoch: 12, iters: 113, time: 0.058, data: 0.001) G_GAN: 1.085 G_L1: 0.521 D_real: 1.408 D_fake: 0.295 \n",
      "(epoch: 12, iters: 213, time: 0.089, data: 0.001) G_GAN: 1.084 G_L1: 6.907 D_real: 0.168 D_fake: 0.500 \n",
      "(epoch: 12, iters: 313, time: 0.058, data: 0.001) G_GAN: 1.704 G_L1: 10.613 D_real: 0.014 D_fake: 0.688 \n",
      "(epoch: 12, iters: 413, time: 0.058, data: 0.001) G_GAN: 1.243 G_L1: 11.647 D_real: 0.238 D_fake: 0.358 \n",
      "saving the latest model (epoch 12, total_iters 5000)\n",
      "End of epoch 12 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 96, time: 0.058, data: 0.001) G_GAN: 1.418 G_L1: 6.639 D_real: 0.021 D_fake: 0.444 \n",
      "(epoch: 13, iters: 196, time: 0.087, data: 0.001) G_GAN: 2.178 G_L1: 11.931 D_real: 0.021 D_fake: 0.155 \n",
      "(epoch: 13, iters: 296, time: 0.058, data: 0.001) G_GAN: 0.869 G_L1: 7.205 D_real: 0.466 D_fake: 0.382 \n",
      "(epoch: 13, iters: 396, time: 0.058, data: 0.001) G_GAN: 1.056 G_L1: 2.762 D_real: 0.817 D_fake: 0.403 \n",
      "End of epoch 13 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 79, time: 0.057, data: 0.001) G_GAN: 1.035 G_L1: 8.633 D_real: 1.010 D_fake: 0.328 \n",
      "(epoch: 14, iters: 179, time: 0.091, data: 0.001) G_GAN: 1.584 G_L1: 12.836 D_real: 0.018 D_fake: 0.661 \n",
      "(epoch: 14, iters: 279, time: 0.058, data: 0.001) G_GAN: 1.454 G_L1: 7.729 D_real: 2.234 D_fake: 0.116 \n",
      "(epoch: 14, iters: 379, time: 0.057, data: 0.001) G_GAN: 1.290 G_L1: 6.986 D_real: 1.507 D_fake: 0.163 \n",
      "End of epoch 14 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 62, time: 0.058, data: 0.001) G_GAN: 0.804 G_L1: 0.405 D_real: 0.955 D_fake: 0.490 \n",
      "(epoch: 15, iters: 162, time: 0.090, data: 0.001) G_GAN: 1.851 G_L1: 16.313 D_real: 0.067 D_fake: 0.264 \n",
      "(epoch: 15, iters: 262, time: 0.057, data: 0.001) G_GAN: 1.946 G_L1: 18.727 D_real: 0.027 D_fake: 0.240 \n",
      "(epoch: 15, iters: 362, time: 0.058, data: 0.001) G_GAN: 0.992 G_L1: 5.351 D_real: 0.546 D_fake: 0.423 \n",
      "saving the model at the end of epoch 15, iters 6255\n",
      "End of epoch 15 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 45, time: 0.057, data: 0.001) G_GAN: 1.512 G_L1: 12.813 D_real: 0.039 D_fake: 0.455 \n",
      "(epoch: 16, iters: 145, time: 0.088, data: 0.001) G_GAN: 0.746 G_L1: 0.237 D_real: 0.858 D_fake: 0.557 \n",
      "(epoch: 16, iters: 245, time: 0.057, data: 0.001) G_GAN: 0.573 G_L1: 3.031 D_real: 0.507 D_fake: 0.989 \n",
      "(epoch: 16, iters: 345, time: 0.058, data: 0.001) G_GAN: 1.193 G_L1: 14.336 D_real: 0.438 D_fake: 0.480 \n",
      "End of epoch 16 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 28, time: 0.057, data: 0.001) G_GAN: 1.176 G_L1: 18.250 D_real: 0.292 D_fake: 0.329 \n",
      "(epoch: 17, iters: 128, time: 0.093, data: 0.001) G_GAN: 1.493 G_L1: 15.765 D_real: 1.641 D_fake: 0.176 \n",
      "(epoch: 17, iters: 228, time: 0.058, data: 0.001) G_GAN: 1.280 G_L1: 18.546 D_real: 0.199 D_fake: 0.489 \n",
      "(epoch: 17, iters: 328, time: 0.058, data: 0.001) G_GAN: 1.004 G_L1: 8.647 D_real: 0.178 D_fake: 1.206 \n",
      "End of epoch 17 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 11, time: 0.058, data: 0.001) G_GAN: 1.089 G_L1: 7.649 D_real: 0.411 D_fake: 0.332 \n",
      "(epoch: 18, iters: 111, time: 0.095, data: 0.001) G_GAN: 0.967 G_L1: 8.152 D_real: 0.228 D_fake: 0.576 \n",
      "(epoch: 18, iters: 211, time: 0.058, data: 0.001) G_GAN: 1.468 G_L1: 16.628 D_real: 0.121 D_fake: 0.813 \n",
      "(epoch: 18, iters: 311, time: 0.058, data: 0.001) G_GAN: 1.475 G_L1: 18.082 D_real: 0.005 D_fake: 0.401 \n",
      "(epoch: 18, iters: 411, time: 0.058, data: 0.001) G_GAN: 0.757 G_L1: 13.900 D_real: 0.802 D_fake: 0.363 \n",
      "End of epoch 18 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 94, time: 0.089, data: 0.001) G_GAN: 0.782 G_L1: 0.200 D_real: 0.732 D_fake: 0.662 \n",
      "(epoch: 19, iters: 194, time: 0.058, data: 0.001) G_GAN: 1.768 G_L1: 10.821 D_real: 0.271 D_fake: 0.203 \n",
      "(epoch: 19, iters: 294, time: 0.057, data: 0.001) G_GAN: 0.899 G_L1: 3.200 D_real: 0.742 D_fake: 0.540 \n",
      "(epoch: 19, iters: 394, time: 0.058, data: 0.001) G_GAN: 1.630 G_L1: 5.375 D_real: 2.366 D_fake: 0.128 \n",
      "End of epoch 19 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 77, time: 0.098, data: 0.001) G_GAN: 1.039 G_L1: 5.881 D_real: 0.239 D_fake: 1.260 \n",
      "(epoch: 20, iters: 177, time: 0.058, data: 0.001) G_GAN: 0.729 G_L1: 0.173 D_real: 0.742 D_fake: 0.660 \n",
      "(epoch: 20, iters: 277, time: 0.058, data: 0.001) G_GAN: 0.947 G_L1: 6.339 D_real: 0.801 D_fake: 0.480 \n",
      "(epoch: 20, iters: 377, time: 0.058, data: 0.001) G_GAN: 0.904 G_L1: 1.733 D_real: 1.164 D_fake: 0.378 \n",
      "saving the model at the end of epoch 20, iters 8340\n",
      "End of epoch 20 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 60, time: 0.096, data: 0.001) G_GAN: 1.369 G_L1: 14.983 D_real: 0.521 D_fake: 0.243 \n",
      "(epoch: 21, iters: 160, time: 0.059, data: 0.001) G_GAN: 0.986 G_L1: 5.751 D_real: 0.280 D_fake: 0.616 \n",
      "(epoch: 21, iters: 260, time: 0.058, data: 0.001) G_GAN: 1.756 G_L1: 9.541 D_real: 0.060 D_fake: 0.509 \n",
      "(epoch: 21, iters: 360, time: 0.058, data: 0.001) G_GAN: 1.333 G_L1: 9.394 D_real: 0.458 D_fake: 0.362 \n",
      "End of epoch 21 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 43, time: 0.099, data: 0.001) G_GAN: 1.801 G_L1: 13.319 D_real: 0.089 D_fake: 0.215 \n",
      "(epoch: 22, iters: 143, time: 0.058, data: 0.001) G_GAN: 1.251 G_L1: 20.918 D_real: 0.230 D_fake: 0.464 \n",
      "(epoch: 22, iters: 243, time: 0.058, data: 0.001) G_GAN: 1.490 G_L1: 17.790 D_real: 0.308 D_fake: 0.245 \n",
      "(epoch: 22, iters: 343, time: 0.057, data: 0.001) G_GAN: 1.468 G_L1: 16.249 D_real: 0.129 D_fake: 0.293 \n",
      "End of epoch 22 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 26, time: 0.098, data: 0.001) G_GAN: 0.818 G_L1: 7.041 D_real: 0.378 D_fake: 0.478 \n",
      "(epoch: 23, iters: 126, time: 0.058, data: 0.001) G_GAN: 0.715 G_L1: 7.375 D_real: 0.156 D_fake: 0.982 \n",
      "(epoch: 23, iters: 226, time: 0.058, data: 0.001) G_GAN: 1.123 G_L1: 9.100 D_real: 1.463 D_fake: 0.149 \n",
      "(epoch: 23, iters: 326, time: 0.058, data: 0.001) G_GAN: 0.869 G_L1: 0.830 D_real: 0.688 D_fake: 0.566 \n",
      "End of epoch 23 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 9, time: 0.095, data: 0.001) G_GAN: 0.970 G_L1: 4.385 D_real: 0.281 D_fake: 0.630 \n",
      "(epoch: 24, iters: 109, time: 0.058, data: 0.001) G_GAN: 0.757 G_L1: 10.515 D_real: 0.163 D_fake: 1.212 \n",
      "(epoch: 24, iters: 209, time: 0.057, data: 0.001) G_GAN: 1.046 G_L1: 8.283 D_real: 0.211 D_fake: 1.378 \n",
      "(epoch: 24, iters: 309, time: 0.058, data: 0.001) G_GAN: 1.782 G_L1: 4.198 D_real: 0.152 D_fake: 0.218 \n",
      "(epoch: 24, iters: 409, time: 0.093, data: 0.001) G_GAN: 1.000 G_L1: 10.280 D_real: 0.845 D_fake: 0.422 \n",
      "saving the latest model (epoch 24, total_iters 10000)\n",
      "End of epoch 24 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 92, time: 0.057, data: 0.001) G_GAN: 1.167 G_L1: 10.548 D_real: 1.387 D_fake: 0.452 \n",
      "(epoch: 25, iters: 192, time: 0.058, data: 0.001) G_GAN: 0.979 G_L1: 19.617 D_real: 0.015 D_fake: 1.126 \n",
      "(epoch: 25, iters: 292, time: 0.058, data: 0.001) G_GAN: 0.795 G_L1: 11.554 D_real: 0.624 D_fake: 0.697 \n",
      "(epoch: 25, iters: 392, time: 0.092, data: 0.001) G_GAN: 0.778 G_L1: 0.182 D_real: 0.834 D_fake: 0.575 \n",
      "saving the model at the end of epoch 25, iters 10425\n",
      "End of epoch 25 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 75, time: 0.058, data: 0.001) G_GAN: 2.220 G_L1: 11.903 D_real: 0.054 D_fake: 0.174 \n",
      "(epoch: 26, iters: 175, time: 0.058, data: 0.001) G_GAN: 0.952 G_L1: 6.198 D_real: 0.168 D_fake: 1.246 \n",
      "(epoch: 26, iters: 275, time: 0.057, data: 0.001) G_GAN: 1.162 G_L1: 12.238 D_real: 1.510 D_fake: 0.213 \n",
      "(epoch: 26, iters: 375, time: 0.097, data: 0.001) G_GAN: 1.383 G_L1: 14.087 D_real: 0.641 D_fake: 0.277 \n",
      "End of epoch 26 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 58, time: 0.057, data: 0.001) G_GAN: 0.898 G_L1: 10.670 D_real: 1.121 D_fake: 0.427 \n",
      "(epoch: 27, iters: 158, time: 0.058, data: 0.001) G_GAN: 1.775 G_L1: 12.930 D_real: 0.174 D_fake: 0.168 \n",
      "(epoch: 27, iters: 258, time: 0.057, data: 0.001) G_GAN: 1.212 G_L1: 8.209 D_real: 0.702 D_fake: 0.325 \n",
      "(epoch: 27, iters: 358, time: 0.100, data: 0.001) G_GAN: 1.650 G_L1: 8.560 D_real: 0.147 D_fake: 0.258 \n",
      "End of epoch 27 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 41, time: 0.057, data: 0.001) G_GAN: 0.688 G_L1: 1.267 D_real: 0.745 D_fake: 0.688 \n",
      "(epoch: 28, iters: 141, time: 0.058, data: 0.001) G_GAN: 1.559 G_L1: 10.759 D_real: 0.515 D_fake: 0.163 \n",
      "(epoch: 28, iters: 241, time: 0.058, data: 0.001) G_GAN: 0.859 G_L1: 2.890 D_real: 0.742 D_fake: 0.588 \n",
      "(epoch: 28, iters: 341, time: 0.102, data: 0.001) G_GAN: 1.843 G_L1: 6.720 D_real: 2.873 D_fake: 0.061 \n",
      "End of epoch 28 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 24, time: 0.062, data: 0.001) G_GAN: 1.045 G_L1: 8.607 D_real: 0.036 D_fake: 1.583 \n",
      "(epoch: 29, iters: 124, time: 0.058, data: 0.001) G_GAN: 1.364 G_L1: 8.379 D_real: 0.815 D_fake: 0.240 \n",
      "(epoch: 29, iters: 224, time: 0.058, data: 0.001) G_GAN: 1.933 G_L1: 8.109 D_real: 0.051 D_fake: 0.168 \n",
      "(epoch: 29, iters: 324, time: 0.105, data: 0.001) G_GAN: 1.170 G_L1: 8.373 D_real: 0.962 D_fake: 0.111 \n",
      "End of epoch 29 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 7, time: 0.057, data: 0.001) G_GAN: 1.440 G_L1: 24.093 D_real: 0.012 D_fake: 0.323 \n",
      "(epoch: 30, iters: 107, time: 0.057, data: 0.000) G_GAN: 0.937 G_L1: 6.686 D_real: 0.789 D_fake: 0.437 \n",
      "(epoch: 30, iters: 207, time: 0.058, data: 0.001) G_GAN: 0.777 G_L1: 9.687 D_real: 0.035 D_fake: 1.771 \n",
      "(epoch: 30, iters: 307, time: 0.102, data: 0.001) G_GAN: 1.842 G_L1: 12.064 D_real: 0.740 D_fake: 0.073 \n",
      "(epoch: 30, iters: 407, time: 0.059, data: 0.001) G_GAN: 1.199 G_L1: 5.999 D_real: 0.188 D_fake: 0.399 \n",
      "saving the model at the end of epoch 30, iters 12510\n",
      "End of epoch 30 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 90, time: 0.057, data: 0.001) G_GAN: 1.587 G_L1: 12.515 D_real: 0.592 D_fake: 0.064 \n",
      "(epoch: 31, iters: 190, time: 0.058, data: 0.001) G_GAN: 2.730 G_L1: 10.201 D_real: 0.228 D_fake: 0.064 \n",
      "(epoch: 31, iters: 290, time: 0.106, data: 0.001) G_GAN: 1.234 G_L1: 8.869 D_real: 0.530 D_fake: 0.422 \n",
      "(epoch: 31, iters: 390, time: 0.058, data: 0.001) G_GAN: 1.545 G_L1: 15.472 D_real: 0.020 D_fake: 0.928 \n",
      "End of epoch 31 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 73, time: 0.059, data: 0.001) G_GAN: 1.029 G_L1: 9.982 D_real: 0.116 D_fake: 0.942 \n",
      "(epoch: 32, iters: 173, time: 0.058, data: 0.001) G_GAN: 2.310 G_L1: 4.402 D_real: 0.570 D_fake: 0.071 \n",
      "(epoch: 32, iters: 273, time: 0.105, data: 0.001) G_GAN: 0.923 G_L1: 13.854 D_real: 0.397 D_fake: 0.678 \n",
      "(epoch: 32, iters: 373, time: 0.058, data: 0.001) G_GAN: 1.587 G_L1: 1.693 D_real: 1.884 D_fake: 0.125 \n",
      "End of epoch 32 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 56, time: 0.058, data: 0.001) G_GAN: 1.168 G_L1: 3.269 D_real: 0.706 D_fake: 0.329 \n",
      "(epoch: 33, iters: 156, time: 0.058, data: 0.001) G_GAN: 0.557 G_L1: 0.097 D_real: 0.574 D_fake: 0.846 \n",
      "(epoch: 33, iters: 256, time: 0.109, data: 0.001) G_GAN: 0.920 G_L1: 8.183 D_real: 0.527 D_fake: 0.697 \n",
      "(epoch: 33, iters: 356, time: 0.058, data: 0.001) G_GAN: 2.042 G_L1: 25.553 D_real: 0.023 D_fake: 0.257 \n",
      "End of epoch 33 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 39, time: 0.058, data: 0.001) G_GAN: 1.394 G_L1: 5.767 D_real: 0.584 D_fake: 0.254 \n",
      "(epoch: 34, iters: 139, time: 0.058, data: 0.001) G_GAN: 1.382 G_L1: 7.036 D_real: 0.484 D_fake: 0.180 \n",
      "(epoch: 34, iters: 239, time: 0.104, data: 0.001) G_GAN: 1.203 G_L1: 6.250 D_real: 0.730 D_fake: 0.246 \n",
      "(epoch: 34, iters: 339, time: 0.057, data: 0.001) G_GAN: 0.931 G_L1: 0.530 D_real: 1.149 D_fake: 0.390 \n",
      "End of epoch 34 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 22, time: 0.059, data: 0.001) G_GAN: 0.983 G_L1: 3.048 D_real: 1.220 D_fake: 0.289 \n",
      "(epoch: 35, iters: 122, time: 0.058, data: 0.001) G_GAN: 1.032 G_L1: 5.845 D_real: 0.492 D_fake: 0.767 \n",
      "(epoch: 35, iters: 222, time: 0.107, data: 0.001) G_GAN: 1.997 G_L1: 10.331 D_real: 0.140 D_fake: 0.230 \n",
      "(epoch: 35, iters: 322, time: 0.059, data: 0.001) G_GAN: 1.637 G_L1: 7.599 D_real: 0.820 D_fake: 0.283 \n",
      "saving the model at the end of epoch 35, iters 14595\n",
      "End of epoch 35 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 5, time: 0.056, data: 0.001) G_GAN: 1.941 G_L1: 7.545 D_real: 0.119 D_fake: 0.219 \n",
      "(epoch: 36, iters: 105, time: 0.058, data: 0.000) G_GAN: 1.470 G_L1: 11.459 D_real: 0.416 D_fake: 0.170 \n",
      "(epoch: 36, iters: 205, time: 0.108, data: 0.001) G_GAN: 1.280 G_L1: 9.235 D_real: 0.102 D_fake: 0.392 \n",
      "(epoch: 36, iters: 305, time: 0.058, data: 0.001) G_GAN: 2.692 G_L1: 15.579 D_real: 0.140 D_fake: 0.094 \n",
      "(epoch: 36, iters: 405, time: 0.058, data: 0.001) G_GAN: 0.571 G_L1: 6.979 D_real: 0.397 D_fake: 0.938 \n",
      "saving the latest model (epoch 36, total_iters 15000)\n",
      "End of epoch 36 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 88, time: 0.059, data: 0.001) G_GAN: 2.834 G_L1: 16.496 D_real: 0.043 D_fake: 0.063 \n",
      "(epoch: 37, iters: 188, time: 0.137, data: 0.001) G_GAN: 1.792 G_L1: 9.237 D_real: 0.126 D_fake: 1.605 \n",
      "(epoch: 37, iters: 288, time: 0.058, data: 0.001) G_GAN: 1.332 G_L1: 4.971 D_real: 1.991 D_fake: 0.154 \n",
      "(epoch: 37, iters: 388, time: 0.058, data: 0.001) G_GAN: 0.836 G_L1: 0.364 D_real: 1.428 D_fake: 0.287 \n",
      "End of epoch 37 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 71, time: 0.057, data: 0.001) G_GAN: 2.758 G_L1: 27.035 D_real: 0.019 D_fake: 0.768 \n",
      "(epoch: 38, iters: 171, time: 0.109, data: 0.001) G_GAN: 1.841 G_L1: 9.336 D_real: 0.304 D_fake: 0.123 \n",
      "(epoch: 38, iters: 271, time: 0.059, data: 0.001) G_GAN: 0.642 G_L1: 0.383 D_real: 0.977 D_fake: 0.476 \n",
      "(epoch: 38, iters: 371, time: 0.059, data: 0.001) G_GAN: 1.237 G_L1: 6.413 D_real: 0.592 D_fake: 0.301 \n",
      "End of epoch 38 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 54, time: 0.057, data: 0.001) G_GAN: 2.126 G_L1: 18.034 D_real: 0.001 D_fake: 0.346 \n",
      "(epoch: 39, iters: 154, time: 0.109, data: 0.001) G_GAN: 1.934 G_L1: 10.580 D_real: 0.527 D_fake: 0.115 \n",
      "(epoch: 39, iters: 254, time: 0.057, data: 0.001) G_GAN: 1.324 G_L1: 5.800 D_real: 0.391 D_fake: 0.399 \n",
      "(epoch: 39, iters: 354, time: 0.058, data: 0.001) G_GAN: 1.371 G_L1: 7.315 D_real: 0.210 D_fake: 0.213 \n",
      "End of epoch 39 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 37, time: 0.058, data: 0.001) G_GAN: 1.368 G_L1: 9.054 D_real: 0.580 D_fake: 0.198 \n",
      "(epoch: 40, iters: 137, time: 0.110, data: 0.001) G_GAN: 1.884 G_L1: 10.742 D_real: 0.471 D_fake: 0.097 \n",
      "(epoch: 40, iters: 237, time: 0.058, data: 0.001) G_GAN: 2.351 G_L1: 17.363 D_real: 0.007 D_fake: 0.168 \n",
      "(epoch: 40, iters: 337, time: 0.058, data: 0.001) G_GAN: 1.206 G_L1: 10.840 D_real: 1.942 D_fake: 0.231 \n",
      "saving the model at the end of epoch 40, iters 16680\n",
      "End of epoch 40 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 20, time: 0.058, data: 0.001) G_GAN: 1.114 G_L1: 1.964 D_real: 1.510 D_fake: 0.357 \n",
      "(epoch: 41, iters: 120, time: 0.107, data: 0.001) G_GAN: 1.099 G_L1: 10.097 D_real: 0.648 D_fake: 0.286 \n",
      "(epoch: 41, iters: 220, time: 0.058, data: 0.001) G_GAN: 1.257 G_L1: 6.839 D_real: 0.307 D_fake: 0.465 \n",
      "(epoch: 41, iters: 320, time: 0.058, data: 0.001) G_GAN: 1.925 G_L1: 13.970 D_real: 0.109 D_fake: 0.175 \n",
      "End of epoch 41 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 3, time: 0.055, data: 0.001) G_GAN: 1.063 G_L1: 5.882 D_real: 0.505 D_fake: 0.214 \n",
      "(epoch: 42, iters: 103, time: 0.116, data: 0.000) G_GAN: 2.585 G_L1: 13.913 D_real: 0.016 D_fake: 0.136 \n",
      "(epoch: 42, iters: 203, time: 0.058, data: 0.001) G_GAN: 2.850 G_L1: 11.093 D_real: 0.049 D_fake: 0.061 \n",
      "(epoch: 42, iters: 303, time: 0.059, data: 0.001) G_GAN: 1.439 G_L1: 7.799 D_real: 0.295 D_fake: 0.527 \n",
      "(epoch: 42, iters: 403, time: 0.058, data: 0.001) G_GAN: 2.166 G_L1: 10.706 D_real: 0.374 D_fake: 0.095 \n",
      "End of epoch 42 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 86, time: 0.102, data: 0.001) G_GAN: 0.766 G_L1: 0.649 D_real: 0.802 D_fake: 0.540 \n",
      "(epoch: 43, iters: 186, time: 0.058, data: 0.001) G_GAN: 1.000 G_L1: 10.383 D_real: 0.509 D_fake: 0.550 \n",
      "(epoch: 43, iters: 286, time: 0.058, data: 0.001) G_GAN: 2.311 G_L1: 7.729 D_real: 0.096 D_fake: 0.230 \n",
      "(epoch: 43, iters: 386, time: 0.058, data: 0.001) G_GAN: 1.618 G_L1: 8.291 D_real: 0.244 D_fake: 0.304 \n",
      "End of epoch 43 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 69, time: 0.104, data: 0.001) G_GAN: 0.668 G_L1: 0.497 D_real: 0.572 D_fake: 0.849 \n",
      "(epoch: 44, iters: 169, time: 0.058, data: 0.001) G_GAN: 1.252 G_L1: 6.416 D_real: 0.267 D_fake: 0.478 \n",
      "(epoch: 44, iters: 269, time: 0.059, data: 0.001) G_GAN: 1.108 G_L1: 7.075 D_real: 0.487 D_fake: 0.852 \n",
      "(epoch: 44, iters: 369, time: 0.058, data: 0.001) G_GAN: 1.084 G_L1: 5.593 D_real: 0.062 D_fake: 1.751 \n",
      "End of epoch 44 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 52, time: 0.113, data: 0.001) G_GAN: 1.923 G_L1: 10.091 D_real: 0.014 D_fake: 1.095 \n",
      "(epoch: 45, iters: 152, time: 0.058, data: 0.001) G_GAN: 2.337 G_L1: 8.195 D_real: 0.040 D_fake: 0.119 \n",
      "(epoch: 45, iters: 252, time: 0.058, data: 0.001) G_GAN: 1.452 G_L1: 3.935 D_real: 0.265 D_fake: 0.298 \n",
      "(epoch: 45, iters: 352, time: 0.058, data: 0.001) G_GAN: 1.182 G_L1: 8.122 D_real: 0.635 D_fake: 0.254 \n",
      "saving the model at the end of epoch 45, iters 18765\n",
      "End of epoch 45 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 35, time: 0.113, data: 0.001) G_GAN: 0.144 G_L1: 8.294 D_real: 1.651 D_fake: 0.386 \n",
      "(epoch: 46, iters: 135, time: 0.058, data: 0.001) G_GAN: 1.772 G_L1: 12.046 D_real: 0.014 D_fake: 0.411 \n",
      "(epoch: 46, iters: 235, time: 0.058, data: 0.001) G_GAN: 1.722 G_L1: 9.256 D_real: 0.560 D_fake: 0.126 \n",
      "(epoch: 46, iters: 335, time: 0.058, data: 0.001) G_GAN: 2.927 G_L1: 11.038 D_real: 0.292 D_fake: 0.043 \n",
      "End of epoch 46 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 18, time: 0.114, data: 0.001) G_GAN: 1.315 G_L1: 10.978 D_real: 0.405 D_fake: 0.444 \n",
      "(epoch: 47, iters: 118, time: 0.058, data: 0.001) G_GAN: 1.750 G_L1: 6.899 D_real: 0.781 D_fake: 0.138 \n",
      "(epoch: 47, iters: 218, time: 0.058, data: 0.001) G_GAN: 1.601 G_L1: 11.690 D_real: 0.446 D_fake: 0.392 \n",
      "(epoch: 47, iters: 318, time: 0.057, data: 0.001) G_GAN: 1.780 G_L1: 16.971 D_real: 0.124 D_fake: 0.369 \n",
      "End of epoch 47 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 1, time: 0.092, data: 0.001) G_GAN: 3.978 G_L1: 15.569 D_real: 0.143 D_fake: 0.014 \n",
      "(epoch: 48, iters: 101, time: 0.058, data: 0.002) G_GAN: 1.390 G_L1: 15.167 D_real: 0.362 D_fake: 0.416 \n",
      "(epoch: 48, iters: 201, time: 0.058, data: 0.001) G_GAN: 1.291 G_L1: 7.322 D_real: 0.375 D_fake: 0.922 \n",
      "(epoch: 48, iters: 301, time: 0.058, data: 0.001) G_GAN: 1.057 G_L1: 0.370 D_real: 1.085 D_fake: 0.420 \n",
      "(epoch: 48, iters: 401, time: 0.110, data: 0.001) G_GAN: 0.810 G_L1: 15.489 D_real: 0.184 D_fake: 0.945 \n",
      "saving the latest model (epoch 48, total_iters 20000)\n",
      "End of epoch 48 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 84, time: 0.058, data: 0.001) G_GAN: 0.843 G_L1: 10.196 D_real: 1.201 D_fake: 0.284 \n",
      "(epoch: 49, iters: 184, time: 0.058, data: 0.001) G_GAN: 1.190 G_L1: 7.645 D_real: 0.080 D_fake: 0.428 \n",
      "(epoch: 49, iters: 284, time: 0.058, data: 0.001) G_GAN: 2.578 G_L1: 11.132 D_real: 0.803 D_fake: 0.013 \n",
      "(epoch: 49, iters: 384, time: 0.116, data: 0.001) G_GAN: 1.298 G_L1: 10.450 D_real: 0.784 D_fake: 0.278 \n",
      "End of epoch 49 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 67, time: 0.057, data: 0.001) G_GAN: 1.051 G_L1: 8.524 D_real: 0.739 D_fake: 0.611 \n",
      "(epoch: 50, iters: 167, time: 0.058, data: 0.001) G_GAN: 2.549 G_L1: 14.933 D_real: 0.009 D_fake: 0.098 \n",
      "(epoch: 50, iters: 267, time: 0.059, data: 0.001) G_GAN: 2.061 G_L1: 8.853 D_real: 0.066 D_fake: 0.252 \n",
      "(epoch: 50, iters: 367, time: 0.116, data: 0.001) G_GAN: 1.371 G_L1: 8.392 D_real: 0.080 D_fake: 0.552 \n",
      "saving the model at the end of epoch 50, iters 20850\n",
      "End of epoch 50 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 50, time: 0.059, data: 0.001) G_GAN: 1.310 G_L1: 6.380 D_real: 0.200 D_fake: 0.730 \n",
      "(epoch: 51, iters: 150, time: 0.058, data: 0.001) G_GAN: 1.466 G_L1: 9.302 D_real: 0.127 D_fake: 0.293 \n",
      "(epoch: 51, iters: 250, time: 0.059, data: 0.001) G_GAN: 1.341 G_L1: 9.746 D_real: 0.953 D_fake: 0.132 \n",
      "(epoch: 51, iters: 350, time: 0.110, data: 0.001) G_GAN: 0.892 G_L1: 0.570 D_real: 1.230 D_fake: 0.355 \n",
      "End of epoch 51 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 33, time: 0.057, data: 0.001) G_GAN: 0.979 G_L1: 3.590 D_real: 1.374 D_fake: 0.294 \n",
      "(epoch: 52, iters: 133, time: 0.058, data: 0.001) G_GAN: 0.799 G_L1: 3.820 D_real: 0.846 D_fake: 0.439 \n",
      "(epoch: 52, iters: 233, time: 0.058, data: 0.001) G_GAN: 1.597 G_L1: 5.330 D_real: 0.219 D_fake: 0.276 \n",
      "(epoch: 52, iters: 333, time: 0.151, data: 0.001) G_GAN: 2.731 G_L1: 10.759 D_real: 0.089 D_fake: 0.693 \n",
      "End of epoch 52 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 16, time: 0.058, data: 0.001) G_GAN: 2.430 G_L1: 14.927 D_real: 0.004 D_fake: 0.298 \n",
      "(epoch: 53, iters: 116, time: 0.059, data: 0.001) G_GAN: 1.322 G_L1: 6.283 D_real: 0.829 D_fake: 0.109 \n",
      "(epoch: 53, iters: 216, time: 0.058, data: 0.001) G_GAN: 1.680 G_L1: 8.284 D_real: 0.057 D_fake: 0.539 \n",
      "(epoch: 53, iters: 316, time: 0.116, data: 0.001) G_GAN: 2.281 G_L1: 7.776 D_real: 0.076 D_fake: 0.116 \n",
      "(epoch: 53, iters: 416, time: 0.058, data: 0.001) G_GAN: 2.384 G_L1: 11.615 D_real: 0.029 D_fake: 0.270 \n",
      "End of epoch 53 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 99, time: 0.059, data: 0.001) G_GAN: 0.695 G_L1: 3.448 D_real: 1.622 D_fake: 0.178 \n",
      "(epoch: 54, iters: 199, time: 0.059, data: 0.001) G_GAN: 1.035 G_L1: 7.663 D_real: 0.464 D_fake: 0.215 \n",
      "(epoch: 54, iters: 299, time: 0.117, data: 0.001) G_GAN: 1.607 G_L1: 6.962 D_real: 0.259 D_fake: 0.252 \n",
      "(epoch: 54, iters: 399, time: 0.058, data: 0.001) G_GAN: 2.060 G_L1: 18.622 D_real: 0.007 D_fake: 0.535 \n",
      "End of epoch 54 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 82, time: 0.059, data: 0.001) G_GAN: 2.168 G_L1: 14.947 D_real: 0.081 D_fake: 0.626 \n",
      "(epoch: 55, iters: 182, time: 0.059, data: 0.001) G_GAN: 4.508 G_L1: 13.042 D_real: 0.150 D_fake: 0.013 \n",
      "(epoch: 55, iters: 282, time: 0.115, data: 0.001) G_GAN: 1.724 G_L1: 7.019 D_real: 0.471 D_fake: 0.140 \n",
      "(epoch: 55, iters: 382, time: 0.058, data: 0.001) G_GAN: 1.459 G_L1: 5.023 D_real: 0.327 D_fake: 0.305 \n",
      "saving the model at the end of epoch 55, iters 22935\n",
      "End of epoch 55 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 65, time: 0.058, data: 0.001) G_GAN: 1.188 G_L1: 10.483 D_real: 1.241 D_fake: 0.113 \n",
      "(epoch: 56, iters: 165, time: 0.058, data: 0.001) G_GAN: 0.670 G_L1: 0.817 D_real: 0.750 D_fake: 0.658 \n",
      "(epoch: 56, iters: 265, time: 0.117, data: 0.001) G_GAN: 1.929 G_L1: 12.908 D_real: 0.007 D_fake: 0.281 \n",
      "(epoch: 56, iters: 365, time: 0.058, data: 0.001) G_GAN: 2.966 G_L1: 16.002 D_real: 0.392 D_fake: 0.030 \n",
      "End of epoch 56 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 48, time: 0.059, data: 0.001) G_GAN: 2.086 G_L1: 14.605 D_real: 0.024 D_fake: 0.114 \n",
      "(epoch: 57, iters: 148, time: 0.058, data: 0.001) G_GAN: 1.207 G_L1: 7.348 D_real: 0.501 D_fake: 0.219 \n",
      "(epoch: 57, iters: 248, time: 0.118, data: 0.001) G_GAN: 2.053 G_L1: 9.922 D_real: 0.090 D_fake: 0.203 \n",
      "(epoch: 57, iters: 348, time: 0.059, data: 0.001) G_GAN: 3.328 G_L1: 10.792 D_real: 0.050 D_fake: 0.059 \n",
      "End of epoch 57 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 31, time: 0.058, data: 0.001) G_GAN: 0.804 G_L1: 4.285 D_real: 0.466 D_fake: 1.592 \n",
      "(epoch: 58, iters: 131, time: 0.058, data: 0.001) G_GAN: 1.775 G_L1: 6.111 D_real: 0.270 D_fake: 0.195 \n",
      "(epoch: 58, iters: 231, time: 0.114, data: 0.001) G_GAN: 0.736 G_L1: 0.666 D_real: 0.938 D_fake: 0.518 \n",
      "(epoch: 58, iters: 331, time: 0.058, data: 0.001) G_GAN: 0.638 G_L1: 0.115 D_real: 0.598 D_fake: 0.861 \n",
      "End of epoch 58 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 14, time: 0.058, data: 0.001) G_GAN: 2.899 G_L1: 8.304 D_real: 0.285 D_fake: 0.054 \n",
      "(epoch: 59, iters: 114, time: 0.057, data: 0.001) G_GAN: 1.833 G_L1: 5.661 D_real: 0.312 D_fake: 0.176 \n",
      "(epoch: 59, iters: 214, time: 0.116, data: 0.001) G_GAN: 4.258 G_L1: 4.232 D_real: 0.124 D_fake: 0.013 \n",
      "(epoch: 59, iters: 314, time: 0.059, data: 0.001) G_GAN: 1.041 G_L1: 0.450 D_real: 1.303 D_fake: 0.323 \n",
      "(epoch: 59, iters: 414, time: 0.059, data: 0.001) G_GAN: 1.710 G_L1: 7.819 D_real: 0.072 D_fake: 0.295 \n",
      "End of epoch 59 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 97, time: 0.058, data: 0.001) G_GAN: 4.583 G_L1: 18.059 D_real: 0.014 D_fake: 0.012 \n",
      "(epoch: 60, iters: 197, time: 0.121, data: 0.001) G_GAN: 0.875 G_L1: 2.409 D_real: 0.342 D_fake: 0.600 \n",
      "(epoch: 60, iters: 297, time: 0.058, data: 0.001) G_GAN: 4.056 G_L1: 5.750 D_real: 1.183 D_fake: 0.006 \n",
      "(epoch: 60, iters: 397, time: 0.058, data: 0.001) G_GAN: 1.457 G_L1: 5.753 D_real: 1.125 D_fake: 0.235 \n",
      "saving the latest model (epoch 60, total_iters 25000)\n",
      "saving the model at the end of epoch 60, iters 25020\n",
      "End of epoch 60 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 80, time: 0.059, data: 0.001) G_GAN: 1.870 G_L1: 9.866 D_real: 1.070 D_fake: 0.104 \n",
      "(epoch: 61, iters: 180, time: 0.121, data: 0.001) G_GAN: 1.654 G_L1: 2.825 D_real: 1.789 D_fake: 0.073 \n",
      "(epoch: 61, iters: 280, time: 0.059, data: 0.001) G_GAN: 1.420 G_L1: 2.995 D_real: 0.368 D_fake: 0.288 \n",
      "(epoch: 61, iters: 380, time: 0.058, data: 0.001) G_GAN: 6.913 G_L1: 13.109 D_real: 0.086 D_fake: 0.001 \n",
      "End of epoch 61 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 63, time: 0.058, data: 0.001) G_GAN: 1.650 G_L1: 8.892 D_real: 1.030 D_fake: 0.154 \n",
      "(epoch: 62, iters: 163, time: 0.118, data: 0.001) G_GAN: 2.063 G_L1: 4.994 D_real: 0.258 D_fake: 0.190 \n",
      "(epoch: 62, iters: 263, time: 0.058, data: 0.001) G_GAN: 2.386 G_L1: 5.100 D_real: 0.332 D_fake: 0.076 \n",
      "(epoch: 62, iters: 363, time: 0.058, data: 0.001) G_GAN: 5.564 G_L1: 8.707 D_real: 0.299 D_fake: 0.003 \n",
      "End of epoch 62 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 46, time: 0.058, data: 0.001) G_GAN: 3.960 G_L1: 5.977 D_real: 0.121 D_fake: 0.013 \n",
      "(epoch: 63, iters: 146, time: 0.124, data: 0.001) G_GAN: 0.752 G_L1: 4.968 D_real: 0.084 D_fake: 1.748 \n",
      "(epoch: 63, iters: 246, time: 0.058, data: 0.001) G_GAN: 6.290 G_L1: 5.417 D_real: 1.610 D_fake: 0.001 \n",
      "(epoch: 63, iters: 346, time: 0.058, data: 0.001) G_GAN: 1.333 G_L1: 5.107 D_real: 0.044 D_fake: 0.511 \n",
      "End of epoch 63 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 29, time: 0.057, data: 0.001) G_GAN: 5.935 G_L1: 6.345 D_real: 0.062 D_fake: 0.003 \n",
      "(epoch: 64, iters: 129, time: 0.122, data: 0.001) G_GAN: 2.016 G_L1: 8.573 D_real: 0.007 D_fake: 0.675 \n",
      "(epoch: 64, iters: 229, time: 0.058, data: 0.001) G_GAN: 1.054 G_L1: 0.300 D_real: 1.424 D_fake: 0.307 \n",
      "(epoch: 64, iters: 329, time: 0.058, data: 0.001) G_GAN: 2.052 G_L1: 11.191 D_real: 0.009 D_fake: 3.127 \n",
      "End of epoch 64 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 12, time: 0.058, data: 0.001) G_GAN: 2.326 G_L1: 8.921 D_real: 0.051 D_fake: 0.123 \n",
      "(epoch: 65, iters: 112, time: 0.157, data: 0.001) G_GAN: 1.129 G_L1: 13.403 D_real: 0.210 D_fake: 0.462 \n",
      "(epoch: 65, iters: 212, time: 0.058, data: 0.001) G_GAN: 1.631 G_L1: 5.939 D_real: 0.009 D_fake: 0.812 \n",
      "(epoch: 65, iters: 312, time: 0.058, data: 0.001) G_GAN: 1.638 G_L1: 8.291 D_real: 0.146 D_fake: 2.325 \n",
      "(epoch: 65, iters: 412, time: 0.059, data: 0.001) G_GAN: 6.285 G_L1: 10.318 D_real: 0.396 D_fake: 0.001 \n",
      "saving the model at the end of epoch 65, iters 27105\n",
      "End of epoch 65 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 95, time: 0.126, data: 0.001) G_GAN: 2.917 G_L1: 14.361 D_real: 0.034 D_fake: 1.477 \n",
      "(epoch: 66, iters: 195, time: 0.059, data: 0.001) G_GAN: 2.857 G_L1: 8.964 D_real: 0.562 D_fake: 0.065 \n",
      "(epoch: 66, iters: 295, time: 0.058, data: 0.001) G_GAN: 3.559 G_L1: 11.665 D_real: 0.035 D_fake: 0.065 \n",
      "(epoch: 66, iters: 395, time: 0.057, data: 0.001) G_GAN: 2.539 G_L1: 11.098 D_real: 0.347 D_fake: 0.070 \n",
      "End of epoch 66 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 78, time: 0.126, data: 0.001) G_GAN: 2.717 G_L1: 18.382 D_real: 0.058 D_fake: 0.091 \n",
      "(epoch: 67, iters: 178, time: 0.058, data: 0.001) G_GAN: 1.569 G_L1: 10.225 D_real: 0.075 D_fake: 0.887 \n",
      "(epoch: 67, iters: 278, time: 0.058, data: 0.001) G_GAN: 5.864 G_L1: 7.864 D_real: 0.983 D_fake: 0.001 \n",
      "(epoch: 67, iters: 378, time: 0.058, data: 0.001) G_GAN: 3.295 G_L1: 12.286 D_real: 0.003 D_fake: 0.462 \n",
      "End of epoch 67 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 61, time: 0.124, data: 0.001) G_GAN: 1.452 G_L1: 2.942 D_real: 0.232 D_fake: 0.661 \n",
      "(epoch: 68, iters: 161, time: 0.059, data: 0.001) G_GAN: 2.094 G_L1: 6.743 D_real: 0.259 D_fake: 0.149 \n",
      "(epoch: 68, iters: 261, time: 0.058, data: 0.001) G_GAN: 3.714 G_L1: 15.701 D_real: 0.012 D_fake: 0.027 \n",
      "(epoch: 68, iters: 361, time: 0.058, data: 0.001) G_GAN: 1.437 G_L1: 4.535 D_real: 0.006 D_fake: 0.520 \n",
      "End of epoch 68 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 44, time: 0.123, data: 0.001) G_GAN: 2.095 G_L1: 7.997 D_real: 0.045 D_fake: 0.164 \n",
      "(epoch: 69, iters: 144, time: 0.059, data: 0.001) G_GAN: 2.241 G_L1: 21.338 D_real: 0.006 D_fake: 0.355 \n",
      "(epoch: 69, iters: 244, time: 0.058, data: 0.001) G_GAN: 1.698 G_L1: 3.349 D_real: 0.120 D_fake: 0.508 \n",
      "(epoch: 69, iters: 344, time: 0.059, data: 0.001) G_GAN: 1.872 G_L1: 19.475 D_real: 0.205 D_fake: 0.203 \n",
      "End of epoch 69 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 27, time: 0.130, data: 0.001) G_GAN: 1.255 G_L1: 15.302 D_real: 0.008 D_fake: 2.120 \n",
      "(epoch: 70, iters: 127, time: 0.058, data: 0.001) G_GAN: 1.319 G_L1: 0.729 D_real: 1.553 D_fake: 0.226 \n",
      "(epoch: 70, iters: 227, time: 0.059, data: 0.001) G_GAN: 5.952 G_L1: 6.066 D_real: 0.068 D_fake: 0.004 \n",
      "(epoch: 70, iters: 327, time: 0.058, data: 0.001) G_GAN: 1.961 G_L1: 15.951 D_real: 0.017 D_fake: 0.171 \n",
      "saving the model at the end of epoch 70, iters 29190\n",
      "End of epoch 70 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 10, time: 0.126, data: 0.001) G_GAN: 1.042 G_L1: 0.625 D_real: 1.466 D_fake: 0.282 \n",
      "(epoch: 71, iters: 110, time: 0.058, data: 0.001) G_GAN: 7.794 G_L1: 12.116 D_real: 0.024 D_fake: 0.001 \n",
      "(epoch: 71, iters: 210, time: 0.058, data: 0.001) G_GAN: 1.862 G_L1: 13.278 D_real: 0.000 D_fake: 1.131 \n",
      "(epoch: 71, iters: 310, time: 0.058, data: 0.001) G_GAN: 0.891 G_L1: 0.333 D_real: 0.933 D_fake: 0.521 \n",
      "(epoch: 71, iters: 410, time: 0.124, data: 0.001) G_GAN: 1.759 G_L1: 6.341 D_real: 0.186 D_fake: 0.803 \n",
      "End of epoch 71 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 93, time: 0.059, data: 0.001) G_GAN: 4.529 G_L1: 10.809 D_real: 0.072 D_fake: 0.011 \n",
      "(epoch: 72, iters: 193, time: 0.058, data: 0.001) G_GAN: 2.542 G_L1: 20.965 D_real: 0.004 D_fake: 0.479 \n",
      "(epoch: 72, iters: 293, time: 0.059, data: 0.001) G_GAN: 4.484 G_L1: 7.198 D_real: 0.143 D_fake: 0.007 \n",
      "(epoch: 72, iters: 393, time: 0.121, data: 0.001) G_GAN: 0.550 G_L1: 0.437 D_real: 0.467 D_fake: 1.041 \n",
      "saving the latest model (epoch 72, total_iters 30000)\n",
      "End of epoch 72 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 76, time: 0.059, data: 0.001) G_GAN: 3.480 G_L1: 5.020 D_real: 0.187 D_fake: 0.035 \n",
      "(epoch: 73, iters: 176, time: 0.058, data: 0.001) G_GAN: 0.724 G_L1: 0.460 D_real: 0.775 D_fake: 0.718 \n",
      "(epoch: 73, iters: 276, time: 0.058, data: 0.001) G_GAN: 1.538 G_L1: 13.200 D_real: 0.050 D_fake: 0.755 \n",
      "(epoch: 73, iters: 376, time: 0.131, data: 0.001) G_GAN: 4.191 G_L1: 11.061 D_real: 0.025 D_fake: 0.021 \n",
      "End of epoch 73 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 59, time: 0.058, data: 0.001) G_GAN: 6.284 G_L1: 9.763 D_real: 0.496 D_fake: 0.001 \n",
      "(epoch: 74, iters: 159, time: 0.058, data: 0.001) G_GAN: 4.373 G_L1: 8.335 D_real: 0.112 D_fake: 0.009 \n",
      "(epoch: 74, iters: 259, time: 0.058, data: 0.001) G_GAN: 1.835 G_L1: 11.753 D_real: 0.359 D_fake: 0.300 \n",
      "(epoch: 74, iters: 359, time: 0.169, data: 0.001) G_GAN: 1.647 G_L1: 4.503 D_real: 0.456 D_fake: 0.109 \n",
      "End of epoch 74 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 42, time: 0.058, data: 0.001) G_GAN: 2.517 G_L1: 9.130 D_real: 0.125 D_fake: 0.090 \n",
      "(epoch: 75, iters: 142, time: 0.059, data: 0.001) G_GAN: 2.727 G_L1: 7.546 D_real: 0.080 D_fake: 0.224 \n",
      "(epoch: 75, iters: 242, time: 0.058, data: 0.001) G_GAN: 1.463 G_L1: 8.052 D_real: 0.519 D_fake: 1.420 \n",
      "(epoch: 75, iters: 342, time: 0.131, data: 0.001) G_GAN: 2.368 G_L1: 21.824 D_real: 0.017 D_fake: 0.099 \n",
      "saving the model at the end of epoch 75, iters 31275\n",
      "End of epoch 75 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 25, time: 0.060, data: 0.001) G_GAN: 1.052 G_L1: 2.356 D_real: 0.081 D_fake: 0.617 \n",
      "(epoch: 76, iters: 125, time: 0.058, data: 0.001) G_GAN: 1.249 G_L1: 12.607 D_real: 0.217 D_fake: 0.258 \n",
      "(epoch: 76, iters: 225, time: 0.058, data: 0.001) G_GAN: 3.365 G_L1: 10.902 D_real: 0.092 D_fake: 0.052 \n",
      "(epoch: 76, iters: 325, time: 0.131, data: 0.001) G_GAN: 2.514 G_L1: 6.337 D_real: 0.066 D_fake: 0.148 \n",
      "End of epoch 76 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 8, time: 0.058, data: 0.001) G_GAN: 2.414 G_L1: 7.720 D_real: 0.303 D_fake: 0.106 \n",
      "(epoch: 77, iters: 108, time: 0.059, data: 0.001) G_GAN: 2.715 G_L1: 15.965 D_real: 0.067 D_fake: 0.084 \n",
      "(epoch: 77, iters: 208, time: 0.057, data: 0.001) G_GAN: 1.045 G_L1: 16.499 D_real: 0.030 D_fake: 0.691 \n",
      "(epoch: 77, iters: 308, time: 0.128, data: 0.001) G_GAN: 2.398 G_L1: 5.032 D_real: 0.133 D_fake: 1.573 \n",
      "(epoch: 77, iters: 408, time: 0.058, data: 0.001) G_GAN: 2.037 G_L1: 4.785 D_real: 0.094 D_fake: 0.637 \n",
      "End of epoch 77 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 91, time: 0.058, data: 0.001) G_GAN: 3.123 G_L1: 5.434 D_real: 0.416 D_fake: 0.040 \n",
      "(epoch: 78, iters: 191, time: 0.058, data: 0.001) G_GAN: 3.450 G_L1: 1.803 D_real: 1.611 D_fake: 0.007 \n",
      "(epoch: 78, iters: 291, time: 0.133, data: 0.001) G_GAN: 2.665 G_L1: 18.318 D_real: 0.009 D_fake: 0.147 \n",
      "(epoch: 78, iters: 391, time: 0.058, data: 0.001) G_GAN: 2.683 G_L1: 7.175 D_real: 0.033 D_fake: 0.446 \n",
      "End of epoch 78 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 74, time: 0.058, data: 0.001) G_GAN: 5.591 G_L1: 20.210 D_real: 0.552 D_fake: 0.002 \n",
      "(epoch: 79, iters: 174, time: 0.058, data: 0.001) G_GAN: 1.772 G_L1: 10.030 D_real: 0.021 D_fake: 0.680 \n",
      "(epoch: 79, iters: 274, time: 0.126, data: 0.001) G_GAN: 0.720 G_L1: 0.148 D_real: 0.712 D_fake: 0.679 \n",
      "(epoch: 79, iters: 374, time: 0.059, data: 0.001) G_GAN: 3.488 G_L1: 14.785 D_real: 0.004 D_fake: 0.055 \n",
      "End of epoch 79 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 57, time: 0.058, data: 0.001) G_GAN: 3.266 G_L1: 7.309 D_real: 0.097 D_fake: 0.852 \n",
      "(epoch: 80, iters: 157, time: 0.058, data: 0.001) G_GAN: 5.960 G_L1: 10.335 D_real: 0.035 D_fake: 0.004 \n",
      "(epoch: 80, iters: 257, time: 0.135, data: 0.001) G_GAN: 5.614 G_L1: 19.701 D_real: 0.054 D_fake: 0.005 \n",
      "(epoch: 80, iters: 357, time: 0.058, data: 0.001) G_GAN: 2.079 G_L1: 7.064 D_real: 0.233 D_fake: 0.125 \n",
      "saving the model at the end of epoch 80, iters 33360\n",
      "End of epoch 80 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 40, time: 0.057, data: 0.001) G_GAN: 1.231 G_L1: 3.958 D_real: 0.103 D_fake: 1.021 \n",
      "(epoch: 81, iters: 140, time: 0.057, data: 0.001) G_GAN: 1.487 G_L1: 7.588 D_real: 2.040 D_fake: 0.039 \n",
      "(epoch: 81, iters: 240, time: 0.127, data: 0.001) G_GAN: 0.782 G_L1: 0.128 D_real: 0.815 D_fake: 0.612 \n",
      "(epoch: 81, iters: 340, time: 0.058, data: 0.001) G_GAN: 5.546 G_L1: 13.708 D_real: 0.869 D_fake: 0.002 \n",
      "End of epoch 81 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 23, time: 0.059, data: 0.001) G_GAN: 3.822 G_L1: 11.666 D_real: 0.008 D_fake: 0.038 \n",
      "(epoch: 82, iters: 123, time: 0.057, data: 0.001) G_GAN: 0.984 G_L1: 0.582 D_real: 1.295 D_fake: 0.317 \n",
      "(epoch: 82, iters: 223, time: 0.134, data: 0.001) G_GAN: 3.424 G_L1: 8.497 D_real: 0.003 D_fake: 0.044 \n",
      "(epoch: 82, iters: 323, time: 0.058, data: 0.001) G_GAN: 4.025 G_L1: 11.665 D_real: 0.073 D_fake: 0.019 \n",
      "End of epoch 82 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 6, time: 0.057, data: 0.001) G_GAN: 4.898 G_L1: 18.983 D_real: 0.037 D_fake: 0.009 \n",
      "(epoch: 83, iters: 106, time: 0.058, data: 0.000) G_GAN: 2.201 G_L1: 8.719 D_real: 0.251 D_fake: 0.161 \n",
      "(epoch: 83, iters: 206, time: 0.170, data: 0.001) G_GAN: 1.642 G_L1: 2.799 D_real: 0.172 D_fake: 0.236 \n",
      "(epoch: 83, iters: 306, time: 0.058, data: 0.001) G_GAN: 3.651 G_L1: 12.717 D_real: 0.014 D_fake: 0.425 \n",
      "(epoch: 83, iters: 406, time: 0.058, data: 0.001) G_GAN: 7.492 G_L1: 16.888 D_real: 0.002 D_fake: 0.001 \n",
      "End of epoch 83 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 89, time: 0.057, data: 0.001) G_GAN: 1.704 G_L1: 5.141 D_real: 0.282 D_fake: 0.323 \n",
      "(epoch: 84, iters: 189, time: 0.135, data: 0.001) G_GAN: 1.817 G_L1: 7.373 D_real: 0.001 D_fake: 0.323 \n",
      "(epoch: 84, iters: 289, time: 0.058, data: 0.001) G_GAN: 1.217 G_L1: 10.870 D_real: 0.523 D_fake: 0.616 \n",
      "(epoch: 84, iters: 389, time: 0.058, data: 0.001) G_GAN: 3.676 G_L1: 2.131 D_real: 0.795 D_fake: 0.017 \n",
      "saving the latest model (epoch 84, total_iters 35000)\n",
      "End of epoch 84 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 72, time: 0.058, data: 0.001) G_GAN: 2.438 G_L1: 15.056 D_real: 0.002 D_fake: 0.105 \n",
      "(epoch: 85, iters: 172, time: 0.132, data: 0.001) G_GAN: 0.833 G_L1: 0.088 D_real: 1.053 D_fake: 0.438 \n",
      "(epoch: 85, iters: 272, time: 0.058, data: 0.001) G_GAN: 7.119 G_L1: 5.743 D_real: 0.456 D_fake: 0.001 \n",
      "(epoch: 85, iters: 372, time: 0.058, data: 0.001) G_GAN: 1.150 G_L1: 14.197 D_real: 1.277 D_fake: 0.173 \n",
      "saving the model at the end of epoch 85, iters 35445\n",
      "End of epoch 85 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 55, time: 0.058, data: 0.001) G_GAN: 7.602 G_L1: 6.354 D_real: 0.002 D_fake: 0.000 \n",
      "(epoch: 86, iters: 155, time: 0.134, data: 0.001) G_GAN: 5.717 G_L1: 12.601 D_real: 0.002 D_fake: 0.004 \n",
      "(epoch: 86, iters: 255, time: 0.059, data: 0.001) G_GAN: 2.009 G_L1: 13.477 D_real: 0.002 D_fake: 2.607 \n",
      "(epoch: 86, iters: 355, time: 0.058, data: 0.001) G_GAN: 0.471 G_L1: 0.926 D_real: 1.749 D_fake: 0.189 \n",
      "End of epoch 86 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 38, time: 0.058, data: 0.001) G_GAN: 5.153 G_L1: 8.675 D_real: 0.758 D_fake: 0.001 \n",
      "(epoch: 87, iters: 138, time: 0.138, data: 0.001) G_GAN: 2.082 G_L1: 12.034 D_real: 0.045 D_fake: 1.108 \n",
      "(epoch: 87, iters: 238, time: 0.058, data: 0.001) G_GAN: 4.862 G_L1: 9.230 D_real: 0.494 D_fake: 0.003 \n",
      "(epoch: 87, iters: 338, time: 0.058, data: 0.001) G_GAN: 1.128 G_L1: 1.625 D_real: 1.036 D_fake: 0.258 \n",
      "End of epoch 87 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 21, time: 0.058, data: 0.001) G_GAN: 1.677 G_L1: 2.439 D_real: 0.025 D_fake: 0.283 \n",
      "(epoch: 88, iters: 121, time: 0.141, data: 0.001) G_GAN: 5.228 G_L1: 7.568 D_real: 0.011 D_fake: 0.006 \n",
      "(epoch: 88, iters: 221, time: 0.058, data: 0.001) G_GAN: 6.368 G_L1: 16.676 D_real: 0.369 D_fake: 0.001 \n",
      "(epoch: 88, iters: 321, time: 0.059, data: 0.001) G_GAN: 1.381 G_L1: 5.437 D_real: 0.646 D_fake: 0.061 \n",
      "End of epoch 88 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 4, time: 0.059, data: 0.001) G_GAN: 6.045 G_L1: 15.090 D_real: 0.009 D_fake: 0.003 \n",
      "(epoch: 89, iters: 104, time: 0.139, data: 0.003) G_GAN: 2.358 G_L1: 7.383 D_real: 0.031 D_fake: 1.439 \n",
      "(epoch: 89, iters: 204, time: 0.058, data: 0.001) G_GAN: 3.083 G_L1: 7.649 D_real: 0.119 D_fake: 0.055 \n",
      "(epoch: 89, iters: 304, time: 0.058, data: 0.001) G_GAN: 0.680 G_L1: 0.682 D_real: 0.767 D_fake: 0.614 \n",
      "(epoch: 89, iters: 404, time: 0.058, data: 0.001) G_GAN: 5.789 G_L1: 12.608 D_real: 0.001 D_fake: 0.004 \n",
      "End of epoch 89 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 87, time: 0.135, data: 0.001) G_GAN: 2.095 G_L1: 7.791 D_real: 0.028 D_fake: 0.235 \n",
      "(epoch: 90, iters: 187, time: 0.058, data: 0.001) G_GAN: 7.314 G_L1: 9.870 D_real: 0.076 D_fake: 0.001 \n",
      "(epoch: 90, iters: 287, time: 0.058, data: 0.001) G_GAN: 2.554 G_L1: 5.055 D_real: 1.236 D_fake: 0.010 \n",
      "(epoch: 90, iters: 387, time: 0.058, data: 0.001) G_GAN: 0.921 G_L1: 3.186 D_real: 1.197 D_fake: 0.542 \n",
      "saving the model at the end of epoch 90, iters 37530\n",
      "End of epoch 90 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 70, time: 0.183, data: 0.001) G_GAN: 2.416 G_L1: 12.581 D_real: 0.001 D_fake: 4.037 \n",
      "(epoch: 91, iters: 170, time: 0.059, data: 0.001) G_GAN: 2.550 G_L1: 9.963 D_real: 0.092 D_fake: 0.091 \n",
      "(epoch: 91, iters: 270, time: 0.058, data: 0.001) G_GAN: 3.194 G_L1: 8.991 D_real: 0.017 D_fake: 1.379 \n",
      "(epoch: 91, iters: 370, time: 0.058, data: 0.001) G_GAN: 0.824 G_L1: 0.502 D_real: 1.288 D_fake: 0.351 \n",
      "End of epoch 91 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 53, time: 0.145, data: 0.001) G_GAN: 0.579 G_L1: 19.837 D_real: 3.703 D_fake: 2.020 \n",
      "(epoch: 92, iters: 153, time: 0.058, data: 0.001) G_GAN: 5.184 G_L1: 9.414 D_real: 0.049 D_fake: 0.007 \n",
      "(epoch: 92, iters: 253, time: 0.058, data: 0.001) G_GAN: 5.316 G_L1: 11.890 D_real: 0.041 D_fake: 0.007 \n",
      "(epoch: 92, iters: 353, time: 0.059, data: 0.001) G_GAN: 1.409 G_L1: 4.228 D_real: 0.034 D_fake: 0.397 \n",
      "End of epoch 92 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 36, time: 0.143, data: 0.001) G_GAN: 6.152 G_L1: 6.921 D_real: 0.021 D_fake: 0.003 \n",
      "(epoch: 93, iters: 136, time: 0.058, data: 0.001) G_GAN: 1.307 G_L1: 8.336 D_real: 0.004 D_fake: 0.461 \n",
      "(epoch: 93, iters: 236, time: 0.058, data: 0.001) G_GAN: 5.871 G_L1: 5.878 D_real: 0.616 D_fake: 0.002 \n",
      "(epoch: 93, iters: 336, time: 0.058, data: 0.001) G_GAN: 6.606 G_L1: 6.848 D_real: 0.037 D_fake: 0.002 \n",
      "End of epoch 93 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 19, time: 0.135, data: 0.001) G_GAN: 2.087 G_L1: 11.648 D_real: 0.080 D_fake: 0.158 \n",
      "(epoch: 94, iters: 119, time: 0.059, data: 0.001) G_GAN: 5.294 G_L1: 15.411 D_real: 1.598 D_fake: 0.004 \n",
      "(epoch: 94, iters: 219, time: 0.058, data: 0.001) G_GAN: 2.544 G_L1: 7.206 D_real: 0.045 D_fake: 0.330 \n",
      "(epoch: 94, iters: 319, time: 0.058, data: 0.001) G_GAN: 4.047 G_L1: 13.757 D_real: 0.300 D_fake: 0.012 \n",
      "End of epoch 94 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 2, time: 0.132, data: 0.001) G_GAN: 6.267 G_L1: 6.212 D_real: 0.011 D_fake: 0.002 \n",
      "(epoch: 95, iters: 102, time: 0.059, data: 0.001) G_GAN: 2.504 G_L1: 5.942 D_real: 0.136 D_fake: 0.081 \n",
      "(epoch: 95, iters: 202, time: 0.058, data: 0.001) G_GAN: 2.281 G_L1: 6.562 D_real: 0.029 D_fake: 0.470 \n",
      "(epoch: 95, iters: 302, time: 0.058, data: 0.001) G_GAN: 2.492 G_L1: 9.098 D_real: 0.012 D_fake: 0.137 \n",
      "(epoch: 95, iters: 402, time: 0.145, data: 0.001) G_GAN: 2.911 G_L1: 13.416 D_real: 0.023 D_fake: 0.085 \n",
      "saving the model at the end of epoch 95, iters 39615\n",
      "End of epoch 95 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 85, time: 0.058, data: 0.001) G_GAN: 2.661 G_L1: 10.727 D_real: 0.052 D_fake: 1.195 \n",
      "(epoch: 96, iters: 185, time: 0.057, data: 0.001) G_GAN: 2.772 G_L1: 6.756 D_real: 0.025 D_fake: 0.100 \n",
      "(epoch: 96, iters: 285, time: 0.058, data: 0.001) G_GAN: 6.464 G_L1: 4.983 D_real: 0.544 D_fake: 0.002 \n",
      "(epoch: 96, iters: 385, time: 0.141, data: 0.001) G_GAN: 1.994 G_L1: 3.821 D_real: 0.161 D_fake: 0.483 \n",
      "saving the latest model (epoch 96, total_iters 40000)\n",
      "End of epoch 96 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 68, time: 0.058, data: 0.001) G_GAN: 5.386 G_L1: 11.049 D_real: 0.164 D_fake: 0.005 \n",
      "(epoch: 97, iters: 168, time: 0.058, data: 0.001) G_GAN: 0.956 G_L1: 2.700 D_real: 0.100 D_fake: 0.491 \n",
      "(epoch: 97, iters: 268, time: 0.058, data: 0.001) G_GAN: 0.715 G_L1: 0.147 D_real: 0.972 D_fake: 0.500 \n",
      "(epoch: 97, iters: 368, time: 0.143, data: 0.001) G_GAN: 1.033 G_L1: 4.508 D_real: 0.831 D_fake: 0.843 \n",
      "End of epoch 97 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 51, time: 0.059, data: 0.001) G_GAN: 6.220 G_L1: 7.703 D_real: 0.019 D_fake: 0.002 \n",
      "(epoch: 98, iters: 151, time: 0.059, data: 0.001) G_GAN: 1.770 G_L1: 7.722 D_real: 0.041 D_fake: 0.633 \n",
      "(epoch: 98, iters: 251, time: 0.058, data: 0.001) G_GAN: 0.861 G_L1: 0.565 D_real: 1.098 D_fake: 0.429 \n",
      "(epoch: 98, iters: 351, time: 0.194, data: 0.001) G_GAN: 1.921 G_L1: 6.602 D_real: 0.168 D_fake: 0.175 \n",
      "End of epoch 98 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 34, time: 0.058, data: 0.001) G_GAN: 3.925 G_L1: 8.486 D_real: 0.006 D_fake: 0.033 \n",
      "(epoch: 99, iters: 134, time: 0.058, data: 0.001) G_GAN: 4.411 G_L1: 2.776 D_real: 3.048 D_fake: 0.002 \n",
      "(epoch: 99, iters: 234, time: 0.057, data: 0.001) G_GAN: 2.421 G_L1: 12.846 D_real: 0.007 D_fake: 1.872 \n",
      "(epoch: 99, iters: 334, time: 0.146, data: 0.001) G_GAN: 7.466 G_L1: 10.984 D_real: 0.048 D_fake: 0.001 \n",
      "End of epoch 99 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 17, time: 0.058, data: 0.001) G_GAN: 2.687 G_L1: 5.651 D_real: 0.081 D_fake: 0.980 \n",
      "(epoch: 100, iters: 117, time: 0.058, data: 0.001) G_GAN: 1.237 G_L1: 0.182 D_real: 1.592 D_fake: 0.234 \n",
      "(epoch: 100, iters: 217, time: 0.058, data: 0.001) G_GAN: 2.541 G_L1: 12.165 D_real: 0.006 D_fake: 2.552 \n",
      "(epoch: 100, iters: 317, time: 0.144, data: 0.001) G_GAN: 3.413 G_L1: 20.027 D_real: 0.065 D_fake: 0.055 \n",
      "(epoch: 100, iters: 417, time: 0.059, data: 0.001) G_GAN: 2.424 G_L1: 8.122 D_real: 0.030 D_fake: 0.689 \n",
      "saving the model at the end of epoch 100, iters 41700\n",
      "End of epoch 100 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.058, data: 0.063) G_GAN: 2.504 G_L1: 7.457 D_real: 0.095 D_fake: 0.111 \n",
      "(epoch: 101, iters: 200, time: 0.058, data: 0.001) G_GAN: 1.730 G_L1: 9.081 D_real: 0.023 D_fake: 0.554 \n",
      "(epoch: 101, iters: 300, time: 0.147, data: 0.001) G_GAN: 2.414 G_L1: 8.762 D_real: 0.368 D_fake: 0.059 \n",
      "(epoch: 101, iters: 400, time: 0.059, data: 0.001) G_GAN: 2.230 G_L1: 16.863 D_real: 0.005 D_fake: 0.290 \n",
      "End of epoch 101 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 83, time: 0.058, data: 0.001) G_GAN: 4.650 G_L1: 3.072 D_real: 0.441 D_fake: 0.011 \n",
      "(epoch: 102, iters: 183, time: 0.058, data: 0.001) G_GAN: 1.360 G_L1: 19.631 D_real: 0.049 D_fake: 2.562 \n",
      "(epoch: 102, iters: 283, time: 0.147, data: 0.001) G_GAN: 2.775 G_L1: 7.628 D_real: 0.038 D_fake: 0.167 \n",
      "(epoch: 102, iters: 383, time: 0.059, data: 0.001) G_GAN: 1.135 G_L1: 0.439 D_real: 1.600 D_fake: 0.237 \n",
      "End of epoch 102 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 66, time: 0.058, data: 0.001) G_GAN: 5.513 G_L1: 11.647 D_real: 0.001 D_fake: 0.005 \n",
      "(epoch: 103, iters: 166, time: 0.058, data: 0.001) G_GAN: 7.532 G_L1: 10.401 D_real: 0.059 D_fake: 0.001 \n",
      "(epoch: 103, iters: 266, time: 0.139, data: 0.001) G_GAN: 1.243 G_L1: 0.195 D_real: 2.328 D_fake: 0.105 \n",
      "(epoch: 103, iters: 366, time: 0.058, data: 0.001) G_GAN: 2.356 G_L1: 18.452 D_real: 0.020 D_fake: 0.123 \n",
      "End of epoch 103 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 49, time: 0.060, data: 0.001) G_GAN: 2.622 G_L1: 11.263 D_real: 0.024 D_fake: 0.819 \n",
      "(epoch: 104, iters: 149, time: 0.058, data: 0.001) G_GAN: 1.825 G_L1: 12.620 D_real: 0.003 D_fake: 0.371 \n",
      "(epoch: 104, iters: 249, time: 0.146, data: 0.001) G_GAN: 6.305 G_L1: 8.255 D_real: 0.018 D_fake: 0.002 \n",
      "(epoch: 104, iters: 349, time: 0.058, data: 0.001) G_GAN: 2.220 G_L1: 7.299 D_real: 0.006 D_fake: 0.902 \n",
      "End of epoch 104 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 32, time: 0.058, data: 0.001) G_GAN: 2.494 G_L1: 15.793 D_real: 0.006 D_fake: 0.226 \n",
      "(epoch: 105, iters: 132, time: 0.058, data: 0.001) G_GAN: 1.932 G_L1: 1.790 D_real: 0.076 D_fake: 0.116 \n",
      "(epoch: 105, iters: 232, time: 0.189, data: 0.001) G_GAN: 1.426 G_L1: 7.827 D_real: 0.447 D_fake: 0.368 \n",
      "(epoch: 105, iters: 332, time: 0.058, data: 0.001) G_GAN: 3.214 G_L1: 17.025 D_real: 0.016 D_fake: 0.050 \n",
      "saving the model at the end of epoch 105, iters 43785\n",
      "End of epoch 105 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 15, time: 0.058, data: 0.001) G_GAN: 0.789 G_L1: 0.122 D_real: 0.895 D_fake: 0.559 \n",
      "(epoch: 106, iters: 115, time: 0.058, data: 0.001) G_GAN: 6.522 G_L1: 23.042 D_real: 0.695 D_fake: 0.001 \n",
      "(epoch: 106, iters: 215, time: 0.150, data: 0.001) G_GAN: 1.464 G_L1: 9.685 D_real: 1.713 D_fake: 0.179 \n",
      "(epoch: 106, iters: 315, time: 0.058, data: 0.001) G_GAN: 2.118 G_L1: 12.165 D_real: 0.081 D_fake: 0.763 \n",
      "(epoch: 106, iters: 415, time: 0.059, data: 0.001) G_GAN: 2.655 G_L1: 7.574 D_real: 0.600 D_fake: 0.015 \n",
      "End of epoch 106 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 98, time: 0.058, data: 0.001) G_GAN: 2.463 G_L1: 8.862 D_real: 0.006 D_fake: 0.088 \n",
      "(epoch: 107, iters: 198, time: 0.152, data: 0.001) G_GAN: 2.705 G_L1: 6.189 D_real: 0.069 D_fake: 0.163 \n",
      "(epoch: 107, iters: 298, time: 0.059, data: 0.001) G_GAN: 6.186 G_L1: 14.969 D_real: 0.057 D_fake: 0.002 \n",
      "(epoch: 107, iters: 398, time: 0.059, data: 0.001) G_GAN: 6.221 G_L1: 12.055 D_real: 0.320 D_fake: 0.001 \n",
      "End of epoch 107 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 81, time: 0.058, data: 0.001) G_GAN: 3.954 G_L1: 6.471 D_real: 0.005 D_fake: 0.023 \n",
      "(epoch: 108, iters: 181, time: 0.148, data: 0.001) G_GAN: 3.660 G_L1: 19.101 D_real: 0.000 D_fake: 0.039 \n",
      "(epoch: 108, iters: 281, time: 0.058, data: 0.001) G_GAN: 2.997 G_L1: 3.415 D_real: 0.164 D_fake: 0.060 \n",
      "(epoch: 108, iters: 381, time: 0.058, data: 0.001) G_GAN: 2.815 G_L1: 18.403 D_real: 1.338 D_fake: 0.015 \n",
      "saving the latest model (epoch 108, total_iters 45000)\n",
      "End of epoch 108 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 64, time: 0.058, data: 0.001) G_GAN: 2.012 G_L1: 5.149 D_real: 0.015 D_fake: 0.257 \n",
      "(epoch: 109, iters: 164, time: 0.150, data: 0.001) G_GAN: 0.999 G_L1: 0.172 D_real: 1.518 D_fake: 0.260 \n",
      "(epoch: 109, iters: 264, time: 0.058, data: 0.001) G_GAN: 2.898 G_L1: 6.570 D_real: 0.056 D_fake: 0.065 \n",
      "(epoch: 109, iters: 364, time: 0.058, data: 0.001) G_GAN: 4.639 G_L1: 14.688 D_real: 0.001 D_fake: 0.009 \n",
      "End of epoch 109 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 47, time: 0.059, data: 0.001) G_GAN: 1.234 G_L1: 4.805 D_real: 0.158 D_fake: 0.547 \n",
      "(epoch: 110, iters: 147, time: 0.146, data: 0.001) G_GAN: 1.391 G_L1: 6.262 D_real: 0.068 D_fake: 0.340 \n",
      "(epoch: 110, iters: 247, time: 0.058, data: 0.001) G_GAN: 1.300 G_L1: 8.080 D_real: 0.003 D_fake: 0.453 \n",
      "(epoch: 110, iters: 347, time: 0.058, data: 0.001) G_GAN: 2.083 G_L1: 21.831 D_real: 0.076 D_fake: 0.163 \n",
      "saving the model at the end of epoch 110, iters 45870\n",
      "End of epoch 110 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 30, time: 0.058, data: 0.001) G_GAN: 4.080 G_L1: 5.711 D_real: 0.035 D_fake: 0.022 \n",
      "(epoch: 111, iters: 130, time: 0.152, data: 0.001) G_GAN: 6.468 G_L1: 12.357 D_real: 0.004 D_fake: 0.002 \n",
      "(epoch: 111, iters: 230, time: 0.059, data: 0.001) G_GAN: 1.802 G_L1: 6.675 D_real: 0.133 D_fake: 0.293 \n",
      "(epoch: 111, iters: 330, time: 0.058, data: 0.001) G_GAN: 2.129 G_L1: 8.898 D_real: 0.010 D_fake: 0.494 \n",
      "End of epoch 111 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 13, time: 0.058, data: 0.001) G_GAN: 6.557 G_L1: 8.186 D_real: 0.006 D_fake: 0.002 \n",
      "(epoch: 112, iters: 113, time: 0.198, data: 0.001) G_GAN: 2.834 G_L1: 6.067 D_real: 0.091 D_fake: 0.080 \n",
      "(epoch: 112, iters: 213, time: 0.058, data: 0.001) G_GAN: 2.462 G_L1: 6.995 D_real: 0.027 D_fake: 0.677 \n",
      "(epoch: 112, iters: 313, time: 0.058, data: 0.001) G_GAN: 2.523 G_L1: 5.292 D_real: 0.116 D_fake: 0.217 \n",
      "(epoch: 112, iters: 413, time: 0.058, data: 0.001) G_GAN: 2.369 G_L1: 13.465 D_real: 0.072 D_fake: 0.155 \n",
      "End of epoch 112 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 96, time: 0.157, data: 0.001) G_GAN: 7.452 G_L1: 13.362 D_real: 0.023 D_fake: 0.001 \n",
      "(epoch: 113, iters: 196, time: 0.058, data: 0.001) G_GAN: 6.975 G_L1: 10.831 D_real: 0.063 D_fake: 0.002 \n",
      "(epoch: 113, iters: 296, time: 0.058, data: 0.001) G_GAN: 2.013 G_L1: 7.457 D_real: 0.838 D_fake: 0.918 \n",
      "(epoch: 113, iters: 396, time: 0.058, data: 0.001) G_GAN: 2.556 G_L1: 10.881 D_real: 0.048 D_fake: 0.173 \n",
      "End of epoch 113 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 79, time: 0.159, data: 0.001) G_GAN: 5.942 G_L1: 9.881 D_real: 0.004 D_fake: 0.004 \n",
      "(epoch: 114, iters: 179, time: 0.058, data: 0.001) G_GAN: 0.885 G_L1: 1.426 D_real: 2.118 D_fake: 0.502 \n",
      "(epoch: 114, iters: 279, time: 0.058, data: 0.001) G_GAN: 1.363 G_L1: 8.286 D_real: 0.520 D_fake: 0.200 \n",
      "(epoch: 114, iters: 379, time: 0.058, data: 0.001) G_GAN: 2.047 G_L1: 13.160 D_real: 0.008 D_fake: 0.958 \n",
      "End of epoch 114 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 62, time: 0.153, data: 0.001) G_GAN: 6.799 G_L1: 8.034 D_real: 1.159 D_fake: 0.001 \n",
      "(epoch: 115, iters: 162, time: 0.059, data: 0.001) G_GAN: 1.737 G_L1: 2.041 D_real: 1.974 D_fake: 0.070 \n",
      "(epoch: 115, iters: 262, time: 0.059, data: 0.001) G_GAN: 5.506 G_L1: 23.450 D_real: 0.000 D_fake: 0.008 \n",
      "(epoch: 115, iters: 362, time: 0.059, data: 0.001) G_GAN: 2.656 G_L1: 11.093 D_real: 0.038 D_fake: 0.111 \n",
      "saving the model at the end of epoch 115, iters 47955\n",
      "End of epoch 115 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 45, time: 0.151, data: 0.001) G_GAN: 1.194 G_L1: 0.267 D_real: 1.773 D_fake: 0.212 \n",
      "(epoch: 116, iters: 145, time: 0.058, data: 0.001) G_GAN: 2.395 G_L1: 6.016 D_real: 0.006 D_fake: 1.092 \n",
      "(epoch: 116, iters: 245, time: 0.057, data: 0.001) G_GAN: 2.628 G_L1: 7.747 D_real: 0.405 D_fake: 0.014 \n",
      "(epoch: 116, iters: 345, time: 0.058, data: 0.001) G_GAN: 5.215 G_L1: 8.764 D_real: 0.227 D_fake: 0.005 \n",
      "End of epoch 116 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 28, time: 0.147, data: 0.001) G_GAN: 1.081 G_L1: 0.310 D_real: 1.328 D_fake: 0.315 \n",
      "(epoch: 117, iters: 128, time: 0.059, data: 0.001) G_GAN: 0.770 G_L1: 6.435 D_real: 1.766 D_fake: 0.048 \n",
      "(epoch: 117, iters: 228, time: 0.059, data: 0.001) G_GAN: 5.067 G_L1: 5.994 D_real: 0.005 D_fake: 0.007 \n",
      "(epoch: 117, iters: 328, time: 0.059, data: 0.001) G_GAN: 2.303 G_L1: 6.563 D_real: 0.136 D_fake: 0.107 \n",
      "End of epoch 117 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 11, time: 0.202, data: 0.001) G_GAN: 1.419 G_L1: 12.930 D_real: 0.081 D_fake: 3.579 \n",
      "(epoch: 118, iters: 111, time: 0.059, data: 0.001) G_GAN: 1.379 G_L1: 2.289 D_real: 0.042 D_fake: 0.321 \n",
      "(epoch: 118, iters: 211, time: 0.058, data: 0.001) G_GAN: 6.474 G_L1: 17.207 D_real: 0.001 D_fake: 0.002 \n",
      "(epoch: 118, iters: 311, time: 0.059, data: 0.001) G_GAN: 3.419 G_L1: 3.070 D_real: 0.116 D_fake: 0.042 \n",
      "(epoch: 118, iters: 411, time: 0.157, data: 0.001) G_GAN: 2.294 G_L1: 20.626 D_real: 0.002 D_fake: 1.049 \n",
      "End of epoch 118 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 94, time: 0.059, data: 0.001) G_GAN: 2.508 G_L1: 8.456 D_real: 0.018 D_fake: 0.097 \n",
      "(epoch: 119, iters: 194, time: 0.058, data: 0.001) G_GAN: 2.736 G_L1: 12.318 D_real: 0.036 D_fake: 0.139 \n",
      "(epoch: 119, iters: 294, time: 0.058, data: 0.001) G_GAN: 5.548 G_L1: 10.775 D_real: 0.131 D_fake: 0.005 \n",
      "(epoch: 119, iters: 394, time: 0.147, data: 0.001) G_GAN: 0.650 G_L1: 0.481 D_real: 0.516 D_fake: 0.934 \n",
      "End of epoch 119 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 77, time: 0.059, data: 0.001) G_GAN: 3.829 G_L1: 11.833 D_real: 0.002 D_fake: 0.029 \n",
      "(epoch: 120, iters: 177, time: 0.058, data: 0.001) G_GAN: 3.154 G_L1: 11.416 D_real: 0.067 D_fake: 0.055 \n",
      "(epoch: 120, iters: 277, time: 0.058, data: 0.001) G_GAN: 3.932 G_L1: 8.181 D_real: 0.116 D_fake: 0.020 \n",
      "(epoch: 120, iters: 377, time: 0.154, data: 0.001) G_GAN: 2.726 G_L1: 5.203 D_real: 0.037 D_fake: 0.181 \n",
      "saving the latest model (epoch 120, total_iters 50000)\n",
      "saving the model at the end of epoch 120, iters 50040\n",
      "End of epoch 120 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 60, time: 0.058, data: 0.001) G_GAN: 5.819 G_L1: 9.213 D_real: 0.002 D_fake: 0.005 \n",
      "(epoch: 121, iters: 160, time: 0.058, data: 0.001) G_GAN: 3.172 G_L1: 6.708 D_real: 0.011 D_fake: 0.046 \n",
      "(epoch: 121, iters: 260, time: 0.058, data: 0.001) G_GAN: 3.307 G_L1: 16.709 D_real: 0.029 D_fake: 0.075 \n",
      "(epoch: 121, iters: 360, time: 0.156, data: 0.001) G_GAN: 2.853 G_L1: 6.481 D_real: 2.730 D_fake: 0.037 \n",
      "End of epoch 121 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 43, time: 0.058, data: 0.001) G_GAN: 0.800 G_L1: 0.233 D_real: 0.883 D_fake: 0.539 \n",
      "(epoch: 122, iters: 143, time: 0.059, data: 0.001) G_GAN: 2.027 G_L1: 16.195 D_real: 0.000 D_fake: 0.176 \n",
      "(epoch: 122, iters: 243, time: 0.058, data: 0.001) G_GAN: 2.706 G_L1: 7.017 D_real: 0.006 D_fake: 0.478 \n",
      "(epoch: 122, iters: 343, time: 0.159, data: 0.001) G_GAN: 2.881 G_L1: 13.724 D_real: 0.059 D_fake: 0.238 \n",
      "End of epoch 122 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 26, time: 0.059, data: 0.001) G_GAN: 1.434 G_L1: 8.719 D_real: 0.355 D_fake: 0.453 \n",
      "(epoch: 123, iters: 126, time: 0.058, data: 0.001) G_GAN: 5.911 G_L1: 7.707 D_real: 0.048 D_fake: 0.003 \n",
      "(epoch: 123, iters: 226, time: 0.060, data: 0.001) G_GAN: 2.817 G_L1: 7.760 D_real: 0.091 D_fake: 0.182 \n",
      "(epoch: 123, iters: 326, time: 0.207, data: 0.001) G_GAN: 2.934 G_L1: 20.988 D_real: 7.158 D_fake: 1.178 \n",
      "End of epoch 123 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 9, time: 0.058, data: 0.001) G_GAN: 7.588 G_L1: 3.288 D_real: 0.151 D_fake: 0.001 \n",
      "(epoch: 124, iters: 109, time: 0.058, data: 0.001) G_GAN: 2.030 G_L1: 2.077 D_real: 0.059 D_fake: 0.231 \n",
      "(epoch: 124, iters: 209, time: 0.059, data: 0.001) G_GAN: 3.269 G_L1: 9.539 D_real: 0.296 D_fake: 0.031 \n",
      "(epoch: 124, iters: 309, time: 0.157, data: 0.001) G_GAN: 1.129 G_L1: 3.771 D_real: 0.055 D_fake: 0.554 \n",
      "(epoch: 124, iters: 409, time: 0.058, data: 0.001) G_GAN: 3.701 G_L1: 10.470 D_real: 0.040 D_fake: 0.036 \n",
      "End of epoch 124 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 92, time: 0.058, data: 0.001) G_GAN: 2.955 G_L1: 6.134 D_real: 0.113 D_fake: 0.048 \n",
      "(epoch: 125, iters: 192, time: 0.058, data: 0.001) G_GAN: 3.588 G_L1: 5.656 D_real: 0.105 D_fake: 0.038 \n",
      "(epoch: 125, iters: 292, time: 0.155, data: 0.001) G_GAN: 1.422 G_L1: 4.954 D_real: 0.039 D_fake: 0.312 \n",
      "(epoch: 125, iters: 392, time: 0.058, data: 0.001) G_GAN: 2.326 G_L1: 9.468 D_real: 1.424 D_fake: 0.029 \n",
      "saving the model at the end of epoch 125, iters 52125\n",
      "End of epoch 125 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 75, time: 0.058, data: 0.001) G_GAN: 0.989 G_L1: 0.196 D_real: 1.346 D_fake: 0.319 \n",
      "(epoch: 126, iters: 175, time: 0.058, data: 0.001) G_GAN: 0.738 G_L1: 0.121 D_real: 0.731 D_fake: 0.701 \n",
      "(epoch: 126, iters: 275, time: 0.159, data: 0.001) G_GAN: 3.828 G_L1: 3.264 D_real: 0.031 D_fake: 0.026 \n",
      "(epoch: 126, iters: 375, time: 0.058, data: 0.001) G_GAN: 2.423 G_L1: 8.948 D_real: 0.264 D_fake: 0.031 \n",
      "End of epoch 126 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 58, time: 0.058, data: 0.001) G_GAN: 1.546 G_L1: 11.672 D_real: 0.010 D_fake: 1.031 \n",
      "(epoch: 127, iters: 158, time: 0.059, data: 0.001) G_GAN: 4.619 G_L1: 13.531 D_real: 0.018 D_fake: 0.017 \n",
      "(epoch: 127, iters: 258, time: 0.162, data: 0.001) G_GAN: 2.259 G_L1: 8.050 D_real: 0.459 D_fake: 0.048 \n",
      "(epoch: 127, iters: 358, time: 0.057, data: 0.001) G_GAN: 7.990 G_L1: 27.302 D_real: 0.006 D_fake: 0.000 \n",
      "End of epoch 127 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 41, time: 0.058, data: 0.001) G_GAN: 0.957 G_L1: 3.942 D_real: 0.002 D_fake: 0.698 \n",
      "(epoch: 128, iters: 141, time: 0.057, data: 0.001) G_GAN: 1.548 G_L1: 14.921 D_real: 0.345 D_fake: 0.270 \n",
      "(epoch: 128, iters: 241, time: 0.157, data: 0.001) G_GAN: 0.706 G_L1: 0.447 D_real: 0.720 D_fake: 0.689 \n",
      "(epoch: 128, iters: 341, time: 0.058, data: 0.001) G_GAN: 3.821 G_L1: 4.657 D_real: 0.033 D_fake: 0.024 \n",
      "End of epoch 128 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 24, time: 0.063, data: 0.001) G_GAN: 1.693 G_L1: 11.218 D_real: 0.027 D_fake: 1.318 \n",
      "(epoch: 129, iters: 124, time: 0.058, data: 0.001) G_GAN: 2.235 G_L1: 7.490 D_real: 0.129 D_fake: 0.155 \n",
      "(epoch: 129, iters: 224, time: 0.211, data: 0.001) G_GAN: 3.964 G_L1: 7.405 D_real: 0.849 D_fake: 0.003 \n",
      "(epoch: 129, iters: 324, time: 0.058, data: 0.001) G_GAN: 2.133 G_L1: 15.222 D_real: 0.037 D_fake: 0.639 \n",
      "End of epoch 129 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 7, time: 0.057, data: 0.001) G_GAN: 1.946 G_L1: 11.467 D_real: 0.009 D_fake: 0.212 \n",
      "(epoch: 130, iters: 107, time: 0.058, data: 0.001) G_GAN: 2.751 G_L1: 7.044 D_real: 0.008 D_fake: 0.353 \n",
      "(epoch: 130, iters: 207, time: 0.164, data: 0.001) G_GAN: 4.684 G_L1: 12.791 D_real: 0.001 D_fake: 0.008 \n",
      "(epoch: 130, iters: 307, time: 0.058, data: 0.001) G_GAN: 4.531 G_L1: 8.757 D_real: 0.012 D_fake: 0.014 \n",
      "(epoch: 130, iters: 407, time: 0.059, data: 0.001) G_GAN: 0.742 G_L1: 7.067 D_real: 0.873 D_fake: 0.654 \n",
      "saving the model at the end of epoch 130, iters 54210\n",
      "End of epoch 130 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 90, time: 0.058, data: 0.001) G_GAN: 1.699 G_L1: 18.766 D_real: 0.005 D_fake: 0.245 \n",
      "(epoch: 131, iters: 190, time: 0.165, data: 0.001) G_GAN: 2.859 G_L1: 9.903 D_real: 0.095 D_fake: 0.080 \n",
      "(epoch: 131, iters: 290, time: 0.059, data: 0.001) G_GAN: 2.188 G_L1: 5.838 D_real: 2.498 D_fake: 0.034 \n",
      "(epoch: 131, iters: 390, time: 0.058, data: 0.001) G_GAN: 5.075 G_L1: 9.555 D_real: 0.075 D_fake: 0.006 \n",
      "End of epoch 131 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 73, time: 0.058, data: 0.001) G_GAN: 2.134 G_L1: 9.606 D_real: 0.001 D_fake: 0.162 \n",
      "(epoch: 132, iters: 173, time: 0.159, data: 0.001) G_GAN: 1.179 G_L1: 4.363 D_real: 0.005 D_fake: 0.442 \n",
      "(epoch: 132, iters: 273, time: 0.058, data: 0.001) G_GAN: 3.571 G_L1: 18.718 D_real: 0.001 D_fake: 0.027 \n",
      "(epoch: 132, iters: 373, time: 0.058, data: 0.001) G_GAN: 1.974 G_L1: 4.120 D_real: 1.812 D_fake: 0.031 \n",
      "saving the latest model (epoch 132, total_iters 55000)\n",
      "End of epoch 132 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 56, time: 0.059, data: 0.001) G_GAN: 3.955 G_L1: 10.201 D_real: 0.112 D_fake: 0.021 \n",
      "(epoch: 133, iters: 156, time: 0.166, data: 0.001) G_GAN: 1.603 G_L1: 10.577 D_real: 0.034 D_fake: 1.063 \n",
      "(epoch: 133, iters: 256, time: 0.058, data: 0.001) G_GAN: 4.598 G_L1: 5.785 D_real: 0.255 D_fake: 0.010 \n",
      "(epoch: 133, iters: 356, time: 0.058, data: 0.001) G_GAN: 4.316 G_L1: 10.051 D_real: 0.004 D_fake: 0.015 \n",
      "End of epoch 133 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 39, time: 0.058, data: 0.001) G_GAN: 5.689 G_L1: 8.846 D_real: 0.081 D_fake: 0.005 \n",
      "(epoch: 134, iters: 139, time: 0.163, data: 0.001) G_GAN: 7.345 G_L1: 11.314 D_real: 0.101 D_fake: 0.001 \n",
      "(epoch: 134, iters: 239, time: 0.059, data: 0.001) G_GAN: 1.942 G_L1: 4.354 D_real: 0.063 D_fake: 0.395 \n",
      "(epoch: 134, iters: 339, time: 0.058, data: 0.001) G_GAN: 1.718 G_L1: 6.856 D_real: 0.006 D_fake: 0.418 \n",
      "End of epoch 134 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 22, time: 0.059, data: 0.001) G_GAN: 1.956 G_L1: 8.866 D_real: 0.005 D_fake: 0.384 \n",
      "(epoch: 135, iters: 122, time: 0.209, data: 0.001) G_GAN: 6.982 G_L1: 7.624 D_real: 0.061 D_fake: 0.001 \n",
      "(epoch: 135, iters: 222, time: 0.058, data: 0.001) G_GAN: 7.388 G_L1: 6.190 D_real: 0.019 D_fake: 0.001 \n",
      "(epoch: 135, iters: 322, time: 0.058, data: 0.001) G_GAN: 7.145 G_L1: 9.349 D_real: 0.010 D_fake: 0.001 \n",
      "saving the model at the end of epoch 135, iters 56295\n",
      "End of epoch 135 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 5, time: 0.058, data: 0.001) G_GAN: 3.495 G_L1: 14.975 D_real: 0.013 D_fake: 0.078 \n",
      "(epoch: 136, iters: 105, time: 0.168, data: 0.002) G_GAN: 2.040 G_L1: 8.525 D_real: 0.120 D_fake: 0.233 \n",
      "(epoch: 136, iters: 205, time: 0.058, data: 0.001) G_GAN: 6.508 G_L1: 10.729 D_real: 0.006 D_fake: 0.002 \n",
      "(epoch: 136, iters: 305, time: 0.058, data: 0.001) G_GAN: 2.595 G_L1: 1.927 D_real: 0.473 D_fake: 0.051 \n",
      "(epoch: 136, iters: 405, time: 0.058, data: 0.001) G_GAN: 3.107 G_L1: 8.756 D_real: 0.141 D_fake: 0.043 \n",
      "End of epoch 136 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 88, time: 0.172, data: 0.001) G_GAN: 5.603 G_L1: 7.052 D_real: 0.005 D_fake: 0.005 \n",
      "(epoch: 137, iters: 188, time: 0.057, data: 0.001) G_GAN: 1.857 G_L1: 15.116 D_real: 0.903 D_fake: 0.126 \n",
      "(epoch: 137, iters: 288, time: 0.058, data: 0.001) G_GAN: 6.385 G_L1: 10.960 D_real: 0.037 D_fake: 0.002 \n",
      "(epoch: 137, iters: 388, time: 0.058, data: 0.001) G_GAN: 1.544 G_L1: 2.427 D_real: 0.264 D_fake: 0.339 \n",
      "End of epoch 137 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 71, time: 0.172, data: 0.001) G_GAN: 5.107 G_L1: 11.535 D_real: 0.003 D_fake: 0.007 \n",
      "(epoch: 138, iters: 171, time: 0.058, data: 0.001) G_GAN: 6.990 G_L1: 9.198 D_real: 0.027 D_fake: 0.002 \n",
      "(epoch: 138, iters: 271, time: 0.058, data: 0.001) G_GAN: 1.253 G_L1: 0.490 D_real: 1.636 D_fake: 0.226 \n",
      "(epoch: 138, iters: 371, time: 0.057, data: 0.001) G_GAN: 2.024 G_L1: 9.907 D_real: 0.203 D_fake: 0.179 \n",
      "End of epoch 138 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 54, time: 0.166, data: 0.001) G_GAN: 5.490 G_L1: 4.696 D_real: 0.140 D_fake: 0.003 \n",
      "(epoch: 139, iters: 154, time: 0.059, data: 0.001) G_GAN: 1.339 G_L1: 15.498 D_real: 0.749 D_fake: 0.055 \n",
      "(epoch: 139, iters: 254, time: 0.058, data: 0.001) G_GAN: 3.821 G_L1: 12.038 D_real: 0.013 D_fake: 0.041 \n",
      "(epoch: 139, iters: 354, time: 0.058, data: 0.001) G_GAN: 1.717 G_L1: 1.764 D_real: 0.053 D_fake: 0.248 \n",
      "End of epoch 139 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 37, time: 0.215, data: 0.001) G_GAN: 8.049 G_L1: 8.828 D_real: 0.001 D_fake: 0.000 \n",
      "(epoch: 140, iters: 137, time: 0.058, data: 0.001) G_GAN: 5.380 G_L1: 9.161 D_real: 0.033 D_fake: 0.008 \n",
      "(epoch: 140, iters: 237, time: 0.058, data: 0.001) G_GAN: 4.394 G_L1: 10.390 D_real: 2.650 D_fake: 0.002 \n",
      "(epoch: 140, iters: 337, time: 0.058, data: 0.001) G_GAN: 2.022 G_L1: 7.687 D_real: 0.018 D_fake: 0.702 \n",
      "saving the model at the end of epoch 140, iters 58380\n",
      "End of epoch 140 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 20, time: 0.170, data: 0.001) G_GAN: 3.105 G_L1: 10.217 D_real: 0.613 D_fake: 0.019 \n",
      "(epoch: 141, iters: 120, time: 0.058, data: 0.002) G_GAN: 4.104 G_L1: 10.498 D_real: 0.008 D_fake: 0.024 \n",
      "(epoch: 141, iters: 220, time: 0.058, data: 0.001) G_GAN: 3.951 G_L1: 6.420 D_real: 0.013 D_fake: 0.026 \n",
      "(epoch: 141, iters: 320, time: 0.058, data: 0.001) G_GAN: 1.787 G_L1: 10.423 D_real: 0.005 D_fake: 0.483 \n",
      "End of epoch 141 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 3, time: 0.176, data: 0.001) G_GAN: 2.029 G_L1: 10.804 D_real: 0.127 D_fake: 0.168 \n",
      "(epoch: 142, iters: 103, time: 0.058, data: 0.000) G_GAN: 3.822 G_L1: 12.431 D_real: 0.313 D_fake: 0.022 \n",
      "(epoch: 142, iters: 203, time: 0.058, data: 0.001) G_GAN: 1.314 G_L1: 0.764 D_real: 1.570 D_fake: 0.255 \n",
      "(epoch: 142, iters: 303, time: 0.059, data: 0.001) G_GAN: 3.751 G_L1: 9.779 D_real: 0.033 D_fake: 0.028 \n",
      "(epoch: 142, iters: 403, time: 0.169, data: 0.001) G_GAN: 3.155 G_L1: 6.368 D_real: 0.268 D_fake: 0.037 \n",
      "End of epoch 142 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 86, time: 0.057, data: 0.002) G_GAN: 1.704 G_L1: 1.965 D_real: 4.707 D_fake: 0.039 \n",
      "(epoch: 143, iters: 186, time: 0.058, data: 0.001) G_GAN: 1.741 G_L1: 9.294 D_real: 0.024 D_fake: 0.325 \n",
      "(epoch: 143, iters: 286, time: 0.058, data: 0.001) G_GAN: 3.561 G_L1: 5.512 D_real: 0.040 D_fake: 0.045 \n",
      "(epoch: 143, iters: 386, time: 0.167, data: 0.001) G_GAN: 0.801 G_L1: 0.272 D_real: 0.836 D_fake: 0.589 \n",
      "End of epoch 143 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 69, time: 0.057, data: 0.001) G_GAN: 3.816 G_L1: 11.009 D_real: 0.073 D_fake: 0.026 \n",
      "(epoch: 144, iters: 169, time: 0.058, data: 0.001) G_GAN: 3.155 G_L1: 5.278 D_real: 0.064 D_fake: 0.080 \n",
      "(epoch: 144, iters: 269, time: 0.058, data: 0.001) G_GAN: 1.773 G_L1: 7.119 D_real: 0.449 D_fake: 0.107 \n",
      "(epoch: 144, iters: 369, time: 0.215, data: 0.001) G_GAN: 1.762 G_L1: 14.031 D_real: 0.142 D_fake: 0.556 \n",
      "saving the latest model (epoch 144, total_iters 60000)\n",
      "End of epoch 144 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 52, time: 0.058, data: 0.001) G_GAN: 2.477 G_L1: 9.813 D_real: 0.094 D_fake: 0.120 \n",
      "(epoch: 145, iters: 152, time: 0.058, data: 0.001) G_GAN: 2.807 G_L1: 9.747 D_real: 0.880 D_fake: 0.055 \n",
      "(epoch: 145, iters: 252, time: 0.057, data: 0.001) G_GAN: 4.031 G_L1: 8.592 D_real: 0.021 D_fake: 0.025 \n",
      "(epoch: 145, iters: 352, time: 0.170, data: 0.001) G_GAN: 6.832 G_L1: 10.644 D_real: 0.000 D_fake: 0.001 \n",
      "saving the model at the end of epoch 145, iters 60465\n",
      "End of epoch 145 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 35, time: 0.058, data: 0.001) G_GAN: 5.445 G_L1: 6.881 D_real: 0.005 D_fake: 0.006 \n",
      "(epoch: 146, iters: 135, time: 0.058, data: 0.001) G_GAN: 1.905 G_L1: 5.814 D_real: 0.042 D_fake: 0.277 \n",
      "(epoch: 146, iters: 235, time: 0.058, data: 0.001) G_GAN: 1.765 G_L1: 3.056 D_real: 0.016 D_fake: 0.238 \n",
      "(epoch: 146, iters: 335, time: 0.169, data: 0.001) G_GAN: 2.639 G_L1: 2.766 D_real: 0.154 D_fake: 0.090 \n",
      "End of epoch 146 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 18, time: 0.057, data: 0.001) G_GAN: 6.141 G_L1: 8.731 D_real: 0.003 D_fake: 0.004 \n",
      "(epoch: 147, iters: 118, time: 0.058, data: 0.001) G_GAN: 3.040 G_L1: 11.021 D_real: 0.184 D_fake: 0.031 \n",
      "(epoch: 147, iters: 218, time: 0.058, data: 0.001) G_GAN: 1.804 G_L1: 4.880 D_real: 0.173 D_fake: 0.219 \n",
      "(epoch: 147, iters: 318, time: 0.173, data: 0.001) G_GAN: 2.448 G_L1: 4.661 D_real: 0.110 D_fake: 0.113 \n",
      "End of epoch 147 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 1, time: 0.033, data: 0.001) G_GAN: 3.164 G_L1: 7.201 D_real: 0.143 D_fake: 0.061 \n",
      "(epoch: 148, iters: 101, time: 0.058, data: 0.000) G_GAN: 2.060 G_L1: 11.201 D_real: 0.025 D_fake: 0.475 \n",
      "(epoch: 148, iters: 201, time: 0.059, data: 0.001) G_GAN: 1.499 G_L1: 2.387 D_real: 0.360 D_fake: 0.313 \n",
      "(epoch: 148, iters: 301, time: 0.175, data: 0.001) G_GAN: 3.173 G_L1: 7.395 D_real: 0.142 D_fake: 0.041 \n",
      "(epoch: 148, iters: 401, time: 0.058, data: 0.001) G_GAN: 1.258 G_L1: 3.402 D_real: 0.013 D_fake: 0.756 \n",
      "End of epoch 148 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 84, time: 0.058, data: 0.001) G_GAN: 1.873 G_L1: 10.393 D_real: 0.038 D_fake: 0.447 \n",
      "(epoch: 149, iters: 184, time: 0.059, data: 0.001) G_GAN: 7.356 G_L1: 11.423 D_real: 0.123 D_fake: 0.001 \n",
      "(epoch: 149, iters: 284, time: 0.218, data: 0.001) G_GAN: 9.095 G_L1: 7.070 D_real: 0.098 D_fake: 0.000 \n",
      "(epoch: 149, iters: 384, time: 0.058, data: 0.001) G_GAN: 3.902 G_L1: 11.915 D_real: 0.014 D_fake: 0.027 \n",
      "End of epoch 149 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 67, time: 0.058, data: 0.001) G_GAN: 2.567 G_L1: 9.589 D_real: 0.064 D_fake: 0.118 \n",
      "(epoch: 150, iters: 167, time: 0.058, data: 0.001) G_GAN: 6.501 G_L1: 11.652 D_real: 0.005 D_fake: 0.002 \n",
      "(epoch: 150, iters: 267, time: 0.169, data: 0.001) G_GAN: 1.397 G_L1: 3.326 D_real: 0.011 D_fake: 0.375 \n",
      "(epoch: 150, iters: 367, time: 0.058, data: 0.001) G_GAN: 2.074 G_L1: 15.041 D_real: 0.091 D_fake: 0.538 \n",
      "saving the model at the end of epoch 150, iters 62550\n",
      "End of epoch 150 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 50, time: 0.059, data: 0.001) G_GAN: 8.093 G_L1: 4.771 D_real: 0.315 D_fake: 0.000 \n",
      "(epoch: 151, iters: 150, time: 0.058, data: 0.001) G_GAN: 2.999 G_L1: 8.438 D_real: 0.141 D_fake: 0.072 \n",
      "(epoch: 151, iters: 250, time: 0.175, data: 0.001) G_GAN: 2.108 G_L1: 10.437 D_real: 0.146 D_fake: 0.182 \n",
      "(epoch: 151, iters: 350, time: 0.058, data: 0.001) G_GAN: 2.309 G_L1: 6.972 D_real: 0.074 D_fake: 0.163 \n",
      "End of epoch 151 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 33, time: 0.057, data: 0.001) G_GAN: 2.825 G_L1: 4.360 D_real: 0.396 D_fake: 0.060 \n",
      "(epoch: 152, iters: 133, time: 0.058, data: 0.001) G_GAN: 1.208 G_L1: 5.072 D_real: 0.095 D_fake: 1.291 \n",
      "(epoch: 152, iters: 233, time: 0.174, data: 0.001) G_GAN: 3.615 G_L1: 8.307 D_real: 0.024 D_fake: 0.026 \n",
      "(epoch: 152, iters: 333, time: 0.058, data: 0.001) G_GAN: 1.514 G_L1: 6.491 D_real: 0.028 D_fake: 0.983 \n",
      "End of epoch 152 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 16, time: 0.058, data: 0.001) G_GAN: 1.421 G_L1: 9.265 D_real: 0.072 D_fake: 0.643 \n",
      "(epoch: 153, iters: 116, time: 0.058, data: 0.001) G_GAN: 2.295 G_L1: 5.734 D_real: 0.050 D_fake: 0.262 \n",
      "(epoch: 153, iters: 216, time: 0.181, data: 0.001) G_GAN: 1.617 G_L1: 6.287 D_real: 0.174 D_fake: 0.507 \n",
      "(epoch: 153, iters: 316, time: 0.058, data: 0.001) G_GAN: 3.596 G_L1: 11.774 D_real: 0.083 D_fake: 0.032 \n",
      "(epoch: 153, iters: 416, time: 0.059, data: 0.001) G_GAN: 6.123 G_L1: 5.263 D_real: 0.008 D_fake: 0.003 \n",
      "End of epoch 153 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 99, time: 0.058, data: 0.001) G_GAN: 2.306 G_L1: 2.951 D_real: 0.168 D_fake: 0.118 \n",
      "(epoch: 154, iters: 199, time: 0.227, data: 0.001) G_GAN: 1.327 G_L1: 11.911 D_real: 0.300 D_fake: 0.739 \n",
      "(epoch: 154, iters: 299, time: 0.058, data: 0.001) G_GAN: 5.631 G_L1: 7.315 D_real: 0.009 D_fake: 0.006 \n",
      "(epoch: 154, iters: 399, time: 0.058, data: 0.001) G_GAN: 4.977 G_L1: 10.497 D_real: 0.006 D_fake: 0.015 \n",
      "End of epoch 154 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 82, time: 0.059, data: 0.001) G_GAN: 7.499 G_L1: 6.273 D_real: 0.160 D_fake: 0.001 \n",
      "(epoch: 155, iters: 182, time: 0.178, data: 0.001) G_GAN: 6.291 G_L1: 10.170 D_real: 0.049 D_fake: 0.003 \n",
      "(epoch: 155, iters: 282, time: 0.059, data: 0.001) G_GAN: 7.474 G_L1: 5.188 D_real: 0.002 D_fake: 0.001 \n",
      "(epoch: 155, iters: 382, time: 0.058, data: 0.001) G_GAN: 3.330 G_L1: 10.541 D_real: 0.246 D_fake: 0.048 \n",
      "saving the model at the end of epoch 155, iters 64635\n",
      "End of epoch 155 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 65, time: 0.057, data: 0.001) G_GAN: 2.057 G_L1: 7.428 D_real: 0.223 D_fake: 0.159 \n",
      "(epoch: 156, iters: 165, time: 0.184, data: 0.001) G_GAN: 2.729 G_L1: 4.331 D_real: 0.389 D_fake: 0.082 \n",
      "(epoch: 156, iters: 265, time: 0.058, data: 0.001) G_GAN: 2.617 G_L1: 8.385 D_real: 0.008 D_fake: 0.115 \n",
      "(epoch: 156, iters: 365, time: 0.058, data: 0.001) G_GAN: 2.417 G_L1: 5.237 D_real: 0.027 D_fake: 0.148 \n",
      "saving the latest model (epoch 156, total_iters 65000)\n",
      "End of epoch 156 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 48, time: 0.060, data: 0.001) G_GAN: 3.257 G_L1: 7.194 D_real: 0.015 D_fake: 0.052 \n",
      "(epoch: 157, iters: 148, time: 0.171, data: 0.001) G_GAN: 0.578 G_L1: 0.068 D_real: 0.534 D_fake: 0.893 \n",
      "(epoch: 157, iters: 248, time: 0.058, data: 0.001) G_GAN: 10.143 G_L1: 14.242 D_real: 0.004 D_fake: 0.000 \n",
      "(epoch: 157, iters: 348, time: 0.058, data: 0.001) G_GAN: 10.232 G_L1: 6.918 D_real: 0.021 D_fake: 0.000 \n",
      "End of epoch 157 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 31, time: 0.058, data: 0.001) G_GAN: 3.619 G_L1: 17.498 D_real: 0.014 D_fake: 0.030 \n",
      "(epoch: 158, iters: 131, time: 0.184, data: 0.001) G_GAN: 2.285 G_L1: 7.498 D_real: 0.061 D_fake: 0.192 \n",
      "(epoch: 158, iters: 231, time: 0.059, data: 0.001) G_GAN: 4.869 G_L1: 18.795 D_real: 0.030 D_fake: 0.011 \n",
      "(epoch: 158, iters: 331, time: 0.058, data: 0.001) G_GAN: 1.539 G_L1: 6.077 D_real: 1.312 D_fake: 0.062 \n",
      "End of epoch 158 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 14, time: 0.058, data: 0.001) G_GAN: 1.700 G_L1: 10.122 D_real: 0.082 D_fake: 0.847 \n",
      "(epoch: 159, iters: 114, time: 0.222, data: 0.001) G_GAN: 2.758 G_L1: 19.184 D_real: 0.003 D_fake: 0.071 \n",
      "(epoch: 159, iters: 214, time: 0.058, data: 0.001) G_GAN: 3.472 G_L1: 8.297 D_real: 0.029 D_fake: 0.050 \n",
      "(epoch: 159, iters: 314, time: 0.058, data: 0.001) G_GAN: 1.212 G_L1: 8.226 D_real: 0.034 D_fake: 0.842 \n",
      "(epoch: 159, iters: 414, time: 0.059, data: 0.001) G_GAN: 2.072 G_L1: 9.023 D_real: 1.587 D_fake: 0.032 \n",
      "End of epoch 159 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 97, time: 0.180, data: 0.001) G_GAN: 1.296 G_L1: 2.101 D_real: 0.650 D_fake: 0.311 \n",
      "(epoch: 160, iters: 197, time: 0.059, data: 0.001) G_GAN: 1.955 G_L1: 4.796 D_real: 0.030 D_fake: 0.226 \n",
      "(epoch: 160, iters: 297, time: 0.058, data: 0.001) G_GAN: 1.792 G_L1: 5.597 D_real: 0.915 D_fake: 0.047 \n",
      "(epoch: 160, iters: 397, time: 0.058, data: 0.001) G_GAN: 4.713 G_L1: 14.272 D_real: 0.001 D_fake: 0.013 \n",
      "saving the model at the end of epoch 160, iters 66720\n",
      "End of epoch 160 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 80, time: 0.192, data: 0.001) G_GAN: 1.075 G_L1: 8.582 D_real: 0.113 D_fake: 2.011 \n",
      "(epoch: 161, iters: 180, time: 0.058, data: 0.001) G_GAN: 1.600 G_L1: 4.372 D_real: 0.316 D_fake: 0.289 \n",
      "(epoch: 161, iters: 280, time: 0.057, data: 0.001) G_GAN: 4.328 G_L1: 7.577 D_real: 0.133 D_fake: 0.013 \n",
      "(epoch: 161, iters: 380, time: 0.059, data: 0.001) G_GAN: 3.695 G_L1: 15.836 D_real: 1.168 D_fake: 0.010 \n",
      "End of epoch 161 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 63, time: 0.188, data: 0.001) G_GAN: 2.437 G_L1: 7.901 D_real: 0.665 D_fake: 0.057 \n",
      "(epoch: 162, iters: 163, time: 0.059, data: 0.001) G_GAN: 0.443 G_L1: 7.571 D_real: 2.407 D_fake: 0.344 \n",
      "(epoch: 162, iters: 263, time: 0.058, data: 0.001) G_GAN: 6.334 G_L1: 14.275 D_real: 0.001 D_fake: 0.003 \n",
      "(epoch: 162, iters: 363, time: 0.058, data: 0.001) G_GAN: 6.650 G_L1: 10.352 D_real: 0.001 D_fake: 0.002 \n",
      "End of epoch 162 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 46, time: 0.228, data: 0.001) G_GAN: 4.356 G_L1: 5.978 D_real: 0.119 D_fake: 0.014 \n",
      "(epoch: 163, iters: 146, time: 0.058, data: 0.001) G_GAN: 3.860 G_L1: 7.511 D_real: 0.000 D_fake: 0.026 \n",
      "(epoch: 163, iters: 246, time: 0.058, data: 0.001) G_GAN: 1.244 G_L1: 0.576 D_real: 1.476 D_fake: 0.276 \n",
      "(epoch: 163, iters: 346, time: 0.058, data: 0.001) G_GAN: 8.601 G_L1: 8.781 D_real: 0.020 D_fake: 0.000 \n",
      "End of epoch 163 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 29, time: 0.189, data: 0.001) G_GAN: 10.301 G_L1: 5.633 D_real: 0.004 D_fake: 0.000 \n",
      "(epoch: 164, iters: 129, time: 0.058, data: 0.001) G_GAN: 5.389 G_L1: 7.492 D_real: 0.046 D_fake: 0.006 \n",
      "(epoch: 164, iters: 229, time: 0.058, data: 0.001) G_GAN: 2.680 G_L1: 8.596 D_real: 0.057 D_fake: 0.092 \n",
      "(epoch: 164, iters: 329, time: 0.058, data: 0.001) G_GAN: 1.820 G_L1: 4.402 D_real: 0.003 D_fake: 0.337 \n",
      "End of epoch 164 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 12, time: 0.192, data: 0.001) G_GAN: 1.582 G_L1: 7.166 D_real: 0.103 D_fake: 0.428 \n",
      "(epoch: 165, iters: 112, time: 0.058, data: 0.001) G_GAN: 3.501 G_L1: 13.282 D_real: 0.012 D_fake: 0.031 \n",
      "(epoch: 165, iters: 212, time: 0.058, data: 0.001) G_GAN: 2.733 G_L1: 14.844 D_real: 0.000 D_fake: 0.117 \n",
      "(epoch: 165, iters: 312, time: 0.058, data: 0.001) G_GAN: 9.603 G_L1: 17.635 D_real: 0.034 D_fake: 0.000 \n",
      "(epoch: 165, iters: 412, time: 0.185, data: 0.001) G_GAN: 8.333 G_L1: 6.827 D_real: 0.009 D_fake: 0.000 \n",
      "saving the model at the end of epoch 165, iters 68805\n",
      "End of epoch 165 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 95, time: 0.057, data: 0.001) G_GAN: 9.113 G_L1: 6.528 D_real: 0.018 D_fake: 0.000 \n",
      "(epoch: 166, iters: 195, time: 0.058, data: 0.001) G_GAN: 3.313 G_L1: 19.248 D_real: 0.011 D_fake: 0.042 \n",
      "(epoch: 166, iters: 295, time: 0.058, data: 0.001) G_GAN: 0.656 G_L1: 0.141 D_real: 0.626 D_fake: 0.781 \n",
      "(epoch: 166, iters: 395, time: 0.188, data: 0.001) G_GAN: 5.271 G_L1: 12.967 D_real: 0.007 D_fake: 0.005 \n",
      "End of epoch 166 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 78, time: 0.058, data: 0.001) G_GAN: 7.918 G_L1: 15.676 D_real: 0.005 D_fake: 0.001 \n",
      "(epoch: 167, iters: 178, time: 0.058, data: 0.001) G_GAN: 2.357 G_L1: 3.161 D_real: 0.021 D_fake: 0.250 \n",
      "(epoch: 167, iters: 278, time: 0.058, data: 0.001) G_GAN: 7.661 G_L1: 8.621 D_real: 0.021 D_fake: 0.001 \n",
      "(epoch: 167, iters: 378, time: 0.226, data: 0.001) G_GAN: 2.204 G_L1: 0.732 D_real: 3.005 D_fake: 0.057 \n",
      "End of epoch 167 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 61, time: 0.057, data: 0.001) G_GAN: 7.906 G_L1: 6.999 D_real: 0.185 D_fake: 0.000 \n",
      "(epoch: 168, iters: 161, time: 0.058, data: 0.001) G_GAN: 4.313 G_L1: 9.522 D_real: 0.037 D_fake: 0.017 \n",
      "(epoch: 168, iters: 261, time: 0.058, data: 0.001) G_GAN: 0.861 G_L1: 4.838 D_real: 0.006 D_fake: 3.325 \n",
      "(epoch: 168, iters: 361, time: 0.189, data: 0.001) G_GAN: 3.504 G_L1: 16.380 D_real: 0.001 D_fake: 0.044 \n",
      "saving the latest model (epoch 168, total_iters 70000)\n",
      "End of epoch 168 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 44, time: 0.057, data: 0.001) G_GAN: 3.254 G_L1: 10.666 D_real: 0.246 D_fake: 0.030 \n",
      "(epoch: 169, iters: 144, time: 0.057, data: 0.001) G_GAN: 1.489 G_L1: 7.601 D_real: 0.229 D_fake: 0.715 \n",
      "(epoch: 169, iters: 244, time: 0.058, data: 0.001) G_GAN: 3.767 G_L1: 16.382 D_real: 0.001 D_fake: 0.041 \n",
      "(epoch: 169, iters: 344, time: 0.194, data: 0.001) G_GAN: 10.766 G_L1: 11.108 D_real: 0.015 D_fake: 0.000 \n",
      "End of epoch 169 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 27, time: 0.058, data: 0.001) G_GAN: 4.272 G_L1: 10.596 D_real: 0.051 D_fake: 0.016 \n",
      "(epoch: 170, iters: 127, time: 0.058, data: 0.001) G_GAN: 8.964 G_L1: 7.111 D_real: 0.002 D_fake: 0.000 \n",
      "(epoch: 170, iters: 227, time: 0.058, data: 0.001) G_GAN: 1.889 G_L1: 7.776 D_real: 0.026 D_fake: 0.503 \n",
      "(epoch: 170, iters: 327, time: 0.185, data: 0.001) G_GAN: 1.836 G_L1: 8.755 D_real: 0.007 D_fake: 0.514 \n",
      "saving the model at the end of epoch 170, iters 70890\n",
      "End of epoch 170 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 10, time: 0.058, data: 0.001) G_GAN: 0.646 G_L1: 0.163 D_real: 0.603 D_fake: 0.819 \n",
      "(epoch: 171, iters: 110, time: 0.058, data: 0.001) G_GAN: 2.943 G_L1: 6.604 D_real: 0.036 D_fake: 0.062 \n",
      "(epoch: 171, iters: 210, time: 0.058, data: 0.001) G_GAN: 2.304 G_L1: 20.597 D_real: 0.005 D_fake: 0.115 \n",
      "(epoch: 171, iters: 310, time: 0.227, data: 0.001) G_GAN: 1.797 G_L1: 0.783 D_real: 1.242 D_fake: 0.125 \n",
      "(epoch: 171, iters: 410, time: 0.058, data: 0.001) G_GAN: 4.132 G_L1: 5.840 D_real: 0.135 D_fake: 0.019 \n",
      "End of epoch 171 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 93, time: 0.058, data: 0.001) G_GAN: 2.194 G_L1: 10.115 D_real: 0.013 D_fake: 0.243 \n",
      "(epoch: 172, iters: 193, time: 0.058, data: 0.001) G_GAN: 1.862 G_L1: 11.054 D_real: 0.037 D_fake: 0.290 \n",
      "(epoch: 172, iters: 293, time: 0.188, data: 0.001) G_GAN: 1.760 G_L1: 4.053 D_real: 0.083 D_fake: 0.184 \n",
      "(epoch: 172, iters: 393, time: 0.058, data: 0.001) G_GAN: 3.167 G_L1: 8.496 D_real: 0.042 D_fake: 0.056 \n",
      "End of epoch 172 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 76, time: 0.058, data: 0.001) G_GAN: 4.309 G_L1: 4.595 D_real: 0.047 D_fake: 0.023 \n",
      "(epoch: 173, iters: 176, time: 0.058, data: 0.001) G_GAN: 1.089 G_L1: 14.223 D_real: 0.024 D_fake: 2.442 \n",
      "(epoch: 173, iters: 276, time: 0.186, data: 0.001) G_GAN: 1.933 G_L1: 2.456 D_real: 0.012 D_fake: 0.181 \n",
      "(epoch: 173, iters: 376, time: 0.058, data: 0.001) G_GAN: 3.882 G_L1: 9.642 D_real: 0.182 D_fake: 0.023 \n",
      "End of epoch 173 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 59, time: 0.058, data: 0.001) G_GAN: 4.483 G_L1: 12.871 D_real: 0.058 D_fake: 0.016 \n",
      "(epoch: 174, iters: 159, time: 0.059, data: 0.001) G_GAN: 1.351 G_L1: 3.969 D_real: 0.046 D_fake: 0.328 \n",
      "(epoch: 174, iters: 259, time: 0.190, data: 0.001) G_GAN: 1.115 G_L1: 0.562 D_real: 1.183 D_fake: 0.361 \n",
      "(epoch: 174, iters: 359, time: 0.058, data: 0.001) G_GAN: 1.037 G_L1: 0.077 D_real: 1.068 D_fake: 0.428 \n",
      "End of epoch 174 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 42, time: 0.058, data: 0.001) G_GAN: 4.321 G_L1: 12.119 D_real: 0.001 D_fake: 0.017 \n",
      "(epoch: 175, iters: 142, time: 0.058, data: 0.001) G_GAN: 2.894 G_L1: 8.919 D_real: 0.022 D_fake: 0.080 \n",
      "(epoch: 175, iters: 242, time: 0.237, data: 0.001) G_GAN: 7.583 G_L1: 9.509 D_real: 0.001 D_fake: 0.001 \n",
      "(epoch: 175, iters: 342, time: 0.058, data: 0.001) G_GAN: 6.097 G_L1: 5.549 D_real: 0.032 D_fake: 0.003 \n",
      "saving the model at the end of epoch 175, iters 72975\n",
      "End of epoch 175 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 25, time: 0.062, data: 0.001) G_GAN: 4.678 G_L1: 7.622 D_real: 0.046 D_fake: 0.013 \n",
      "(epoch: 176, iters: 125, time: 0.058, data: 0.001) G_GAN: 0.536 G_L1: 0.134 D_real: 0.526 D_fake: 0.917 \n",
      "(epoch: 176, iters: 225, time: 0.198, data: 0.001) G_GAN: 2.003 G_L1: 11.159 D_real: 0.002 D_fake: 0.218 \n",
      "(epoch: 176, iters: 325, time: 0.058, data: 0.001) G_GAN: 2.408 G_L1: 9.058 D_real: 0.014 D_fake: 0.158 \n",
      "End of epoch 176 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 8, time: 0.059, data: 0.001) G_GAN: 1.139 G_L1: 15.456 D_real: 0.192 D_fake: 0.841 \n",
      "(epoch: 177, iters: 108, time: 0.058, data: 0.001) G_GAN: 10.062 G_L1: 7.871 D_real: 0.000 D_fake: 0.000 \n",
      "(epoch: 177, iters: 208, time: 0.194, data: 0.001) G_GAN: 10.025 G_L1: 6.417 D_real: 0.000 D_fake: 0.000 \n",
      "(epoch: 177, iters: 308, time: 0.057, data: 0.001) G_GAN: 0.302 G_L1: 3.734 D_real: 0.011 D_fake: 2.517 \n",
      "(epoch: 177, iters: 408, time: 0.058, data: 0.001) G_GAN: 5.488 G_L1: 12.606 D_real: 0.011 D_fake: 0.007 \n",
      "End of epoch 177 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 91, time: 0.057, data: 0.001) G_GAN: 7.214 G_L1: 11.067 D_real: 0.048 D_fake: 0.001 \n",
      "(epoch: 178, iters: 191, time: 0.199, data: 0.001) G_GAN: 5.798 G_L1: 5.079 D_real: 0.622 D_fake: 0.002 \n",
      "(epoch: 178, iters: 291, time: 0.058, data: 0.001) G_GAN: 1.651 G_L1: 6.993 D_real: 0.230 D_fake: 0.390 \n",
      "(epoch: 178, iters: 391, time: 0.057, data: 0.001) G_GAN: 4.236 G_L1: 11.240 D_real: 0.214 D_fake: 0.015 \n",
      "End of epoch 178 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 74, time: 0.059, data: 0.001) G_GAN: 7.222 G_L1: 7.243 D_real: 0.098 D_fake: 0.001 \n",
      "(epoch: 179, iters: 174, time: 0.238, data: 0.001) G_GAN: 4.416 G_L1: 6.225 D_real: 0.007 D_fake: 0.014 \n",
      "(epoch: 179, iters: 274, time: 0.058, data: 0.001) G_GAN: 1.487 G_L1: 0.229 D_real: 1.642 D_fake: 0.225 \n",
      "(epoch: 179, iters: 374, time: 0.058, data: 0.001) G_GAN: 3.113 G_L1: 13.486 D_real: 0.038 D_fake: 0.056 \n",
      "End of epoch 179 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000416\n",
      "(epoch: 180, iters: 57, time: 0.058, data: 0.001) G_GAN: 2.834 G_L1: 9.284 D_real: 0.002 D_fake: 0.112 \n",
      "(epoch: 180, iters: 157, time: 0.197, data: 0.001) G_GAN: 2.696 G_L1: 6.574 D_real: 0.001 D_fake: 0.077 \n",
      "(epoch: 180, iters: 257, time: 0.057, data: 0.001) G_GAN: 5.516 G_L1: 4.943 D_real: 1.437 D_fake: 0.001 \n",
      "(epoch: 180, iters: 357, time: 0.059, data: 0.001) G_GAN: 6.545 G_L1: 12.640 D_real: 0.013 D_fake: 0.002 \n",
      "saving the latest model (epoch 180, total_iters 75000)\n",
      "saving the model at the end of epoch 180, iters 75060\n",
      "End of epoch 180 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 40, time: 0.058, data: 0.001) G_GAN: 5.485 G_L1: 8.156 D_real: 0.033 D_fake: 0.006 \n",
      "(epoch: 181, iters: 140, time: 0.192, data: 0.001) G_GAN: 0.804 G_L1: 0.252 D_real: 0.849 D_fake: 0.585 \n",
      "(epoch: 181, iters: 240, time: 0.058, data: 0.001) G_GAN: 4.625 G_L1: 9.077 D_real: 0.070 D_fake: 0.012 \n",
      "(epoch: 181, iters: 340, time: 0.058, data: 0.001) G_GAN: 0.716 G_L1: 11.301 D_real: 0.002 D_fake: 1.691 \n",
      "End of epoch 181 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 23, time: 0.060, data: 0.001) G_GAN: 2.126 G_L1: 8.630 D_real: 0.011 D_fake: 0.143 \n",
      "(epoch: 182, iters: 123, time: 0.204, data: 0.001) G_GAN: 8.553 G_L1: 20.393 D_real: 0.044 D_fake: 0.000 \n",
      "(epoch: 182, iters: 223, time: 0.058, data: 0.001) G_GAN: 5.637 G_L1: 14.857 D_real: 0.028 D_fake: 0.004 \n",
      "(epoch: 182, iters: 323, time: 0.058, data: 0.001) G_GAN: 1.905 G_L1: 10.501 D_real: 0.014 D_fake: 0.241 \n",
      "End of epoch 182 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 6, time: 0.057, data: 0.001) G_GAN: 1.658 G_L1: 10.755 D_real: 0.002 D_fake: 0.230 \n",
      "(epoch: 183, iters: 106, time: 0.237, data: 0.000) G_GAN: 0.645 G_L1: 7.981 D_real: 0.017 D_fake: 1.387 \n",
      "(epoch: 183, iters: 206, time: 0.058, data: 0.001) G_GAN: 6.845 G_L1: 4.891 D_real: 0.017 D_fake: 0.002 \n",
      "(epoch: 183, iters: 306, time: 0.057, data: 0.001) G_GAN: 1.238 G_L1: 3.715 D_real: 0.182 D_fake: 0.420 \n",
      "(epoch: 183, iters: 406, time: 0.060, data: 0.001) G_GAN: 1.693 G_L1: 8.779 D_real: 0.038 D_fake: 0.292 \n",
      "End of epoch 183 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 89, time: 0.193, data: 0.001) G_GAN: 3.566 G_L1: 3.923 D_real: 0.071 D_fake: 0.031 \n",
      "(epoch: 184, iters: 189, time: 0.057, data: 0.001) G_GAN: 1.536 G_L1: 6.542 D_real: 0.035 D_fake: 0.428 \n",
      "(epoch: 184, iters: 289, time: 0.057, data: 0.001) G_GAN: 2.109 G_L1: 13.875 D_real: 0.089 D_fake: 0.153 \n",
      "(epoch: 184, iters: 389, time: 0.057, data: 0.001) G_GAN: 3.823 G_L1: 9.893 D_real: 0.018 D_fake: 0.023 \n",
      "End of epoch 184 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 72, time: 0.200, data: 0.001) G_GAN: 6.267 G_L1: 8.956 D_real: 0.007 D_fake: 0.003 \n",
      "(epoch: 185, iters: 172, time: 0.058, data: 0.001) G_GAN: 1.922 G_L1: 2.780 D_real: 0.069 D_fake: 0.171 \n",
      "(epoch: 185, iters: 272, time: 0.057, data: 0.001) G_GAN: 2.052 G_L1: 0.750 D_real: 2.299 D_fake: 0.112 \n",
      "(epoch: 185, iters: 372, time: 0.057, data: 0.001) G_GAN: 0.574 G_L1: 4.829 D_real: 0.013 D_fake: 1.555 \n",
      "saving the model at the end of epoch 185, iters 77145\n",
      "End of epoch 185 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 55, time: 0.199, data: 0.001) G_GAN: 1.995 G_L1: 4.710 D_real: 0.091 D_fake: 0.175 \n",
      "(epoch: 186, iters: 155, time: 0.057, data: 0.001) G_GAN: 5.058 G_L1: 6.837 D_real: 0.019 D_fake: 0.006 \n",
      "(epoch: 186, iters: 255, time: 0.057, data: 0.001) G_GAN: 8.876 G_L1: 6.156 D_real: 0.003 D_fake: 0.000 \n",
      "(epoch: 186, iters: 355, time: 0.057, data: 0.001) G_GAN: 9.338 G_L1: 14.850 D_real: 0.000 D_fake: 0.000 \n",
      "End of epoch 186 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 38, time: 0.242, data: 0.001) G_GAN: 9.871 G_L1: 12.299 D_real: 0.000 D_fake: 0.000 \n",
      "(epoch: 187, iters: 138, time: 0.057, data: 0.001) G_GAN: 1.032 G_L1: 5.691 D_real: 0.155 D_fake: 0.635 \n",
      "(epoch: 187, iters: 238, time: 0.057, data: 0.001) G_GAN: 1.368 G_L1: 0.449 D_real: 1.506 D_fake: 0.268 \n",
      "(epoch: 187, iters: 338, time: 0.057, data: 0.001) G_GAN: 3.440 G_L1: 16.523 D_real: 0.003 D_fake: 0.040 \n",
      "End of epoch 187 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 21, time: 0.195, data: 0.001) G_GAN: 0.994 G_L1: 0.956 D_real: 0.089 D_fake: 0.492 \n",
      "(epoch: 188, iters: 121, time: 0.057, data: 0.001) G_GAN: 9.486 G_L1: 10.524 D_real: 0.001 D_fake: 0.000 \n",
      "(epoch: 188, iters: 221, time: 0.057, data: 0.001) G_GAN: 7.879 G_L1: 8.063 D_real: 0.008 D_fake: 0.001 \n",
      "(epoch: 188, iters: 321, time: 0.057, data: 0.001) G_GAN: 3.193 G_L1: 11.411 D_real: 0.001 D_fake: 0.051 \n",
      "End of epoch 188 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 4, time: 0.202, data: 0.001) G_GAN: 2.432 G_L1: 8.546 D_real: 0.023 D_fake: 0.116 \n",
      "(epoch: 189, iters: 104, time: 0.057, data: 0.002) G_GAN: 5.458 G_L1: 10.181 D_real: 0.010 D_fake: 0.005 \n",
      "(epoch: 189, iters: 204, time: 0.057, data: 0.001) G_GAN: 9.581 G_L1: 6.090 D_real: 0.075 D_fake: 0.000 \n",
      "(epoch: 189, iters: 304, time: 0.057, data: 0.001) G_GAN: 6.489 G_L1: 8.679 D_real: 0.879 D_fake: 0.001 \n",
      "(epoch: 189, iters: 404, time: 0.197, data: 0.001) G_GAN: 3.772 G_L1: 6.382 D_real: 0.097 D_fake: 0.027 \n",
      "End of epoch 189 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 87, time: 0.057, data: 0.002) G_GAN: 4.818 G_L1: 13.391 D_real: 0.001 D_fake: 0.011 \n",
      "(epoch: 190, iters: 187, time: 0.057, data: 0.001) G_GAN: 1.634 G_L1: 5.867 D_real: 0.263 D_fake: 0.252 \n",
      "(epoch: 190, iters: 287, time: 0.057, data: 0.001) G_GAN: 5.293 G_L1: 1.537 D_real: 0.078 D_fake: 0.007 \n",
      "(epoch: 190, iters: 387, time: 0.239, data: 0.001) G_GAN: 5.368 G_L1: 19.838 D_real: 0.004 D_fake: 0.007 \n",
      "saving the model at the end of epoch 190, iters 79230\n",
      "End of epoch 190 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 70, time: 0.057, data: 0.001) G_GAN: 3.683 G_L1: 23.612 D_real: 0.001 D_fake: 0.031 \n",
      "(epoch: 191, iters: 170, time: 0.057, data: 0.001) G_GAN: 7.961 G_L1: 8.456 D_real: 0.008 D_fake: 0.000 \n",
      "(epoch: 191, iters: 270, time: 0.058, data: 0.001) G_GAN: 0.733 G_L1: 7.237 D_real: 0.054 D_fake: 1.109 \n",
      "(epoch: 191, iters: 370, time: 0.200, data: 0.001) G_GAN: 3.289 G_L1: 3.631 D_real: 0.123 D_fake: 0.037 \n",
      "End of epoch 191 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 53, time: 0.057, data: 0.001) G_GAN: 5.494 G_L1: 7.009 D_real: 0.159 D_fake: 0.005 \n",
      "(epoch: 192, iters: 153, time: 0.056, data: 0.001) G_GAN: 11.854 G_L1: 8.547 D_real: 0.027 D_fake: 0.000 \n",
      "(epoch: 192, iters: 253, time: 0.082, data: 0.001) G_GAN: 1.822 G_L1: 0.545 D_real: 2.000 D_fake: 0.159 \n",
      "(epoch: 192, iters: 353, time: 0.268, data: 0.001) G_GAN: 1.280 G_L1: 8.795 D_real: 0.024 D_fake: 0.478 \n",
      "saving the latest model (epoch 192, total_iters 80000)\n",
      "End of epoch 192 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 36, time: 0.056, data: 0.001) G_GAN: 9.314 G_L1: 8.979 D_real: 0.007 D_fake: 0.000 \n",
      "(epoch: 193, iters: 136, time: 0.056, data: 0.001) G_GAN: 1.370 G_L1: 0.760 D_real: 1.391 D_fake: 0.284 \n",
      "(epoch: 193, iters: 236, time: 0.057, data: 0.001) G_GAN: 2.033 G_L1: 11.815 D_real: 0.020 D_fake: 0.180 \n",
      "(epoch: 193, iters: 336, time: 0.201, data: 0.001) G_GAN: 2.846 G_L1: 14.550 D_real: 0.001 D_fake: 0.069 \n",
      "End of epoch 193 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 19, time: 0.057, data: 0.001) G_GAN: 5.791 G_L1: 8.726 D_real: 0.003 D_fake: 0.004 \n",
      "(epoch: 194, iters: 119, time: 0.057, data: 0.001) G_GAN: 4.580 G_L1: 6.956 D_real: 0.072 D_fake: 0.014 \n",
      "(epoch: 194, iters: 219, time: 0.057, data: 0.001) G_GAN: 8.578 G_L1: 8.015 D_real: 0.034 D_fake: 0.000 \n",
      "(epoch: 194, iters: 319, time: 0.251, data: 0.001) G_GAN: 4.278 G_L1: 2.700 D_real: 0.301 D_fake: 0.015 \n",
      "End of epoch 194 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 2, time: 0.045, data: 0.001) G_GAN: 1.895 G_L1: 5.351 D_real: 0.249 D_fake: 0.166 \n",
      "(epoch: 195, iters: 102, time: 0.058, data: 0.000) G_GAN: 4.446 G_L1: 7.657 D_real: 0.017 D_fake: 0.014 \n",
      "(epoch: 195, iters: 202, time: 0.059, data: 0.001) G_GAN: 1.990 G_L1: 4.643 D_real: 0.031 D_fake: 0.190 \n",
      "(epoch: 195, iters: 302, time: 0.204, data: 0.001) G_GAN: 3.683 G_L1: 12.662 D_real: 0.315 D_fake: 0.025 \n",
      "(epoch: 195, iters: 402, time: 0.057, data: 0.001) G_GAN: 7.999 G_L1: 10.404 D_real: 0.079 D_fake: 0.001 \n",
      "saving the model at the end of epoch 195, iters 81315\n",
      "End of epoch 195 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 85, time: 0.057, data: 0.001) G_GAN: 1.150 G_L1: 9.654 D_real: 0.090 D_fake: 0.462 \n",
      "(epoch: 196, iters: 185, time: 0.059, data: 0.001) G_GAN: 1.947 G_L1: 18.775 D_real: 0.001 D_fake: 0.161 \n",
      "(epoch: 196, iters: 285, time: 0.206, data: 0.001) G_GAN: 2.699 G_L1: 12.587 D_real: 0.001 D_fake: 0.073 \n",
      "(epoch: 196, iters: 385, time: 0.057, data: 0.001) G_GAN: 2.762 G_L1: 3.771 D_real: 0.667 D_fake: 0.074 \n",
      "End of epoch 196 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 68, time: 0.058, data: 0.001) G_GAN: 1.510 G_L1: 0.360 D_real: 1.567 D_fake: 0.246 \n",
      "(epoch: 197, iters: 168, time: 0.057, data: 0.001) G_GAN: 6.950 G_L1: 9.673 D_real: 0.084 D_fake: 0.001 \n",
      "(epoch: 197, iters: 268, time: 0.212, data: 0.001) G_GAN: 2.241 G_L1: 8.390 D_real: 0.218 D_fake: 0.135 \n",
      "(epoch: 197, iters: 368, time: 0.057, data: 0.001) G_GAN: 3.560 G_L1: 12.055 D_real: 0.047 D_fake: 0.037 \n",
      "End of epoch 197 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 51, time: 0.057, data: 0.001) G_GAN: 2.857 G_L1: 13.751 D_real: 0.001 D_fake: 0.065 \n",
      "(epoch: 198, iters: 151, time: 0.055, data: 0.001) G_GAN: 0.678 G_L1: 0.182 D_real: 0.660 D_fake: 0.720 \n",
      "(epoch: 198, iters: 251, time: 0.246, data: 0.001) G_GAN: 4.028 G_L1: 3.288 D_real: 0.007 D_fake: 0.020 \n",
      "(epoch: 198, iters: 351, time: 0.056, data: 0.001) G_GAN: 4.037 G_L1: 12.080 D_real: 0.014 D_fake: 0.024 \n",
      "End of epoch 198 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 34, time: 0.064, data: 0.001) G_GAN: 3.238 G_L1: 1.522 D_real: 0.255 D_fake: 0.042 \n",
      "(epoch: 199, iters: 134, time: 0.057, data: 0.001) G_GAN: 8.825 G_L1: 9.518 D_real: 0.002 D_fake: 0.000 \n",
      "(epoch: 199, iters: 234, time: 0.206, data: 0.001) G_GAN: 5.302 G_L1: 10.716 D_real: 0.023 D_fake: 0.006 \n",
      "(epoch: 199, iters: 334, time: 0.057, data: 0.001) G_GAN: 8.121 G_L1: 20.899 D_real: 1.366 D_fake: 0.000 \n",
      "End of epoch 199 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 17, time: 0.057, data: 0.001) G_GAN: 0.736 G_L1: 0.464 D_real: 0.761 D_fake: 0.656 \n",
      "(epoch: 200, iters: 117, time: 0.056, data: 0.001) G_GAN: 0.977 G_L1: 5.447 D_real: 0.086 D_fake: 0.542 \n",
      "(epoch: 200, iters: 217, time: 0.207, data: 0.001) G_GAN: 9.300 G_L1: 5.589 D_real: 0.291 D_fake: 0.000 \n",
      "(epoch: 200, iters: 317, time: 0.056, data: 0.001) G_GAN: 8.566 G_L1: 7.630 D_real: 0.087 D_fake: 0.000 \n",
      "(epoch: 200, iters: 417, time: 0.058, data: 0.001) G_GAN: 0.847 G_L1: 0.063 D_real: 0.848 D_fake: 0.575 \n",
      "saving the model at the end of epoch 200, iters 83400\n",
      "End of epoch 200 / 200 \t Time Taken: 16 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot extracolor/AB --model pix2pix --crop_size 128 --no_dropout --output_nc 1 --norm batch --checkpoints_dir apr25 --netG resnet_9blocks --preprocess crop --name apr19256_REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: apr25                         \t[default: ./checkpoints]\n",
      "                crop_size: 128                           \t[default: 256]\n",
      "                 dataroot: lp                            \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: apr19256_REAL                 \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: results_apr25                 \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from apr25/apr19256_REAL/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['lp/Alabama.jpg']\n",
      "processing (0005)-th image... ['lp/Colorado.jpg']\n",
      "processing (0010)-th image... ['lp/Georgia.jpg']\n",
      "processing (0015)-th image... ['lp/Indiana.jpg']\n",
      "processing (0020)-th image... ['lp/Maine.jpg']\n",
      "processing (0025)-th image... ['lp/Mississippi.jpg']\n",
      "processing (0030)-th image... ['lp/NewHampshire.jpg']\n",
      "processing (0035)-th image... ['lp/NorthDakota.jpg']\n",
      "processing (0040)-th image... ['lp/PuertoRico.jpg']\n",
      "processing (0045)-th image... ['lp/Texas.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot lp --dataset_mode single --model test --results_dir results_apr25 --netG resnet_9blocks --crop_size 128 --preprocess resize_and_crop --name apr19256_REAL  --norm batch --checkpoints_dir apr25 --output_nc 1 --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: may21                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: smallcluster                  \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: crop256                       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_jun22                 \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from may21/crop256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "DataParallel(\n",
      "  (module): ResnetGenerator(\n",
      "    (model): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (18): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (26): Conv2d(64, 1, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (27): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-----------------------------------------------\n",
      "The image size needs to be a multiple of 4. The loaded image size was (180, 49), so it was adjusted to (180, 48). This adjustment will be done to all images whose sizes are not multiples of 4\n",
      "processing (0000)-th image... ['smallcluster/1.JPG']\n",
      "processing (0005)-th image... ['smallcluster/111.JPG']\n",
      "processing (0010)-th image... ['smallcluster/15.JPG']\n",
      "processing (0015)-th image... ['smallcluster/24.JPG']\n",
      "processing (0020)-th image... ['smallcluster/36.JPG']\n",
      "processing (0025)-th image... ['smallcluster/53.JPG']\n",
      "processing (0030)-th image... ['smallcluster/76.JPG']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot smallcluster --dataset_mode single --model test --results_dir results_jun22 --netG resnet_9blocks --preprocess none --name crop256  --norm batch --checkpoints_dir may21 --output_nc 1 --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 3                             \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: may15                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: baw/AB                        \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: real396bw                     \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 396\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "[Network D] Total number of parameters : 2.767 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory may15/real396bw/web...\n",
      "(epoch: 1, iters: 300, time: 0.526, data: 0.103) G_GAN: 1.975 G_L1: 14.419 D_real: 0.404 D_fake: 0.226 \n",
      "End of epoch 1 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 204, time: 0.507, data: 0.002) G_GAN: 1.627 G_L1: 12.927 D_real: 0.195 D_fake: 0.908 \n",
      "End of epoch 2 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 108, time: 0.512, data: 0.002) G_GAN: 0.717 G_L1: 9.396 D_real: 0.978 D_fake: 0.330 \n",
      "End of epoch 3 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 12, time: 0.612, data: 0.002) G_GAN: 1.100 G_L1: 13.812 D_real: 0.739 D_fake: 0.385 \n",
      "(epoch: 4, iters: 312, time: 0.529, data: 0.003) G_GAN: 0.597 G_L1: 6.370 D_real: 0.519 D_fake: 0.728 \n",
      "End of epoch 4 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 216, time: 0.511, data: 0.002) G_GAN: 0.678 G_L1: 6.781 D_real: 1.760 D_fake: 0.264 \n",
      "saving the model at the end of epoch 5, iters 1980\n",
      "End of epoch 5 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 120, time: 0.513, data: 0.002) G_GAN: 0.945 G_L1: 10.190 D_real: 0.228 D_fake: 0.823 \n",
      "End of epoch 6 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 24, time: 0.603, data: 0.002) G_GAN: 0.933 G_L1: 6.683 D_real: 0.799 D_fake: 0.504 \n",
      "(epoch: 7, iters: 324, time: 0.559, data: 0.002) G_GAN: 0.911 G_L1: 8.306 D_real: 0.680 D_fake: 0.475 \n",
      "End of epoch 7 / 200 \t Time Taken: 135 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 228, time: 0.541, data: 0.002) G_GAN: 0.493 G_L1: 8.994 D_real: 0.505 D_fake: 0.847 \n",
      "End of epoch 8 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 132, time: 0.539, data: 0.002) G_GAN: 1.346 G_L1: 11.589 D_real: 0.483 D_fake: 0.337 \n",
      "End of epoch 9 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 36, time: 0.638, data: 0.003) G_GAN: 0.997 G_L1: 10.801 D_real: 0.255 D_fake: 0.727 \n",
      "(epoch: 10, iters: 336, time: 0.540, data: 0.002) G_GAN: 1.005 G_L1: 9.677 D_real: 0.690 D_fake: 0.363 \n",
      "saving the model at the end of epoch 10, iters 3960\n",
      "End of epoch 10 / 200 \t Time Taken: 138 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 240, time: 0.541, data: 0.002) G_GAN: 1.006 G_L1: 7.896 D_real: 0.281 D_fake: 0.896 \n",
      "End of epoch 11 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 144, time: 0.538, data: 0.002) G_GAN: 0.917 G_L1: 7.608 D_real: 0.509 D_fake: 0.524 \n",
      "End of epoch 12 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 48, time: 0.647, data: 0.002) G_GAN: 0.590 G_L1: 6.474 D_real: 0.900 D_fake: 0.431 \n",
      "(epoch: 13, iters: 348, time: 0.538, data: 0.002) G_GAN: 1.185 G_L1: 10.284 D_real: 0.328 D_fake: 0.482 \n",
      "End of epoch 13 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 252, time: 0.538, data: 0.002) G_GAN: 1.128 G_L1: 10.426 D_real: 0.098 D_fake: 1.354 \n",
      "End of epoch 14 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 156, time: 0.537, data: 0.002) G_GAN: 1.025 G_L1: 7.267 D_real: 0.631 D_fake: 0.455 \n",
      "saving the model at the end of epoch 15, iters 5940\n",
      "End of epoch 15 / 200 \t Time Taken: 138 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 60, time: 0.634, data: 0.002) G_GAN: 0.963 G_L1: 10.197 D_real: 0.379 D_fake: 0.499 \n",
      "(epoch: 16, iters: 360, time: 0.540, data: 0.002) G_GAN: 0.827 G_L1: 10.258 D_real: 0.567 D_fake: 0.495 \n",
      "End of epoch 16 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 264, time: 0.538, data: 0.002) G_GAN: 1.111 G_L1: 8.159 D_real: 0.228 D_fake: 0.906 \n",
      "End of epoch 17 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 168, time: 0.540, data: 0.002) G_GAN: 0.477 G_L1: 8.659 D_real: 0.105 D_fake: 2.085 \n",
      "End of epoch 18 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 72, time: 0.647, data: 0.002) G_GAN: 0.785 G_L1: 8.772 D_real: 0.239 D_fake: 0.987 \n",
      "(epoch: 19, iters: 372, time: 0.514, data: 0.002) G_GAN: 1.112 G_L1: 7.497 D_real: 1.306 D_fake: 0.283 \n",
      "End of epoch 19 / 200 \t Time Taken: 139 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 276, time: 0.513, data: 0.002) G_GAN: 1.111 G_L1: 6.269 D_real: 1.163 D_fake: 0.217 \n",
      "saving the model at the end of epoch 20, iters 7920\n",
      "End of epoch 20 / 200 \t Time Taken: 133 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 180, time: 0.514, data: 0.002) G_GAN: 0.687 G_L1: 6.103 D_real: 0.840 D_fake: 0.491 \n",
      "End of epoch 21 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 84, time: 0.617, data: 0.002) G_GAN: 0.829 G_L1: 5.157 D_real: 0.406 D_fake: 0.792 \n",
      "(epoch: 22, iters: 384, time: 0.514, data: 0.002) G_GAN: 0.911 G_L1: 6.601 D_real: 0.471 D_fake: 0.542 \n",
      "End of epoch 22 / 200 \t Time Taken: 134 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 288, time: 0.516, data: 0.002) G_GAN: 0.735 G_L1: 6.757 D_real: 0.647 D_fake: 0.470 \n",
      "End of epoch 23 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 192, time: 0.518, data: 0.002) G_GAN: 0.804 G_L1: 5.640 D_real: 1.291 D_fake: 0.290 \n",
      "End of epoch 24 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 96, time: 0.616, data: 0.002) G_GAN: 1.205 G_L1: 6.481 D_real: 0.265 D_fake: 0.825 \n",
      "(epoch: 25, iters: 396, time: 0.516, data: 0.002) G_GAN: 1.482 G_L1: 5.086 D_real: 2.170 D_fake: 0.118 \n",
      "saving the model at the end of epoch 25, iters 9900\n",
      "End of epoch 25 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 300, time: 0.518, data: 0.095) G_GAN: 0.723 G_L1: 10.035 D_real: 0.103 D_fake: 1.589 \n",
      "End of epoch 26 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 204, time: 0.519, data: 0.002) G_GAN: 0.904 G_L1: 7.175 D_real: 0.643 D_fake: 0.359 \n",
      "End of epoch 27 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 108, time: 0.631, data: 0.002) G_GAN: 1.064 G_L1: 8.683 D_real: 0.509 D_fake: 0.375 \n",
      "End of epoch 28 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 12, time: 0.516, data: 0.002) G_GAN: 1.168 G_L1: 6.174 D_real: 0.446 D_fake: 0.519 \n",
      "(epoch: 29, iters: 312, time: 0.513, data: 0.003) G_GAN: 0.810 G_L1: 6.594 D_real: 0.714 D_fake: 0.414 \n",
      "End of epoch 29 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 216, time: 0.516, data: 0.002) G_GAN: 1.054 G_L1: 6.060 D_real: 0.491 D_fake: 0.531 \n",
      "saving the model at the end of epoch 30, iters 11880\n",
      "End of epoch 30 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 120, time: 0.636, data: 0.002) G_GAN: 1.010 G_L1: 7.168 D_real: 0.243 D_fake: 0.685 \n",
      "End of epoch 31 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 24, time: 0.513, data: 0.002) G_GAN: 0.803 G_L1: 5.097 D_real: 0.674 D_fake: 0.592 \n",
      "(epoch: 32, iters: 324, time: 0.517, data: 0.002) G_GAN: 1.205 G_L1: 8.851 D_real: 0.540 D_fake: 0.437 \n",
      "End of epoch 32 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 228, time: 0.524, data: 0.002) G_GAN: 0.549 G_L1: 7.485 D_real: 0.531 D_fake: 0.426 \n",
      "End of epoch 33 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 132, time: 0.713, data: 0.002) G_GAN: 1.785 G_L1: 7.125 D_real: 0.137 D_fake: 1.267 \n",
      "End of epoch 34 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 36, time: 0.516, data: 0.004) G_GAN: 1.074 G_L1: 7.604 D_real: 0.382 D_fake: 0.712 \n",
      "(epoch: 35, iters: 336, time: 0.512, data: 0.002) G_GAN: 1.245 G_L1: 7.827 D_real: 0.200 D_fake: 1.127 \n",
      "saving the model at the end of epoch 35, iters 13860\n",
      "End of epoch 35 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 240, time: 0.512, data: 0.002) G_GAN: 0.804 G_L1: 7.083 D_real: 0.217 D_fake: 1.209 \n",
      "End of epoch 36 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 144, time: 0.643, data: 0.002) G_GAN: 1.509 G_L1: 8.055 D_real: 0.533 D_fake: 0.405 \n",
      "End of epoch 37 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 48, time: 0.515, data: 0.002) G_GAN: 0.997 G_L1: 6.958 D_real: 0.366 D_fake: 0.859 \n",
      "(epoch: 38, iters: 348, time: 0.514, data: 0.002) G_GAN: 0.842 G_L1: 7.083 D_real: 0.730 D_fake: 0.479 \n",
      "saving the latest model (epoch 38, total_iters 15000)\n",
      "End of epoch 38 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 252, time: 0.512, data: 0.002) G_GAN: 0.826 G_L1: 6.939 D_real: 0.687 D_fake: 0.519 \n",
      "End of epoch 39 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 156, time: 0.649, data: 0.002) G_GAN: 0.780 G_L1: 8.057 D_real: 0.142 D_fake: 1.656 \n",
      "saving the model at the end of epoch 40, iters 15840\n",
      "End of epoch 40 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 60, time: 0.516, data: 0.002) G_GAN: 0.722 G_L1: 6.500 D_real: 0.530 D_fake: 0.606 \n",
      "(epoch: 41, iters: 360, time: 0.516, data: 0.002) G_GAN: 0.833 G_L1: 8.108 D_real: 0.570 D_fake: 0.670 \n",
      "End of epoch 41 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 264, time: 0.517, data: 0.002) G_GAN: 0.785 G_L1: 3.838 D_real: 0.454 D_fake: 0.792 \n",
      "End of epoch 42 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 168, time: 0.648, data: 0.002) G_GAN: 0.959 G_L1: 7.817 D_real: 0.236 D_fake: 1.133 \n",
      "End of epoch 43 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 72, time: 0.515, data: 0.002) G_GAN: 0.734 G_L1: 7.088 D_real: 1.224 D_fake: 0.259 \n",
      "(epoch: 44, iters: 372, time: 0.513, data: 0.002) G_GAN: 1.315 G_L1: 6.356 D_real: 0.305 D_fake: 0.751 \n",
      "End of epoch 44 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 276, time: 0.515, data: 0.002) G_GAN: 0.696 G_L1: 5.005 D_real: 0.916 D_fake: 0.327 \n",
      "saving the model at the end of epoch 45, iters 17820\n",
      "End of epoch 45 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 180, time: 0.649, data: 0.002) G_GAN: 0.960 G_L1: 6.317 D_real: 0.950 D_fake: 0.292 \n",
      "End of epoch 46 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 84, time: 0.513, data: 0.002) G_GAN: 1.059 G_L1: 8.224 D_real: 0.337 D_fake: 0.759 \n",
      "(epoch: 47, iters: 384, time: 0.513, data: 0.002) G_GAN: 0.978 G_L1: 6.228 D_real: 0.332 D_fake: 0.940 \n",
      "End of epoch 47 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 288, time: 0.515, data: 0.002) G_GAN: 0.935 G_L1: 7.991 D_real: 0.411 D_fake: 0.722 \n",
      "End of epoch 48 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 192, time: 0.645, data: 0.002) G_GAN: 0.734 G_L1: 3.861 D_real: 1.027 D_fake: 0.368 \n",
      "End of epoch 49 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 96, time: 0.512, data: 0.002) G_GAN: 1.148 G_L1: 7.852 D_real: 0.533 D_fake: 0.485 \n",
      "(epoch: 50, iters: 396, time: 0.516, data: 0.002) G_GAN: 1.202 G_L1: 7.250 D_real: 0.484 D_fake: 0.445 \n",
      "saving the model at the end of epoch 50, iters 19800\n",
      "End of epoch 50 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 300, time: 0.514, data: 0.096) G_GAN: 1.248 G_L1: 5.688 D_real: 0.308 D_fake: 0.843 \n",
      "End of epoch 51 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 204, time: 0.651, data: 0.002) G_GAN: 0.858 G_L1: 6.949 D_real: 0.759 D_fake: 0.389 \n",
      "End of epoch 52 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 108, time: 0.513, data: 0.002) G_GAN: 1.195 G_L1: 8.509 D_real: 0.616 D_fake: 0.330 \n",
      "End of epoch 53 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 12, time: 0.516, data: 0.002) G_GAN: 0.818 G_L1: 6.280 D_real: 0.958 D_fake: 0.356 \n",
      "(epoch: 54, iters: 312, time: 0.512, data: 0.003) G_GAN: 0.731 G_L1: 4.722 D_real: 0.596 D_fake: 0.595 \n",
      "End of epoch 54 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 216, time: 0.666, data: 0.002) G_GAN: 1.594 G_L1: 8.146 D_real: 0.070 D_fake: 1.505 \n",
      "saving the model at the end of epoch 55, iters 21780\n",
      "End of epoch 55 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 120, time: 0.517, data: 0.002) G_GAN: 1.189 G_L1: 9.619 D_real: 0.433 D_fake: 0.533 \n",
      "End of epoch 56 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 24, time: 0.513, data: 0.002) G_GAN: 1.286 G_L1: 7.929 D_real: 0.366 D_fake: 0.587 \n",
      "(epoch: 57, iters: 324, time: 0.518, data: 0.002) G_GAN: 0.737 G_L1: 5.035 D_real: 1.033 D_fake: 0.299 \n",
      "End of epoch 57 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 228, time: 0.659, data: 0.002) G_GAN: 2.327 G_L1: 9.114 D_real: 0.123 D_fake: 0.716 \n",
      "End of epoch 58 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 132, time: 0.513, data: 0.002) G_GAN: 2.208 G_L1: 7.175 D_real: 0.210 D_fake: 0.929 \n",
      "End of epoch 59 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 36, time: 0.517, data: 0.002) G_GAN: 1.137 G_L1: 6.152 D_real: 0.449 D_fake: 0.377 \n",
      "(epoch: 60, iters: 336, time: 0.514, data: 0.002) G_GAN: 1.433 G_L1: 7.716 D_real: 0.482 D_fake: 0.271 \n",
      "saving the model at the end of epoch 60, iters 23760\n",
      "End of epoch 60 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 240, time: 0.670, data: 0.002) G_GAN: 1.146 G_L1: 8.482 D_real: 0.303 D_fake: 0.448 \n",
      "End of epoch 61 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 144, time: 0.513, data: 0.002) G_GAN: 1.012 G_L1: 9.587 D_real: 0.153 D_fake: 0.849 \n",
      "End of epoch 62 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 48, time: 0.513, data: 0.002) G_GAN: 0.738 G_L1: 7.783 D_real: 0.440 D_fake: 0.979 \n",
      "(epoch: 63, iters: 348, time: 0.515, data: 0.002) G_GAN: 1.378 G_L1: 7.780 D_real: 0.244 D_fake: 0.467 \n",
      "End of epoch 63 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 252, time: 0.677, data: 0.002) G_GAN: 2.133 G_L1: 9.238 D_real: 0.135 D_fake: 0.878 \n",
      "End of epoch 64 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 156, time: 0.515, data: 0.002) G_GAN: 2.085 G_L1: 8.863 D_real: 0.198 D_fake: 0.575 \n",
      "saving the model at the end of epoch 65, iters 25740\n",
      "End of epoch 65 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 60, time: 0.515, data: 0.002) G_GAN: 1.007 G_L1: 6.774 D_real: 0.461 D_fake: 0.425 \n",
      "(epoch: 66, iters: 360, time: 0.514, data: 0.002) G_GAN: 1.236 G_L1: 5.527 D_real: 0.467 D_fake: 0.281 \n",
      "End of epoch 66 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 264, time: 0.696, data: 0.002) G_GAN: 1.063 G_L1: 9.805 D_real: 0.501 D_fake: 0.652 \n",
      "End of epoch 67 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 168, time: 0.511, data: 0.002) G_GAN: 1.085 G_L1: 6.901 D_real: 0.498 D_fake: 0.284 \n",
      "End of epoch 68 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 72, time: 0.512, data: 0.002) G_GAN: 1.466 G_L1: 9.156 D_real: 0.741 D_fake: 0.149 \n",
      "(epoch: 69, iters: 372, time: 0.510, data: 0.002) G_GAN: 1.183 G_L1: 6.343 D_real: 1.163 D_fake: 0.059 \n",
      "End of epoch 69 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 276, time: 0.665, data: 0.002) G_GAN: 1.896 G_L1: 8.802 D_real: 1.465 D_fake: 0.042 \n",
      "saving the model at the end of epoch 70, iters 27720\n",
      "End of epoch 70 / 200 \t Time Taken: 135 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 180, time: 0.510, data: 0.002) G_GAN: 0.892 G_L1: 9.145 D_real: 0.575 D_fake: 0.165 \n",
      "End of epoch 71 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 84, time: 0.509, data: 0.002) G_GAN: 2.255 G_L1: 10.032 D_real: 0.060 D_fake: 0.399 \n",
      "(epoch: 72, iters: 384, time: 0.517, data: 0.002) G_GAN: 2.258 G_L1: 9.410 D_real: 0.328 D_fake: 0.334 \n",
      "End of epoch 72 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 288, time: 0.684, data: 0.004) G_GAN: 1.861 G_L1: 9.957 D_real: 0.255 D_fake: 0.234 \n",
      "End of epoch 73 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 192, time: 0.512, data: 0.002) G_GAN: 2.081 G_L1: 11.077 D_real: 0.130 D_fake: 0.265 \n",
      "End of epoch 74 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 96, time: 0.513, data: 0.002) G_GAN: 3.212 G_L1: 9.399 D_real: 0.012 D_fake: 1.461 \n",
      "(epoch: 75, iters: 396, time: 0.511, data: 0.002) G_GAN: 3.067 G_L1: 11.291 D_real: 0.065 D_fake: 0.771 \n",
      "saving the model at the end of epoch 75, iters 29700\n",
      "End of epoch 75 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 300, time: 0.684, data: 0.098) G_GAN: 2.813 G_L1: 12.894 D_real: 0.122 D_fake: 0.335 \n",
      "saving the latest model (epoch 76, total_iters 30000)\n",
      "End of epoch 76 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 204, time: 0.509, data: 0.002) G_GAN: 2.506 G_L1: 11.270 D_real: 0.265 D_fake: 0.091 \n",
      "End of epoch 77 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 108, time: 0.517, data: 0.002) G_GAN: 1.822 G_L1: 10.527 D_real: 0.120 D_fake: 0.353 \n",
      "End of epoch 78 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 12, time: 0.512, data: 0.002) G_GAN: 2.793 G_L1: 9.984 D_real: 0.109 D_fake: 0.114 \n",
      "(epoch: 79, iters: 312, time: 0.685, data: 0.004) G_GAN: 1.822 G_L1: 11.181 D_real: 0.206 D_fake: 0.174 \n",
      "End of epoch 79 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 216, time: 0.510, data: 0.002) G_GAN: 2.622 G_L1: 9.532 D_real: 0.090 D_fake: 0.809 \n",
      "saving the model at the end of epoch 80, iters 31680\n",
      "End of epoch 80 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 120, time: 0.509, data: 0.002) G_GAN: 3.364 G_L1: 10.491 D_real: 0.079 D_fake: 0.054 \n",
      "End of epoch 81 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 24, time: 0.514, data: 0.002) G_GAN: 4.191 G_L1: 9.526 D_real: 0.020 D_fake: 1.165 \n",
      "(epoch: 82, iters: 324, time: 0.688, data: 0.002) G_GAN: 3.722 G_L1: 11.004 D_real: 0.119 D_fake: 0.069 \n",
      "End of epoch 82 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 228, time: 0.513, data: 0.002) G_GAN: 0.999 G_L1: 4.368 D_real: 0.188 D_fake: 0.411 \n",
      "End of epoch 83 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 132, time: 0.509, data: 0.002) G_GAN: 2.750 G_L1: 9.719 D_real: 0.093 D_fake: 0.118 \n",
      "End of epoch 84 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 36, time: 0.513, data: 0.002) G_GAN: 1.800 G_L1: 8.142 D_real: 0.271 D_fake: 0.274 \n",
      "(epoch: 85, iters: 336, time: 0.692, data: 0.002) G_GAN: 2.620 G_L1: 9.727 D_real: 0.037 D_fake: 0.174 \n",
      "saving the model at the end of epoch 85, iters 33660\n",
      "End of epoch 85 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 240, time: 0.516, data: 0.002) G_GAN: 0.459 G_L1: 3.515 D_real: 1.615 D_fake: 0.149 \n",
      "End of epoch 86 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 144, time: 0.514, data: 0.002) G_GAN: 3.673 G_L1: 11.171 D_real: 0.086 D_fake: 0.586 \n",
      "End of epoch 87 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 48, time: 0.513, data: 0.002) G_GAN: 3.185 G_L1: 9.589 D_real: 0.073 D_fake: 0.273 \n",
      "(epoch: 88, iters: 348, time: 0.693, data: 0.002) G_GAN: 2.694 G_L1: 9.979 D_real: 0.340 D_fake: 0.057 \n",
      "End of epoch 88 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 252, time: 0.515, data: 0.002) G_GAN: 2.159 G_L1: 7.669 D_real: 0.563 D_fake: 0.025 \n",
      "End of epoch 89 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 156, time: 0.517, data: 0.002) G_GAN: 4.940 G_L1: 11.476 D_real: 0.217 D_fake: 0.024 \n",
      "saving the model at the end of epoch 90, iters 35640\n",
      "End of epoch 90 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 60, time: 0.515, data: 0.002) G_GAN: 2.372 G_L1: 10.226 D_real: 0.025 D_fake: 0.057 \n",
      "(epoch: 91, iters: 360, time: 0.692, data: 0.002) G_GAN: 2.604 G_L1: 7.172 D_real: 0.118 D_fake: 0.103 \n",
      "End of epoch 91 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 264, time: 0.512, data: 0.002) G_GAN: 3.538 G_L1: 10.858 D_real: 0.116 D_fake: 0.048 \n",
      "End of epoch 92 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 168, time: 0.512, data: 0.002) G_GAN: 1.389 G_L1: 9.715 D_real: 0.280 D_fake: 0.131 \n",
      "End of epoch 93 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 72, time: 0.515, data: 0.002) G_GAN: 2.128 G_L1: 10.394 D_real: 0.091 D_fake: 0.109 \n",
      "(epoch: 94, iters: 372, time: 0.724, data: 0.002) G_GAN: 1.995 G_L1: 8.616 D_real: 0.822 D_fake: 0.046 \n",
      "End of epoch 94 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 276, time: 0.514, data: 0.002) G_GAN: 2.142 G_L1: 7.348 D_real: 0.395 D_fake: 0.124 \n",
      "saving the model at the end of epoch 95, iters 37620\n",
      "End of epoch 95 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 180, time: 0.515, data: 0.002) G_GAN: 1.949 G_L1: 9.160 D_real: 0.464 D_fake: 0.031 \n",
      "End of epoch 96 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 84, time: 0.513, data: 0.002) G_GAN: 4.097 G_L1: 11.940 D_real: 0.246 D_fake: 0.018 \n",
      "(epoch: 97, iters: 384, time: 0.703, data: 0.002) G_GAN: 3.066 G_L1: 10.100 D_real: 0.007 D_fake: 0.591 \n",
      "End of epoch 97 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 288, time: 0.515, data: 0.002) G_GAN: 3.161 G_L1: 9.894 D_real: 0.010 D_fake: 1.977 \n",
      "End of epoch 98 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 192, time: 0.514, data: 0.002) G_GAN: 2.174 G_L1: 9.478 D_real: 0.305 D_fake: 0.214 \n",
      "End of epoch 99 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 96, time: 0.513, data: 0.002) G_GAN: 2.727 G_L1: 10.395 D_real: 0.011 D_fake: 0.310 \n",
      "(epoch: 100, iters: 396, time: 0.711, data: 0.002) G_GAN: 3.860 G_L1: 12.345 D_real: 0.073 D_fake: 0.588 \n",
      "saving the model at the end of epoch 100, iters 39600\n",
      "End of epoch 100 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 300, time: 0.510, data: 0.096) G_GAN: 2.765 G_L1: 9.487 D_real: 0.053 D_fake: 0.133 \n",
      "End of epoch 101 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 204, time: 0.513, data: 0.002) G_GAN: 2.634 G_L1: 6.658 D_real: 0.106 D_fake: 0.336 \n",
      "End of epoch 102 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 108, time: 0.513, data: 0.002) G_GAN: 2.575 G_L1: 16.036 D_real: 0.002 D_fake: 1.362 \n",
      "End of epoch 103 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 12, time: 0.711, data: 0.002) G_GAN: 3.873 G_L1: 10.066 D_real: 0.047 D_fake: 0.128 \n",
      "(epoch: 104, iters: 312, time: 0.514, data: 0.004) G_GAN: 3.881 G_L1: 15.984 D_real: 0.026 D_fake: 0.031 \n",
      "End of epoch 104 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 216, time: 0.511, data: 0.002) G_GAN: 2.783 G_L1: 11.977 D_real: 0.055 D_fake: 0.083 \n",
      "saving the model at the end of epoch 105, iters 41580\n",
      "End of epoch 105 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 120, time: 0.513, data: 0.002) G_GAN: 2.056 G_L1: 9.799 D_real: 0.040 D_fake: 0.235 \n",
      "End of epoch 106 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 24, time: 0.719, data: 0.002) G_GAN: 2.773 G_L1: 9.517 D_real: 0.097 D_fake: 0.082 \n",
      "(epoch: 107, iters: 324, time: 0.515, data: 0.002) G_GAN: 4.079 G_L1: 10.126 D_real: 0.015 D_fake: 0.358 \n",
      "End of epoch 107 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 228, time: 0.515, data: 0.002) G_GAN: 3.195 G_L1: 7.900 D_real: 0.750 D_fake: 0.007 \n",
      "End of epoch 108 / 200 \t Time Taken: 133 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 132, time: 0.567, data: 0.003) G_GAN: 2.807 G_L1: 11.143 D_real: 0.244 D_fake: 0.069 \n",
      "End of epoch 109 / 200 \t Time Taken: 134 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 36, time: 0.863, data: 0.002) G_GAN: 4.341 G_L1: 11.037 D_real: 0.056 D_fake: 0.158 \n",
      "(epoch: 110, iters: 336, time: 0.522, data: 0.002) G_GAN: 4.070 G_L1: 10.430 D_real: 0.008 D_fake: 0.856 \n",
      "saving the model at the end of epoch 110, iters 43560\n",
      "End of epoch 110 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 240, time: 0.564, data: 0.003) G_GAN: 3.740 G_L1: 9.789 D_real: 0.007 D_fake: 0.510 \n",
      "End of epoch 111 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 144, time: 0.512, data: 0.002) G_GAN: 2.248 G_L1: 9.786 D_real: 1.903 D_fake: 0.004 \n",
      "End of epoch 112 / 200 \t Time Taken: 133 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 48, time: 0.775, data: 0.002) G_GAN: 3.386 G_L1: 11.021 D_real: 0.024 D_fake: 0.148 \n",
      "(epoch: 113, iters: 348, time: 0.595, data: 0.002) G_GAN: 3.444 G_L1: 8.236 D_real: 0.072 D_fake: 0.835 \n",
      "End of epoch 113 / 200 \t Time Taken: 139 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 252, time: 0.515, data: 0.002) G_GAN: 3.555 G_L1: 9.255 D_real: 0.028 D_fake: 1.293 \n",
      "saving the latest model (epoch 114, total_iters 45000)\n",
      "End of epoch 114 / 200 \t Time Taken: 134 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 156, time: 0.513, data: 0.002) G_GAN: 3.908 G_L1: 14.122 D_real: 0.630 D_fake: 0.015 \n",
      "saving the model at the end of epoch 115, iters 45540\n",
      "End of epoch 115 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 60, time: 0.745, data: 0.002) G_GAN: 2.767 G_L1: 7.434 D_real: 0.034 D_fake: 0.544 \n",
      "(epoch: 116, iters: 360, time: 0.513, data: 0.002) G_GAN: 3.909 G_L1: 9.053 D_real: 0.038 D_fake: 0.078 \n",
      "End of epoch 116 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 264, time: 0.508, data: 0.002) G_GAN: 2.258 G_L1: 12.260 D_real: 0.052 D_fake: 0.332 \n",
      "End of epoch 117 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 168, time: 0.506, data: 0.002) G_GAN: 4.078 G_L1: 11.057 D_real: 0.035 D_fake: 0.172 \n",
      "End of epoch 118 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 72, time: 0.713, data: 0.002) G_GAN: 2.494 G_L1: 6.767 D_real: 0.155 D_fake: 0.226 \n",
      "(epoch: 119, iters: 372, time: 0.503, data: 0.002) G_GAN: 2.605 G_L1: 9.451 D_real: 0.039 D_fake: 0.158 \n",
      "End of epoch 119 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 276, time: 0.506, data: 0.002) G_GAN: 2.722 G_L1: 9.275 D_real: 0.273 D_fake: 0.073 \n",
      "saving the model at the end of epoch 120, iters 47520\n",
      "End of epoch 120 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 180, time: 0.508, data: 0.002) G_GAN: 3.260 G_L1: 10.006 D_real: 0.094 D_fake: 0.105 \n",
      "End of epoch 121 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 84, time: 0.726, data: 0.002) G_GAN: 1.158 G_L1: 8.142 D_real: 0.070 D_fake: 0.148 \n",
      "(epoch: 122, iters: 384, time: 0.508, data: 0.002) G_GAN: 2.090 G_L1: 7.765 D_real: 0.808 D_fake: 0.005 \n",
      "End of epoch 122 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 288, time: 0.507, data: 0.002) G_GAN: 3.976 G_L1: 6.665 D_real: 0.028 D_fake: 1.511 \n",
      "End of epoch 123 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 192, time: 0.507, data: 0.002) G_GAN: 3.695 G_L1: 10.235 D_real: 0.007 D_fake: 0.098 \n",
      "End of epoch 124 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 96, time: 0.747, data: 0.002) G_GAN: 2.173 G_L1: 7.908 D_real: 0.178 D_fake: 0.100 \n",
      "(epoch: 125, iters: 396, time: 0.507, data: 0.002) G_GAN: 3.170 G_L1: 8.354 D_real: 0.028 D_fake: 0.215 \n",
      "saving the model at the end of epoch 125, iters 49500\n",
      "End of epoch 125 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 300, time: 0.508, data: 0.110) G_GAN: 2.037 G_L1: 8.621 D_real: 0.042 D_fake: 0.246 \n",
      "End of epoch 126 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 204, time: 0.509, data: 0.002) G_GAN: 6.190 G_L1: 6.904 D_real: 0.007 D_fake: 0.880 \n",
      "End of epoch 127 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 108, time: 0.744, data: 0.002) G_GAN: 3.374 G_L1: 11.551 D_real: 0.035 D_fake: 0.052 \n",
      "End of epoch 128 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 12, time: 0.529, data: 0.002) G_GAN: 5.189 G_L1: 9.642 D_real: 0.022 D_fake: 0.149 \n",
      "(epoch: 129, iters: 312, time: 0.512, data: 0.002) G_GAN: 2.684 G_L1: 7.351 D_real: 0.069 D_fake: 0.233 \n",
      "End of epoch 129 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 216, time: 0.511, data: 0.002) G_GAN: 3.679 G_L1: 8.573 D_real: 0.094 D_fake: 0.033 \n",
      "saving the model at the end of epoch 130, iters 51480\n",
      "End of epoch 130 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 120, time: 0.747, data: 0.002) G_GAN: 1.913 G_L1: 7.474 D_real: 0.701 D_fake: 0.019 \n",
      "End of epoch 131 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 24, time: 0.511, data: 0.002) G_GAN: 3.889 G_L1: 10.326 D_real: 0.058 D_fake: 0.271 \n",
      "(epoch: 132, iters: 324, time: 0.514, data: 0.002) G_GAN: 1.996 G_L1: 9.920 D_real: 0.388 D_fake: 0.088 \n",
      "End of epoch 132 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 228, time: 0.515, data: 0.002) G_GAN: 4.541 G_L1: 8.833 D_real: 0.094 D_fake: 0.084 \n",
      "End of epoch 133 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 132, time: 0.744, data: 0.002) G_GAN: 4.562 G_L1: 10.338 D_real: 0.567 D_fake: 0.006 \n",
      "End of epoch 134 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 36, time: 0.515, data: 0.002) G_GAN: 3.082 G_L1: 5.407 D_real: 0.013 D_fake: 0.116 \n",
      "(epoch: 135, iters: 336, time: 0.513, data: 0.002) G_GAN: 2.747 G_L1: 8.923 D_real: 0.012 D_fake: 0.144 \n",
      "saving the model at the end of epoch 135, iters 53460\n",
      "End of epoch 135 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 240, time: 0.513, data: 0.002) G_GAN: 1.678 G_L1: 9.463 D_real: 0.263 D_fake: 0.067 \n",
      "End of epoch 136 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 144, time: 0.758, data: 0.002) G_GAN: 1.801 G_L1: 8.226 D_real: 0.053 D_fake: 0.368 \n",
      "End of epoch 137 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 48, time: 0.516, data: 0.002) G_GAN: 3.466 G_L1: 10.576 D_real: 0.166 D_fake: 0.016 \n",
      "(epoch: 138, iters: 348, time: 0.513, data: 0.002) G_GAN: 4.019 G_L1: 11.541 D_real: 0.010 D_fake: 0.525 \n",
      "End of epoch 138 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 252, time: 0.511, data: 0.002) G_GAN: 3.053 G_L1: 9.749 D_real: 0.050 D_fake: 0.274 \n",
      "End of epoch 139 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 156, time: 0.762, data: 0.002) G_GAN: 4.458 G_L1: 11.220 D_real: 0.005 D_fake: 0.516 \n",
      "saving the model at the end of epoch 140, iters 55440\n",
      "End of epoch 140 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 60, time: 0.511, data: 0.002) G_GAN: 3.900 G_L1: 8.874 D_real: 0.072 D_fake: 0.019 \n",
      "(epoch: 141, iters: 360, time: 0.512, data: 0.002) G_GAN: 3.185 G_L1: 9.873 D_real: 0.028 D_fake: 0.303 \n",
      "End of epoch 141 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 264, time: 0.512, data: 0.002) G_GAN: 5.128 G_L1: 11.703 D_real: 0.023 D_fake: 0.006 \n",
      "End of epoch 142 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 168, time: 0.771, data: 0.002) G_GAN: 3.193 G_L1: 10.747 D_real: 0.037 D_fake: 0.081 \n",
      "End of epoch 143 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 72, time: 0.514, data: 0.002) G_GAN: 4.935 G_L1: 10.609 D_real: 0.001 D_fake: 0.709 \n",
      "(epoch: 144, iters: 372, time: 0.513, data: 0.002) G_GAN: 4.887 G_L1: 10.085 D_real: 0.001 D_fake: 0.834 \n",
      "End of epoch 144 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 276, time: 0.512, data: 0.002) G_GAN: 3.157 G_L1: 10.746 D_real: 0.199 D_fake: 0.112 \n",
      "saving the model at the end of epoch 145, iters 57420\n",
      "End of epoch 145 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 180, time: 0.769, data: 0.002) G_GAN: 2.357 G_L1: 11.287 D_real: 0.023 D_fake: 0.118 \n",
      "End of epoch 146 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 84, time: 0.511, data: 0.002) G_GAN: 3.269 G_L1: 7.679 D_real: 0.004 D_fake: 0.235 \n",
      "(epoch: 147, iters: 384, time: 0.546, data: 0.002) G_GAN: 3.095 G_L1: 9.745 D_real: 0.139 D_fake: 0.069 \n",
      "End of epoch 147 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 288, time: 0.534, data: 0.002) G_GAN: 3.586 G_L1: 6.981 D_real: 0.028 D_fake: 0.429 \n",
      "End of epoch 148 / 200 \t Time Taken: 135 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 192, time: 0.787, data: 0.002) G_GAN: 3.643 G_L1: 9.035 D_real: 0.012 D_fake: 0.059 \n",
      "End of epoch 149 / 200 \t Time Taken: 133 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 96, time: 0.512, data: 0.002) G_GAN: 3.535 G_L1: 10.430 D_real: 0.020 D_fake: 0.082 \n",
      "(epoch: 150, iters: 396, time: 0.510, data: 0.002) G_GAN: 3.363 G_L1: 11.381 D_real: 0.010 D_fake: 0.246 \n",
      "saving the model at the end of epoch 150, iters 59400\n",
      "End of epoch 150 / 200 \t Time Taken: 134 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 300, time: 0.514, data: 0.104) G_GAN: 1.995 G_L1: 6.437 D_real: 0.042 D_fake: 0.474 \n",
      "End of epoch 151 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 204, time: 0.765, data: 0.002) G_GAN: 3.146 G_L1: 8.484 D_real: 0.121 D_fake: 0.030 \n",
      "saving the latest model (epoch 152, total_iters 60000)\n",
      "End of epoch 152 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 108, time: 0.511, data: 0.002) G_GAN: 1.801 G_L1: 11.826 D_real: 0.127 D_fake: 0.063 \n",
      "End of epoch 153 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 12, time: 0.512, data: 0.002) G_GAN: 3.272 G_L1: 9.887 D_real: 0.002 D_fake: 0.194 \n",
      "(epoch: 154, iters: 312, time: 0.513, data: 0.003) G_GAN: 3.817 G_L1: 9.584 D_real: 0.022 D_fake: 0.023 \n",
      "End of epoch 154 / 200 \t Time Taken: 134 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 216, time: 0.768, data: 0.002) G_GAN: 3.625 G_L1: 7.894 D_real: 0.023 D_fake: 0.045 \n",
      "saving the model at the end of epoch 155, iters 61380\n",
      "End of epoch 155 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 120, time: 0.515, data: 0.002) G_GAN: 2.907 G_L1: 11.379 D_real: 0.066 D_fake: 0.052 \n",
      "End of epoch 156 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 24, time: 0.514, data: 0.002) G_GAN: 2.451 G_L1: 9.990 D_real: 0.407 D_fake: 0.021 \n",
      "(epoch: 157, iters: 324, time: 0.513, data: 0.002) G_GAN: 3.710 G_L1: 9.142 D_real: 0.091 D_fake: 0.050 \n",
      "End of epoch 157 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 228, time: 0.788, data: 0.002) G_GAN: 3.781 G_L1: 8.817 D_real: 0.010 D_fake: 0.251 \n",
      "End of epoch 158 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 132, time: 0.515, data: 0.002) G_GAN: 4.692 G_L1: 7.463 D_real: 0.044 D_fake: 0.013 \n",
      "End of epoch 159 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 36, time: 0.511, data: 0.003) G_GAN: 3.175 G_L1: 8.230 D_real: 0.013 D_fake: 0.445 \n",
      "(epoch: 160, iters: 336, time: 0.510, data: 0.002) G_GAN: 2.485 G_L1: 7.940 D_real: 0.260 D_fake: 0.038 \n",
      "saving the model at the end of epoch 160, iters 63360\n",
      "End of epoch 160 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 240, time: 0.792, data: 0.002) G_GAN: 2.304 G_L1: 9.381 D_real: 0.001 D_fake: 0.744 \n",
      "End of epoch 161 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 144, time: 0.511, data: 0.002) G_GAN: 2.809 G_L1: 14.494 D_real: 0.004 D_fake: 0.213 \n",
      "End of epoch 162 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 48, time: 0.511, data: 0.002) G_GAN: 2.035 G_L1: 6.592 D_real: 0.197 D_fake: 0.058 \n",
      "(epoch: 163, iters: 348, time: 0.510, data: 0.002) G_GAN: 3.328 G_L1: 7.098 D_real: 0.081 D_fake: 0.043 \n",
      "End of epoch 163 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 252, time: 0.776, data: 0.002) G_GAN: 2.590 G_L1: 10.870 D_real: 0.110 D_fake: 0.055 \n",
      "End of epoch 164 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 156, time: 4.035, data: 0.002) G_GAN: 3.488 G_L1: 9.761 D_real: 0.024 D_fake: 0.073 \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 51, in <module>\n",
      "    model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
      "  File \"/home/kalai/exp/pytorch-CycleGAN-and-pix2pix/models/pix2pix_model.py\", line 127, in optimize_parameters\n",
      "    self.optimizer_G.step()             # udpate G's weights\n",
      "  File \"/home/kalai/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 66, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/kalai/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/optim/adam.py\", line 96, in step\n",
      "    exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot baw/AB --model pix2pix --batch_size 3 --no_dropout --output_nc 1 --norm batch --checkpoints_dir may15 --netG resnet_9blocks --preprocess none --name real396bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: maydfjyhfd5                   \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: baw/AB                        \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: real396bw                     \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 396\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "[Network D] Total number of parameters : 2.767 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/urllib3/connection.py\", line 160, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 677, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 392, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/http/client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/http/client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/http/client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/http/client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/http/client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/urllib3/connection.py\", line 187, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/urllib3/connection.py\", line 172, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f2fa5fd3f10>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 725, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/urllib3/util/retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f2fa5fd3f10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/visdom/__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/visdom/__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/requests/sessions.py\", line 578, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/kalai/anaconda3/envs/samy/lib/python3.7/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f2fa5fd3f10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "[Errno 111] Connection refused\n",
      "\n",
      "\n",
      "Could not connect to Visdom server. \n",
      " Trying to start a server....\n",
      "Command: /home/kalai/anaconda3/envs/samy/bin/python -m visdom.server -p 8097 &>/dev/null &\n",
      "create web directory maydfjyhfd5/real396bw/web...\n",
      "(epoch: 1, iters: 100, time: 0.625, data: 0.082) G_GAN: 3.581 G_L1: 12.733 D_real: 0.024 D_fake: 0.032 \n",
      "(epoch: 1, iters: 200, time: 0.588, data: 0.001) G_GAN: 2.186 G_L1: 18.597 D_real: 0.042 D_fake: 0.408 \n",
      "(epoch: 1, iters: 300, time: 0.604, data: 0.002) G_GAN: 2.359 G_L1: 18.711 D_real: 0.013 D_fake: 0.529 \n",
      "End of epoch 1 / 200 \t Time Taken: 151 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 4, time: 0.891, data: 0.001) G_GAN: 1.597 G_L1: 15.469 D_real: 0.073 D_fake: 0.390 \n",
      "(epoch: 2, iters: 104, time: 0.594, data: 0.001) G_GAN: 1.023 G_L1: 10.979 D_real: 0.729 D_fake: 0.510 \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 50, in <module>\n",
      "    model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
      "  File \"/home/kalai/exp/pytorch-CycleGAN-and-pix2pix/models/pix2pix_model.py\", line 82, in set_input\n",
      "    self.real_A = input['A' if AtoB else 'B'].to(self.device)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot baw/AB --model pix2pix --batch_size 1 --no_dropout --output_nc 1 --norm batch --checkpoints_dir maydfjyhfd5 --netG resnet_9blocks --preprocess none --name real396bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: may14                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: pix2pix/AB                    \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: pixelreal396                  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: pixel                         \t[default: basic]\n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 396\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "[Network D] Total number of parameters : 0.009 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory may14/pixelreal396/web...\n",
      "(epoch: 1, iters: 100, time: 0.533, data: 0.106) G_GAN: 0.776 G_L1: 13.844 D_real: 0.533 D_fake: 0.621 \n",
      "(epoch: 1, iters: 200, time: 0.543, data: 0.001) G_GAN: 0.877 G_L1: 10.118 D_real: 0.467 D_fake: 0.546 \n",
      "(epoch: 1, iters: 300, time: 0.545, data: 0.001) G_GAN: 1.070 G_L1: 6.972 D_real: 0.425 D_fake: 0.455 \n",
      "End of epoch 1 / 200 \t Time Taken: 142 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 4, time: 0.819, data: 0.001) G_GAN: 0.910 G_L1: 6.961 D_real: 0.558 D_fake: 0.522 \n",
      "(epoch: 2, iters: 104, time: 0.547, data: 0.001) G_GAN: 1.176 G_L1: 14.995 D_real: 0.324 D_fake: 0.391 \n",
      "(epoch: 2, iters: 204, time: 0.548, data: 0.001) G_GAN: 0.809 G_L1: 7.876 D_real: 0.443 D_fake: 0.602 \n",
      "(epoch: 2, iters: 304, time: 0.550, data: 0.001) G_GAN: 0.637 G_L1: 8.532 D_real: 0.540 D_fake: 0.776 \n",
      "End of epoch 2 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 8, time: 0.787, data: 0.001) G_GAN: 0.935 G_L1: 5.530 D_real: 0.660 D_fake: 0.518 \n",
      "(epoch: 3, iters: 108, time: 0.548, data: 0.001) G_GAN: 0.912 G_L1: 9.653 D_real: 0.385 D_fake: 0.531 \n",
      "(epoch: 3, iters: 208, time: 0.548, data: 0.001) G_GAN: 0.622 G_L1: 5.162 D_real: 0.541 D_fake: 0.792 \n",
      "(epoch: 3, iters: 308, time: 0.549, data: 0.001) G_GAN: 0.602 G_L1: 5.682 D_real: 0.517 D_fake: 0.839 \n",
      "End of epoch 3 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 12, time: 0.812, data: 0.001) G_GAN: 1.032 G_L1: 4.342 D_real: 0.816 D_fake: 0.453 \n",
      "(epoch: 4, iters: 112, time: 0.549, data: 0.001) G_GAN: 0.643 G_L1: 10.580 D_real: 0.404 D_fake: 0.778 \n",
      "(epoch: 4, iters: 212, time: 0.547, data: 0.001) G_GAN: 1.023 G_L1: 3.054 D_real: 0.973 D_fake: 0.423 \n",
      "(epoch: 4, iters: 312, time: 0.551, data: 0.001) G_GAN: 0.852 G_L1: 9.537 D_real: 0.349 D_fake: 0.654 \n",
      "End of epoch 4 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 16, time: 0.822, data: 0.001) G_GAN: 0.826 G_L1: 6.949 D_real: 0.553 D_fake: 0.591 \n",
      "(epoch: 5, iters: 116, time: 0.547, data: 0.001) G_GAN: 0.632 G_L1: 7.705 D_real: 0.433 D_fake: 0.783 \n",
      "(epoch: 5, iters: 216, time: 0.549, data: 0.001) G_GAN: 0.685 G_L1: 6.175 D_real: 0.497 D_fake: 0.726 \n",
      "(epoch: 5, iters: 316, time: 0.550, data: 0.002) G_GAN: 1.054 G_L1: 2.705 D_real: 1.147 D_fake: 0.428 \n",
      "saving the model at the end of epoch 5, iters 1980\n",
      "End of epoch 5 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 20, time: 0.794, data: 0.001) G_GAN: 0.765 G_L1: 4.889 D_real: 0.769 D_fake: 0.628 \n",
      "(epoch: 6, iters: 120, time: 0.551, data: 0.002) G_GAN: 0.970 G_L1: 9.040 D_real: 0.493 D_fake: 0.492 \n",
      "(epoch: 6, iters: 220, time: 0.550, data: 0.001) G_GAN: 0.623 G_L1: 5.182 D_real: 0.587 D_fake: 0.781 \n",
      "(epoch: 6, iters: 320, time: 0.551, data: 0.001) G_GAN: 0.587 G_L1: 6.428 D_real: 0.533 D_fake: 0.833 \n",
      "End of epoch 6 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 24, time: 0.838, data: 0.001) G_GAN: 0.533 G_L1: 7.022 D_real: 0.404 D_fake: 0.933 \n",
      "(epoch: 7, iters: 124, time: 0.550, data: 0.001) G_GAN: 0.685 G_L1: 4.394 D_real: 0.594 D_fake: 0.704 \n",
      "(epoch: 7, iters: 224, time: 0.550, data: 0.001) G_GAN: 1.148 G_L1: 8.652 D_real: 0.522 D_fake: 0.386 \n",
      "(epoch: 7, iters: 324, time: 0.552, data: 0.001) G_GAN: 0.662 G_L1: 5.784 D_real: 0.748 D_fake: 0.721 \n",
      "End of epoch 7 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 28, time: 0.828, data: 0.001) G_GAN: 1.025 G_L1: 6.207 D_real: 0.824 D_fake: 0.439 \n",
      "(epoch: 8, iters: 128, time: 0.549, data: 0.001) G_GAN: 0.805 G_L1: 3.442 D_real: 0.867 D_fake: 0.599 \n",
      "(epoch: 8, iters: 228, time: 0.550, data: 0.001) G_GAN: 0.825 G_L1: 5.969 D_real: 0.560 D_fake: 0.595 \n",
      "(epoch: 8, iters: 328, time: 0.549, data: 0.001) G_GAN: 0.788 G_L1: 5.832 D_real: 0.529 D_fake: 0.608 \n",
      "End of epoch 8 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 32, time: 0.821, data: 0.001) G_GAN: 0.731 G_L1: 10.273 D_real: 0.213 D_fake: 0.696 \n",
      "(epoch: 9, iters: 132, time: 0.548, data: 0.001) G_GAN: 0.653 G_L1: 5.415 D_real: 0.490 D_fake: 0.767 \n",
      "(epoch: 9, iters: 232, time: 0.550, data: 0.001) G_GAN: 1.093 G_L1: 4.497 D_real: 0.762 D_fake: 0.407 \n",
      "(epoch: 9, iters: 332, time: 0.548, data: 0.001) G_GAN: 0.671 G_L1: 4.800 D_real: 0.779 D_fake: 0.719 \n",
      "End of epoch 9 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 36, time: 0.835, data: 0.001) G_GAN: 0.868 G_L1: 7.117 D_real: 0.503 D_fake: 0.559 \n",
      "(epoch: 10, iters: 136, time: 0.546, data: 0.001) G_GAN: 1.106 G_L1: 0.040 D_real: 1.142 D_fake: 0.386 \n",
      "(epoch: 10, iters: 236, time: 0.549, data: 0.001) G_GAN: 0.494 G_L1: 5.116 D_real: 0.393 D_fake: 1.004 \n",
      "(epoch: 10, iters: 336, time: 0.554, data: 0.001) G_GAN: 0.763 G_L1: 5.104 D_real: 0.747 D_fake: 0.613 \n",
      "saving the model at the end of epoch 10, iters 3960\n",
      "End of epoch 10 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 40, time: 0.848, data: 0.001) G_GAN: 0.874 G_L1: 5.769 D_real: 0.784 D_fake: 0.542 \n",
      "(epoch: 11, iters: 140, time: 0.547, data: 0.001) G_GAN: 0.741 G_L1: 8.389 D_real: 0.423 D_fake: 0.679 \n",
      "(epoch: 11, iters: 240, time: 0.549, data: 0.001) G_GAN: 0.764 G_L1: 6.388 D_real: 0.706 D_fake: 0.642 \n",
      "(epoch: 11, iters: 340, time: 0.550, data: 0.001) G_GAN: 0.995 G_L1: 2.150 D_real: 1.097 D_fake: 0.434 \n",
      "End of epoch 11 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 44, time: 0.835, data: 0.001) G_GAN: 0.871 G_L1: 7.530 D_real: 0.437 D_fake: 0.563 \n",
      "(epoch: 12, iters: 144, time: 0.550, data: 0.001) G_GAN: 0.706 G_L1: 5.307 D_real: 0.612 D_fake: 0.677 \n",
      "(epoch: 12, iters: 244, time: 0.549, data: 0.001) G_GAN: 0.923 G_L1: 4.245 D_real: 0.767 D_fake: 0.508 \n",
      "(epoch: 12, iters: 344, time: 0.550, data: 0.001) G_GAN: 1.078 G_L1: 0.024 D_real: 1.144 D_fake: 0.386 \n",
      "End of epoch 12 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 48, time: 0.805, data: 0.001) G_GAN: 1.116 G_L1: 0.023 D_real: 1.171 D_fake: 0.373 \n",
      "(epoch: 13, iters: 148, time: 0.549, data: 0.001) G_GAN: 0.799 G_L1: 5.103 D_real: 0.602 D_fake: 0.596 \n",
      "(epoch: 13, iters: 248, time: 0.550, data: 0.001) G_GAN: 0.643 G_L1: 5.947 D_real: 0.511 D_fake: 0.777 \n",
      "saving the latest model (epoch 13, total_iters 5000)\n",
      "(epoch: 13, iters: 348, time: 0.550, data: 0.001) G_GAN: 0.961 G_L1: 5.212 D_real: 0.914 D_fake: 0.461 \n",
      "End of epoch 13 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 52, time: 0.872, data: 0.001) G_GAN: 0.877 G_L1: 3.483 D_real: 0.852 D_fake: 0.525 \n",
      "(epoch: 14, iters: 152, time: 0.549, data: 0.001) G_GAN: 0.907 G_L1: 5.355 D_real: 0.956 D_fake: 0.497 \n",
      "(epoch: 14, iters: 252, time: 0.549, data: 0.001) G_GAN: 0.726 G_L1: 8.131 D_real: 0.275 D_fake: 0.699 \n",
      "(epoch: 14, iters: 352, time: 0.546, data: 0.001) G_GAN: 0.590 G_L1: 5.212 D_real: 0.560 D_fake: 0.854 \n",
      "End of epoch 14 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 56, time: 0.860, data: 0.001) G_GAN: 0.835 G_L1: 9.493 D_real: 0.665 D_fake: 0.573 \n",
      "(epoch: 15, iters: 156, time: 0.550, data: 0.001) G_GAN: 0.830 G_L1: 3.334 D_real: 0.685 D_fake: 0.563 \n",
      "(epoch: 15, iters: 256, time: 0.549, data: 0.001) G_GAN: 0.731 G_L1: 4.304 D_real: 0.569 D_fake: 0.693 \n",
      "(epoch: 15, iters: 356, time: 0.552, data: 0.001) G_GAN: 0.592 G_L1: 6.389 D_real: 0.536 D_fake: 0.831 \n",
      "saving the model at the end of epoch 15, iters 5940\n",
      "End of epoch 15 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 60, time: 0.888, data: 0.001) G_GAN: 0.843 G_L1: 4.010 D_real: 0.877 D_fake: 0.557 \n",
      "(epoch: 16, iters: 160, time: 0.548, data: 0.001) G_GAN: 0.775 G_L1: 2.716 D_real: 0.791 D_fake: 0.618 \n",
      "(epoch: 16, iters: 260, time: 0.547, data: 0.001) G_GAN: 0.881 G_L1: 3.629 D_real: 0.932 D_fake: 0.517 \n",
      "(epoch: 16, iters: 360, time: 0.547, data: 0.001) G_GAN: 0.798 G_L1: 7.860 D_real: 0.267 D_fake: 0.605 \n",
      "End of epoch 16 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 64, time: 0.882, data: 0.001) G_GAN: 0.768 G_L1: 5.215 D_real: 0.848 D_fake: 0.633 \n",
      "(epoch: 17, iters: 164, time: 0.548, data: 0.001) G_GAN: 0.831 G_L1: 5.489 D_real: 0.714 D_fake: 0.566 \n",
      "(epoch: 17, iters: 264, time: 0.549, data: 0.001) G_GAN: 0.450 G_L1: 8.538 D_real: 0.278 D_fake: 1.104 \n",
      "(epoch: 17, iters: 364, time: 0.547, data: 0.001) G_GAN: 0.764 G_L1: 5.293 D_real: 0.700 D_fake: 0.651 \n",
      "End of epoch 17 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 68, time: 0.871, data: 0.001) G_GAN: 0.756 G_L1: 8.745 D_real: 0.657 D_fake: 0.632 \n",
      "(epoch: 18, iters: 168, time: 0.549, data: 0.001) G_GAN: 0.648 G_L1: 7.108 D_real: 0.260 D_fake: 0.853 \n",
      "(epoch: 18, iters: 268, time: 0.549, data: 0.001) G_GAN: 0.627 G_L1: 5.057 D_real: 0.459 D_fake: 0.799 \n",
      "(epoch: 18, iters: 368, time: 0.549, data: 0.001) G_GAN: 0.494 G_L1: 5.888 D_real: 0.327 D_fake: 1.084 \n",
      "End of epoch 18 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 72, time: 0.898, data: 0.001) G_GAN: 0.846 G_L1: 6.584 D_real: 0.496 D_fake: 0.600 \n",
      "(epoch: 19, iters: 172, time: 0.550, data: 0.001) G_GAN: 0.253 G_L1: 5.198 D_real: 0.236 D_fake: 1.787 \n",
      "(epoch: 19, iters: 272, time: 0.547, data: 0.001) G_GAN: 0.722 G_L1: 3.249 D_real: 0.610 D_fake: 0.674 \n",
      "(epoch: 19, iters: 372, time: 0.549, data: 0.001) G_GAN: 0.997 G_L1: 0.028 D_real: 1.007 D_fake: 0.456 \n",
      "End of epoch 19 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 76, time: 0.866, data: 0.001) G_GAN: 0.783 G_L1: 5.660 D_real: 0.612 D_fake: 0.609 \n",
      "(epoch: 20, iters: 176, time: 0.548, data: 0.001) G_GAN: 0.891 G_L1: 5.043 D_real: 0.605 D_fake: 0.524 \n",
      "(epoch: 20, iters: 276, time: 0.548, data: 0.001) G_GAN: 0.714 G_L1: 5.417 D_real: 0.496 D_fake: 0.699 \n",
      "(epoch: 20, iters: 376, time: 0.546, data: 0.001) G_GAN: 0.921 G_L1: 5.726 D_real: 0.919 D_fake: 0.527 \n",
      "saving the model at the end of epoch 20, iters 7920\n",
      "End of epoch 20 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 80, time: 1.002, data: 0.001) G_GAN: 0.721 G_L1: 7.545 D_real: 0.430 D_fake: 0.668 \n",
      "(epoch: 21, iters: 180, time: 0.651, data: 0.001) G_GAN: 0.786 G_L1: 3.448 D_real: 0.744 D_fake: 0.630 \n",
      "(epoch: 21, iters: 280, time: 0.545, data: 0.001) G_GAN: 0.919 G_L1: 4.830 D_real: 0.876 D_fake: 0.499 \n",
      "(epoch: 21, iters: 380, time: 0.681, data: 0.001) G_GAN: 0.808 G_L1: 6.754 D_real: 0.646 D_fake: 0.584 \n",
      "End of epoch 21 / 200 \t Time Taken: 154 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 84, time: 0.936, data: 0.001) G_GAN: 0.777 G_L1: 3.669 D_real: 0.781 D_fake: 0.612 \n",
      "(epoch: 22, iters: 184, time: 0.541, data: 0.001) G_GAN: 0.680 G_L1: 5.312 D_real: 0.574 D_fake: 0.727 \n",
      "(epoch: 22, iters: 284, time: 0.566, data: 0.001) G_GAN: 0.427 G_L1: 3.845 D_real: 0.389 D_fake: 1.155 \n",
      "(epoch: 22, iters: 384, time: 0.549, data: 0.001) G_GAN: 0.866 G_L1: 3.755 D_real: 0.773 D_fake: 0.534 \n",
      "End of epoch 22 / 200 \t Time Taken: 148 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 88, time: 0.992, data: 0.001) G_GAN: 0.966 G_L1: 0.092 D_real: 0.984 D_fake: 0.470 \n",
      "(epoch: 23, iters: 188, time: 0.544, data: 0.001) G_GAN: 0.590 G_L1: 4.244 D_real: 0.608 D_fake: 0.829 \n",
      "(epoch: 23, iters: 288, time: 0.607, data: 0.001) G_GAN: 0.855 G_L1: 3.529 D_real: 0.801 D_fake: 0.541 \n",
      "(epoch: 23, iters: 388, time: 0.602, data: 0.002) G_GAN: 0.815 G_L1: 5.170 D_real: 0.755 D_fake: 0.589 \n",
      "End of epoch 23 / 200 \t Time Taken: 152 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 92, time: 0.955, data: 0.001) G_GAN: 0.786 G_L1: 3.084 D_real: 0.799 D_fake: 0.600 \n",
      "(epoch: 24, iters: 192, time: 0.581, data: 0.001) G_GAN: 0.758 G_L1: 4.982 D_real: 0.537 D_fake: 0.639 \n",
      "(epoch: 24, iters: 292, time: 0.582, data: 0.001) G_GAN: 0.788 G_L1: 5.596 D_real: 0.674 D_fake: 0.605 \n",
      "(epoch: 24, iters: 392, time: 0.585, data: 0.002) G_GAN: 0.776 G_L1: 7.642 D_real: 0.253 D_fake: 0.708 \n",
      "End of epoch 24 / 200 \t Time Taken: 154 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 96, time: 0.899, data: 0.001) G_GAN: 0.676 G_L1: 5.518 D_real: 0.405 D_fake: 0.734 \n",
      "(epoch: 25, iters: 196, time: 0.593, data: 0.001) G_GAN: 0.801 G_L1: 0.028 D_real: 0.825 D_fake: 0.583 \n",
      "(epoch: 25, iters: 296, time: 0.541, data: 0.001) G_GAN: 0.733 G_L1: 4.170 D_real: 0.576 D_fake: 0.679 \n",
      "(epoch: 25, iters: 396, time: 0.542, data: 0.001) G_GAN: 0.847 G_L1: 4.566 D_real: 0.757 D_fake: 0.551 \n",
      "saving the model at the end of epoch 25, iters 9900\n",
      "End of epoch 25 / 200 \t Time Taken: 148 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.899, data: 0.080) G_GAN: 0.754 G_L1: 6.060 D_real: 0.633 D_fake: 0.647 \n",
      "saving the latest model (epoch 26, total_iters 10000)\n",
      "(epoch: 26, iters: 200, time: 0.541, data: 0.001) G_GAN: 0.558 G_L1: 5.799 D_real: 0.671 D_fake: 0.907 \n",
      "(epoch: 26, iters: 300, time: 0.541, data: 0.001) G_GAN: 0.633 G_L1: 6.048 D_real: 0.469 D_fake: 0.819 \n",
      "End of epoch 26 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 4, time: 0.587, data: 0.001) G_GAN: 0.564 G_L1: 4.200 D_real: 0.406 D_fake: 0.898 \n",
      "(epoch: 27, iters: 104, time: 0.912, data: 0.002) G_GAN: 0.906 G_L1: 4.642 D_real: 0.825 D_fake: 0.509 \n",
      "(epoch: 27, iters: 204, time: 0.541, data: 0.001) G_GAN: 0.899 G_L1: 1.367 D_real: 0.901 D_fake: 0.515 \n",
      "(epoch: 27, iters: 304, time: 0.543, data: 0.001) G_GAN: 0.695 G_L1: 3.960 D_real: 0.655 D_fake: 0.691 \n",
      "End of epoch 27 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 8, time: 0.538, data: 0.001) G_GAN: 0.773 G_L1: 2.502 D_real: 0.711 D_fake: 0.647 \n",
      "(epoch: 28, iters: 108, time: 0.896, data: 0.001) G_GAN: 0.919 G_L1: 1.299 D_real: 0.913 D_fake: 0.503 \n",
      "(epoch: 28, iters: 208, time: 0.541, data: 0.001) G_GAN: 0.710 G_L1: 6.709 D_real: 0.538 D_fake: 0.676 \n",
      "(epoch: 28, iters: 308, time: 0.539, data: 0.001) G_GAN: 0.771 G_L1: 3.666 D_real: 0.621 D_fake: 0.614 \n",
      "End of epoch 28 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 12, time: 0.540, data: 0.001) G_GAN: 0.971 G_L1: 3.777 D_real: 0.949 D_fake: 0.475 \n",
      "(epoch: 29, iters: 112, time: 0.880, data: 0.001) G_GAN: 0.663 G_L1: 3.768 D_real: 0.645 D_fake: 0.741 \n",
      "(epoch: 29, iters: 212, time: 0.539, data: 0.001) G_GAN: 0.711 G_L1: 5.919 D_real: 0.555 D_fake: 0.690 \n",
      "(epoch: 29, iters: 312, time: 0.541, data: 0.001) G_GAN: 0.632 G_L1: 4.451 D_real: 0.651 D_fake: 0.796 \n",
      "End of epoch 29 / 200 \t Time Taken: 141 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 16, time: 0.542, data: 0.001) G_GAN: 0.712 G_L1: 5.058 D_real: 0.777 D_fake: 0.671 \n",
      "(epoch: 30, iters: 116, time: 0.918, data: 0.001) G_GAN: 0.742 G_L1: 4.530 D_real: 0.627 D_fake: 0.655 \n",
      "(epoch: 30, iters: 216, time: 0.538, data: 0.001) G_GAN: 0.530 G_L1: 4.685 D_real: 0.504 D_fake: 0.987 \n",
      "(epoch: 30, iters: 316, time: 0.541, data: 0.001) G_GAN: 0.728 G_L1: 3.636 D_real: 0.627 D_fake: 0.690 \n",
      "saving the model at the end of epoch 30, iters 11880\n",
      "End of epoch 30 / 200 \t Time Taken: 142 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 20, time: 0.541, data: 0.001) G_GAN: 0.605 G_L1: 4.845 D_real: 0.622 D_fake: 0.814 \n",
      "(epoch: 31, iters: 120, time: 0.928, data: 0.001) G_GAN: 0.621 G_L1: 3.035 D_real: 0.563 D_fake: 0.795 \n",
      "(epoch: 31, iters: 220, time: 0.539, data: 0.001) G_GAN: 0.685 G_L1: 3.731 D_real: 0.634 D_fake: 0.705 \n",
      "(epoch: 31, iters: 320, time: 0.541, data: 0.001) G_GAN: 0.504 G_L1: 4.780 D_real: 0.489 D_fake: 1.045 \n",
      "End of epoch 31 / 200 \t Time Taken: 142 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 24, time: 0.541, data: 0.001) G_GAN: 0.718 G_L1: 4.188 D_real: 0.656 D_fake: 0.630 \n",
      "(epoch: 32, iters: 124, time: 0.883, data: 0.001) G_GAN: 0.781 G_L1: 3.232 D_real: 0.718 D_fake: 0.623 \n",
      "(epoch: 32, iters: 224, time: 0.541, data: 0.001) G_GAN: 0.851 G_L1: 3.595 D_real: 0.785 D_fake: 0.535 \n",
      "(epoch: 32, iters: 324, time: 0.544, data: 0.001) G_GAN: 0.690 G_L1: 4.101 D_real: 0.669 D_fake: 0.717 \n",
      "End of epoch 32 / 200 \t Time Taken: 142 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 28, time: 0.540, data: 0.001) G_GAN: 0.851 G_L1: 4.586 D_real: 0.646 D_fake: 0.551 \n",
      "(epoch: 33, iters: 128, time: 0.962, data: 0.001) G_GAN: 0.727 G_L1: 4.344 D_real: 0.605 D_fake: 0.683 \n",
      "(epoch: 33, iters: 228, time: 0.543, data: 0.001) G_GAN: 0.511 G_L1: 4.758 D_real: 0.521 D_fake: 0.993 \n",
      "(epoch: 33, iters: 328, time: 0.540, data: 0.001) G_GAN: 0.796 G_L1: 4.367 D_real: 0.752 D_fake: 0.589 \n",
      "End of epoch 33 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 32, time: 0.539, data: 0.001) G_GAN: 0.745 G_L1: 0.033 D_real: 0.749 D_fake: 0.641 \n",
      "(epoch: 34, iters: 132, time: 0.911, data: 0.001) G_GAN: 0.718 G_L1: 2.486 D_real: 0.681 D_fake: 0.674 \n",
      "(epoch: 34, iters: 232, time: 0.540, data: 0.001) G_GAN: 0.847 G_L1: 0.032 D_real: 0.850 D_fake: 0.558 \n",
      "(epoch: 34, iters: 332, time: 0.541, data: 0.001) G_GAN: 0.817 G_L1: 0.027 D_real: 0.825 D_fake: 0.586 \n",
      "End of epoch 34 / 200 \t Time Taken: 142 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 36, time: 0.542, data: 0.001) G_GAN: 0.783 G_L1: 4.013 D_real: 0.772 D_fake: 0.643 \n",
      "(epoch: 35, iters: 136, time: 1.090, data: 0.001) G_GAN: 0.717 G_L1: 4.015 D_real: 0.579 D_fake: 0.722 \n",
      "(epoch: 35, iters: 236, time: 0.543, data: 0.001) G_GAN: 0.760 G_L1: 3.575 D_real: 0.809 D_fake: 0.629 \n",
      "(epoch: 35, iters: 336, time: 0.539, data: 0.001) G_GAN: 0.911 G_L1: 2.148 D_real: 0.852 D_fake: 0.509 \n",
      "saving the model at the end of epoch 35, iters 13860\n",
      "End of epoch 35 / 200 \t Time Taken: 146 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 40, time: 0.540, data: 0.001) G_GAN: 0.805 G_L1: 2.825 D_real: 0.735 D_fake: 0.575 \n",
      "(epoch: 36, iters: 140, time: 0.945, data: 0.001) G_GAN: 0.588 G_L1: 6.915 D_real: 0.312 D_fake: 0.999 \n",
      "(epoch: 36, iters: 240, time: 0.544, data: 0.001) G_GAN: 0.820 G_L1: 0.833 D_real: 0.824 D_fake: 0.580 \n",
      "(epoch: 36, iters: 340, time: 0.546, data: 0.001) G_GAN: 0.896 G_L1: 2.278 D_real: 0.895 D_fake: 0.510 \n",
      "End of epoch 36 / 200 \t Time Taken: 142 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 44, time: 0.547, data: 0.001) G_GAN: 0.709 G_L1: 4.627 D_real: 0.527 D_fake: 0.742 \n",
      "(epoch: 37, iters: 144, time: 0.923, data: 0.001) G_GAN: 0.691 G_L1: 4.993 D_real: 0.445 D_fake: 0.915 \n",
      "(epoch: 37, iters: 244, time: 0.547, data: 0.001) G_GAN: 0.827 G_L1: 4.637 D_real: 0.684 D_fake: 0.571 \n",
      "(epoch: 37, iters: 344, time: 0.545, data: 0.001) G_GAN: 0.891 G_L1: 2.232 D_real: 0.862 D_fake: 0.524 \n",
      "End of epoch 37 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 48, time: 0.546, data: 0.001) G_GAN: 0.821 G_L1: 3.405 D_real: 0.828 D_fake: 0.574 \n",
      "(epoch: 38, iters: 148, time: 0.944, data: 0.002) G_GAN: 0.776 G_L1: 4.217 D_real: 0.636 D_fake: 0.605 \n",
      "(epoch: 38, iters: 248, time: 0.546, data: 0.001) G_GAN: 0.860 G_L1: 2.337 D_real: 0.890 D_fake: 0.551 \n",
      "(epoch: 38, iters: 348, time: 0.546, data: 0.002) G_GAN: 0.891 G_L1: 3.205 D_real: 0.761 D_fake: 0.492 \n",
      "saving the latest model (epoch 38, total_iters 15000)\n",
      "End of epoch 38 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 52, time: 0.547, data: 0.002) G_GAN: 0.558 G_L1: 5.467 D_real: 0.346 D_fake: 1.062 \n",
      "(epoch: 39, iters: 152, time: 0.936, data: 0.001) G_GAN: 0.679 G_L1: 4.124 D_real: 0.549 D_fake: 0.731 \n",
      "(epoch: 39, iters: 252, time: 0.547, data: 0.001) G_GAN: 0.686 G_L1: 3.064 D_real: 0.632 D_fake: 0.733 \n",
      "(epoch: 39, iters: 352, time: 0.548, data: 0.002) G_GAN: 0.706 G_L1: 5.222 D_real: 0.583 D_fake: 0.701 \n",
      "End of epoch 39 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 56, time: 0.544, data: 0.001) G_GAN: 0.708 G_L1: 2.612 D_real: 0.676 D_fake: 0.663 \n",
      "(epoch: 40, iters: 156, time: 0.960, data: 0.001) G_GAN: 0.656 G_L1: 2.858 D_real: 0.599 D_fake: 0.775 \n",
      "(epoch: 40, iters: 256, time: 0.546, data: 0.002) G_GAN: 0.607 G_L1: 3.046 D_real: 0.491 D_fake: 0.835 \n",
      "(epoch: 40, iters: 356, time: 0.547, data: 0.002) G_GAN: 0.825 G_L1: 4.353 D_real: 0.746 D_fake: 0.660 \n",
      "saving the model at the end of epoch 40, iters 15840\n",
      "End of epoch 40 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 60, time: 0.547, data: 0.001) G_GAN: 0.679 G_L1: 2.718 D_real: 0.569 D_fake: 0.729 \n",
      "(epoch: 41, iters: 160, time: 0.950, data: 0.001) G_GAN: 0.788 G_L1: 3.471 D_real: 0.711 D_fake: 0.616 \n",
      "(epoch: 41, iters: 260, time: 0.547, data: 0.001) G_GAN: 0.691 G_L1: 4.247 D_real: 0.464 D_fake: 0.725 \n",
      "(epoch: 41, iters: 360, time: 0.547, data: 0.001) G_GAN: 0.718 G_L1: 3.537 D_real: 0.723 D_fake: 0.667 \n",
      "End of epoch 41 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 64, time: 0.550, data: 0.001) G_GAN: 0.791 G_L1: 2.767 D_real: 0.621 D_fake: 0.611 \n",
      "(epoch: 42, iters: 164, time: 0.920, data: 0.001) G_GAN: 0.819 G_L1: 1.262 D_real: 0.796 D_fake: 0.585 \n",
      "(epoch: 42, iters: 264, time: 0.548, data: 0.001) G_GAN: 0.635 G_L1: 4.073 D_real: 0.428 D_fake: 0.911 \n",
      "(epoch: 42, iters: 364, time: 0.546, data: 0.001) G_GAN: 0.757 G_L1: 4.276 D_real: 0.671 D_fake: 0.663 \n",
      "End of epoch 42 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 68, time: 0.548, data: 0.001) G_GAN: 0.734 G_L1: 0.026 D_real: 0.740 D_fake: 0.650 \n",
      "(epoch: 43, iters: 168, time: 0.990, data: 0.001) G_GAN: 0.578 G_L1: 3.641 D_real: 0.515 D_fake: 0.871 \n",
      "(epoch: 43, iters: 268, time: 0.547, data: 0.001) G_GAN: 0.862 G_L1: 3.239 D_real: 0.763 D_fake: 0.535 \n",
      "(epoch: 43, iters: 368, time: 0.547, data: 0.001) G_GAN: 0.565 G_L1: 3.833 D_real: 0.500 D_fake: 1.001 \n",
      "End of epoch 43 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 72, time: 0.549, data: 0.001) G_GAN: 0.599 G_L1: 2.929 D_real: 0.460 D_fake: 0.843 \n",
      "(epoch: 44, iters: 172, time: 0.969, data: 0.001) G_GAN: 0.795 G_L1: 2.971 D_real: 0.768 D_fake: 0.537 \n",
      "(epoch: 44, iters: 272, time: 0.547, data: 0.002) G_GAN: 0.789 G_L1: 2.825 D_real: 0.604 D_fake: 0.598 \n",
      "(epoch: 44, iters: 372, time: 0.548, data: 0.001) G_GAN: 0.696 G_L1: 2.844 D_real: 0.626 D_fake: 0.721 \n",
      "End of epoch 44 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 76, time: 0.550, data: 0.001) G_GAN: 0.780 G_L1: 4.451 D_real: 0.506 D_fake: 0.706 \n",
      "(epoch: 45, iters: 176, time: 0.949, data: 0.001) G_GAN: 0.790 G_L1: 1.027 D_real: 0.762 D_fake: 0.605 \n",
      "(epoch: 45, iters: 276, time: 0.548, data: 0.001) G_GAN: 0.802 G_L1: 2.652 D_real: 0.650 D_fake: 0.631 \n",
      "(epoch: 45, iters: 376, time: 0.547, data: 0.001) G_GAN: 0.682 G_L1: 0.019 D_real: 0.741 D_fake: 0.651 \n",
      "saving the model at the end of epoch 45, iters 17820\n",
      "End of epoch 45 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 80, time: 0.548, data: 0.001) G_GAN: 0.660 G_L1: 4.585 D_real: 0.465 D_fake: 0.784 \n",
      "(epoch: 46, iters: 180, time: 0.996, data: 0.001) G_GAN: 0.781 G_L1: 3.192 D_real: 0.571 D_fake: 0.638 \n",
      "(epoch: 46, iters: 280, time: 0.550, data: 0.001) G_GAN: 0.609 G_L1: 3.003 D_real: 0.449 D_fake: 0.930 \n",
      "(epoch: 46, iters: 380, time: 0.549, data: 0.001) G_GAN: 0.689 G_L1: 4.042 D_real: 0.605 D_fake: 0.725 \n",
      "End of epoch 46 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 84, time: 0.549, data: 0.001) G_GAN: 0.754 G_L1: 3.438 D_real: 0.476 D_fake: 0.705 \n",
      "(epoch: 47, iters: 184, time: 0.946, data: 0.001) G_GAN: 0.754 G_L1: 3.104 D_real: 0.585 D_fake: 0.663 \n",
      "(epoch: 47, iters: 284, time: 0.547, data: 0.001) G_GAN: 0.714 G_L1: 3.252 D_real: 0.531 D_fake: 0.770 \n",
      "(epoch: 47, iters: 384, time: 0.549, data: 0.001) G_GAN: 0.740 G_L1: 2.305 D_real: 0.660 D_fake: 0.587 \n",
      "End of epoch 47 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 88, time: 0.547, data: 0.001) G_GAN: 0.885 G_L1: 3.153 D_real: 0.652 D_fake: 0.522 \n",
      "(epoch: 48, iters: 188, time: 1.033, data: 0.001) G_GAN: 0.784 G_L1: 4.531 D_real: 0.582 D_fake: 0.726 \n",
      "(epoch: 48, iters: 288, time: 0.547, data: 0.001) G_GAN: 0.723 G_L1: 2.988 D_real: 0.635 D_fake: 0.687 \n",
      "(epoch: 48, iters: 388, time: 0.551, data: 0.001) G_GAN: 0.690 G_L1: 2.870 D_real: 0.616 D_fake: 0.744 \n",
      "End of epoch 48 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 92, time: 0.549, data: 0.001) G_GAN: 0.721 G_L1: 3.426 D_real: 0.598 D_fake: 0.702 \n",
      "(epoch: 49, iters: 192, time: 0.965, data: 0.002) G_GAN: 0.642 G_L1: 5.021 D_real: 0.522 D_fake: 0.893 \n",
      "(epoch: 49, iters: 292, time: 0.548, data: 0.001) G_GAN: 0.748 G_L1: 0.042 D_real: 0.749 D_fake: 0.640 \n",
      "(epoch: 49, iters: 392, time: 0.546, data: 0.002) G_GAN: 0.867 G_L1: 3.806 D_real: 0.660 D_fake: 0.535 \n",
      "End of epoch 49 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 96, time: 0.548, data: 0.001) G_GAN: 0.692 G_L1: 3.607 D_real: 0.420 D_fake: 0.887 \n",
      "(epoch: 50, iters: 196, time: 0.982, data: 0.001) G_GAN: 0.632 G_L1: 3.697 D_real: 0.536 D_fake: 0.861 \n",
      "(epoch: 50, iters: 296, time: 0.546, data: 0.001) G_GAN: 0.752 G_L1: 0.037 D_real: 0.754 D_fake: 0.636 \n",
      "(epoch: 50, iters: 396, time: 0.549, data: 0.001) G_GAN: 0.748 G_L1: 2.841 D_real: 0.691 D_fake: 0.673 \n",
      "saving the model at the end of epoch 50, iters 19800\n",
      "End of epoch 50 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.548, data: 0.079) G_GAN: 0.779 G_L1: 1.862 D_real: 0.854 D_fake: 0.577 \n",
      "(epoch: 51, iters: 200, time: 0.986, data: 0.001) G_GAN: 0.704 G_L1: 2.982 D_real: 0.720 D_fake: 0.686 \n",
      "saving the latest model (epoch 51, total_iters 20000)\n",
      "(epoch: 51, iters: 300, time: 0.550, data: 0.001) G_GAN: 0.602 G_L1: 2.849 D_real: 0.688 D_fake: 0.851 \n",
      "End of epoch 51 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 4, time: 0.552, data: 0.001) G_GAN: 0.793 G_L1: 1.857 D_real: 0.821 D_fake: 0.580 \n",
      "(epoch: 52, iters: 104, time: 0.552, data: 0.002) G_GAN: 0.759 G_L1: 3.908 D_real: 0.942 D_fake: 0.592 \n",
      "(epoch: 52, iters: 204, time: 0.970, data: 0.002) G_GAN: 0.774 G_L1: 2.013 D_real: 0.815 D_fake: 0.595 \n",
      "(epoch: 52, iters: 304, time: 0.549, data: 0.001) G_GAN: 0.594 G_L1: 3.539 D_real: 0.473 D_fake: 0.873 \n",
      "End of epoch 52 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 8, time: 0.555, data: 0.001) G_GAN: 0.573 G_L1: 3.125 D_real: 0.514 D_fake: 0.915 \n",
      "(epoch: 53, iters: 108, time: 0.549, data: 0.001) G_GAN: 0.745 G_L1: 2.102 D_real: 0.811 D_fake: 0.632 \n",
      "(epoch: 53, iters: 208, time: 0.979, data: 0.001) G_GAN: 0.786 G_L1: 1.938 D_real: 0.775 D_fake: 0.594 \n",
      "(epoch: 53, iters: 308, time: 0.555, data: 0.001) G_GAN: 0.775 G_L1: 3.588 D_real: 0.599 D_fake: 0.605 \n",
      "End of epoch 53 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 12, time: 0.551, data: 0.001) G_GAN: 0.719 G_L1: 2.477 D_real: 0.592 D_fake: 0.700 \n",
      "(epoch: 54, iters: 112, time: 0.551, data: 0.002) G_GAN: 0.733 G_L1: 2.443 D_real: 0.720 D_fake: 0.655 \n",
      "(epoch: 54, iters: 212, time: 0.997, data: 0.001) G_GAN: 0.747 G_L1: 2.977 D_real: 0.649 D_fake: 0.671 \n",
      "(epoch: 54, iters: 312, time: 0.556, data: 0.001) G_GAN: 0.717 G_L1: 2.563 D_real: 0.614 D_fake: 0.682 \n",
      "End of epoch 54 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 16, time: 0.553, data: 0.001) G_GAN: 0.759 G_L1: 3.073 D_real: 0.749 D_fake: 0.653 \n",
      "(epoch: 55, iters: 116, time: 0.549, data: 0.002) G_GAN: 0.710 G_L1: 2.858 D_real: 0.554 D_fake: 0.716 \n",
      "(epoch: 55, iters: 216, time: 0.987, data: 0.001) G_GAN: 0.792 G_L1: 2.360 D_real: 0.645 D_fake: 0.616 \n",
      "(epoch: 55, iters: 316, time: 0.551, data: 0.001) G_GAN: 0.772 G_L1: 2.177 D_real: 0.789 D_fake: 0.561 \n",
      "saving the model at the end of epoch 55, iters 21780\n",
      "End of epoch 55 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 20, time: 0.550, data: 0.001) G_GAN: 0.734 G_L1: 3.145 D_real: 0.744 D_fake: 0.659 \n",
      "(epoch: 56, iters: 120, time: 0.555, data: 0.001) G_GAN: 0.668 G_L1: 3.026 D_real: 0.568 D_fake: 0.753 \n",
      "(epoch: 56, iters: 220, time: 0.964, data: 0.001) G_GAN: 0.895 G_L1: 2.232 D_real: 0.828 D_fake: 0.509 \n",
      "(epoch: 56, iters: 320, time: 0.553, data: 0.001) G_GAN: 0.722 G_L1: 3.470 D_real: 0.469 D_fake: 0.756 \n",
      "End of epoch 56 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 24, time: 0.553, data: 0.001) G_GAN: 0.674 G_L1: 3.311 D_real: 0.567 D_fake: 0.781 \n",
      "(epoch: 57, iters: 124, time: 0.551, data: 0.001) G_GAN: 0.769 G_L1: 3.167 D_real: 0.749 D_fake: 0.589 \n",
      "(epoch: 57, iters: 224, time: 1.016, data: 0.001) G_GAN: 0.723 G_L1: 2.713 D_real: 0.671 D_fake: 0.650 \n",
      "(epoch: 57, iters: 324, time: 0.552, data: 0.001) G_GAN: 0.621 G_L1: 3.198 D_real: 0.500 D_fake: 0.851 \n",
      "End of epoch 57 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 28, time: 0.550, data: 0.001) G_GAN: 0.640 G_L1: 3.211 D_real: 0.599 D_fake: 0.733 \n",
      "(epoch: 58, iters: 128, time: 0.556, data: 0.001) G_GAN: 0.641 G_L1: 4.245 D_real: 0.497 D_fake: 0.909 \n",
      "(epoch: 58, iters: 228, time: 1.007, data: 0.001) G_GAN: 0.598 G_L1: 3.314 D_real: 0.503 D_fake: 0.893 \n",
      "(epoch: 58, iters: 328, time: 0.550, data: 0.001) G_GAN: 0.836 G_L1: 2.550 D_real: 0.667 D_fake: 0.557 \n",
      "End of epoch 58 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 32, time: 0.565, data: 0.001) G_GAN: 0.793 G_L1: 2.941 D_real: 0.711 D_fake: 0.590 \n",
      "(epoch: 59, iters: 132, time: 0.550, data: 0.001) G_GAN: 0.731 G_L1: 2.682 D_real: 0.609 D_fake: 0.656 \n",
      "(epoch: 59, iters: 232, time: 1.024, data: 0.001) G_GAN: 0.791 G_L1: 1.543 D_real: 0.667 D_fake: 0.606 \n",
      "(epoch: 59, iters: 332, time: 0.542, data: 0.001) G_GAN: 0.802 G_L1: 3.444 D_real: 0.628 D_fake: 0.595 \n",
      "End of epoch 59 / 200 \t Time Taken: 149 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 36, time: 0.539, data: 0.001) G_GAN: 0.863 G_L1: 4.085 D_real: 0.667 D_fake: 0.554 \n",
      "(epoch: 60, iters: 136, time: 0.540, data: 0.001) G_GAN: 0.649 G_L1: 2.632 D_real: 0.557 D_fake: 0.774 \n",
      "(epoch: 60, iters: 236, time: 0.994, data: 0.001) G_GAN: 0.787 G_L1: 2.061 D_real: 0.657 D_fake: 0.634 \n",
      "(epoch: 60, iters: 336, time: 0.559, data: 0.001) G_GAN: 0.537 G_L1: 3.385 D_real: 0.516 D_fake: 0.983 \n",
      "saving the model at the end of epoch 60, iters 23760\n",
      "End of epoch 60 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 40, time: 0.539, data: 0.001) G_GAN: 0.574 G_L1: 2.994 D_real: 0.646 D_fake: 0.875 \n",
      "(epoch: 61, iters: 140, time: 0.539, data: 0.001) G_GAN: 0.687 G_L1: 0.027 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 61, iters: 240, time: 1.055, data: 0.001) G_GAN: 0.776 G_L1: 3.201 D_real: 0.644 D_fake: 0.658 \n",
      "(epoch: 61, iters: 340, time: 0.541, data: 0.001) G_GAN: 0.769 G_L1: 2.514 D_real: 1.002 D_fake: 0.558 \n",
      "End of epoch 61 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 44, time: 0.542, data: 0.001) G_GAN: 0.699 G_L1: 1.527 D_real: 0.727 D_fake: 0.684 \n",
      "(epoch: 62, iters: 144, time: 0.542, data: 0.001) G_GAN: 0.734 G_L1: 0.989 D_real: 0.685 D_fake: 0.668 \n",
      "(epoch: 62, iters: 244, time: 1.043, data: 0.001) G_GAN: 0.659 G_L1: 3.362 D_real: 0.498 D_fake: 0.811 \n",
      "(epoch: 62, iters: 344, time: 0.628, data: 0.001) G_GAN: 0.786 G_L1: 1.369 D_real: 0.695 D_fake: 0.611 \n",
      "End of epoch 62 / 200 \t Time Taken: 146 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 48, time: 0.540, data: 0.001) G_GAN: 0.700 G_L1: 2.260 D_real: 0.600 D_fake: 0.712 \n",
      "(epoch: 63, iters: 148, time: 0.544, data: 0.001) G_GAN: 0.759 G_L1: 2.423 D_real: 0.595 D_fake: 0.660 \n",
      "(epoch: 63, iters: 248, time: 1.090, data: 0.001) G_GAN: 0.752 G_L1: 2.674 D_real: 0.703 D_fake: 0.625 \n",
      "(epoch: 63, iters: 348, time: 0.540, data: 0.001) G_GAN: 0.746 G_L1: 2.449 D_real: 0.690 D_fake: 0.636 \n",
      "End of epoch 63 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 52, time: 0.613, data: 0.001) G_GAN: 0.700 G_L1: 0.031 D_real: 0.701 D_fake: 0.686 \n",
      "saving the latest model (epoch 64, total_iters 25000)\n",
      "(epoch: 64, iters: 152, time: 0.539, data: 0.001) G_GAN: 0.732 G_L1: 2.085 D_real: 0.734 D_fake: 0.682 \n",
      "(epoch: 64, iters: 252, time: 1.031, data: 0.001) G_GAN: 0.714 G_L1: 3.270 D_real: 0.742 D_fake: 0.636 \n",
      "(epoch: 64, iters: 352, time: 0.542, data: 0.001) G_GAN: 0.759 G_L1: 1.571 D_real: 0.782 D_fake: 0.615 \n",
      "End of epoch 64 / 200 \t Time Taken: 146 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 56, time: 0.553, data: 0.001) G_GAN: 0.699 G_L1: 2.932 D_real: 0.637 D_fake: 0.735 \n",
      "(epoch: 65, iters: 156, time: 0.608, data: 0.001) G_GAN: 0.684 G_L1: 0.031 D_real: 0.686 D_fake: 0.699 \n",
      "(epoch: 65, iters: 256, time: 1.025, data: 0.001) G_GAN: 0.790 G_L1: 2.511 D_real: 0.702 D_fake: 0.604 \n",
      "(epoch: 65, iters: 356, time: 0.543, data: 0.001) G_GAN: 0.798 G_L1: 1.923 D_real: 0.712 D_fake: 0.627 \n",
      "saving the model at the end of epoch 65, iters 25740\n",
      "End of epoch 65 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 60, time: 0.541, data: 0.001) G_GAN: 0.727 G_L1: 2.004 D_real: 0.654 D_fake: 0.663 \n",
      "(epoch: 66, iters: 160, time: 0.541, data: 0.001) G_GAN: 0.636 G_L1: 2.421 D_real: 0.507 D_fake: 0.780 \n",
      "(epoch: 66, iters: 260, time: 1.026, data: 0.001) G_GAN: 0.686 G_L1: 1.848 D_real: 0.687 D_fake: 0.724 \n",
      "(epoch: 66, iters: 360, time: 0.542, data: 0.001) G_GAN: 0.690 G_L1: 3.331 D_real: 0.486 D_fake: 0.901 \n",
      "End of epoch 66 / 200 \t Time Taken: 142 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 64, time: 0.547, data: 0.001) G_GAN: 0.779 G_L1: 1.781 D_real: 0.782 D_fake: 0.586 \n",
      "(epoch: 67, iters: 164, time: 0.546, data: 0.001) G_GAN: 0.838 G_L1: 1.973 D_real: 0.956 D_fake: 0.464 \n",
      "(epoch: 67, iters: 264, time: 1.032, data: 0.001) G_GAN: 0.684 G_L1: 2.744 D_real: 0.691 D_fake: 0.707 \n",
      "(epoch: 67, iters: 364, time: 0.545, data: 0.001) G_GAN: 0.696 G_L1: 2.774 D_real: 0.570 D_fake: 0.730 \n",
      "End of epoch 67 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 68, time: 0.549, data: 0.001) G_GAN: 0.690 G_L1: 2.194 D_real: 0.577 D_fake: 0.797 \n",
      "(epoch: 68, iters: 168, time: 0.548, data: 0.001) G_GAN: 0.785 G_L1: 1.144 D_real: 0.689 D_fake: 0.620 \n",
      "(epoch: 68, iters: 268, time: 1.046, data: 0.001) G_GAN: 0.724 G_L1: 2.232 D_real: 0.755 D_fake: 0.649 \n",
      "(epoch: 68, iters: 368, time: 0.549, data: 0.001) G_GAN: 0.880 G_L1: 2.330 D_real: 0.953 D_fake: 0.503 \n",
      "End of epoch 68 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 72, time: 0.548, data: 0.002) G_GAN: 0.690 G_L1: 2.079 D_real: 0.685 D_fake: 0.679 \n",
      "(epoch: 69, iters: 172, time: 0.548, data: 0.001) G_GAN: 0.845 G_L1: 2.608 D_real: 0.948 D_fake: 0.552 \n",
      "(epoch: 69, iters: 272, time: 1.042, data: 0.001) G_GAN: 0.802 G_L1: 2.720 D_real: 0.847 D_fake: 0.549 \n",
      "(epoch: 69, iters: 372, time: 0.550, data: 0.001) G_GAN: 0.767 G_L1: 2.852 D_real: 0.763 D_fake: 0.568 \n",
      "End of epoch 69 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 76, time: 0.549, data: 0.001) G_GAN: 0.803 G_L1: 1.423 D_real: 0.733 D_fake: 0.598 \n",
      "(epoch: 70, iters: 176, time: 0.549, data: 0.001) G_GAN: 0.693 G_L1: 0.049 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 70, iters: 276, time: 1.030, data: 0.001) G_GAN: 0.790 G_L1: 2.286 D_real: 0.988 D_fake: 0.539 \n",
      "(epoch: 70, iters: 376, time: 0.549, data: 0.001) G_GAN: 0.733 G_L1: 1.542 D_real: 0.739 D_fake: 0.657 \n",
      "saving the model at the end of epoch 70, iters 27720\n",
      "End of epoch 70 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 80, time: 0.550, data: 0.001) G_GAN: 0.789 G_L1: 1.427 D_real: 0.780 D_fake: 0.604 \n",
      "(epoch: 71, iters: 180, time: 0.550, data: 0.001) G_GAN: 0.793 G_L1: 1.416 D_real: 0.701 D_fake: 0.605 \n",
      "(epoch: 71, iters: 280, time: 1.067, data: 0.001) G_GAN: 0.803 G_L1: 2.101 D_real: 0.836 D_fake: 0.528 \n",
      "(epoch: 71, iters: 380, time: 0.550, data: 0.001) G_GAN: 0.638 G_L1: 2.286 D_real: 0.626 D_fake: 0.779 \n",
      "End of epoch 71 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 84, time: 0.607, data: 0.001) G_GAN: 0.673 G_L1: 0.043 D_real: 0.702 D_fake: 0.696 \n",
      "(epoch: 72, iters: 184, time: 0.558, data: 0.001) G_GAN: 0.775 G_L1: 1.688 D_real: 0.714 D_fake: 0.630 \n",
      "(epoch: 72, iters: 284, time: 1.104, data: 0.001) G_GAN: 0.675 G_L1: 1.941 D_real: 0.656 D_fake: 0.744 \n",
      "(epoch: 72, iters: 384, time: 0.557, data: 0.001) G_GAN: 0.677 G_L1: 2.468 D_real: 0.613 D_fake: 0.722 \n",
      "End of epoch 72 / 200 \t Time Taken: 148 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 88, time: 0.555, data: 0.001) G_GAN: 0.733 G_L1: 2.159 D_real: 0.699 D_fake: 0.646 \n",
      "(epoch: 73, iters: 188, time: 0.551, data: 0.001) G_GAN: 0.844 G_L1: 2.031 D_real: 0.946 D_fake: 0.526 \n",
      "(epoch: 73, iters: 288, time: 1.034, data: 0.001) G_GAN: 0.752 G_L1: 1.397 D_real: 0.657 D_fake: 0.640 \n",
      "(epoch: 73, iters: 388, time: 0.545, data: 0.001) G_GAN: 0.769 G_L1: 2.258 D_real: 0.651 D_fake: 0.656 \n",
      "End of epoch 73 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 92, time: 0.550, data: 0.001) G_GAN: 0.681 G_L1: 2.315 D_real: 0.649 D_fake: 0.727 \n",
      "(epoch: 74, iters: 192, time: 0.557, data: 0.001) G_GAN: 0.721 G_L1: 0.044 D_real: 0.734 D_fake: 0.661 \n",
      "(epoch: 74, iters: 292, time: 1.072, data: 0.002) G_GAN: 0.688 G_L1: 1.738 D_real: 0.735 D_fake: 0.683 \n",
      "(epoch: 74, iters: 392, time: 0.549, data: 0.001) G_GAN: 0.779 G_L1: 3.017 D_real: 0.769 D_fake: 0.658 \n",
      "End of epoch 74 / 200 \t Time Taken: 147 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 96, time: 0.560, data: 0.001) G_GAN: 0.605 G_L1: 3.562 D_real: 0.591 D_fake: 0.845 \n",
      "(epoch: 75, iters: 196, time: 0.551, data: 0.001) G_GAN: 0.689 G_L1: 2.526 D_real: 0.655 D_fake: 0.702 \n",
      "(epoch: 75, iters: 296, time: 1.072, data: 0.001) G_GAN: 0.772 G_L1: 1.498 D_real: 0.752 D_fake: 0.635 \n",
      "(epoch: 75, iters: 396, time: 0.600, data: 0.001) G_GAN: 0.761 G_L1: 2.434 D_real: 0.609 D_fake: 0.651 \n",
      "saving the model at the end of epoch 75, iters 29700\n",
      "End of epoch 75 / 200 \t Time Taken: 149 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 100, time: 0.553, data: 0.088) G_GAN: 0.738 G_L1: 0.844 D_real: 0.705 D_fake: 0.657 \n",
      "(epoch: 76, iters: 200, time: 0.552, data: 0.001) G_GAN: 0.706 G_L1: 0.023 D_real: 0.706 D_fake: 0.685 \n",
      "(epoch: 76, iters: 300, time: 1.063, data: 0.001) G_GAN: 0.790 G_L1: 1.341 D_real: 0.824 D_fake: 0.578 \n",
      "saving the latest model (epoch 76, total_iters 30000)\n",
      "End of epoch 76 / 200 \t Time Taken: 146 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 4, time: 0.550, data: 0.001) G_GAN: 0.740 G_L1: 2.240 D_real: 0.694 D_fake: 0.654 \n",
      "(epoch: 77, iters: 104, time: 0.553, data: 0.002) G_GAN: 0.649 G_L1: 2.572 D_real: 0.537 D_fake: 0.819 \n",
      "(epoch: 77, iters: 204, time: 0.552, data: 0.001) G_GAN: 0.644 G_L1: 2.041 D_real: 0.569 D_fake: 0.821 \n",
      "(epoch: 77, iters: 304, time: 1.120, data: 0.001) G_GAN: 0.685 G_L1: 2.516 D_real: 0.674 D_fake: 0.745 \n",
      "End of epoch 77 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 8, time: 0.553, data: 0.001) G_GAN: 0.785 G_L1: 2.002 D_real: 0.789 D_fake: 0.589 \n",
      "(epoch: 78, iters: 108, time: 0.551, data: 0.001) G_GAN: 0.725 G_L1: 2.523 D_real: 0.798 D_fake: 0.634 \n",
      "(epoch: 78, iters: 208, time: 0.621, data: 0.001) G_GAN: 0.719 G_L1: 2.255 D_real: 0.609 D_fake: 0.654 \n",
      "(epoch: 78, iters: 308, time: 1.226, data: 0.001) G_GAN: 0.716 G_L1: 1.907 D_real: 0.705 D_fake: 0.680 \n",
      "End of epoch 78 / 200 \t Time Taken: 153 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 12, time: 0.628, data: 0.002) G_GAN: 0.759 G_L1: 1.313 D_real: 0.763 D_fake: 0.615 \n",
      "(epoch: 79, iters: 112, time: 0.544, data: 0.001) G_GAN: 0.662 G_L1: 2.107 D_real: 0.612 D_fake: 0.748 \n",
      "(epoch: 79, iters: 212, time: 0.564, data: 0.002) G_GAN: 0.736 G_L1: 2.940 D_real: 0.700 D_fake: 0.631 \n",
      "(epoch: 79, iters: 312, time: 1.084, data: 0.001) G_GAN: 0.659 G_L1: 2.726 D_real: 0.562 D_fake: 0.808 \n",
      "End of epoch 79 / 200 \t Time Taken: 148 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 16, time: 0.558, data: 0.001) G_GAN: 0.706 G_L1: 1.735 D_real: 0.702 D_fake: 0.669 \n",
      "(epoch: 80, iters: 116, time: 0.551, data: 0.001) G_GAN: 0.684 G_L1: 2.202 D_real: 0.653 D_fake: 0.690 \n",
      "(epoch: 80, iters: 216, time: 0.559, data: 0.001) G_GAN: 0.809 G_L1: 1.709 D_real: 0.773 D_fake: 0.570 \n",
      "(epoch: 80, iters: 316, time: 1.099, data: 0.001) G_GAN: 0.649 G_L1: 3.069 D_real: 0.529 D_fake: 0.826 \n",
      "saving the model at the end of epoch 80, iters 31680\n",
      "End of epoch 80 / 200 \t Time Taken: 147 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 20, time: 0.544, data: 0.002) G_GAN: 0.883 G_L1: 1.456 D_real: 0.803 D_fake: 0.542 \n",
      "(epoch: 81, iters: 120, time: 0.541, data: 0.001) G_GAN: 0.828 G_L1: 1.674 D_real: 0.820 D_fake: 0.549 \n",
      "(epoch: 81, iters: 220, time: 0.599, data: 0.001) G_GAN: 0.630 G_L1: 3.252 D_real: 0.505 D_fake: 0.873 \n",
      "(epoch: 81, iters: 320, time: 1.059, data: 0.001) G_GAN: 0.763 G_L1: 1.089 D_real: 0.692 D_fake: 0.634 \n",
      "End of epoch 81 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 24, time: 0.541, data: 0.001) G_GAN: 0.725 G_L1: 1.465 D_real: 0.710 D_fake: 0.655 \n",
      "(epoch: 82, iters: 124, time: 0.541, data: 0.001) G_GAN: 0.712 G_L1: 0.054 D_real: 0.713 D_fake: 0.676 \n",
      "(epoch: 82, iters: 224, time: 0.551, data: 0.002) G_GAN: 0.742 G_L1: 1.996 D_real: 0.674 D_fake: 0.632 \n",
      "(epoch: 82, iters: 324, time: 1.213, data: 0.001) G_GAN: 0.723 G_L1: 1.992 D_real: 0.664 D_fake: 0.679 \n",
      "End of epoch 82 / 200 \t Time Taken: 147 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 28, time: 0.614, data: 0.001) G_GAN: 0.580 G_L1: 3.646 D_real: 0.414 D_fake: 1.022 \n",
      "(epoch: 83, iters: 128, time: 0.541, data: 0.001) G_GAN: 0.712 G_L1: 0.700 D_real: 0.680 D_fake: 0.675 \n",
      "(epoch: 83, iters: 228, time: 0.543, data: 0.001) G_GAN: 0.661 G_L1: 1.854 D_real: 0.650 D_fake: 0.755 \n",
      "(epoch: 83, iters: 328, time: 1.098, data: 0.001) G_GAN: 0.734 G_L1: 1.730 D_real: 0.746 D_fake: 0.625 \n",
      "End of epoch 83 / 200 \t Time Taken: 148 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 32, time: 0.552, data: 0.001) G_GAN: 0.654 G_L1: 0.682 D_real: 0.711 D_fake: 0.676 \n",
      "(epoch: 84, iters: 132, time: 0.570, data: 0.001) G_GAN: 0.761 G_L1: 2.331 D_real: 0.666 D_fake: 0.641 \n",
      "(epoch: 84, iters: 232, time: 0.544, data: 0.001) G_GAN: 0.765 G_L1: 1.907 D_real: 0.766 D_fake: 0.611 \n",
      "(epoch: 84, iters: 332, time: 1.220, data: 0.001) G_GAN: 0.688 G_L1: 2.071 D_real: 0.625 D_fake: 0.737 \n",
      "End of epoch 84 / 200 \t Time Taken: 146 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 36, time: 0.560, data: 0.001) G_GAN: 0.708 G_L1: 3.004 D_real: 0.507 D_fake: 0.723 \n",
      "(epoch: 85, iters: 136, time: 0.668, data: 0.001) G_GAN: 0.590 G_L1: 2.587 D_real: 0.515 D_fake: 0.860 \n",
      "(epoch: 85, iters: 236, time: 0.546, data: 0.001) G_GAN: 0.773 G_L1: 1.801 D_real: 0.727 D_fake: 0.633 \n",
      "(epoch: 85, iters: 336, time: 1.106, data: 0.002) G_GAN: 0.762 G_L1: 1.569 D_real: 0.731 D_fake: 0.617 \n",
      "saving the model at the end of epoch 85, iters 33660\n",
      "End of epoch 85 / 200 \t Time Taken: 148 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 40, time: 0.545, data: 0.001) G_GAN: 0.604 G_L1: 1.927 D_real: 0.527 D_fake: 0.868 \n",
      "(epoch: 86, iters: 140, time: 0.546, data: 0.001) G_GAN: 0.665 G_L1: 1.918 D_real: 0.641 D_fake: 0.738 \n",
      "(epoch: 86, iters: 240, time: 0.547, data: 0.001) G_GAN: 0.821 G_L1: 2.289 D_real: 0.821 D_fake: 0.562 \n",
      "(epoch: 86, iters: 340, time: 0.993, data: 0.001) G_GAN: 0.700 G_L1: 0.684 D_real: 0.673 D_fake: 0.691 \n",
      "End of epoch 86 / 200 \t Time Taken: 143 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 44, time: 0.548, data: 0.001) G_GAN: 0.799 G_L1: 1.422 D_real: 0.746 D_fake: 0.594 \n",
      "(epoch: 87, iters: 144, time: 0.550, data: 0.001) G_GAN: 0.776 G_L1: 1.738 D_real: 0.728 D_fake: 0.616 \n",
      "(epoch: 87, iters: 244, time: 0.550, data: 0.001) G_GAN: 0.760 G_L1: 1.351 D_real: 0.752 D_fake: 0.645 \n",
      "(epoch: 87, iters: 344, time: 1.121, data: 0.002) G_GAN: 0.706 G_L1: 2.804 D_real: 0.560 D_fake: 0.886 \n",
      "End of epoch 87 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 48, time: 0.549, data: 0.001) G_GAN: 0.752 G_L1: 1.710 D_real: 0.710 D_fake: 0.629 \n",
      "(epoch: 88, iters: 148, time: 0.550, data: 0.001) G_GAN: 0.793 G_L1: 1.745 D_real: 0.770 D_fake: 0.593 \n",
      "(epoch: 88, iters: 248, time: 0.552, data: 0.001) G_GAN: 0.698 G_L1: 2.504 D_real: 0.694 D_fake: 0.699 \n",
      "(epoch: 88, iters: 348, time: 1.038, data: 0.001) G_GAN: 0.732 G_L1: 0.128 D_real: 0.754 D_fake: 0.642 \n",
      "End of epoch 88 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 52, time: 0.550, data: 0.001) G_GAN: 0.758 G_L1: 1.854 D_real: 0.727 D_fake: 0.617 \n",
      "(epoch: 89, iters: 152, time: 0.551, data: 0.001) G_GAN: 0.689 G_L1: 2.420 D_real: 0.658 D_fake: 0.734 \n",
      "saving the latest model (epoch 89, total_iters 35000)\n",
      "(epoch: 89, iters: 252, time: 0.545, data: 0.001) G_GAN: 0.689 G_L1: 2.225 D_real: 0.592 D_fake: 0.772 \n",
      "(epoch: 89, iters: 352, time: 1.129, data: 0.002) G_GAN: 0.661 G_L1: 1.961 D_real: 0.606 D_fake: 0.755 \n",
      "End of epoch 89 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 56, time: 0.549, data: 0.001) G_GAN: 0.734 G_L1: 1.674 D_real: 0.698 D_fake: 0.654 \n",
      "(epoch: 90, iters: 156, time: 0.549, data: 0.001) G_GAN: 0.819 G_L1: 1.958 D_real: 0.865 D_fake: 0.562 \n",
      "(epoch: 90, iters: 256, time: 0.551, data: 0.001) G_GAN: 0.818 G_L1: 1.988 D_real: 0.740 D_fake: 0.571 \n",
      "(epoch: 90, iters: 356, time: 1.166, data: 0.001) G_GAN: 0.720 G_L1: 2.518 D_real: 0.632 D_fake: 0.677 \n",
      "saving the model at the end of epoch 90, iters 35640\n",
      "End of epoch 90 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 60, time: 0.548, data: 0.001) G_GAN: 0.729 G_L1: 1.916 D_real: 0.747 D_fake: 0.637 \n",
      "(epoch: 91, iters: 160, time: 0.550, data: 0.001) G_GAN: 0.732 G_L1: 1.355 D_real: 0.724 D_fake: 0.655 \n",
      "(epoch: 91, iters: 260, time: 0.551, data: 0.001) G_GAN: 0.652 G_L1: 3.152 D_real: 0.585 D_fake: 0.788 \n",
      "(epoch: 91, iters: 360, time: 1.139, data: 0.001) G_GAN: 0.670 G_L1: 3.185 D_real: 0.601 D_fake: 0.763 \n",
      "End of epoch 91 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 64, time: 0.549, data: 0.001) G_GAN: 0.730 G_L1: 1.873 D_real: 0.728 D_fake: 0.650 \n",
      "(epoch: 92, iters: 164, time: 0.553, data: 0.002) G_GAN: 0.718 G_L1: 1.873 D_real: 0.719 D_fake: 0.673 \n",
      "(epoch: 92, iters: 264, time: 0.548, data: 0.001) G_GAN: 0.737 G_L1: 1.690 D_real: 0.701 D_fake: 0.657 \n",
      "(epoch: 92, iters: 364, time: 1.122, data: 0.001) G_GAN: 0.721 G_L1: 1.896 D_real: 0.705 D_fake: 0.755 \n",
      "End of epoch 92 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 68, time: 0.551, data: 0.001) G_GAN: 0.617 G_L1: 1.906 D_real: 0.588 D_fake: 0.824 \n",
      "(epoch: 93, iters: 168, time: 0.547, data: 0.001) G_GAN: 0.730 G_L1: 2.972 D_real: 0.520 D_fake: 0.699 \n",
      "(epoch: 93, iters: 268, time: 0.550, data: 0.001) G_GAN: 0.709 G_L1: 2.611 D_real: 0.803 D_fake: 0.645 \n",
      "(epoch: 93, iters: 368, time: 1.127, data: 0.001) G_GAN: 0.636 G_L1: 3.035 D_real: 0.536 D_fake: 0.799 \n",
      "End of epoch 93 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 72, time: 0.550, data: 0.001) G_GAN: 0.687 G_L1: 1.496 D_real: 0.657 D_fake: 0.698 \n",
      "(epoch: 94, iters: 172, time: 0.551, data: 0.001) G_GAN: 0.922 G_L1: 1.434 D_real: 0.894 D_fake: 0.497 \n",
      "(epoch: 94, iters: 272, time: 0.551, data: 0.002) G_GAN: 0.719 G_L1: 1.723 D_real: 0.640 D_fake: 0.711 \n",
      "(epoch: 94, iters: 372, time: 1.100, data: 0.001) G_GAN: 0.757 G_L1: 0.858 D_real: 0.714 D_fake: 0.631 \n",
      "End of epoch 94 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 76, time: 0.548, data: 0.001) G_GAN: 0.843 G_L1: 1.736 D_real: 0.878 D_fake: 0.532 \n",
      "(epoch: 95, iters: 176, time: 0.550, data: 0.001) G_GAN: 0.754 G_L1: 1.655 D_real: 0.735 D_fake: 0.630 \n",
      "(epoch: 95, iters: 276, time: 0.551, data: 0.001) G_GAN: 0.670 G_L1: 1.731 D_real: 0.620 D_fake: 0.727 \n",
      "(epoch: 95, iters: 376, time: 1.133, data: 0.001) G_GAN: 0.708 G_L1: 1.938 D_real: 0.680 D_fake: 0.679 \n",
      "saving the model at the end of epoch 95, iters 37620\n",
      "End of epoch 95 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 80, time: 0.550, data: 0.002) G_GAN: 0.631 G_L1: 2.459 D_real: 0.584 D_fake: 0.804 \n",
      "(epoch: 96, iters: 180, time: 0.549, data: 0.002) G_GAN: 0.723 G_L1: 2.018 D_real: 0.675 D_fake: 0.676 \n",
      "(epoch: 96, iters: 280, time: 0.551, data: 0.001) G_GAN: 0.805 G_L1: 1.534 D_real: 0.784 D_fake: 0.586 \n",
      "(epoch: 96, iters: 380, time: 1.127, data: 0.001) G_GAN: 0.728 G_L1: 1.469 D_real: 0.684 D_fake: 0.658 \n",
      "End of epoch 96 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 84, time: 0.549, data: 0.001) G_GAN: 0.659 G_L1: 1.908 D_real: 0.621 D_fake: 0.751 \n",
      "(epoch: 97, iters: 184, time: 0.551, data: 0.001) G_GAN: 0.660 G_L1: 2.259 D_real: 0.593 D_fake: 0.757 \n",
      "(epoch: 97, iters: 284, time: 0.551, data: 0.002) G_GAN: 0.742 G_L1: 1.611 D_real: 0.730 D_fake: 0.640 \n",
      "(epoch: 97, iters: 384, time: 1.166, data: 0.001) G_GAN: 0.725 G_L1: 2.098 D_real: 0.691 D_fake: 0.675 \n",
      "End of epoch 97 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 88, time: 0.547, data: 0.001) G_GAN: 0.656 G_L1: 1.857 D_real: 0.667 D_fake: 0.724 \n",
      "(epoch: 98, iters: 188, time: 0.549, data: 0.001) G_GAN: 0.718 G_L1: 2.493 D_real: 0.637 D_fake: 0.680 \n",
      "(epoch: 98, iters: 288, time: 0.548, data: 0.001) G_GAN: 0.715 G_L1: 1.568 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 98, iters: 388, time: 1.168, data: 0.001) G_GAN: 0.818 G_L1: 1.238 D_real: 0.792 D_fake: 0.586 \n",
      "End of epoch 98 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 92, time: 0.549, data: 0.002) G_GAN: 0.657 G_L1: 2.111 D_real: 0.673 D_fake: 0.770 \n",
      "(epoch: 99, iters: 192, time: 0.549, data: 0.001) G_GAN: 0.701 G_L1: 0.027 D_real: 0.711 D_fake: 0.677 \n",
      "(epoch: 99, iters: 292, time: 0.550, data: 0.001) G_GAN: 0.673 G_L1: 2.144 D_real: 0.683 D_fake: 0.739 \n",
      "(epoch: 99, iters: 392, time: 1.140, data: 0.001) G_GAN: 0.739 G_L1: 2.278 D_real: 0.756 D_fake: 0.639 \n",
      "End of epoch 99 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 96, time: 0.552, data: 0.001) G_GAN: 0.715 G_L1: 1.628 D_real: 0.693 D_fake: 0.666 \n",
      "(epoch: 100, iters: 196, time: 0.550, data: 0.001) G_GAN: 0.738 G_L1: 1.655 D_real: 0.715 D_fake: 0.650 \n",
      "(epoch: 100, iters: 296, time: 0.551, data: 0.002) G_GAN: 0.706 G_L1: 1.896 D_real: 0.691 D_fake: 0.663 \n",
      "(epoch: 100, iters: 396, time: 1.144, data: 0.001) G_GAN: 0.693 G_L1: 2.096 D_real: 0.654 D_fake: 0.689 \n",
      "saving the model at the end of epoch 100, iters 39600\n",
      "End of epoch 100 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.552, data: 0.077) G_GAN: 0.817 G_L1: 1.750 D_real: 0.707 D_fake: 0.576 \n",
      "(epoch: 101, iters: 200, time: 0.550, data: 0.001) G_GAN: 0.752 G_L1: 0.927 D_real: 0.743 D_fake: 0.643 \n",
      "(epoch: 101, iters: 300, time: 0.549, data: 0.002) G_GAN: 0.726 G_L1: 1.727 D_real: 0.723 D_fake: 0.658 \n",
      "End of epoch 101 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 4, time: 1.159, data: 0.001) G_GAN: 0.759 G_L1: 2.150 D_real: 0.709 D_fake: 0.645 \n",
      "saving the latest model (epoch 102, total_iters 40000)\n",
      "(epoch: 102, iters: 104, time: 0.548, data: 0.003) G_GAN: 0.757 G_L1: 1.693 D_real: 0.713 D_fake: 0.631 \n",
      "(epoch: 102, iters: 204, time: 0.548, data: 0.001) G_GAN: 0.714 G_L1: 1.591 D_real: 0.662 D_fake: 0.702 \n",
      "(epoch: 102, iters: 304, time: 0.550, data: 0.001) G_GAN: 0.776 G_L1: 1.492 D_real: 0.808 D_fake: 0.613 \n",
      "End of epoch 102 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 8, time: 1.220, data: 0.001) G_GAN: 0.422 G_L1: 3.157 D_real: 0.468 D_fake: 1.433 \n",
      "(epoch: 103, iters: 108, time: 0.550, data: 0.001) G_GAN: 0.729 G_L1: 1.560 D_real: 0.707 D_fake: 0.656 \n",
      "(epoch: 103, iters: 208, time: 0.549, data: 0.001) G_GAN: 0.701 G_L1: 2.879 D_real: 0.504 D_fake: 0.896 \n",
      "(epoch: 103, iters: 308, time: 0.550, data: 0.001) G_GAN: 0.778 G_L1: 2.174 D_real: 0.727 D_fake: 0.615 \n",
      "End of epoch 103 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 12, time: 1.176, data: 0.001) G_GAN: 0.705 G_L1: 1.702 D_real: 0.711 D_fake: 0.686 \n",
      "(epoch: 104, iters: 112, time: 0.550, data: 0.001) G_GAN: 0.750 G_L1: 1.158 D_real: 0.744 D_fake: 0.639 \n",
      "(epoch: 104, iters: 212, time: 0.549, data: 0.001) G_GAN: 0.666 G_L1: 2.515 D_real: 0.571 D_fake: 0.750 \n",
      "(epoch: 104, iters: 312, time: 0.545, data: 0.001) G_GAN: 0.699 G_L1: 2.130 D_real: 0.635 D_fake: 0.702 \n",
      "End of epoch 104 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 16, time: 1.138, data: 0.002) G_GAN: 0.714 G_L1: 0.726 D_real: 0.692 D_fake: 0.679 \n",
      "(epoch: 105, iters: 116, time: 0.550, data: 0.001) G_GAN: 0.717 G_L1: 2.801 D_real: 0.665 D_fake: 0.667 \n",
      "(epoch: 105, iters: 216, time: 0.552, data: 0.001) G_GAN: 0.707 G_L1: 0.019 D_real: 0.710 D_fake: 0.676 \n",
      "(epoch: 105, iters: 316, time: 0.546, data: 0.001) G_GAN: 0.727 G_L1: 1.754 D_real: 0.752 D_fake: 0.630 \n",
      "saving the model at the end of epoch 105, iters 41580\n",
      "End of epoch 105 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 20, time: 1.236, data: 0.001) G_GAN: 0.771 G_L1: 1.981 D_real: 0.726 D_fake: 0.632 \n",
      "(epoch: 106, iters: 120, time: 0.547, data: 0.001) G_GAN: 0.711 G_L1: 1.186 D_real: 0.683 D_fake: 0.681 \n",
      "(epoch: 106, iters: 220, time: 0.550, data: 0.001) G_GAN: 0.729 G_L1: 2.429 D_real: 0.687 D_fake: 0.644 \n",
      "(epoch: 106, iters: 320, time: 0.547, data: 0.002) G_GAN: 0.603 G_L1: 2.381 D_real: 0.594 D_fake: 0.914 \n",
      "End of epoch 106 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 24, time: 1.152, data: 0.002) G_GAN: 0.781 G_L1: 0.881 D_real: 0.771 D_fake: 0.610 \n",
      "(epoch: 107, iters: 124, time: 0.548, data: 0.001) G_GAN: 0.712 G_L1: 1.750 D_real: 0.677 D_fake: 0.688 \n",
      "(epoch: 107, iters: 224, time: 0.549, data: 0.001) G_GAN: 0.697 G_L1: 1.955 D_real: 0.636 D_fake: 0.689 \n",
      "(epoch: 107, iters: 324, time: 0.551, data: 0.001) G_GAN: 0.711 G_L1: 1.892 D_real: 0.672 D_fake: 0.694 \n",
      "End of epoch 107 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 28, time: 1.175, data: 0.001) G_GAN: 0.741 G_L1: 1.382 D_real: 0.752 D_fake: 0.672 \n",
      "(epoch: 108, iters: 128, time: 0.552, data: 0.001) G_GAN: 0.678 G_L1: 0.027 D_real: 0.678 D_fake: 0.709 \n",
      "(epoch: 108, iters: 228, time: 0.549, data: 0.001) G_GAN: 0.673 G_L1: 1.668 D_real: 0.650 D_fake: 0.738 \n",
      "(epoch: 108, iters: 328, time: 0.548, data: 0.002) G_GAN: 0.707 G_L1: 0.752 D_real: 0.690 D_fake: 0.678 \n",
      "End of epoch 108 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 32, time: 1.166, data: 0.001) G_GAN: 0.740 G_L1: 1.258 D_real: 0.714 D_fake: 0.646 \n",
      "(epoch: 109, iters: 132, time: 0.548, data: 0.002) G_GAN: 0.773 G_L1: 1.134 D_real: 0.757 D_fake: 0.613 \n",
      "(epoch: 109, iters: 232, time: 0.551, data: 0.002) G_GAN: 0.678 G_L1: 0.019 D_real: 0.685 D_fake: 0.701 \n",
      "(epoch: 109, iters: 332, time: 0.549, data: 0.001) G_GAN: 0.728 G_L1: 1.688 D_real: 0.737 D_fake: 0.658 \n",
      "End of epoch 109 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 36, time: 1.195, data: 0.001) G_GAN: 0.662 G_L1: 1.774 D_real: 0.634 D_fake: 0.745 \n",
      "(epoch: 110, iters: 136, time: 0.549, data: 0.001) G_GAN: 0.629 G_L1: 2.272 D_real: 0.520 D_fake: 0.910 \n",
      "(epoch: 110, iters: 236, time: 0.548, data: 0.001) G_GAN: 0.702 G_L1: 2.768 D_real: 0.581 D_fake: 0.740 \n",
      "(epoch: 110, iters: 336, time: 0.550, data: 0.001) G_GAN: 0.635 G_L1: 2.504 D_real: 0.560 D_fake: 0.808 \n",
      "saving the model at the end of epoch 110, iters 43560\n",
      "End of epoch 110 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 40, time: 1.194, data: 0.001) G_GAN: 0.675 G_L1: 2.163 D_real: 0.586 D_fake: 0.751 \n",
      "(epoch: 111, iters: 140, time: 0.550, data: 0.001) G_GAN: 0.697 G_L1: 2.440 D_real: 0.595 D_fake: 0.731 \n",
      "(epoch: 111, iters: 240, time: 0.552, data: 0.001) G_GAN: 0.755 G_L1: 1.649 D_real: 0.725 D_fake: 0.659 \n",
      "(epoch: 111, iters: 340, time: 0.549, data: 0.001) G_GAN: 0.763 G_L1: 1.233 D_real: 0.744 D_fake: 0.639 \n",
      "End of epoch 111 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 44, time: 1.223, data: 0.001) G_GAN: 0.698 G_L1: 1.968 D_real: 0.651 D_fake: 0.710 \n",
      "(epoch: 112, iters: 144, time: 0.549, data: 0.001) G_GAN: 0.715 G_L1: 1.582 D_real: 0.704 D_fake: 0.646 \n",
      "(epoch: 112, iters: 244, time: 0.551, data: 0.001) G_GAN: 0.694 G_L1: 2.056 D_real: 0.625 D_fake: 0.706 \n",
      "(epoch: 112, iters: 344, time: 0.549, data: 0.002) G_GAN: 0.727 G_L1: 1.675 D_real: 0.704 D_fake: 0.671 \n",
      "End of epoch 112 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 48, time: 1.143, data: 0.002) G_GAN: 0.705 G_L1: 0.036 D_real: 0.706 D_fake: 0.680 \n",
      "(epoch: 113, iters: 148, time: 0.550, data: 0.001) G_GAN: 0.770 G_L1: 1.512 D_real: 0.766 D_fake: 0.611 \n",
      "(epoch: 113, iters: 248, time: 0.549, data: 0.002) G_GAN: 0.625 G_L1: 1.780 D_real: 0.593 D_fake: 0.822 \n",
      "(epoch: 113, iters: 348, time: 0.545, data: 0.001) G_GAN: 0.670 G_L1: 1.952 D_real: 0.645 D_fake: 0.741 \n",
      "End of epoch 113 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 52, time: 1.216, data: 0.001) G_GAN: 0.635 G_L1: 2.347 D_real: 0.587 D_fake: 0.790 \n",
      "(epoch: 114, iters: 152, time: 0.551, data: 0.001) G_GAN: 0.637 G_L1: 2.232 D_real: 0.586 D_fake: 0.797 \n",
      "(epoch: 114, iters: 252, time: 0.550, data: 0.001) G_GAN: 0.711 G_L1: 1.571 D_real: 0.688 D_fake: 0.696 \n",
      "saving the latest model (epoch 114, total_iters 45000)\n",
      "(epoch: 114, iters: 352, time: 0.550, data: 0.001) G_GAN: 0.810 G_L1: 1.317 D_real: 0.800 D_fake: 0.591 \n",
      "End of epoch 114 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 56, time: 1.193, data: 0.001) G_GAN: 0.804 G_L1: 1.448 D_real: 0.763 D_fake: 0.594 \n",
      "(epoch: 115, iters: 156, time: 0.550, data: 0.002) G_GAN: 0.763 G_L1: 1.602 D_real: 0.752 D_fake: 0.632 \n",
      "(epoch: 115, iters: 256, time: 0.545, data: 0.001) G_GAN: 0.662 G_L1: 1.971 D_real: 0.651 D_fake: 0.777 \n",
      "(epoch: 115, iters: 356, time: 0.550, data: 0.001) G_GAN: 0.732 G_L1: 1.759 D_real: 0.697 D_fake: 0.650 \n",
      "saving the model at the end of epoch 115, iters 45540\n",
      "End of epoch 115 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 60, time: 1.239, data: 0.002) G_GAN: 0.711 G_L1: 1.687 D_real: 0.640 D_fake: 0.700 \n",
      "(epoch: 116, iters: 160, time: 0.551, data: 0.001) G_GAN: 0.656 G_L1: 1.920 D_real: 0.625 D_fake: 0.779 \n",
      "(epoch: 116, iters: 260, time: 0.550, data: 0.001) G_GAN: 0.772 G_L1: 1.688 D_real: 0.759 D_fake: 0.617 \n",
      "(epoch: 116, iters: 360, time: 0.547, data: 0.001) G_GAN: 0.761 G_L1: 1.901 D_real: 0.707 D_fake: 0.635 \n",
      "End of epoch 116 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 64, time: 1.207, data: 0.001) G_GAN: 0.684 G_L1: 1.821 D_real: 0.626 D_fake: 0.716 \n",
      "(epoch: 117, iters: 164, time: 0.551, data: 0.001) G_GAN: 0.694 G_L1: 1.780 D_real: 0.662 D_fake: 0.694 \n",
      "(epoch: 117, iters: 264, time: 0.554, data: 0.001) G_GAN: 0.703 G_L1: 1.421 D_real: 0.628 D_fake: 0.709 \n",
      "(epoch: 117, iters: 364, time: 0.551, data: 0.001) G_GAN: 0.647 G_L1: 1.856 D_real: 0.607 D_fake: 0.773 \n",
      "End of epoch 117 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 68, time: 1.162, data: 0.001) G_GAN: 0.698 G_L1: 0.020 D_real: 0.705 D_fake: 0.681 \n",
      "(epoch: 118, iters: 168, time: 0.551, data: 0.002) G_GAN: 0.742 G_L1: 1.553 D_real: 0.721 D_fake: 0.659 \n",
      "(epoch: 118, iters: 268, time: 0.547, data: 0.001) G_GAN: 0.718 G_L1: 1.565 D_real: 0.609 D_fake: 0.785 \n",
      "(epoch: 118, iters: 368, time: 0.549, data: 0.001) G_GAN: 0.681 G_L1: 1.730 D_real: 0.625 D_fake: 0.731 \n",
      "End of epoch 118 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 72, time: 1.277, data: 0.001) G_GAN: 0.703 G_L1: 1.809 D_real: 0.696 D_fake: 0.735 \n",
      "(epoch: 119, iters: 172, time: 0.551, data: 0.001) G_GAN: 0.671 G_L1: 1.344 D_real: 0.652 D_fake: 0.754 \n",
      "(epoch: 119, iters: 272, time: 0.549, data: 0.001) G_GAN: 0.682 G_L1: 1.662 D_real: 0.668 D_fake: 0.713 \n",
      "(epoch: 119, iters: 372, time: 0.552, data: 0.002) G_GAN: 0.779 G_L1: 0.960 D_real: 0.788 D_fake: 0.595 \n",
      "End of epoch 119 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 76, time: 1.229, data: 0.002) G_GAN: 0.747 G_L1: 1.686 D_real: 0.744 D_fake: 0.634 \n",
      "(epoch: 120, iters: 176, time: 0.551, data: 0.001) G_GAN: 0.748 G_L1: 2.320 D_real: 0.665 D_fake: 0.651 \n",
      "(epoch: 120, iters: 276, time: 0.548, data: 0.001) G_GAN: 0.713 G_L1: 0.019 D_real: 0.684 D_fake: 0.706 \n",
      "(epoch: 120, iters: 376, time: 0.548, data: 0.001) G_GAN: 0.754 G_L1: 1.242 D_real: 0.755 D_fake: 0.641 \n",
      "saving the model at the end of epoch 120, iters 47520\n",
      "End of epoch 120 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 80, time: 1.213, data: 0.002) G_GAN: 0.733 G_L1: 1.561 D_real: 0.689 D_fake: 0.656 \n",
      "(epoch: 121, iters: 180, time: 0.550, data: 0.001) G_GAN: 0.712 G_L1: 1.982 D_real: 0.740 D_fake: 0.653 \n",
      "(epoch: 121, iters: 280, time: 0.552, data: 0.001) G_GAN: 0.774 G_L1: 0.960 D_real: 0.776 D_fake: 0.608 \n",
      "(epoch: 121, iters: 380, time: 0.551, data: 0.001) G_GAN: 0.791 G_L1: 1.250 D_real: 0.782 D_fake: 0.594 \n",
      "End of epoch 121 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 84, time: 1.210, data: 0.002) G_GAN: 0.712 G_L1: 1.505 D_real: 0.674 D_fake: 0.674 \n",
      "(epoch: 122, iters: 184, time: 0.549, data: 0.001) G_GAN: 0.707 G_L1: 1.688 D_real: 0.720 D_fake: 0.642 \n",
      "(epoch: 122, iters: 284, time: 0.550, data: 0.002) G_GAN: 0.760 G_L1: 1.558 D_real: 0.751 D_fake: 0.646 \n",
      "(epoch: 122, iters: 384, time: 0.551, data: 0.001) G_GAN: 0.692 G_L1: 1.836 D_real: 0.689 D_fake: 0.694 \n",
      "End of epoch 122 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 88, time: 1.301, data: 0.002) G_GAN: 0.713 G_L1: 1.661 D_real: 0.698 D_fake: 0.662 \n",
      "(epoch: 123, iters: 188, time: 0.548, data: 0.001) G_GAN: 0.695 G_L1: 1.686 D_real: 0.650 D_fake: 0.720 \n",
      "(epoch: 123, iters: 288, time: 0.548, data: 0.001) G_GAN: 0.758 G_L1: 0.991 D_real: 0.733 D_fake: 0.635 \n",
      "(epoch: 123, iters: 388, time: 0.553, data: 0.001) G_GAN: 0.682 G_L1: 1.710 D_real: 0.616 D_fake: 0.721 \n",
      "End of epoch 123 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 92, time: 1.247, data: 0.001) G_GAN: 0.697 G_L1: 1.297 D_real: 0.694 D_fake: 0.688 \n",
      "(epoch: 124, iters: 192, time: 0.548, data: 0.001) G_GAN: 0.768 G_L1: 1.282 D_real: 0.762 D_fake: 0.621 \n",
      "(epoch: 124, iters: 292, time: 0.549, data: 0.001) G_GAN: 0.727 G_L1: 1.313 D_real: 0.716 D_fake: 0.671 \n",
      "(epoch: 124, iters: 392, time: 0.552, data: 0.002) G_GAN: 0.666 G_L1: 1.671 D_real: 0.676 D_fake: 0.752 \n",
      "End of epoch 124 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 96, time: 1.260, data: 0.001) G_GAN: 0.673 G_L1: 1.350 D_real: 0.671 D_fake: 0.722 \n",
      "(epoch: 125, iters: 196, time: 0.549, data: 0.001) G_GAN: 0.663 G_L1: 1.862 D_real: 0.657 D_fake: 0.732 \n",
      "(epoch: 125, iters: 296, time: 0.550, data: 0.001) G_GAN: 0.749 G_L1: 0.999 D_real: 0.734 D_fake: 0.635 \n",
      "(epoch: 125, iters: 396, time: 0.552, data: 0.002) G_GAN: 0.676 G_L1: 1.574 D_real: 0.604 D_fake: 0.742 \n",
      "saving the model at the end of epoch 125, iters 49500\n",
      "End of epoch 125 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 100, time: 1.306, data: 0.089) G_GAN: 0.676 G_L1: 1.901 D_real: 0.630 D_fake: 0.726 \n",
      "(epoch: 126, iters: 200, time: 0.550, data: 0.001) G_GAN: 0.798 G_L1: 1.041 D_real: 0.774 D_fake: 0.600 \n",
      "(epoch: 126, iters: 300, time: 0.551, data: 0.001) G_GAN: 0.771 G_L1: 1.185 D_real: 0.743 D_fake: 0.598 \n",
      "End of epoch 126 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 4, time: 0.550, data: 0.001) G_GAN: 0.641 G_L1: 1.928 D_real: 0.576 D_fake: 0.784 \n",
      "(epoch: 127, iters: 104, time: 1.266, data: 0.002) G_GAN: 0.679 G_L1: 1.939 D_real: 0.639 D_fake: 0.723 \n",
      "saving the latest model (epoch 127, total_iters 50000)\n",
      "(epoch: 127, iters: 204, time: 0.554, data: 0.002) G_GAN: 0.701 G_L1: 1.644 D_real: 0.660 D_fake: 0.689 \n",
      "(epoch: 127, iters: 304, time: 0.550, data: 0.001) G_GAN: 0.753 G_L1: 1.704 D_real: 0.683 D_fake: 0.639 \n",
      "End of epoch 127 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 8, time: 0.553, data: 0.001) G_GAN: 0.697 G_L1: 1.345 D_real: 0.653 D_fake: 0.691 \n",
      "(epoch: 128, iters: 108, time: 1.237, data: 0.001) G_GAN: 0.695 G_L1: 1.495 D_real: 0.690 D_fake: 0.714 \n",
      "(epoch: 128, iters: 208, time: 0.553, data: 0.001) G_GAN: 0.807 G_L1: 1.710 D_real: 0.804 D_fake: 0.583 \n",
      "(epoch: 128, iters: 308, time: 0.551, data: 0.002) G_GAN: 0.708 G_L1: 1.756 D_real: 0.665 D_fake: 0.698 \n",
      "End of epoch 128 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 12, time: 0.552, data: 0.001) G_GAN: 0.746 G_L1: 1.563 D_real: 0.711 D_fake: 0.642 \n",
      "(epoch: 129, iters: 112, time: 1.239, data: 0.001) G_GAN: 0.795 G_L1: 1.034 D_real: 0.796 D_fake: 0.588 \n",
      "(epoch: 129, iters: 212, time: 0.551, data: 0.001) G_GAN: 0.763 G_L1: 1.239 D_real: 0.748 D_fake: 0.627 \n",
      "(epoch: 129, iters: 312, time: 0.551, data: 0.001) G_GAN: 0.695 G_L1: 1.554 D_real: 0.660 D_fake: 0.696 \n",
      "End of epoch 129 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 16, time: 0.550, data: 0.001) G_GAN: 0.731 G_L1: 0.540 D_real: 0.714 D_fake: 0.657 \n",
      "(epoch: 130, iters: 116, time: 1.288, data: 0.001) G_GAN: 0.728 G_L1: 1.463 D_real: 0.707 D_fake: 0.661 \n",
      "(epoch: 130, iters: 216, time: 0.551, data: 0.001) G_GAN: 0.673 G_L1: 2.126 D_real: 0.608 D_fake: 0.746 \n",
      "(epoch: 130, iters: 316, time: 0.547, data: 0.002) G_GAN: 0.693 G_L1: 1.719 D_real: 0.622 D_fake: 0.725 \n",
      "saving the model at the end of epoch 130, iters 51480\n",
      "End of epoch 130 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 20, time: 0.550, data: 0.001) G_GAN: 0.732 G_L1: 1.044 D_real: 0.715 D_fake: 0.655 \n",
      "(epoch: 131, iters: 120, time: 1.262, data: 0.001) G_GAN: 0.658 G_L1: 1.436 D_real: 0.640 D_fake: 0.743 \n",
      "(epoch: 131, iters: 220, time: 0.548, data: 0.002) G_GAN: 0.692 G_L1: 0.020 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 131, iters: 320, time: 0.553, data: 0.001) G_GAN: 0.716 G_L1: 1.648 D_real: 0.658 D_fake: 0.687 \n",
      "End of epoch 131 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 24, time: 0.554, data: 0.001) G_GAN: 0.706 G_L1: 1.553 D_real: 0.657 D_fake: 0.697 \n",
      "(epoch: 132, iters: 124, time: 1.267, data: 0.001) G_GAN: 0.710 G_L1: 1.322 D_real: 0.706 D_fake: 0.673 \n",
      "(epoch: 132, iters: 224, time: 0.549, data: 0.001) G_GAN: 0.706 G_L1: 2.032 D_real: 0.667 D_fake: 0.684 \n",
      "(epoch: 132, iters: 324, time: 0.550, data: 0.002) G_GAN: 0.687 G_L1: 1.819 D_real: 0.608 D_fake: 0.744 \n",
      "End of epoch 132 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 28, time: 0.552, data: 0.001) G_GAN: 0.674 G_L1: 1.754 D_real: 0.666 D_fake: 0.733 \n",
      "(epoch: 133, iters: 128, time: 1.215, data: 0.002) G_GAN: 0.697 G_L1: 0.603 D_real: 0.677 D_fake: 0.695 \n",
      "(epoch: 133, iters: 228, time: 0.549, data: 0.001) G_GAN: 0.713 G_L1: 1.878 D_real: 0.681 D_fake: 0.689 \n",
      "(epoch: 133, iters: 328, time: 0.552, data: 0.001) G_GAN: 0.678 G_L1: 3.135 D_real: 0.633 D_fake: 0.721 \n",
      "End of epoch 133 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 32, time: 0.549, data: 0.002) G_GAN: 0.698 G_L1: 1.591 D_real: 0.650 D_fake: 0.701 \n",
      "(epoch: 134, iters: 132, time: 1.271, data: 0.001) G_GAN: 0.699 G_L1: 1.686 D_real: 0.659 D_fake: 0.693 \n",
      "(epoch: 134, iters: 232, time: 0.549, data: 0.001) G_GAN: 0.684 G_L1: 0.022 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 134, iters: 332, time: 0.550, data: 0.001) G_GAN: 0.730 G_L1: 1.418 D_real: 0.718 D_fake: 0.676 \n",
      "End of epoch 134 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 36, time: 0.551, data: 0.001) G_GAN: 0.686 G_L1: 1.810 D_real: 0.664 D_fake: 0.704 \n",
      "(epoch: 135, iters: 136, time: 1.297, data: 0.002) G_GAN: 0.682 G_L1: 1.868 D_real: 0.677 D_fake: 0.721 \n",
      "(epoch: 135, iters: 236, time: 0.551, data: 0.001) G_GAN: 0.740 G_L1: 1.247 D_real: 0.727 D_fake: 0.652 \n",
      "(epoch: 135, iters: 336, time: 0.550, data: 0.001) G_GAN: 0.749 G_L1: 1.574 D_real: 0.766 D_fake: 0.616 \n",
      "saving the model at the end of epoch 135, iters 53460\n",
      "End of epoch 135 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 40, time: 0.551, data: 0.001) G_GAN: 0.659 G_L1: 1.807 D_real: 0.625 D_fake: 0.765 \n",
      "(epoch: 136, iters: 140, time: 1.294, data: 0.001) G_GAN: 0.736 G_L1: 1.428 D_real: 0.713 D_fake: 0.659 \n",
      "(epoch: 136, iters: 240, time: 0.547, data: 0.002) G_GAN: 0.695 G_L1: 1.534 D_real: 0.655 D_fake: 0.710 \n",
      "(epoch: 136, iters: 340, time: 0.550, data: 0.001) G_GAN: 0.653 G_L1: 1.720 D_real: 0.603 D_fake: 0.782 \n",
      "End of epoch 136 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 44, time: 0.552, data: 0.001) G_GAN: 0.727 G_L1: 1.331 D_real: 0.715 D_fake: 0.657 \n",
      "(epoch: 137, iters: 144, time: 1.262, data: 0.001) G_GAN: 0.737 G_L1: 1.406 D_real: 0.712 D_fake: 0.663 \n",
      "(epoch: 137, iters: 244, time: 0.550, data: 0.001) G_GAN: 0.700 G_L1: 0.653 D_real: 0.680 D_fake: 0.689 \n",
      "(epoch: 137, iters: 344, time: 0.549, data: 0.002) G_GAN: 0.726 G_L1: 1.107 D_real: 0.730 D_fake: 0.657 \n",
      "End of epoch 137 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 48, time: 0.551, data: 0.001) G_GAN: 0.694 G_L1: 1.379 D_real: 0.682 D_fake: 0.698 \n",
      "(epoch: 138, iters: 148, time: 1.301, data: 0.001) G_GAN: 0.668 G_L1: 1.467 D_real: 0.632 D_fake: 0.740 \n",
      "(epoch: 138, iters: 248, time: 0.545, data: 0.002) G_GAN: 0.645 G_L1: 1.512 D_real: 0.605 D_fake: 0.768 \n",
      "(epoch: 138, iters: 348, time: 0.548, data: 0.001) G_GAN: 0.690 G_L1: 1.549 D_real: 0.653 D_fake: 0.722 \n",
      "End of epoch 138 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 52, time: 0.552, data: 0.001) G_GAN: 0.746 G_L1: 0.989 D_real: 0.726 D_fake: 0.653 \n",
      "(epoch: 139, iters: 152, time: 1.266, data: 0.001) G_GAN: 0.687 G_L1: 1.498 D_real: 0.668 D_fake: 0.707 \n",
      "(epoch: 139, iters: 252, time: 0.549, data: 0.001) G_GAN: 0.713 G_L1: 1.201 D_real: 0.685 D_fake: 0.680 \n",
      "(epoch: 139, iters: 352, time: 0.550, data: 0.002) G_GAN: 0.703 G_L1: 1.732 D_real: 0.641 D_fake: 0.705 \n",
      "saving the latest model (epoch 139, total_iters 55000)\n",
      "End of epoch 139 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 56, time: 0.552, data: 0.002) G_GAN: 0.674 G_L1: 1.212 D_real: 0.644 D_fake: 0.735 \n",
      "(epoch: 140, iters: 156, time: 1.300, data: 0.001) G_GAN: 0.705 G_L1: 1.675 D_real: 0.628 D_fake: 0.702 \n",
      "(epoch: 140, iters: 256, time: 0.544, data: 0.001) G_GAN: 0.735 G_L1: 0.730 D_real: 0.731 D_fake: 0.651 \n",
      "(epoch: 140, iters: 356, time: 0.551, data: 0.001) G_GAN: 0.677 G_L1: 1.477 D_real: 0.654 D_fake: 0.732 \n",
      "saving the model at the end of epoch 140, iters 55440\n",
      "End of epoch 140 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 60, time: 0.551, data: 0.001) G_GAN: 0.735 G_L1: 1.326 D_real: 0.728 D_fake: 0.650 \n",
      "(epoch: 141, iters: 160, time: 1.356, data: 0.001) G_GAN: 0.624 G_L1: 1.921 D_real: 0.588 D_fake: 0.830 \n",
      "(epoch: 141, iters: 260, time: 0.553, data: 0.001) G_GAN: 0.686 G_L1: 2.050 D_real: 0.650 D_fake: 0.715 \n",
      "(epoch: 141, iters: 360, time: 0.549, data: 0.001) G_GAN: 0.707 G_L1: 1.176 D_real: 0.695 D_fake: 0.682 \n",
      "End of epoch 141 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 64, time: 0.549, data: 0.002) G_GAN: 0.737 G_L1: 1.255 D_real: 0.720 D_fake: 0.650 \n",
      "(epoch: 142, iters: 164, time: 1.309, data: 0.001) G_GAN: 0.776 G_L1: 1.737 D_real: 0.730 D_fake: 0.631 \n",
      "(epoch: 142, iters: 264, time: 0.551, data: 0.001) G_GAN: 0.698 G_L1: 1.902 D_real: 0.645 D_fake: 0.712 \n",
      "(epoch: 142, iters: 364, time: 0.552, data: 0.001) G_GAN: 0.639 G_L1: 1.454 D_real: 0.593 D_fake: 0.783 \n",
      "End of epoch 142 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 68, time: 0.550, data: 0.001) G_GAN: 0.731 G_L1: 0.504 D_real: 0.720 D_fake: 0.658 \n",
      "(epoch: 143, iters: 168, time: 1.305, data: 0.001) G_GAN: 0.666 G_L1: 1.749 D_real: 0.610 D_fake: 0.753 \n",
      "(epoch: 143, iters: 268, time: 0.550, data: 0.001) G_GAN: 0.673 G_L1: 1.882 D_real: 0.637 D_fake: 0.741 \n",
      "(epoch: 143, iters: 368, time: 0.549, data: 0.001) G_GAN: 0.755 G_L1: 1.313 D_real: 0.751 D_fake: 0.635 \n",
      "End of epoch 143 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 72, time: 0.553, data: 0.001) G_GAN: 0.693 G_L1: 1.212 D_real: 0.664 D_fake: 0.697 \n",
      "(epoch: 144, iters: 172, time: 1.320, data: 0.002) G_GAN: 0.723 G_L1: 1.302 D_real: 0.702 D_fake: 0.662 \n",
      "(epoch: 144, iters: 272, time: 0.548, data: 0.001) G_GAN: 0.735 G_L1: 2.236 D_real: 0.697 D_fake: 0.663 \n",
      "(epoch: 144, iters: 372, time: 0.553, data: 0.001) G_GAN: 0.770 G_L1: 1.331 D_real: 0.743 D_fake: 0.632 \n",
      "End of epoch 144 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 76, time: 0.554, data: 0.002) G_GAN: 0.699 G_L1: 1.371 D_real: 0.636 D_fake: 0.719 \n",
      "(epoch: 145, iters: 176, time: 1.246, data: 0.001) G_GAN: 0.685 G_L1: 0.023 D_real: 0.685 D_fake: 0.702 \n",
      "(epoch: 145, iters: 276, time: 0.549, data: 0.002) G_GAN: 0.772 G_L1: 0.959 D_real: 0.734 D_fake: 0.631 \n",
      "(epoch: 145, iters: 376, time: 0.550, data: 0.002) G_GAN: 0.731 G_L1: 1.596 D_real: 0.696 D_fake: 0.676 \n",
      "saving the model at the end of epoch 145, iters 57420\n",
      "End of epoch 145 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 80, time: 0.553, data: 0.001) G_GAN: 0.673 G_L1: 1.267 D_real: 0.642 D_fake: 0.726 \n",
      "(epoch: 146, iters: 180, time: 1.367, data: 0.001) G_GAN: 0.666 G_L1: 1.390 D_real: 0.638 D_fake: 0.746 \n",
      "(epoch: 146, iters: 280, time: 0.550, data: 0.001) G_GAN: 0.735 G_L1: 1.502 D_real: 0.700 D_fake: 0.646 \n",
      "(epoch: 146, iters: 380, time: 0.551, data: 0.001) G_GAN: 0.728 G_L1: 1.570 D_real: 0.721 D_fake: 0.657 \n",
      "End of epoch 146 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 84, time: 0.547, data: 0.001) G_GAN: 0.663 G_L1: 1.484 D_real: 0.648 D_fake: 0.745 \n",
      "(epoch: 147, iters: 184, time: 1.353, data: 0.001) G_GAN: 0.690 G_L1: 1.628 D_real: 0.654 D_fake: 0.705 \n",
      "(epoch: 147, iters: 284, time: 0.550, data: 0.001) G_GAN: 0.733 G_L1: 1.114 D_real: 0.728 D_fake: 0.652 \n",
      "(epoch: 147, iters: 384, time: 0.548, data: 0.001) G_GAN: 0.730 G_L1: 1.271 D_real: 0.715 D_fake: 0.655 \n",
      "End of epoch 147 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 88, time: 0.552, data: 0.001) G_GAN: 0.706 G_L1: 2.292 D_real: 0.649 D_fake: 0.703 \n",
      "(epoch: 148, iters: 188, time: 1.329, data: 0.001) G_GAN: 0.657 G_L1: 1.650 D_real: 0.594 D_fake: 0.763 \n",
      "(epoch: 148, iters: 288, time: 0.549, data: 0.001) G_GAN: 0.715 G_L1: 0.918 D_real: 0.689 D_fake: 0.677 \n",
      "(epoch: 148, iters: 388, time: 0.552, data: 0.002) G_GAN: 0.801 G_L1: 1.230 D_real: 0.770 D_fake: 0.594 \n",
      "End of epoch 148 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 92, time: 0.550, data: 0.002) G_GAN: 0.725 G_L1: 1.213 D_real: 0.706 D_fake: 0.664 \n",
      "(epoch: 149, iters: 192, time: 1.322, data: 0.001) G_GAN: 0.740 G_L1: 0.912 D_real: 0.713 D_fake: 0.649 \n",
      "(epoch: 149, iters: 292, time: 0.549, data: 0.002) G_GAN: 0.686 G_L1: 1.688 D_real: 0.633 D_fake: 0.713 \n",
      "(epoch: 149, iters: 392, time: 0.551, data: 0.001) G_GAN: 0.638 G_L1: 2.209 D_real: 0.611 D_fake: 0.787 \n",
      "End of epoch 149 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 96, time: 0.550, data: 0.001) G_GAN: 0.727 G_L1: 1.204 D_real: 0.701 D_fake: 0.660 \n",
      "(epoch: 150, iters: 196, time: 1.308, data: 0.001) G_GAN: 0.743 G_L1: 1.209 D_real: 0.769 D_fake: 0.617 \n",
      "(epoch: 150, iters: 296, time: 0.549, data: 0.001) G_GAN: 0.727 G_L1: 1.249 D_real: 0.703 D_fake: 0.656 \n",
      "(epoch: 150, iters: 396, time: 0.553, data: 0.001) G_GAN: 0.716 G_L1: 1.371 D_real: 0.693 D_fake: 0.683 \n",
      "saving the model at the end of epoch 150, iters 59400\n",
      "End of epoch 150 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 100, time: 0.551, data: 0.079) G_GAN: 0.673 G_L1: 1.936 D_real: 0.598 D_fake: 0.764 \n",
      "(epoch: 151, iters: 200, time: 1.354, data: 0.001) G_GAN: 0.674 G_L1: 1.957 D_real: 0.610 D_fake: 0.743 \n",
      "(epoch: 151, iters: 300, time: 0.550, data: 0.001) G_GAN: 0.658 G_L1: 1.631 D_real: 0.623 D_fake: 0.767 \n",
      "End of epoch 151 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 4, time: 0.550, data: 0.001) G_GAN: 0.676 G_L1: 1.193 D_real: 0.630 D_fake: 0.736 \n",
      "(epoch: 152, iters: 104, time: 0.550, data: 0.003) G_GAN: 0.728 G_L1: 1.124 D_real: 0.719 D_fake: 0.655 \n",
      "(epoch: 152, iters: 204, time: 1.329, data: 0.001) G_GAN: 0.683 G_L1: 1.312 D_real: 0.670 D_fake: 0.714 \n",
      "saving the latest model (epoch 152, total_iters 60000)\n",
      "(epoch: 152, iters: 304, time: 0.551, data: 0.001) G_GAN: 0.689 G_L1: 1.593 D_real: 0.635 D_fake: 0.722 \n",
      "End of epoch 152 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 8, time: 0.551, data: 0.001) G_GAN: 0.714 G_L1: 1.280 D_real: 0.699 D_fake: 0.675 \n",
      "(epoch: 153, iters: 108, time: 0.548, data: 0.001) G_GAN: 0.671 G_L1: 1.397 D_real: 0.632 D_fake: 0.740 \n",
      "(epoch: 153, iters: 208, time: 1.282, data: 0.001) G_GAN: 0.713 G_L1: 1.397 D_real: 0.692 D_fake: 0.678 \n",
      "(epoch: 153, iters: 308, time: 0.550, data: 0.001) G_GAN: 0.755 G_L1: 1.354 D_real: 0.730 D_fake: 0.619 \n",
      "End of epoch 153 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 12, time: 0.550, data: 0.001) G_GAN: 0.731 G_L1: 1.235 D_real: 0.705 D_fake: 0.669 \n",
      "(epoch: 154, iters: 112, time: 0.550, data: 0.002) G_GAN: 0.682 G_L1: 1.593 D_real: 0.624 D_fake: 0.728 \n",
      "(epoch: 154, iters: 212, time: 1.317, data: 0.001) G_GAN: 0.744 G_L1: 0.877 D_real: 0.729 D_fake: 0.652 \n",
      "(epoch: 154, iters: 312, time: 0.549, data: 0.001) G_GAN: 0.688 G_L1: 1.325 D_real: 0.674 D_fake: 0.698 \n",
      "End of epoch 154 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 16, time: 0.549, data: 0.001) G_GAN: 0.752 G_L1: 1.080 D_real: 0.727 D_fake: 0.633 \n",
      "(epoch: 155, iters: 116, time: 0.547, data: 0.002) G_GAN: 0.674 G_L1: 1.087 D_real: 0.678 D_fake: 0.735 \n",
      "(epoch: 155, iters: 216, time: 1.334, data: 0.002) G_GAN: 0.695 G_L1: 0.531 D_real: 0.685 D_fake: 0.695 \n",
      "(epoch: 155, iters: 316, time: 0.551, data: 0.001) G_GAN: 0.680 G_L1: 1.168 D_real: 0.670 D_fake: 0.721 \n",
      "saving the model at the end of epoch 155, iters 61380\n",
      "End of epoch 155 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 20, time: 0.546, data: 0.001) G_GAN: 0.755 G_L1: 1.471 D_real: 0.810 D_fake: 0.624 \n",
      "(epoch: 156, iters: 120, time: 0.549, data: 0.001) G_GAN: 0.671 G_L1: 1.397 D_real: 0.659 D_fake: 0.725 \n",
      "(epoch: 156, iters: 220, time: 1.295, data: 0.001) G_GAN: 0.705 G_L1: 0.026 D_real: 0.709 D_fake: 0.675 \n",
      "(epoch: 156, iters: 320, time: 0.549, data: 0.001) G_GAN: 0.733 G_L1: 1.167 D_real: 0.709 D_fake: 0.664 \n",
      "End of epoch 156 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 24, time: 0.550, data: 0.001) G_GAN: 0.647 G_L1: 1.736 D_real: 0.594 D_fake: 0.780 \n",
      "(epoch: 157, iters: 124, time: 0.550, data: 0.001) G_GAN: 0.716 G_L1: 1.370 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 157, iters: 224, time: 1.323, data: 0.001) G_GAN: 0.735 G_L1: 0.735 D_real: 0.707 D_fake: 0.653 \n",
      "(epoch: 157, iters: 324, time: 0.551, data: 0.002) G_GAN: 0.748 G_L1: 1.206 D_real: 0.748 D_fake: 0.641 \n",
      "End of epoch 157 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 28, time: 0.550, data: 0.001) G_GAN: 0.692 G_L1: 0.019 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 158, iters: 128, time: 0.550, data: 0.001) G_GAN: 0.721 G_L1: 1.537 D_real: 0.702 D_fake: 0.666 \n",
      "(epoch: 158, iters: 228, time: 1.368, data: 0.002) G_GAN: 0.747 G_L1: 0.987 D_real: 0.727 D_fake: 0.638 \n",
      "(epoch: 158, iters: 328, time: 0.553, data: 0.001) G_GAN: 0.652 G_L1: 1.861 D_real: 0.580 D_fake: 0.786 \n",
      "End of epoch 158 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 32, time: 0.550, data: 0.001) G_GAN: 0.683 G_L1: 0.020 D_real: 0.682 D_fake: 0.704 \n",
      "(epoch: 159, iters: 132, time: 0.553, data: 0.001) G_GAN: 0.693 G_L1: 1.076 D_real: 0.686 D_fake: 0.716 \n",
      "(epoch: 159, iters: 232, time: 1.376, data: 0.001) G_GAN: 0.694 G_L1: 1.454 D_real: 0.657 D_fake: 0.711 \n",
      "(epoch: 159, iters: 332, time: 0.545, data: 0.002) G_GAN: 0.741 G_L1: 1.133 D_real: 0.716 D_fake: 0.645 \n",
      "End of epoch 159 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 36, time: 0.547, data: 0.002) G_GAN: 0.703 G_L1: 0.024 D_real: 0.706 D_fake: 0.679 \n",
      "(epoch: 160, iters: 136, time: 0.552, data: 0.001) G_GAN: 0.712 G_L1: 2.085 D_real: 0.669 D_fake: 0.676 \n",
      "(epoch: 160, iters: 236, time: 1.392, data: 0.001) G_GAN: 0.686 G_L1: 1.843 D_real: 0.604 D_fake: 0.734 \n",
      "(epoch: 160, iters: 336, time: 0.549, data: 0.001) G_GAN: 0.707 G_L1: 1.344 D_real: 0.684 D_fake: 0.681 \n",
      "saving the model at the end of epoch 160, iters 63360\n",
      "End of epoch 160 / 200 \t Time Taken: 145 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 40, time: 0.551, data: 0.002) G_GAN: 0.706 G_L1: 1.475 D_real: 0.682 D_fake: 0.683 \n",
      "(epoch: 161, iters: 140, time: 0.549, data: 0.001) G_GAN: 0.767 G_L1: 0.936 D_real: 0.766 D_fake: 0.621 \n",
      "(epoch: 161, iters: 240, time: 1.343, data: 0.002) G_GAN: 0.719 G_L1: 1.222 D_real: 0.697 D_fake: 0.671 \n",
      "(epoch: 161, iters: 340, time: 0.549, data: 0.001) G_GAN: 0.788 G_L1: 0.983 D_real: 0.778 D_fake: 0.604 \n",
      "End of epoch 161 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 44, time: 0.551, data: 0.001) G_GAN: 0.734 G_L1: 0.962 D_real: 0.704 D_fake: 0.656 \n",
      "(epoch: 162, iters: 144, time: 0.547, data: 0.002) G_GAN: 0.677 G_L1: 0.017 D_real: 0.676 D_fake: 0.709 \n",
      "(epoch: 162, iters: 244, time: 1.357, data: 0.002) G_GAN: 0.802 G_L1: 1.065 D_real: 0.793 D_fake: 0.589 \n",
      "(epoch: 162, iters: 344, time: 0.549, data: 0.002) G_GAN: 0.677 G_L1: 0.019 D_real: 0.677 D_fake: 0.711 \n",
      "End of epoch 162 / 200 \t Time Taken: 144 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 48, time: 0.549, data: 0.002) G_GAN: 0.749 G_L1: 1.448 D_real: 0.720 D_fake: 0.634 \n",
      "(epoch: 163, iters: 148, time: 0.550, data: 0.001) G_GAN: 0.730 G_L1: 0.844 D_real: 0.712 D_fake: 0.659 \n",
      "(epoch: 163, iters: 248, time: 1.377, data: 0.001) G_GAN: 0.707 G_L1: 1.547 D_real: 0.676 D_fake: 0.680 \n",
      "(epoch: 163, iters: 348, time: 0.543, data: 0.001) G_GAN: 0.747 G_L1: 0.877 D_real: 0.725 D_fake: 0.648 \n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot pix2pix/AB --no_flip --model pix2pix --no_dropout --output_nc 1 --norm batch --checkpoints_dir may14 --netD pixel --netG resnet_9blocks --preprocess none --name pixelreal396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: may17                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: testimg/                      \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: pixel                         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: pixel                         \t[default: basic]\n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: True                          \t[default: False]\n",
      "                     norm: batch                         \t[default: instance]\n",
      "                    ntest: inf                           \n",
      "                 num_test: 120                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_may16                 \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from may17/pixel/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['testimg/001.jpg']\n",
      "processing (0005)-th image... ['testimg/006.jpg']\n",
      "processing (0010)-th image... ['testimg/011.jpg']\n",
      "processing (0015)-th image... ['testimg/016.jpg']\n",
      "processing (0020)-th image... ['testimg/021.jpg']\n",
      "processing (0025)-th image... ['testimg/026.jpg']\n",
      "processing (0030)-th image... ['testimg/031.jpg']\n",
      "processing (0035)-th image... ['testimg/036.jpg']\n",
      "processing (0040)-th image... ['testimg/041.jpg']\n",
      "processing (0045)-th image... ['testimg/046.jpg']\n",
      "processing (0050)-th image... ['testimg/051.jpg']\n",
      "processing (0055)-th image... ['testimg/056.jpg']\n",
      "processing (0060)-th image... ['testimg/061.jpg']\n",
      "processing (0065)-th image... ['testimg/066.jpg']\n",
      "processing (0070)-th image... ['testimg/071.jpg']\n",
      "processing (0075)-th image... ['testimg/076.jpg']\n",
      "processing (0080)-th image... ['testimg/081.jpg']\n",
      "processing (0085)-th image... ['testimg/086.jpg']\n",
      "processing (0090)-th image... ['testimg/091.jpg']\n",
      "processing (0095)-th image... ['testimg/096.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot smallcluster/ --num_test 120 --dataset_mode single --model test --results_dir resul --netG resnet_9blocks --netD pixel --preprocess none --no_flip --name pixel --norm batch --checkpoints_dir may17 --output_nc 1 --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: may17                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: baw/AB                        \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: pixel                         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: pixel                         \t[default: basic]\n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 25                            \t[default: 100]\n",
      "              niter_decay: 25                            \t[default: 100]\n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 396\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "[Network D] Total number of parameters : 0.009 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory may17/pixel/web...\n",
      "(epoch: 1, iters: 100, time: 0.509, data: 0.119) G_GAN: 0.809 G_L1: 19.890 D_real: 0.534 D_fake: 0.605 \n",
      "(epoch: 1, iters: 200, time: 0.518, data: 0.001) G_GAN: 0.950 G_L1: 13.103 D_real: 0.469 D_fake: 0.503 \n",
      "(epoch: 1, iters: 300, time: 0.559, data: 0.001) G_GAN: 1.112 G_L1: 20.565 D_real: 0.367 D_fake: 0.399 \n",
      "End of epoch 1 / 50 \t Time Taken: 135 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 4, time: 0.742, data: 0.002) G_GAN: 1.147 G_L1: 15.056 D_real: 0.375 D_fake: 0.392 \n",
      "(epoch: 2, iters: 104, time: 0.529, data: 0.004) G_GAN: 0.850 G_L1: 16.855 D_real: 0.328 D_fake: 0.609 \n",
      "(epoch: 2, iters: 204, time: 0.528, data: 0.002) G_GAN: 0.864 G_L1: 12.893 D_real: 0.460 D_fake: 0.632 \n",
      "(epoch: 2, iters: 304, time: 0.529, data: 0.001) G_GAN: 0.850 G_L1: 9.532 D_real: 0.723 D_fake: 0.586 \n",
      "End of epoch 2 / 50 \t Time Taken: 135 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 8, time: 0.766, data: 0.001) G_GAN: 0.995 G_L1: 10.104 D_real: 0.575 D_fake: 0.485 \n",
      "(epoch: 3, iters: 108, time: 0.530, data: 0.001) G_GAN: 0.801 G_L1: 12.293 D_real: 0.752 D_fake: 0.618 \n",
      "(epoch: 3, iters: 208, time: 0.530, data: 0.001) G_GAN: 0.656 G_L1: 12.938 D_real: 0.381 D_fake: 0.787 \n",
      "(epoch: 3, iters: 308, time: 0.533, data: 0.001) G_GAN: 0.817 G_L1: 12.758 D_real: 0.422 D_fake: 0.593 \n",
      "End of epoch 3 / 50 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 12, time: 0.795, data: 0.001) G_GAN: 0.764 G_L1: 11.513 D_real: 0.540 D_fake: 0.655 \n",
      "(epoch: 4, iters: 112, time: 0.534, data: 0.002) G_GAN: 0.669 G_L1: 8.113 D_real: 0.481 D_fake: 0.777 \n",
      "(epoch: 4, iters: 212, time: 0.534, data: 0.001) G_GAN: 0.858 G_L1: 7.771 D_real: 0.610 D_fake: 0.543 \n",
      "(epoch: 4, iters: 312, time: 0.532, data: 0.001) G_GAN: 1.255 G_L1: 20.120 D_real: 0.355 D_fake: 0.359 \n",
      "End of epoch 4 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 16, time: 0.781, data: 0.001) G_GAN: 0.703 G_L1: 14.373 D_real: 0.562 D_fake: 0.696 \n",
      "(epoch: 5, iters: 116, time: 0.535, data: 0.001) G_GAN: 0.725 G_L1: 6.090 D_real: 0.740 D_fake: 0.669 \n",
      "(epoch: 5, iters: 216, time: 0.535, data: 0.001) G_GAN: 0.992 G_L1: 5.204 D_real: 0.892 D_fake: 0.451 \n",
      "(epoch: 5, iters: 316, time: 0.534, data: 0.001) G_GAN: 0.808 G_L1: 9.065 D_real: 0.814 D_fake: 0.620 \n",
      "saving the model at the end of epoch 5, iters 1980\n",
      "End of epoch 5 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 20, time: 0.792, data: 0.001) G_GAN: 0.939 G_L1: 9.407 D_real: 0.703 D_fake: 0.482 \n",
      "(epoch: 6, iters: 120, time: 0.531, data: 0.001) G_GAN: 0.928 G_L1: 7.355 D_real: 0.707 D_fake: 0.496 \n",
      "(epoch: 6, iters: 220, time: 0.532, data: 0.001) G_GAN: 0.737 G_L1: 9.943 D_real: 0.647 D_fake: 0.662 \n",
      "(epoch: 6, iters: 320, time: 0.536, data: 0.001) G_GAN: 0.810 G_L1: 10.213 D_real: 0.485 D_fake: 0.587 \n",
      "End of epoch 6 / 50 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 24, time: 0.809, data: 0.001) G_GAN: 0.745 G_L1: 10.162 D_real: 0.513 D_fake: 0.658 \n",
      "(epoch: 7, iters: 124, time: 0.531, data: 0.001) G_GAN: 0.819 G_L1: 6.970 D_real: 0.610 D_fake: 0.583 \n",
      "(epoch: 7, iters: 224, time: 0.532, data: 0.001) G_GAN: 0.873 G_L1: 7.792 D_real: 0.791 D_fake: 0.538 \n",
      "(epoch: 7, iters: 324, time: 0.534, data: 0.002) G_GAN: 0.929 G_L1: 21.184 D_real: 0.332 D_fake: 0.515 \n",
      "End of epoch 7 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 28, time: 0.820, data: 0.001) G_GAN: 0.650 G_L1: 5.782 D_real: 0.622 D_fake: 0.759 \n",
      "(epoch: 8, iters: 128, time: 0.534, data: 0.001) G_GAN: 0.653 G_L1: 7.335 D_real: 0.527 D_fake: 0.778 \n",
      "(epoch: 8, iters: 228, time: 0.532, data: 0.001) G_GAN: 0.680 G_L1: 8.527 D_real: 0.566 D_fake: 0.703 \n",
      "(epoch: 8, iters: 328, time: 0.532, data: 0.001) G_GAN: 0.608 G_L1: 9.463 D_real: 0.408 D_fake: 0.812 \n",
      "End of epoch 8 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 32, time: 0.814, data: 0.001) G_GAN: 0.658 G_L1: 5.473 D_real: 0.632 D_fake: 0.748 \n",
      "(epoch: 9, iters: 132, time: 0.534, data: 0.001) G_GAN: 0.609 G_L1: 6.841 D_real: 0.699 D_fake: 0.770 \n",
      "(epoch: 9, iters: 232, time: 0.535, data: 0.001) G_GAN: 0.642 G_L1: 6.340 D_real: 0.534 D_fake: 0.808 \n",
      "(epoch: 9, iters: 332, time: 0.534, data: 0.001) G_GAN: 0.798 G_L1: 10.486 D_real: 0.423 D_fake: 0.620 \n",
      "End of epoch 9 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 36, time: 0.823, data: 0.001) G_GAN: 0.670 G_L1: 7.963 D_real: 0.497 D_fake: 0.732 \n",
      "(epoch: 10, iters: 136, time: 0.534, data: 0.001) G_GAN: 0.837 G_L1: 7.482 D_real: 0.669 D_fake: 0.576 \n",
      "(epoch: 10, iters: 236, time: 0.536, data: 0.001) G_GAN: 0.837 G_L1: 8.384 D_real: 0.623 D_fake: 0.566 \n",
      "(epoch: 10, iters: 336, time: 0.532, data: 0.001) G_GAN: 0.705 G_L1: 19.379 D_real: 0.264 D_fake: 0.747 \n",
      "saving the model at the end of epoch 10, iters 3960\n",
      "End of epoch 10 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 40, time: 0.820, data: 0.001) G_GAN: 0.688 G_L1: 6.225 D_real: 0.619 D_fake: 0.699 \n",
      "(epoch: 11, iters: 140, time: 0.534, data: 0.001) G_GAN: 0.705 G_L1: 6.802 D_real: 0.480 D_fake: 0.688 \n",
      "(epoch: 11, iters: 240, time: 0.533, data: 0.001) G_GAN: 0.645 G_L1: 9.448 D_real: 0.612 D_fake: 0.750 \n",
      "(epoch: 11, iters: 340, time: 0.534, data: 0.001) G_GAN: 0.705 G_L1: 6.567 D_real: 0.511 D_fake: 0.697 \n",
      "End of epoch 11 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 44, time: 0.806, data: 0.001) G_GAN: 0.831 G_L1: 8.025 D_real: 0.719 D_fake: 0.562 \n",
      "(epoch: 12, iters: 144, time: 0.529, data: 0.001) G_GAN: 0.838 G_L1: 4.810 D_real: 0.867 D_fake: 0.559 \n",
      "(epoch: 12, iters: 244, time: 0.532, data: 0.001) G_GAN: 0.692 G_L1: 5.864 D_real: 0.689 D_fake: 0.708 \n",
      "(epoch: 12, iters: 344, time: 0.533, data: 0.001) G_GAN: 0.862 G_L1: 4.999 D_real: 0.748 D_fake: 0.548 \n",
      "End of epoch 12 / 50 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 48, time: 0.849, data: 0.001) G_GAN: 0.539 G_L1: 12.015 D_real: 0.415 D_fake: 0.933 \n",
      "(epoch: 13, iters: 148, time: 0.532, data: 0.001) G_GAN: 0.752 G_L1: 8.753 D_real: 0.527 D_fake: 0.655 \n",
      "(epoch: 13, iters: 248, time: 0.534, data: 0.002) G_GAN: 0.870 G_L1: 6.157 D_real: 0.652 D_fake: 0.548 \n",
      "saving the latest model (epoch 13, total_iters 5000)\n",
      "(epoch: 13, iters: 348, time: 0.534, data: 0.001) G_GAN: 0.759 G_L1: 4.473 D_real: 0.673 D_fake: 0.644 \n",
      "End of epoch 13 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 52, time: 0.831, data: 0.001) G_GAN: 0.699 G_L1: 7.935 D_real: 0.534 D_fake: 0.701 \n",
      "(epoch: 14, iters: 152, time: 0.529, data: 0.001) G_GAN: 1.036 G_L1: 8.755 D_real: 0.804 D_fake: 0.434 \n",
      "(epoch: 14, iters: 252, time: 0.533, data: 0.001) G_GAN: 0.794 G_L1: 7.513 D_real: 0.845 D_fake: 0.607 \n",
      "(epoch: 14, iters: 352, time: 0.535, data: 0.001) G_GAN: 0.721 G_L1: 6.424 D_real: 0.616 D_fake: 0.662 \n",
      "End of epoch 14 / 50 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 56, time: 0.793, data: 0.001) G_GAN: 1.148 G_L1: 1.591 D_real: 1.141 D_fake: 0.387 \n",
      "(epoch: 15, iters: 156, time: 0.532, data: 0.001) G_GAN: 0.871 G_L1: 6.258 D_real: 0.828 D_fake: 0.524 \n",
      "(epoch: 15, iters: 256, time: 0.535, data: 0.001) G_GAN: 0.638 G_L1: 7.614 D_real: 0.474 D_fake: 0.779 \n",
      "(epoch: 15, iters: 356, time: 0.537, data: 0.002) G_GAN: 1.071 G_L1: 4.455 D_real: 0.981 D_fake: 0.419 \n",
      "saving the model at the end of epoch 15, iters 5940\n",
      "End of epoch 15 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 60, time: 0.824, data: 0.001) G_GAN: 0.918 G_L1: 4.090 D_real: 0.970 D_fake: 0.492 \n",
      "(epoch: 16, iters: 160, time: 0.536, data: 0.001) G_GAN: 0.693 G_L1: 7.684 D_real: 0.612 D_fake: 0.695 \n",
      "(epoch: 16, iters: 260, time: 0.533, data: 0.001) G_GAN: 0.641 G_L1: 8.161 D_real: 0.511 D_fake: 0.754 \n",
      "(epoch: 16, iters: 360, time: 0.532, data: 0.001) G_GAN: 0.670 G_L1: 6.344 D_real: 0.617 D_fake: 0.760 \n",
      "End of epoch 16 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 64, time: 0.838, data: 0.001) G_GAN: 0.744 G_L1: 6.531 D_real: 0.694 D_fake: 0.646 \n",
      "(epoch: 17, iters: 164, time: 0.533, data: 0.001) G_GAN: 0.866 G_L1: 7.399 D_real: 0.698 D_fake: 0.547 \n",
      "(epoch: 17, iters: 264, time: 0.532, data: 0.001) G_GAN: 0.813 G_L1: 6.852 D_real: 0.710 D_fake: 0.600 \n",
      "(epoch: 17, iters: 364, time: 0.529, data: 0.001) G_GAN: 0.915 G_L1: 6.172 D_real: 0.743 D_fake: 0.561 \n",
      "End of epoch 17 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 68, time: 0.780, data: 0.001) G_GAN: 1.232 G_L1: 0.515 D_real: 1.218 D_fake: 0.358 \n",
      "(epoch: 18, iters: 168, time: 0.533, data: 0.001) G_GAN: 1.025 G_L1: 0.008 D_real: 1.047 D_fake: 0.437 \n",
      "(epoch: 18, iters: 268, time: 0.534, data: 0.001) G_GAN: 0.623 G_L1: 9.553 D_real: 0.413 D_fake: 0.799 \n",
      "(epoch: 18, iters: 368, time: 0.531, data: 0.001) G_GAN: 0.639 G_L1: 6.980 D_real: 0.518 D_fake: 0.763 \n",
      "End of epoch 18 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 72, time: 0.849, data: 0.001) G_GAN: 0.718 G_L1: 6.247 D_real: 0.692 D_fake: 0.678 \n",
      "(epoch: 19, iters: 172, time: 0.533, data: 0.001) G_GAN: 0.614 G_L1: 7.242 D_real: 0.524 D_fake: 0.807 \n",
      "(epoch: 19, iters: 272, time: 0.534, data: 0.001) G_GAN: 0.526 G_L1: 11.157 D_real: 0.403 D_fake: 0.944 \n",
      "(epoch: 19, iters: 372, time: 0.529, data: 0.001) G_GAN: 0.737 G_L1: 6.596 D_real: 0.604 D_fake: 0.666 \n",
      "End of epoch 19 / 50 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 76, time: 0.878, data: 0.001) G_GAN: 0.554 G_L1: 7.495 D_real: 0.364 D_fake: 0.920 \n",
      "(epoch: 20, iters: 176, time: 0.535, data: 0.001) G_GAN: 0.562 G_L1: 7.457 D_real: 0.583 D_fake: 0.901 \n",
      "(epoch: 20, iters: 276, time: 0.532, data: 0.001) G_GAN: 0.926 G_L1: 10.723 D_real: 0.624 D_fake: 0.507 \n",
      "(epoch: 20, iters: 376, time: 0.533, data: 0.001) G_GAN: 0.705 G_L1: 4.334 D_real: 0.680 D_fake: 0.685 \n",
      "saving the model at the end of epoch 20, iters 7920\n",
      "End of epoch 20 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 80, time: 0.837, data: 0.001) G_GAN: 0.944 G_L1: 3.001 D_real: 0.935 D_fake: 0.492 \n",
      "(epoch: 21, iters: 180, time: 0.534, data: 0.001) G_GAN: 0.806 G_L1: 4.049 D_real: 0.861 D_fake: 0.609 \n",
      "(epoch: 21, iters: 280, time: 0.533, data: 0.001) G_GAN: 0.992 G_L1: 5.890 D_real: 0.959 D_fake: 0.471 \n",
      "(epoch: 21, iters: 380, time: 0.534, data: 0.001) G_GAN: 0.642 G_L1: 6.129 D_real: 0.605 D_fake: 0.799 \n",
      "End of epoch 21 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 84, time: 0.824, data: 0.001) G_GAN: 0.990 G_L1: 0.980 D_real: 0.994 D_fake: 0.464 \n",
      "(epoch: 22, iters: 184, time: 0.531, data: 0.001) G_GAN: 0.788 G_L1: 5.193 D_real: 0.733 D_fake: 0.602 \n",
      "(epoch: 22, iters: 284, time: 0.532, data: 0.001) G_GAN: 0.857 G_L1: 2.638 D_real: 0.846 D_fake: 0.543 \n",
      "(epoch: 22, iters: 384, time: 0.535, data: 0.001) G_GAN: 0.680 G_L1: 6.822 D_real: 0.595 D_fake: 0.703 \n",
      "End of epoch 22 / 50 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 88, time: 0.852, data: 0.001) G_GAN: 0.703 G_L1: 5.754 D_real: 0.570 D_fake: 0.708 \n",
      "(epoch: 23, iters: 188, time: 0.533, data: 0.001) G_GAN: 1.028 G_L1: 0.063 D_real: 1.021 D_fake: 0.448 \n",
      "(epoch: 23, iters: 288, time: 0.533, data: 0.001) G_GAN: 0.773 G_L1: 5.068 D_real: 0.812 D_fake: 0.638 \n",
      "(epoch: 23, iters: 388, time: 0.530, data: 0.001) G_GAN: 0.817 G_L1: 7.216 D_real: 0.658 D_fake: 0.576 \n",
      "End of epoch 23 / 50 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 92, time: 0.881, data: 0.001) G_GAN: 0.591 G_L1: 10.907 D_real: 0.531 D_fake: 0.911 \n",
      "(epoch: 24, iters: 192, time: 0.533, data: 0.001) G_GAN: 0.650 G_L1: 4.737 D_real: 0.612 D_fake: 0.754 \n",
      "(epoch: 24, iters: 292, time: 0.530, data: 0.001) G_GAN: 0.735 G_L1: 9.028 D_real: 0.468 D_fake: 0.661 \n",
      "(epoch: 24, iters: 392, time: 0.532, data: 0.001) G_GAN: 0.876 G_L1: 0.667 D_real: 0.892 D_fake: 0.537 \n",
      "End of epoch 24 / 50 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 96, time: 0.852, data: 0.001) G_GAN: 0.590 G_L1: 5.900 D_real: 0.433 D_fake: 0.868 \n",
      "(epoch: 25, iters: 196, time: 0.534, data: 0.001) G_GAN: 0.750 G_L1: 5.484 D_real: 0.695 D_fake: 0.641 \n",
      "(epoch: 25, iters: 296, time: 0.529, data: 0.001) G_GAN: 0.712 G_L1: 5.973 D_real: 0.652 D_fake: 0.679 \n",
      "(epoch: 25, iters: 396, time: 0.530, data: 0.001) G_GAN: 0.716 G_L1: 8.012 D_real: 0.615 D_fake: 0.698 \n",
      "saving the model at the end of epoch 25, iters 9900\n",
      "End of epoch 25 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0001923\n",
      "(epoch: 26, iters: 100, time: 0.861, data: 0.080) G_GAN: 0.618 G_L1: 5.937 D_real: 0.465 D_fake: 0.835 \n",
      "saving the latest model (epoch 26, total_iters 10000)\n",
      "(epoch: 26, iters: 200, time: 0.533, data: 0.001) G_GAN: 0.844 G_L1: 6.205 D_real: 0.745 D_fake: 0.562 \n",
      "(epoch: 26, iters: 300, time: 0.532, data: 0.001) G_GAN: 0.831 G_L1: 3.778 D_real: 0.788 D_fake: 0.573 \n",
      "End of epoch 26 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0001846\n",
      "(epoch: 27, iters: 4, time: 0.531, data: 0.001) G_GAN: 0.855 G_L1: 0.006 D_real: 0.861 D_fake: 0.553 \n",
      "(epoch: 27, iters: 104, time: 0.857, data: 0.002) G_GAN: 0.653 G_L1: 5.992 D_real: 0.509 D_fake: 0.755 \n",
      "(epoch: 27, iters: 204, time: 0.533, data: 0.001) G_GAN: 0.810 G_L1: 3.572 D_real: 0.743 D_fake: 0.589 \n",
      "(epoch: 27, iters: 304, time: 0.533, data: 0.001) G_GAN: 0.749 G_L1: 6.081 D_real: 0.729 D_fake: 0.656 \n",
      "End of epoch 27 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0001769\n",
      "(epoch: 28, iters: 8, time: 0.535, data: 0.001) G_GAN: 0.678 G_L1: 6.687 D_real: 0.602 D_fake: 0.728 \n",
      "(epoch: 28, iters: 108, time: 0.838, data: 0.001) G_GAN: 0.866 G_L1: 1.002 D_real: 0.864 D_fake: 0.553 \n",
      "(epoch: 28, iters: 208, time: 0.529, data: 0.001) G_GAN: 0.728 G_L1: 5.377 D_real: 0.701 D_fake: 0.667 \n",
      "(epoch: 28, iters: 308, time: 0.533, data: 0.001) G_GAN: 0.805 G_L1: 4.673 D_real: 0.737 D_fake: 0.593 \n",
      "End of epoch 28 / 50 \t Time Taken: 136 sec\n",
      "learning rate = 0.0001692\n",
      "(epoch: 29, iters: 12, time: 0.534, data: 0.001) G_GAN: 0.811 G_L1: 3.802 D_real: 0.829 D_fake: 0.590 \n",
      "(epoch: 29, iters: 112, time: 0.870, data: 0.001) G_GAN: 0.788 G_L1: 4.344 D_real: 0.779 D_fake: 0.610 \n",
      "(epoch: 29, iters: 212, time: 0.534, data: 0.001) G_GAN: 0.721 G_L1: 4.606 D_real: 0.638 D_fake: 0.671 \n",
      "(epoch: 29, iters: 312, time: 0.533, data: 0.001) G_GAN: 0.773 G_L1: 4.825 D_real: 0.789 D_fake: 0.625 \n",
      "End of epoch 29 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0001615\n",
      "(epoch: 30, iters: 16, time: 0.532, data: 0.001) G_GAN: 0.752 G_L1: 3.361 D_real: 0.734 D_fake: 0.643 \n",
      "(epoch: 30, iters: 116, time: 0.896, data: 0.001) G_GAN: 0.767 G_L1: 5.755 D_real: 0.724 D_fake: 0.626 \n",
      "(epoch: 30, iters: 216, time: 0.531, data: 0.001) G_GAN: 0.622 G_L1: 6.942 D_real: 0.524 D_fake: 0.788 \n",
      "(epoch: 30, iters: 316, time: 0.530, data: 0.001) G_GAN: 0.705 G_L1: 4.777 D_real: 0.693 D_fake: 0.683 \n",
      "saving the model at the end of epoch 30, iters 11880\n",
      "End of epoch 30 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0001538\n",
      "(epoch: 31, iters: 20, time: 0.533, data: 0.001) G_GAN: 0.726 G_L1: 4.866 D_real: 0.616 D_fake: 0.671 \n",
      "(epoch: 31, iters: 120, time: 0.909, data: 0.001) G_GAN: 0.727 G_L1: 4.492 D_real: 0.645 D_fake: 0.665 \n",
      "(epoch: 31, iters: 220, time: 0.532, data: 0.001) G_GAN: 0.668 G_L1: 4.851 D_real: 0.580 D_fake: 0.725 \n",
      "(epoch: 31, iters: 320, time: 0.532, data: 0.001) G_GAN: 0.742 G_L1: 4.926 D_real: 0.699 D_fake: 0.655 \n",
      "End of epoch 31 / 50 \t Time Taken: 136 sec\n",
      "learning rate = 0.0001462\n",
      "(epoch: 32, iters: 24, time: 0.534, data: 0.001) G_GAN: 0.711 G_L1: 4.269 D_real: 0.710 D_fake: 0.681 \n",
      "(epoch: 32, iters: 124, time: 0.862, data: 0.001) G_GAN: 0.708 G_L1: 4.491 D_real: 0.643 D_fake: 0.688 \n",
      "(epoch: 32, iters: 224, time: 0.529, data: 0.001) G_GAN: 0.673 G_L1: 6.847 D_real: 0.670 D_fake: 0.722 \n",
      "(epoch: 32, iters: 324, time: 0.531, data: 0.001) G_GAN: 0.721 G_L1: 4.266 D_real: 0.700 D_fake: 0.669 \n",
      "End of epoch 32 / 50 \t Time Taken: 136 sec\n",
      "learning rate = 0.0001385\n",
      "(epoch: 33, iters: 28, time: 0.568, data: 0.001) G_GAN: 0.732 G_L1: 3.451 D_real: 0.737 D_fake: 0.667 \n",
      "(epoch: 33, iters: 128, time: 0.898, data: 0.002) G_GAN: 0.605 G_L1: 6.657 D_real: 0.610 D_fake: 0.849 \n",
      "(epoch: 33, iters: 228, time: 0.536, data: 0.001) G_GAN: 0.810 G_L1: 3.082 D_real: 0.771 D_fake: 0.588 \n",
      "(epoch: 33, iters: 328, time: 0.635, data: 0.001) G_GAN: 0.562 G_L1: 7.740 D_real: 0.439 D_fake: 0.867 \n",
      "End of epoch 33 / 50 \t Time Taken: 148 sec\n",
      "learning rate = 0.0001308\n",
      "(epoch: 34, iters: 32, time: 0.624, data: 0.002) G_GAN: 0.729 G_L1: 4.684 D_real: 0.671 D_fake: 0.662 \n",
      "(epoch: 34, iters: 132, time: 6.441, data: 0.002) G_GAN: 0.710 G_L1: 5.668 D_real: 0.614 D_fake: 0.681 \n",
      "(epoch: 34, iters: 232, time: 3.031, data: 0.002) G_GAN: 0.686 G_L1: 5.400 D_real: 0.712 D_fake: 0.710 \n",
      "(epoch: 34, iters: 332, time: 5.539, data: 0.002) G_GAN: 0.739 G_L1: 4.257 D_real: 0.718 D_fake: 0.652 \n",
      "End of epoch 34 / 50 \t Time Taken: 1176 sec\n",
      "learning rate = 0.0001231\n",
      "(epoch: 35, iters: 36, time: 5.035, data: 0.003) G_GAN: 0.740 G_L1: 4.350 D_real: 0.670 D_fake: 0.652 \n",
      "(epoch: 35, iters: 136, time: 3.607, data: 0.001) G_GAN: 0.787 G_L1: 2.776 D_real: 0.752 D_fake: 0.607 \n",
      "(epoch: 35, iters: 236, time: 3.059, data: 0.004) G_GAN: 0.740 G_L1: 5.020 D_real: 0.748 D_fake: 0.698 \n",
      "(epoch: 35, iters: 336, time: 3.734, data: 0.002) G_GAN: 0.759 G_L1: 4.588 D_real: 0.725 D_fake: 0.633 \n",
      "saving the model at the end of epoch 35, iters 13860\n",
      "End of epoch 35 / 50 \t Time Taken: 979 sec\n",
      "learning rate = 0.0001154\n",
      "(epoch: 36, iters: 40, time: 3.051, data: 0.006) G_GAN: 0.752 G_L1: 2.446 D_real: 0.737 D_fake: 0.638 \n",
      "(epoch: 36, iters: 140, time: 0.936, data: 0.006) G_GAN: 0.679 G_L1: 5.683 D_real: 0.605 D_fake: 0.724 \n",
      "(epoch: 36, iters: 240, time: 0.559, data: 0.001) G_GAN: 0.748 G_L1: 0.702 D_real: 0.750 D_fake: 0.646 \n",
      "(epoch: 36, iters: 340, time: 0.569, data: 0.001) G_GAN: 0.676 G_L1: 6.796 D_real: 0.723 D_fake: 0.720 \n",
      "End of epoch 36 / 50 \t Time Taken: 336 sec\n",
      "learning rate = 0.0001077\n",
      "(epoch: 37, iters: 44, time: 0.567, data: 0.001) G_GAN: 0.670 G_L1: 5.923 D_real: 0.628 D_fake: 0.725 \n",
      "(epoch: 37, iters: 144, time: 0.983, data: 0.001) G_GAN: 0.654 G_L1: 5.534 D_real: 0.666 D_fake: 0.749 \n",
      "(epoch: 37, iters: 244, time: 0.538, data: 0.001) G_GAN: 0.711 G_L1: 5.156 D_real: 0.649 D_fake: 0.681 \n",
      "(epoch: 37, iters: 344, time: 0.529, data: 0.001) G_GAN: 0.785 G_L1: 3.394 D_real: 0.754 D_fake: 0.618 \n",
      "End of epoch 37 / 50 \t Time Taken: 143 sec\n",
      "learning rate = 0.0001000\n",
      "(epoch: 38, iters: 48, time: 0.532, data: 0.001) G_GAN: 0.778 G_L1: 3.811 D_real: 0.758 D_fake: 0.632 \n",
      "(epoch: 38, iters: 148, time: 0.905, data: 0.001) G_GAN: 0.694 G_L1: 3.576 D_real: 0.701 D_fake: 0.720 \n",
      "(epoch: 38, iters: 248, time: 0.530, data: 0.001) G_GAN: 0.749 G_L1: 3.995 D_real: 0.708 D_fake: 0.643 \n",
      "(epoch: 38, iters: 348, time: 0.532, data: 0.001) G_GAN: 0.775 G_L1: 3.006 D_real: 0.770 D_fake: 0.620 \n",
      "saving the latest model (epoch 38, total_iters 15000)\n",
      "End of epoch 38 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000923\n",
      "(epoch: 39, iters: 52, time: 0.534, data: 0.001) G_GAN: 0.733 G_L1: 3.432 D_real: 0.688 D_fake: 0.657 \n",
      "(epoch: 39, iters: 152, time: 0.897, data: 0.001) G_GAN: 0.741 G_L1: 3.149 D_real: 0.727 D_fake: 0.650 \n",
      "(epoch: 39, iters: 252, time: 0.533, data: 0.001) G_GAN: 0.781 G_L1: 3.056 D_real: 0.753 D_fake: 0.622 \n",
      "(epoch: 39, iters: 352, time: 0.533, data: 0.001) G_GAN: 0.804 G_L1: 2.181 D_real: 0.788 D_fake: 0.603 \n",
      "End of epoch 39 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000846\n",
      "(epoch: 40, iters: 56, time: 0.532, data: 0.001) G_GAN: 0.769 G_L1: 3.220 D_real: 0.745 D_fake: 0.623 \n",
      "(epoch: 40, iters: 156, time: 0.933, data: 0.001) G_GAN: 0.768 G_L1: 3.062 D_real: 0.759 D_fake: 0.625 \n",
      "(epoch: 40, iters: 256, time: 0.533, data: 0.001) G_GAN: 0.766 G_L1: 3.492 D_real: 0.741 D_fake: 0.628 \n",
      "(epoch: 40, iters: 356, time: 0.533, data: 0.001) G_GAN: 0.751 G_L1: 2.920 D_real: 0.728 D_fake: 0.641 \n",
      "saving the model at the end of epoch 40, iters 15840\n",
      "End of epoch 40 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000769\n",
      "(epoch: 41, iters: 60, time: 0.530, data: 0.001) G_GAN: 0.726 G_L1: 5.136 D_real: 0.642 D_fake: 0.665 \n",
      "(epoch: 41, iters: 160, time: 0.931, data: 0.001) G_GAN: 0.695 G_L1: 3.363 D_real: 0.673 D_fake: 0.698 \n",
      "(epoch: 41, iters: 260, time: 0.535, data: 0.001) G_GAN: 0.767 G_L1: 2.391 D_real: 0.741 D_fake: 0.627 \n",
      "(epoch: 41, iters: 360, time: 0.535, data: 0.001) G_GAN: 0.721 G_L1: 4.401 D_real: 0.649 D_fake: 0.670 \n",
      "End of epoch 41 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000692\n",
      "(epoch: 42, iters: 64, time: 0.530, data: 0.001) G_GAN: 0.674 G_L1: 7.145 D_real: 0.553 D_fake: 0.726 \n",
      "(epoch: 42, iters: 164, time: 0.931, data: 0.001) G_GAN: 0.755 G_L1: 3.055 D_real: 0.739 D_fake: 0.638 \n",
      "(epoch: 42, iters: 264, time: 0.531, data: 0.001) G_GAN: 0.716 G_L1: 3.144 D_real: 0.681 D_fake: 0.674 \n",
      "(epoch: 42, iters: 364, time: 0.533, data: 0.001) G_GAN: 0.783 G_L1: 1.871 D_real: 0.766 D_fake: 0.614 \n",
      "End of epoch 42 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000615\n",
      "(epoch: 43, iters: 68, time: 0.533, data: 0.001) G_GAN: 0.730 G_L1: 1.196 D_real: 0.719 D_fake: 0.661 \n",
      "(epoch: 43, iters: 168, time: 0.896, data: 0.001) G_GAN: 0.735 G_L1: 2.541 D_real: 0.713 D_fake: 0.657 \n",
      "(epoch: 43, iters: 268, time: 0.533, data: 0.001) G_GAN: 0.690 G_L1: 0.005 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 43, iters: 368, time: 0.534, data: 0.001) G_GAN: 0.727 G_L1: 0.312 D_real: 0.726 D_fake: 0.665 \n",
      "End of epoch 43 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000538\n",
      "(epoch: 44, iters: 72, time: 0.531, data: 0.001) G_GAN: 0.584 G_L1: 6.485 D_real: 0.470 D_fake: 0.836 \n",
      "(epoch: 44, iters: 172, time: 0.926, data: 0.001) G_GAN: 0.684 G_L1: 4.645 D_real: 0.600 D_fake: 0.708 \n",
      "(epoch: 44, iters: 272, time: 0.535, data: 0.001) G_GAN: 0.752 G_L1: 3.873 D_real: 0.709 D_fake: 0.640 \n",
      "(epoch: 44, iters: 372, time: 0.530, data: 0.001) G_GAN: 0.688 G_L1: 0.009 D_real: 0.688 D_fake: 0.699 \n",
      "End of epoch 44 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000462\n",
      "(epoch: 45, iters: 76, time: 0.533, data: 0.001) G_GAN: 0.729 G_L1: 2.460 D_real: 0.713 D_fake: 0.661 \n",
      "(epoch: 45, iters: 176, time: 0.922, data: 0.001) G_GAN: 0.744 G_L1: 2.750 D_real: 0.728 D_fake: 0.647 \n",
      "(epoch: 45, iters: 276, time: 0.532, data: 0.001) G_GAN: 0.784 G_L1: 1.764 D_real: 0.764 D_fake: 0.613 \n",
      "(epoch: 45, iters: 376, time: 0.530, data: 0.001) G_GAN: 0.639 G_L1: 3.347 D_real: 0.595 D_fake: 0.760 \n",
      "saving the model at the end of epoch 45, iters 17820\n",
      "End of epoch 45 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000385\n",
      "(epoch: 46, iters: 80, time: 0.534, data: 0.001) G_GAN: 0.750 G_L1: 2.869 D_real: 0.742 D_fake: 0.646 \n",
      "(epoch: 46, iters: 180, time: 0.957, data: 0.001) G_GAN: 0.570 G_L1: 2.504 D_real: 0.512 D_fake: 0.854 \n",
      "(epoch: 46, iters: 280, time: 0.536, data: 0.001) G_GAN: 0.706 G_L1: 2.674 D_real: 0.666 D_fake: 0.684 \n",
      "(epoch: 46, iters: 380, time: 0.531, data: 0.001) G_GAN: 0.607 G_L1: 5.670 D_real: 0.537 D_fake: 0.803 \n",
      "End of epoch 46 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000308\n",
      "(epoch: 47, iters: 84, time: 0.531, data: 0.001) G_GAN: 0.756 G_L1: 2.394 D_real: 0.744 D_fake: 0.637 \n",
      "(epoch: 47, iters: 184, time: 0.951, data: 0.001) G_GAN: 0.698 G_L1: 2.548 D_real: 0.667 D_fake: 0.691 \n",
      "(epoch: 47, iters: 284, time: 0.533, data: 0.001) G_GAN: 0.602 G_L1: 5.509 D_real: 0.564 D_fake: 0.807 \n",
      "(epoch: 47, iters: 384, time: 0.532, data: 0.001) G_GAN: 0.764 G_L1: 2.553 D_real: 0.754 D_fake: 0.633 \n",
      "End of epoch 47 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000231\n",
      "(epoch: 48, iters: 88, time: 0.534, data: 0.001) G_GAN: 0.744 G_L1: 1.247 D_real: 0.732 D_fake: 0.648 \n",
      "(epoch: 48, iters: 188, time: 0.915, data: 0.001) G_GAN: 0.689 G_L1: 0.002 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 48, iters: 288, time: 0.534, data: 0.002) G_GAN: 0.742 G_L1: 2.454 D_real: 0.724 D_fake: 0.650 \n",
      "(epoch: 48, iters: 388, time: 0.537, data: 0.001) G_GAN: 0.731 G_L1: 0.495 D_real: 0.725 D_fake: 0.662 \n",
      "End of epoch 48 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000154\n",
      "(epoch: 49, iters: 92, time: 0.533, data: 0.001) G_GAN: 0.727 G_L1: 2.755 D_real: 0.702 D_fake: 0.664 \n",
      "(epoch: 49, iters: 192, time: 0.964, data: 0.001) G_GAN: 0.624 G_L1: 4.740 D_real: 0.545 D_fake: 0.776 \n",
      "(epoch: 49, iters: 292, time: 0.534, data: 0.001) G_GAN: 0.714 G_L1: 5.358 D_real: 0.612 D_fake: 0.676 \n",
      "(epoch: 49, iters: 392, time: 0.535, data: 0.001) G_GAN: 0.751 G_L1: 2.263 D_real: 0.744 D_fake: 0.641 \n",
      "End of epoch 49 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000077\n",
      "(epoch: 50, iters: 96, time: 0.530, data: 0.001) G_GAN: 0.730 G_L1: 1.973 D_real: 0.720 D_fake: 0.661 \n",
      "(epoch: 50, iters: 196, time: 0.950, data: 0.001) G_GAN: 0.589 G_L1: 4.405 D_real: 0.624 D_fake: 0.819 \n",
      "(epoch: 50, iters: 296, time: 0.535, data: 0.001) G_GAN: 0.716 G_L1: 0.253 D_real: 0.716 D_fake: 0.672 \n",
      "(epoch: 50, iters: 396, time: 0.536, data: 0.002) G_GAN: 0.666 G_L1: 2.732 D_real: 0.635 D_fake: 0.725 \n",
      "saving the model at the end of epoch 50, iters 19800\n",
      "End of epoch 50 / 50 \t Time Taken: 137 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot baw/AB --model pix2pix --no_dropout --output_nc 1 --norm batch --niter 25 --niter_decay 25 --no_flip --checkpoints_dir may17 --netG resnet_9blocks --netD pixel --preprocess none --name pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: may16                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: AB                            \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: test30train366                \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 366\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "[Network D] Total number of parameters : 2.767 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory may16/test30train366/web...\n",
      "(epoch: 1, iters: 100, time: 0.517, data: 0.098) G_GAN: 2.640 G_L1: 16.549 D_real: 0.075 D_fake: 0.084 \n",
      "(epoch: 1, iters: 200, time: 0.531, data: 0.001) G_GAN: 1.457 G_L1: 8.097 D_real: 0.067 D_fake: 0.325 \n",
      "(epoch: 1, iters: 300, time: 0.594, data: 0.001) G_GAN: 1.609 G_L1: 11.589 D_real: 0.455 D_fake: 0.215 \n",
      "End of epoch 1 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 34, time: 0.813, data: 0.001) G_GAN: 0.977 G_L1: 7.549 D_real: 1.623 D_fake: 0.634 \n",
      "(epoch: 2, iters: 134, time: 0.549, data: 0.001) G_GAN: 1.316 G_L1: 9.204 D_real: 0.880 D_fake: 0.158 \n",
      "(epoch: 2, iters: 234, time: 0.533, data: 0.001) G_GAN: 1.644 G_L1: 9.516 D_real: 0.090 D_fake: 0.269 \n",
      "(epoch: 2, iters: 334, time: 0.537, data: 0.001) G_GAN: 1.469 G_L1: 10.750 D_real: 0.331 D_fake: 0.220 \n",
      "End of epoch 2 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 68, time: 0.810, data: 0.001) G_GAN: 1.536 G_L1: 9.499 D_real: 0.216 D_fake: 0.214 \n",
      "(epoch: 3, iters: 168, time: 0.536, data: 0.001) G_GAN: 1.272 G_L1: 6.750 D_real: 1.352 D_fake: 0.233 \n",
      "(epoch: 3, iters: 268, time: 0.539, data: 0.001) G_GAN: 1.215 G_L1: 0.770 D_real: 0.921 D_fake: 0.347 \n",
      "End of epoch 3 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 2, time: 0.538, data: 0.001) G_GAN: 1.182 G_L1: 12.807 D_real: 0.077 D_fake: 0.385 \n",
      "(epoch: 4, iters: 102, time: 0.807, data: 0.000) G_GAN: 0.602 G_L1: 5.599 D_real: 0.444 D_fake: 1.036 \n",
      "(epoch: 4, iters: 202, time: 0.539, data: 0.001) G_GAN: 1.347 G_L1: 10.023 D_real: 0.125 D_fake: 0.397 \n",
      "(epoch: 4, iters: 302, time: 0.540, data: 0.001) G_GAN: 1.069 G_L1: 6.179 D_real: 0.597 D_fake: 0.488 \n",
      "End of epoch 4 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 36, time: 0.543, data: 0.001) G_GAN: 0.845 G_L1: 6.849 D_real: 0.411 D_fake: 0.602 \n",
      "(epoch: 5, iters: 136, time: 0.785, data: 0.001) G_GAN: 0.939 G_L1: 5.465 D_real: 1.372 D_fake: 0.349 \n",
      "(epoch: 5, iters: 236, time: 0.536, data: 0.001) G_GAN: 0.955 G_L1: 0.414 D_real: 0.762 D_fake: 0.483 \n",
      "(epoch: 5, iters: 336, time: 0.538, data: 0.001) G_GAN: 0.726 G_L1: 10.146 D_real: 0.101 D_fake: 0.980 \n",
      "saving the model at the end of epoch 5, iters 1830\n",
      "End of epoch 5 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 70, time: 0.540, data: 0.001) G_GAN: 0.596 G_L1: 5.331 D_real: 0.513 D_fake: 0.912 \n",
      "(epoch: 6, iters: 170, time: 0.858, data: 0.001) G_GAN: 0.968 G_L1: 6.666 D_real: 0.385 D_fake: 0.453 \n",
      "(epoch: 6, iters: 270, time: 0.541, data: 0.001) G_GAN: 1.314 G_L1: 4.315 D_real: 1.324 D_fake: 0.591 \n",
      "End of epoch 6 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 4, time: 0.541, data: 0.001) G_GAN: 0.699 G_L1: 6.171 D_real: 1.119 D_fake: 0.513 \n",
      "(epoch: 7, iters: 104, time: 0.541, data: 0.002) G_GAN: 0.589 G_L1: 6.898 D_real: 0.476 D_fake: 0.826 \n",
      "(epoch: 7, iters: 204, time: 0.835, data: 0.001) G_GAN: 0.606 G_L1: 4.182 D_real: 0.570 D_fake: 0.807 \n",
      "(epoch: 7, iters: 304, time: 0.541, data: 0.001) G_GAN: 0.773 G_L1: 0.057 D_real: 1.080 D_fake: 0.444 \n",
      "End of epoch 7 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 38, time: 0.540, data: 0.001) G_GAN: 0.866 G_L1: 5.519 D_real: 0.768 D_fake: 0.482 \n",
      "(epoch: 8, iters: 138, time: 0.540, data: 0.001) G_GAN: 0.851 G_L1: 5.233 D_real: 0.433 D_fake: 0.542 \n",
      "(epoch: 8, iters: 238, time: 0.839, data: 0.001) G_GAN: 0.426 G_L1: 7.703 D_real: 0.415 D_fake: 2.470 \n",
      "(epoch: 8, iters: 338, time: 0.542, data: 0.001) G_GAN: 0.828 G_L1: 6.510 D_real: 0.150 D_fake: 1.087 \n",
      "End of epoch 8 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 72, time: 0.539, data: 0.001) G_GAN: 0.957 G_L1: 7.178 D_real: 0.631 D_fake: 0.354 \n",
      "(epoch: 9, iters: 172, time: 0.538, data: 0.001) G_GAN: 1.092 G_L1: 2.464 D_real: 1.001 D_fake: 0.398 \n",
      "(epoch: 9, iters: 272, time: 0.822, data: 0.001) G_GAN: 0.833 G_L1: 6.634 D_real: 0.351 D_fake: 0.604 \n",
      "End of epoch 9 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 6, time: 0.543, data: 0.001) G_GAN: 0.884 G_L1: 5.548 D_real: 0.351 D_fake: 0.801 \n",
      "(epoch: 10, iters: 106, time: 0.540, data: 0.002) G_GAN: 1.579 G_L1: 11.066 D_real: 0.145 D_fake: 0.466 \n",
      "(epoch: 10, iters: 206, time: 0.539, data: 0.001) G_GAN: 1.365 G_L1: 3.812 D_real: 1.558 D_fake: 0.224 \n",
      "(epoch: 10, iters: 306, time: 0.823, data: 0.001) G_GAN: 0.755 G_L1: 4.042 D_real: 0.815 D_fake: 0.579 \n",
      "saving the model at the end of epoch 10, iters 3660\n",
      "End of epoch 10 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 40, time: 0.540, data: 0.001) G_GAN: 0.731 G_L1: 4.795 D_real: 0.667 D_fake: 0.503 \n",
      "(epoch: 11, iters: 140, time: 0.541, data: 0.001) G_GAN: 1.263 G_L1: 6.373 D_real: 0.434 D_fake: 1.020 \n",
      "(epoch: 11, iters: 240, time: 0.540, data: 0.001) G_GAN: 1.024 G_L1: 6.568 D_real: 1.062 D_fake: 0.263 \n",
      "(epoch: 11, iters: 340, time: 0.822, data: 0.001) G_GAN: 1.084 G_L1: 7.009 D_real: 0.283 D_fake: 0.541 \n",
      "End of epoch 11 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 74, time: 0.543, data: 0.001) G_GAN: 0.773 G_L1: 3.475 D_real: 0.872 D_fake: 0.455 \n",
      "(epoch: 12, iters: 174, time: 0.544, data: 0.001) G_GAN: 0.851 G_L1: 4.733 D_real: 0.726 D_fake: 0.371 \n",
      "(epoch: 12, iters: 274, time: 0.544, data: 0.001) G_GAN: 1.051 G_L1: 5.795 D_real: 0.468 D_fake: 0.484 \n",
      "End of epoch 12 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 8, time: 0.845, data: 0.001) G_GAN: 1.052 G_L1: 8.016 D_real: 0.199 D_fake: 0.669 \n",
      "(epoch: 13, iters: 108, time: 0.537, data: 0.001) G_GAN: 0.782 G_L1: 6.195 D_real: 1.092 D_fake: 0.342 \n",
      "(epoch: 13, iters: 208, time: 0.540, data: 0.001) G_GAN: 1.152 G_L1: 9.045 D_real: 0.164 D_fake: 0.785 \n",
      "(epoch: 13, iters: 308, time: 0.541, data: 0.001) G_GAN: 0.683 G_L1: 4.542 D_real: 1.001 D_fake: 0.683 \n",
      "End of epoch 13 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 42, time: 0.827, data: 0.001) G_GAN: 1.137 G_L1: 7.017 D_real: 0.369 D_fake: 0.813 \n",
      "(epoch: 14, iters: 142, time: 0.540, data: 0.001) G_GAN: 1.199 G_L1: 4.659 D_real: 0.514 D_fake: 0.644 \n",
      "(epoch: 14, iters: 242, time: 0.542, data: 0.001) G_GAN: 0.970 G_L1: 4.757 D_real: 1.048 D_fake: 0.261 \n",
      "saving the latest model (epoch 14, total_iters 5000)\n",
      "(epoch: 14, iters: 342, time: 0.539, data: 0.002) G_GAN: 1.184 G_L1: 6.082 D_real: 0.585 D_fake: 0.514 \n",
      "End of epoch 14 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 76, time: 0.854, data: 0.001) G_GAN: 1.229 G_L1: 6.682 D_real: 0.327 D_fake: 0.501 \n",
      "(epoch: 15, iters: 176, time: 0.545, data: 0.001) G_GAN: 1.397 G_L1: 5.852 D_real: 0.130 D_fake: 1.166 \n",
      "(epoch: 15, iters: 276, time: 0.540, data: 0.001) G_GAN: 1.452 G_L1: 4.048 D_real: 0.922 D_fake: 0.189 \n",
      "saving the model at the end of epoch 15, iters 5490\n",
      "End of epoch 15 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 10, time: 0.540, data: 0.001) G_GAN: 0.729 G_L1: 1.576 D_real: 0.641 D_fake: 0.643 \n",
      "(epoch: 16, iters: 110, time: 0.860, data: 0.002) G_GAN: 1.805 G_L1: 6.117 D_real: 0.182 D_fake: 0.393 \n",
      "(epoch: 16, iters: 210, time: 0.542, data: 0.001) G_GAN: 1.212 G_L1: 5.800 D_real: 0.808 D_fake: 0.247 \n",
      "(epoch: 16, iters: 310, time: 0.539, data: 0.001) G_GAN: 1.168 G_L1: 5.604 D_real: 0.193 D_fake: 0.631 \n",
      "End of epoch 16 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 44, time: 0.543, data: 0.001) G_GAN: 1.517 G_L1: 3.118 D_real: 0.664 D_fake: 0.131 \n",
      "(epoch: 17, iters: 144, time: 0.874, data: 0.001) G_GAN: 2.329 G_L1: 10.282 D_real: 0.016 D_fake: 0.463 \n",
      "(epoch: 17, iters: 244, time: 0.543, data: 0.001) G_GAN: 1.156 G_L1: 7.600 D_real: 0.051 D_fake: 1.721 \n",
      "(epoch: 17, iters: 344, time: 0.543, data: 0.001) G_GAN: 1.654 G_L1: 4.560 D_real: 0.503 D_fake: 0.283 \n",
      "End of epoch 17 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 78, time: 0.563, data: 0.001) G_GAN: 1.736 G_L1: 7.288 D_real: 0.032 D_fake: 1.151 \n",
      "(epoch: 18, iters: 178, time: 0.869, data: 0.001) G_GAN: 2.272 G_L1: 9.623 D_real: 0.168 D_fake: 0.142 \n",
      "(epoch: 18, iters: 278, time: 0.544, data: 0.001) G_GAN: 2.111 G_L1: 10.654 D_real: 0.101 D_fake: 0.359 \n",
      "End of epoch 18 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 12, time: 0.540, data: 0.001) G_GAN: 1.700 G_L1: 5.548 D_real: 0.301 D_fake: 0.292 \n",
      "(epoch: 19, iters: 112, time: 0.539, data: 0.001) G_GAN: 0.949 G_L1: 0.264 D_real: 0.948 D_fake: 0.449 \n",
      "(epoch: 19, iters: 212, time: 0.896, data: 0.001) G_GAN: 2.769 G_L1: 4.572 D_real: 0.070 D_fake: 0.461 \n",
      "(epoch: 19, iters: 312, time: 0.542, data: 0.001) G_GAN: 3.144 G_L1: 4.290 D_real: 0.205 D_fake: 0.045 \n",
      "End of epoch 19 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 46, time: 0.543, data: 0.001) G_GAN: 0.840 G_L1: 5.148 D_real: 0.803 D_fake: 0.193 \n",
      "(epoch: 20, iters: 146, time: 0.539, data: 0.001) G_GAN: 1.888 G_L1: 5.574 D_real: 0.126 D_fake: 0.432 \n",
      "(epoch: 20, iters: 246, time: 0.868, data: 0.002) G_GAN: 1.681 G_L1: 5.687 D_real: 0.086 D_fake: 0.551 \n",
      "(epoch: 20, iters: 346, time: 0.543, data: 0.001) G_GAN: 1.231 G_L1: 3.229 D_real: 0.326 D_fake: 0.443 \n",
      "saving the model at the end of epoch 20, iters 7320\n",
      "End of epoch 20 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 80, time: 0.542, data: 0.001) G_GAN: 1.150 G_L1: 8.297 D_real: 0.848 D_fake: 0.313 \n",
      "(epoch: 21, iters: 180, time: 0.540, data: 0.001) G_GAN: 1.234 G_L1: 4.744 D_real: 0.509 D_fake: 0.419 \n",
      "(epoch: 21, iters: 280, time: 0.851, data: 0.001) G_GAN: 1.800 G_L1: 5.141 D_real: 0.226 D_fake: 0.898 \n",
      "End of epoch 21 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 14, time: 0.539, data: 0.001) G_GAN: 1.320 G_L1: 5.825 D_real: 1.668 D_fake: 0.086 \n",
      "(epoch: 22, iters: 114, time: 0.540, data: 0.001) G_GAN: 1.976 G_L1: 7.963 D_real: 0.066 D_fake: 1.159 \n",
      "(epoch: 22, iters: 214, time: 0.544, data: 0.001) G_GAN: 1.430 G_L1: 4.979 D_real: 0.148 D_fake: 1.144 \n",
      "(epoch: 22, iters: 314, time: 0.916, data: 0.001) G_GAN: 1.287 G_L1: 9.291 D_real: 0.567 D_fake: 0.421 \n",
      "End of epoch 22 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 48, time: 0.538, data: 0.001) G_GAN: 1.032 G_L1: 0.229 D_real: 0.526 D_fake: 0.565 \n",
      "(epoch: 23, iters: 148, time: 0.541, data: 0.001) G_GAN: 0.903 G_L1: 3.677 D_real: 0.912 D_fake: 0.456 \n",
      "(epoch: 23, iters: 248, time: 0.544, data: 0.001) G_GAN: 1.885 G_L1: 6.782 D_real: 0.148 D_fake: 0.724 \n",
      "(epoch: 23, iters: 348, time: 0.883, data: 0.001) G_GAN: 1.750 G_L1: 4.319 D_real: 0.432 D_fake: 0.200 \n",
      "End of epoch 23 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 82, time: 0.538, data: 0.002) G_GAN: 1.794 G_L1: 4.755 D_real: 0.438 D_fake: 0.278 \n",
      "(epoch: 24, iters: 182, time: 0.541, data: 0.001) G_GAN: 1.762 G_L1: 7.837 D_real: 0.310 D_fake: 0.879 \n",
      "(epoch: 24, iters: 282, time: 0.543, data: 0.001) G_GAN: 1.210 G_L1: 4.811 D_real: 1.419 D_fake: 0.256 \n",
      "End of epoch 24 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 16, time: 0.916, data: 0.001) G_GAN: 1.618 G_L1: 10.296 D_real: 0.189 D_fake: 0.363 \n",
      "(epoch: 25, iters: 116, time: 0.539, data: 0.001) G_GAN: 1.103 G_L1: 4.288 D_real: 0.405 D_fake: 0.468 \n",
      "(epoch: 25, iters: 216, time: 0.541, data: 0.001) G_GAN: 0.771 G_L1: 2.706 D_real: 1.050 D_fake: 0.597 \n",
      "(epoch: 25, iters: 316, time: 0.543, data: 0.001) G_GAN: 1.769 G_L1: 3.827 D_real: 0.250 D_fake: 0.339 \n",
      "saving the model at the end of epoch 25, iters 9150\n",
      "End of epoch 25 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 50, time: 0.890, data: 0.001) G_GAN: 1.264 G_L1: 3.154 D_real: 1.601 D_fake: 0.120 \n",
      "(epoch: 26, iters: 150, time: 0.540, data: 0.001) G_GAN: 1.337 G_L1: 3.488 D_real: 0.527 D_fake: 0.250 \n",
      "(epoch: 26, iters: 250, time: 0.540, data: 0.001) G_GAN: 1.464 G_L1: 5.699 D_real: 0.135 D_fake: 0.826 \n",
      "(epoch: 26, iters: 350, time: 0.543, data: 0.001) G_GAN: 0.745 G_L1: 3.498 D_real: 0.518 D_fake: 0.710 \n",
      "End of epoch 26 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 84, time: 0.930, data: 0.001) G_GAN: 1.504 G_L1: 8.592 D_real: 0.212 D_fake: 1.118 \n",
      "(epoch: 27, iters: 184, time: 0.539, data: 0.001) G_GAN: 1.229 G_L1: 7.865 D_real: 0.296 D_fake: 0.408 \n",
      "(epoch: 27, iters: 284, time: 0.540, data: 0.001) G_GAN: 1.496 G_L1: 5.340 D_real: 0.259 D_fake: 0.514 \n",
      "End of epoch 27 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 18, time: 0.541, data: 0.001) G_GAN: 1.639 G_L1: 5.373 D_real: 0.270 D_fake: 1.204 \n",
      "(epoch: 28, iters: 118, time: 0.887, data: 0.001) G_GAN: 0.701 G_L1: 4.101 D_real: 0.748 D_fake: 0.714 \n",
      "saving the latest model (epoch 28, total_iters 10000)\n",
      "(epoch: 28, iters: 218, time: 0.540, data: 0.003) G_GAN: 0.925 G_L1: 4.635 D_real: 0.892 D_fake: 0.485 \n",
      "(epoch: 28, iters: 318, time: 0.541, data: 0.001) G_GAN: 0.827 G_L1: 6.416 D_real: 0.919 D_fake: 0.626 \n",
      "End of epoch 28 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 52, time: 0.542, data: 0.001) G_GAN: 0.768 G_L1: 1.757 D_real: 0.553 D_fake: 0.771 \n",
      "(epoch: 29, iters: 152, time: 0.884, data: 0.001) G_GAN: 0.764 G_L1: 2.895 D_real: 0.560 D_fake: 0.659 \n",
      "(epoch: 29, iters: 252, time: 0.541, data: 0.001) G_GAN: 0.790 G_L1: 3.498 D_real: 0.604 D_fake: 0.786 \n",
      "(epoch: 29, iters: 352, time: 0.543, data: 0.001) G_GAN: 1.114 G_L1: 6.421 D_real: 0.232 D_fake: 1.028 \n",
      "End of epoch 29 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 86, time: 0.540, data: 0.001) G_GAN: 0.892 G_L1: 6.639 D_real: 0.654 D_fake: 0.498 \n",
      "(epoch: 30, iters: 186, time: 0.873, data: 0.001) G_GAN: 0.780 G_L1: 5.637 D_real: 1.278 D_fake: 0.288 \n",
      "(epoch: 30, iters: 286, time: 0.542, data: 0.001) G_GAN: 0.851 G_L1: 4.642 D_real: 0.908 D_fake: 0.343 \n",
      "saving the model at the end of epoch 30, iters 10980\n",
      "End of epoch 30 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 20, time: 0.545, data: 0.001) G_GAN: 0.861 G_L1: 5.500 D_real: 0.681 D_fake: 0.471 \n",
      "(epoch: 31, iters: 120, time: 0.542, data: 0.001) G_GAN: 1.028 G_L1: 3.022 D_real: 1.232 D_fake: 0.349 \n",
      "(epoch: 31, iters: 220, time: 0.918, data: 0.001) G_GAN: 0.724 G_L1: 2.806 D_real: 0.665 D_fake: 0.639 \n",
      "(epoch: 31, iters: 320, time: 0.540, data: 0.001) G_GAN: 0.937 G_L1: 5.259 D_real: 0.856 D_fake: 0.662 \n",
      "End of epoch 31 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 54, time: 0.541, data: 0.001) G_GAN: 0.825 G_L1: 3.346 D_real: 0.790 D_fake: 0.448 \n",
      "(epoch: 32, iters: 154, time: 0.542, data: 0.001) G_GAN: 0.848 G_L1: 3.922 D_real: 0.758 D_fake: 0.504 \n",
      "(epoch: 32, iters: 254, time: 0.904, data: 0.001) G_GAN: 0.881 G_L1: 5.587 D_real: 0.704 D_fake: 0.911 \n",
      "(epoch: 32, iters: 354, time: 0.542, data: 0.001) G_GAN: 0.800 G_L1: 4.131 D_real: 0.688 D_fake: 0.574 \n",
      "End of epoch 32 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 88, time: 0.545, data: 0.001) G_GAN: 0.648 G_L1: 3.447 D_real: 0.586 D_fake: 0.726 \n",
      "(epoch: 33, iters: 188, time: 0.541, data: 0.001) G_GAN: 0.607 G_L1: 3.318 D_real: 0.543 D_fake: 1.018 \n",
      "(epoch: 33, iters: 288, time: 0.901, data: 0.001) G_GAN: 0.728 G_L1: 3.093 D_real: 0.486 D_fake: 0.807 \n",
      "End of epoch 33 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 22, time: 0.542, data: 0.001) G_GAN: 0.751 G_L1: 0.178 D_real: 0.818 D_fake: 0.578 \n",
      "(epoch: 34, iters: 122, time: 0.541, data: 0.001) G_GAN: 0.763 G_L1: 3.846 D_real: 0.565 D_fake: 0.791 \n",
      "(epoch: 34, iters: 222, time: 0.543, data: 0.001) G_GAN: 0.787 G_L1: 1.295 D_real: 0.630 D_fake: 0.691 \n",
      "(epoch: 34, iters: 322, time: 0.921, data: 0.001) G_GAN: 0.883 G_L1: 5.100 D_real: 0.233 D_fake: 0.892 \n",
      "End of epoch 34 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 56, time: 0.538, data: 0.001) G_GAN: 0.781 G_L1: 2.477 D_real: 0.825 D_fake: 0.401 \n",
      "(epoch: 35, iters: 156, time: 0.539, data: 0.001) G_GAN: 1.239 G_L1: 4.207 D_real: 0.230 D_fake: 1.448 \n",
      "(epoch: 35, iters: 256, time: 0.544, data: 0.001) G_GAN: 0.740 G_L1: 4.835 D_real: 0.538 D_fake: 0.809 \n",
      "(epoch: 35, iters: 356, time: 0.916, data: 0.001) G_GAN: 0.738 G_L1: 4.427 D_real: 0.635 D_fake: 0.527 \n",
      "saving the model at the end of epoch 35, iters 12810\n",
      "End of epoch 35 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 90, time: 0.542, data: 0.001) G_GAN: 0.820 G_L1: 4.435 D_real: 0.470 D_fake: 0.938 \n",
      "(epoch: 36, iters: 190, time: 0.570, data: 0.001) G_GAN: 0.841 G_L1: 4.556 D_real: 0.556 D_fake: 0.595 \n",
      "(epoch: 36, iters: 290, time: 0.537, data: 0.001) G_GAN: 1.108 G_L1: 6.643 D_real: 0.378 D_fake: 0.852 \n",
      "End of epoch 36 / 200 \t Time Taken: 131 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 24, time: 0.974, data: 0.001) G_GAN: 0.730 G_L1: 4.745 D_real: 0.775 D_fake: 0.379 \n",
      "(epoch: 37, iters: 124, time: 0.537, data: 0.001) G_GAN: 0.808 G_L1: 4.250 D_real: 0.821 D_fake: 0.424 \n",
      "(epoch: 37, iters: 224, time: 0.582, data: 0.001) G_GAN: 1.013 G_L1: 5.749 D_real: 0.543 D_fake: 0.383 \n",
      "(epoch: 37, iters: 324, time: 0.535, data: 0.001) G_GAN: 0.646 G_L1: 0.067 D_real: 0.598 D_fake: 0.816 \n",
      "End of epoch 37 / 200 \t Time Taken: 134 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 58, time: 0.934, data: 0.001) G_GAN: 0.806 G_L1: 5.122 D_real: 0.560 D_fake: 0.958 \n",
      "(epoch: 38, iters: 158, time: 0.638, data: 0.001) G_GAN: 0.698 G_L1: 0.028 D_real: 0.635 D_fake: 0.775 \n",
      "(epoch: 38, iters: 258, time: 0.545, data: 0.001) G_GAN: 0.844 G_L1: 4.058 D_real: 0.846 D_fake: 0.446 \n",
      "(epoch: 38, iters: 358, time: 0.536, data: 0.002) G_GAN: 0.998 G_L1: 4.604 D_real: 0.505 D_fake: 0.574 \n",
      "End of epoch 38 / 200 \t Time Taken: 134 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 92, time: 0.903, data: 0.001) G_GAN: 0.943 G_L1: 1.790 D_real: 0.841 D_fake: 0.436 \n",
      "(epoch: 39, iters: 192, time: 0.540, data: 0.001) G_GAN: 0.821 G_L1: 3.543 D_real: 0.541 D_fake: 0.665 \n",
      "(epoch: 39, iters: 292, time: 0.543, data: 0.001) G_GAN: 0.748 G_L1: 4.341 D_real: 0.398 D_fake: 1.019 \n",
      "End of epoch 39 / 200 \t Time Taken: 132 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 26, time: 0.654, data: 0.001) G_GAN: 0.780 G_L1: 5.231 D_real: 0.847 D_fake: 0.430 \n",
      "(epoch: 40, iters: 126, time: 0.991, data: 0.001) G_GAN: 0.692 G_L1: 4.683 D_real: 0.574 D_fake: 0.979 \n",
      "(epoch: 40, iters: 226, time: 0.575, data: 0.001) G_GAN: 0.602 G_L1: 2.498 D_real: 0.438 D_fake: 0.957 \n",
      "(epoch: 40, iters: 326, time: 0.572, data: 0.001) G_GAN: 0.751 G_L1: 3.547 D_real: 0.456 D_fake: 0.894 \n",
      "saving the model at the end of epoch 40, iters 14640\n",
      "End of epoch 40 / 200 \t Time Taken: 141 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 60, time: 0.571, data: 0.001) G_GAN: 0.800 G_L1: 4.785 D_real: 0.625 D_fake: 0.527 \n",
      "(epoch: 41, iters: 160, time: 0.992, data: 0.001) G_GAN: 0.661 G_L1: 2.316 D_real: 0.470 D_fake: 0.716 \n",
      "(epoch: 41, iters: 260, time: 0.573, data: 0.001) G_GAN: 0.726 G_L1: 3.316 D_real: 0.392 D_fake: 0.848 \n",
      "(epoch: 41, iters: 360, time: 0.572, data: 0.001) G_GAN: 0.856 G_L1: 3.835 D_real: 0.157 D_fake: 1.728 \n",
      "saving the latest model (epoch 41, total_iters 15000)\n",
      "End of epoch 41 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 94, time: 0.574, data: 0.001) G_GAN: 0.898 G_L1: 3.756 D_real: 0.793 D_fake: 0.514 \n",
      "(epoch: 42, iters: 194, time: 1.015, data: 0.001) G_GAN: 0.819 G_L1: 4.388 D_real: 0.292 D_fake: 1.125 \n",
      "(epoch: 42, iters: 294, time: 0.577, data: 0.001) G_GAN: 0.925 G_L1: 5.568 D_real: 0.676 D_fake: 0.497 \n",
      "End of epoch 42 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 28, time: 0.570, data: 0.001) G_GAN: 0.994 G_L1: 4.443 D_real: 0.414 D_fake: 0.766 \n",
      "(epoch: 43, iters: 128, time: 0.541, data: 0.001) G_GAN: 0.754 G_L1: 4.704 D_real: 1.154 D_fake: 0.254 \n",
      "(epoch: 43, iters: 228, time: 1.011, data: 0.001) G_GAN: 0.957 G_L1: 3.887 D_real: 0.397 D_fake: 0.864 \n",
      "(epoch: 43, iters: 328, time: 0.567, data: 0.001) G_GAN: 0.714 G_L1: 2.404 D_real: 0.671 D_fake: 0.697 \n",
      "End of epoch 43 / 200 \t Time Taken: 135 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 62, time: 0.549, data: 0.001) G_GAN: 0.870 G_L1: 3.010 D_real: 1.689 D_fake: 0.142 \n",
      "(epoch: 44, iters: 162, time: 0.549, data: 0.001) G_GAN: 0.841 G_L1: 6.032 D_real: 0.419 D_fake: 0.749 \n",
      "(epoch: 44, iters: 262, time: 0.968, data: 0.001) G_GAN: 0.802 G_L1: 3.159 D_real: 0.904 D_fake: 0.459 \n",
      "(epoch: 44, iters: 362, time: 0.540, data: 0.001) G_GAN: 1.025 G_L1: 4.289 D_real: 0.608 D_fake: 0.541 \n",
      "End of epoch 44 / 200 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 96, time: 0.543, data: 0.001) G_GAN: 0.897 G_L1: 4.248 D_real: 0.428 D_fake: 0.770 \n",
      "(epoch: 45, iters: 196, time: 0.542, data: 0.001) G_GAN: 0.854 G_L1: 3.148 D_real: 0.545 D_fake: 0.648 \n",
      "(epoch: 45, iters: 296, time: 0.971, data: 0.001) G_GAN: 0.886 G_L1: 3.083 D_real: 0.712 D_fake: 0.495 \n",
      "saving the model at the end of epoch 45, iters 16470\n",
      "End of epoch 45 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 30, time: 0.542, data: 0.001) G_GAN: 0.650 G_L1: 2.224 D_real: 0.708 D_fake: 0.601 \n",
      "(epoch: 46, iters: 130, time: 0.539, data: 0.001) G_GAN: 1.272 G_L1: 3.117 D_real: 0.599 D_fake: 0.489 \n",
      "(epoch: 46, iters: 230, time: 0.542, data: 0.001) G_GAN: 0.756 G_L1: 3.370 D_real: 0.507 D_fake: 0.942 \n",
      "(epoch: 46, iters: 330, time: 0.958, data: 0.001) G_GAN: 0.681 G_L1: 3.613 D_real: 0.674 D_fake: 0.535 \n",
      "End of epoch 46 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 64, time: 0.543, data: 0.001) G_GAN: 0.950 G_L1: 3.504 D_real: 0.648 D_fake: 0.586 \n",
      "(epoch: 47, iters: 164, time: 0.541, data: 0.001) G_GAN: 0.933 G_L1: 2.807 D_real: 0.398 D_fake: 0.893 \n",
      "(epoch: 47, iters: 264, time: 0.544, data: 0.001) G_GAN: 0.767 G_L1: 1.211 D_real: 0.858 D_fake: 0.507 \n",
      "(epoch: 47, iters: 364, time: 0.974, data: 0.001) G_GAN: 0.942 G_L1: 3.257 D_real: 0.648 D_fake: 0.601 \n",
      "End of epoch 47 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 98, time: 0.538, data: 0.001) G_GAN: 0.862 G_L1: 2.537 D_real: 1.270 D_fake: 0.290 \n",
      "(epoch: 48, iters: 198, time: 0.539, data: 0.001) G_GAN: 1.081 G_L1: 3.345 D_real: 0.550 D_fake: 0.612 \n",
      "(epoch: 48, iters: 298, time: 0.543, data: 0.001) G_GAN: 0.815 G_L1: 3.072 D_real: 0.773 D_fake: 0.504 \n",
      "End of epoch 48 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 32, time: 0.993, data: 0.001) G_GAN: 0.883 G_L1: 4.395 D_real: 0.749 D_fake: 0.532 \n",
      "(epoch: 49, iters: 132, time: 0.540, data: 0.001) G_GAN: 0.825 G_L1: 3.278 D_real: 0.926 D_fake: 0.357 \n",
      "(epoch: 49, iters: 232, time: 0.543, data: 0.001) G_GAN: 0.905 G_L1: 2.973 D_real: 0.574 D_fake: 0.715 \n",
      "(epoch: 49, iters: 332, time: 0.544, data: 0.001) G_GAN: 0.661 G_L1: 0.022 D_real: 0.597 D_fake: 0.809 \n",
      "End of epoch 49 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 66, time: 0.952, data: 0.001) G_GAN: 0.792 G_L1: 2.491 D_real: 0.680 D_fake: 0.574 \n",
      "(epoch: 50, iters: 166, time: 0.543, data: 0.001) G_GAN: 1.060 G_L1: 4.416 D_real: 0.792 D_fake: 0.464 \n",
      "(epoch: 50, iters: 266, time: 0.543, data: 0.001) G_GAN: 0.910 G_L1: 3.340 D_real: 0.543 D_fake: 0.830 \n",
      "(epoch: 50, iters: 366, time: 0.543, data: 0.001) G_GAN: 0.891 G_L1: 2.499 D_real: 0.584 D_fake: 0.533 \n",
      "saving the model at the end of epoch 50, iters 18300\n",
      "End of epoch 50 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 100, time: 1.023, data: 0.078) G_GAN: 0.973 G_L1: 3.381 D_real: 0.573 D_fake: 0.397 \n",
      "(epoch: 51, iters: 200, time: 0.542, data: 0.001) G_GAN: 0.641 G_L1: 2.833 D_real: 0.966 D_fake: 0.514 \n",
      "(epoch: 51, iters: 300, time: 0.543, data: 0.001) G_GAN: 0.964 G_L1: 5.157 D_real: 0.894 D_fake: 0.441 \n",
      "End of epoch 51 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 34, time: 0.540, data: 0.001) G_GAN: 0.658 G_L1: 3.752 D_real: 0.656 D_fake: 0.776 \n",
      "(epoch: 52, iters: 134, time: 0.994, data: 0.001) G_GAN: 0.881 G_L1: 2.644 D_real: 0.546 D_fake: 0.728 \n",
      "(epoch: 52, iters: 234, time: 0.542, data: 0.001) G_GAN: 0.741 G_L1: 0.024 D_real: 0.709 D_fake: 0.692 \n",
      "(epoch: 52, iters: 334, time: 0.544, data: 0.001) G_GAN: 0.924 G_L1: 2.441 D_real: 0.497 D_fake: 0.710 \n",
      "End of epoch 52 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 68, time: 0.542, data: 0.001) G_GAN: 1.104 G_L1: 3.357 D_real: 0.465 D_fake: 0.683 \n",
      "(epoch: 53, iters: 168, time: 1.007, data: 0.001) G_GAN: 0.759 G_L1: 3.608 D_real: 0.807 D_fake: 0.445 \n",
      "(epoch: 53, iters: 268, time: 0.546, data: 0.001) G_GAN: 0.716 G_L1: 0.034 D_real: 0.715 D_fake: 0.672 \n",
      "End of epoch 53 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 2, time: 0.541, data: 0.001) G_GAN: 0.733 G_L1: 3.833 D_real: 0.739 D_fake: 0.537 \n",
      "(epoch: 54, iters: 102, time: 0.540, data: 0.002) G_GAN: 0.753 G_L1: 0.025 D_real: 0.812 D_fake: 0.600 \n",
      "(epoch: 54, iters: 202, time: 0.995, data: 0.001) G_GAN: 0.702 G_L1: 3.195 D_real: 1.089 D_fake: 0.472 \n",
      "(epoch: 54, iters: 302, time: 0.542, data: 0.001) G_GAN: 0.977 G_L1: 4.267 D_real: 0.526 D_fake: 0.486 \n",
      "End of epoch 54 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 36, time: 0.542, data: 0.001) G_GAN: 0.666 G_L1: 3.060 D_real: 0.839 D_fake: 0.577 \n",
      "(epoch: 55, iters: 136, time: 0.542, data: 0.001) G_GAN: 0.793 G_L1: 3.385 D_real: 0.578 D_fake: 0.653 \n",
      "(epoch: 55, iters: 236, time: 1.013, data: 0.001) G_GAN: 0.767 G_L1: 3.573 D_real: 0.592 D_fake: 0.490 \n",
      "saving the latest model (epoch 55, total_iters 20000)\n",
      "(epoch: 55, iters: 336, time: 0.541, data: 0.001) G_GAN: 0.727 G_L1: 3.323 D_real: 0.638 D_fake: 0.493 \n",
      "saving the model at the end of epoch 55, iters 20130\n",
      "End of epoch 55 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 70, time: 0.543, data: 0.001) G_GAN: 1.291 G_L1: 4.631 D_real: 0.414 D_fake: 0.966 \n",
      "(epoch: 56, iters: 170, time: 0.541, data: 0.001) G_GAN: 0.776 G_L1: 2.830 D_real: 0.372 D_fake: 0.766 \n",
      "(epoch: 56, iters: 270, time: 1.027, data: 0.001) G_GAN: 0.986 G_L1: 3.292 D_real: 0.490 D_fake: 0.481 \n",
      "End of epoch 56 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 4, time: 0.542, data: 0.001) G_GAN: 0.820 G_L1: 0.116 D_real: 0.833 D_fake: 0.568 \n",
      "(epoch: 57, iters: 104, time: 0.544, data: 0.003) G_GAN: 0.748 G_L1: 3.798 D_real: 0.891 D_fake: 0.419 \n",
      "(epoch: 57, iters: 204, time: 0.541, data: 0.001) G_GAN: 0.724 G_L1: 2.747 D_real: 0.915 D_fake: 0.627 \n",
      "(epoch: 57, iters: 304, time: 0.937, data: 0.001) G_GAN: 0.693 G_L1: 0.028 D_real: 0.708 D_fake: 0.675 \n",
      "End of epoch 57 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 38, time: 0.578, data: 0.001) G_GAN: 0.921 G_L1: 3.419 D_real: 0.352 D_fake: 0.768 \n",
      "(epoch: 58, iters: 138, time: 0.578, data: 0.001) G_GAN: 0.769 G_L1: 1.112 D_real: 0.719 D_fake: 0.624 \n",
      "(epoch: 58, iters: 238, time: 0.569, data: 0.001) G_GAN: 1.095 G_L1: 4.331 D_real: 0.617 D_fake: 0.502 \n",
      "(epoch: 58, iters: 338, time: 1.066, data: 0.001) G_GAN: 0.745 G_L1: 3.288 D_real: 0.798 D_fake: 0.386 \n",
      "End of epoch 58 / 200 \t Time Taken: 138 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 72, time: 0.579, data: 0.001) G_GAN: 0.677 G_L1: 3.090 D_real: 0.624 D_fake: 0.649 \n",
      "(epoch: 59, iters: 172, time: 0.569, data: 0.001) G_GAN: 1.083 G_L1: 3.034 D_real: 0.565 D_fake: 0.757 \n",
      "(epoch: 59, iters: 272, time: 0.576, data: 0.001) G_GAN: 0.858 G_L1: 2.858 D_real: 0.916 D_fake: 0.479 \n",
      "End of epoch 59 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 6, time: 1.070, data: 0.001) G_GAN: 1.010 G_L1: 3.054 D_real: 1.082 D_fake: 0.328 \n",
      "(epoch: 60, iters: 106, time: 0.574, data: 0.000) G_GAN: 0.888 G_L1: 1.853 D_real: 0.668 D_fake: 0.553 \n",
      "(epoch: 60, iters: 206, time: 0.573, data: 0.001) G_GAN: 0.705 G_L1: 1.836 D_real: 0.737 D_fake: 0.780 \n",
      "(epoch: 60, iters: 306, time: 0.576, data: 0.001) G_GAN: 0.807 G_L1: 1.960 D_real: 0.602 D_fake: 0.751 \n",
      "saving the model at the end of epoch 60, iters 21960\n",
      "End of epoch 60 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 40, time: 1.081, data: 0.001) G_GAN: 0.744 G_L1: 3.047 D_real: 0.691 D_fake: 0.597 \n",
      "(epoch: 61, iters: 140, time: 0.572, data: 0.001) G_GAN: 0.824 G_L1: 3.278 D_real: 0.412 D_fake: 0.915 \n",
      "(epoch: 61, iters: 240, time: 0.576, data: 0.001) G_GAN: 0.612 G_L1: 1.851 D_real: 0.877 D_fake: 0.584 \n",
      "(epoch: 61, iters: 340, time: 0.572, data: 0.001) G_GAN: 0.774 G_L1: 3.743 D_real: 0.621 D_fake: 0.581 \n",
      "End of epoch 61 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 74, time: 1.088, data: 0.001) G_GAN: 0.849 G_L1: 3.519 D_real: 0.790 D_fake: 0.534 \n",
      "(epoch: 62, iters: 174, time: 0.574, data: 0.001) G_GAN: 1.106 G_L1: 2.608 D_real: 0.440 D_fake: 0.776 \n",
      "(epoch: 62, iters: 274, time: 0.572, data: 0.001) G_GAN: 0.678 G_L1: 2.527 D_real: 0.634 D_fake: 0.538 \n",
      "End of epoch 62 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 8, time: 0.575, data: 0.001) G_GAN: 0.895 G_L1: 2.671 D_real: 0.475 D_fake: 0.789 \n",
      "(epoch: 63, iters: 108, time: 1.085, data: 0.001) G_GAN: 0.845 G_L1: 3.240 D_real: 0.486 D_fake: 0.759 \n",
      "(epoch: 63, iters: 208, time: 0.572, data: 0.002) G_GAN: 1.021 G_L1: 4.713 D_real: 0.371 D_fake: 1.115 \n",
      "(epoch: 63, iters: 308, time: 0.574, data: 0.001) G_GAN: 0.470 G_L1: 2.773 D_real: 1.251 D_fake: 0.259 \n",
      "End of epoch 63 / 200 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 42, time: 0.580, data: 0.001) G_GAN: 0.736 G_L1: 1.784 D_real: 0.674 D_fake: 0.630 \n",
      "(epoch: 64, iters: 142, time: 1.112, data: 0.001) G_GAN: 0.713 G_L1: 1.032 D_real: 0.882 D_fake: 0.426 \n",
      "(epoch: 64, iters: 242, time: 0.577, data: 0.001) G_GAN: 0.837 G_L1: 3.922 D_real: 0.596 D_fake: 0.820 \n",
      "(epoch: 64, iters: 342, time: 0.577, data: 0.001) G_GAN: 0.793 G_L1: 3.353 D_real: 0.774 D_fake: 0.370 \n",
      "End of epoch 64 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 76, time: 0.574, data: 0.001) G_GAN: 0.905 G_L1: 3.303 D_real: 0.500 D_fake: 0.832 \n",
      "(epoch: 65, iters: 176, time: 1.083, data: 0.001) G_GAN: 0.728 G_L1: 2.779 D_real: 1.163 D_fake: 0.321 \n",
      "(epoch: 65, iters: 276, time: 0.572, data: 0.001) G_GAN: 0.818 G_L1: 2.753 D_real: 0.556 D_fake: 0.651 \n",
      "saving the model at the end of epoch 65, iters 23790\n",
      "End of epoch 65 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 10, time: 0.542, data: 0.001) G_GAN: 0.918 G_L1: 2.677 D_real: 0.625 D_fake: 0.548 \n",
      "(epoch: 66, iters: 110, time: 0.543, data: 0.001) G_GAN: 0.729 G_L1: 2.195 D_real: 0.561 D_fake: 0.752 \n",
      "(epoch: 66, iters: 210, time: 1.107, data: 0.001) G_GAN: 0.901 G_L1: 2.537 D_real: 0.550 D_fake: 0.639 \n",
      "(epoch: 66, iters: 310, time: 0.567, data: 0.001) G_GAN: 0.664 G_L1: 0.596 D_real: 0.655 D_fake: 0.784 \n",
      "End of epoch 66 / 200 \t Time Taken: 133 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 44, time: 0.570, data: 0.001) G_GAN: 0.741 G_L1: 2.475 D_real: 0.347 D_fake: 1.222 \n",
      "(epoch: 67, iters: 144, time: 0.576, data: 0.002) G_GAN: 0.636 G_L1: 2.430 D_real: 0.772 D_fake: 0.700 \n",
      "(epoch: 67, iters: 244, time: 1.088, data: 0.001) G_GAN: 0.612 G_L1: 2.075 D_real: 0.913 D_fake: 0.502 \n",
      "(epoch: 67, iters: 344, time: 0.574, data: 0.001) G_GAN: 0.755 G_L1: 0.941 D_real: 0.688 D_fake: 0.684 \n",
      "End of epoch 67 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 78, time: 0.574, data: 0.001) G_GAN: 0.829 G_L1: 3.261 D_real: 0.828 D_fake: 0.520 \n",
      "(epoch: 68, iters: 178, time: 0.575, data: 0.001) G_GAN: 0.826 G_L1: 2.440 D_real: 0.928 D_fake: 0.391 \n",
      "(epoch: 68, iters: 278, time: 1.043, data: 0.001) G_GAN: 0.714 G_L1: 0.021 D_real: 0.652 D_fake: 0.736 \n",
      "End of epoch 68 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 12, time: 0.573, data: 0.002) G_GAN: 0.773 G_L1: 1.801 D_real: 0.740 D_fake: 0.530 \n",
      "(epoch: 69, iters: 112, time: 0.573, data: 0.002) G_GAN: 0.674 G_L1: 2.567 D_real: 0.623 D_fake: 0.749 \n",
      "saving the latest model (epoch 69, total_iters 25000)\n",
      "(epoch: 69, iters: 212, time: 0.574, data: 0.001) G_GAN: 0.853 G_L1: 2.331 D_real: 0.705 D_fake: 0.616 \n",
      "(epoch: 69, iters: 312, time: 1.100, data: 0.001) G_GAN: 0.670 G_L1: 2.015 D_real: 0.783 D_fake: 0.646 \n",
      "End of epoch 69 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 46, time: 0.570, data: 0.001) G_GAN: 0.744 G_L1: 2.527 D_real: 0.834 D_fake: 0.644 \n",
      "(epoch: 70, iters: 146, time: 0.576, data: 0.001) G_GAN: 0.773 G_L1: 0.953 D_real: 0.805 D_fake: 0.560 \n",
      "(epoch: 70, iters: 246, time: 0.574, data: 0.001) G_GAN: 1.003 G_L1: 1.618 D_real: 0.576 D_fake: 0.704 \n",
      "(epoch: 70, iters: 346, time: 1.078, data: 0.001) G_GAN: 0.649 G_L1: 0.025 D_real: 0.639 D_fake: 0.774 \n",
      "saving the model at the end of epoch 70, iters 25620\n",
      "End of epoch 70 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 80, time: 0.573, data: 0.001) G_GAN: 0.987 G_L1: 2.335 D_real: 0.491 D_fake: 0.771 \n",
      "(epoch: 71, iters: 180, time: 0.576, data: 0.001) G_GAN: 0.759 G_L1: 2.493 D_real: 0.596 D_fake: 0.694 \n",
      "(epoch: 71, iters: 280, time: 0.569, data: 0.001) G_GAN: 0.709 G_L1: 1.037 D_real: 1.072 D_fake: 0.465 \n",
      "End of epoch 71 / 200 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 14, time: 1.138, data: 0.001) G_GAN: 0.785 G_L1: 2.134 D_real: 0.928 D_fake: 0.447 \n",
      "(epoch: 72, iters: 114, time: 0.576, data: 0.001) G_GAN: 0.709 G_L1: 1.691 D_real: 0.596 D_fake: 0.802 \n",
      "(epoch: 72, iters: 214, time: 0.572, data: 0.001) G_GAN: 0.823 G_L1: 2.093 D_real: 0.526 D_fake: 0.689 \n",
      "(epoch: 72, iters: 314, time: 0.576, data: 0.001) G_GAN: 0.743 G_L1: 3.029 D_real: 0.653 D_fake: 0.704 \n",
      "End of epoch 72 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 48, time: 1.032, data: 0.001) G_GAN: 0.717 G_L1: 0.022 D_real: 0.707 D_fake: 0.673 \n",
      "(epoch: 73, iters: 148, time: 0.571, data: 0.001) G_GAN: 0.710 G_L1: 3.083 D_real: 0.524 D_fake: 0.743 \n",
      "(epoch: 73, iters: 248, time: 0.573, data: 0.001) G_GAN: 0.712 G_L1: 1.976 D_real: 0.714 D_fake: 0.738 \n",
      "(epoch: 73, iters: 348, time: 0.574, data: 0.002) G_GAN: 0.746 G_L1: 2.624 D_real: 0.864 D_fake: 0.593 \n",
      "End of epoch 73 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 82, time: 1.114, data: 0.001) G_GAN: 0.850 G_L1: 2.186 D_real: 0.558 D_fake: 0.876 \n",
      "(epoch: 74, iters: 182, time: 0.574, data: 0.001) G_GAN: 1.184 G_L1: 3.960 D_real: 0.372 D_fake: 0.947 \n",
      "(epoch: 74, iters: 282, time: 0.594, data: 0.001) G_GAN: 0.764 G_L1: 2.407 D_real: 0.936 D_fake: 0.582 \n",
      "End of epoch 74 / 200 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 16, time: 0.538, data: 0.001) G_GAN: 1.124 G_L1: 3.422 D_real: 0.261 D_fake: 1.469 \n",
      "(epoch: 75, iters: 116, time: 1.166, data: 0.001) G_GAN: 0.920 G_L1: 1.620 D_real: 0.612 D_fake: 0.783 \n",
      "(epoch: 75, iters: 216, time: 0.571, data: 0.001) G_GAN: 0.536 G_L1: 1.834 D_real: 1.057 D_fake: 0.465 \n",
      "(epoch: 75, iters: 316, time: 0.571, data: 0.001) G_GAN: 0.883 G_L1: 3.476 D_real: 0.606 D_fake: 0.728 \n",
      "saving the model at the end of epoch 75, iters 27450\n",
      "End of epoch 75 / 200 \t Time Taken: 135 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 50, time: 0.570, data: 0.001) G_GAN: 0.763 G_L1: 2.791 D_real: 0.831 D_fake: 0.344 \n",
      "(epoch: 76, iters: 150, time: 1.188, data: 0.001) G_GAN: 0.574 G_L1: 2.021 D_real: 0.661 D_fake: 0.360 \n",
      "(epoch: 76, iters: 250, time: 0.572, data: 0.001) G_GAN: 0.613 G_L1: 2.950 D_real: 0.819 D_fake: 0.448 \n",
      "(epoch: 76, iters: 350, time: 0.575, data: 0.001) G_GAN: 0.830 G_L1: 2.931 D_real: 0.419 D_fake: 0.861 \n",
      "End of epoch 76 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 84, time: 0.569, data: 0.001) G_GAN: 0.702 G_L1: 2.732 D_real: 0.630 D_fake: 0.585 \n",
      "(epoch: 77, iters: 184, time: 1.120, data: 0.001) G_GAN: 0.816 G_L1: 2.217 D_real: 0.664 D_fake: 0.681 \n",
      "(epoch: 77, iters: 284, time: 0.576, data: 0.001) G_GAN: 0.769 G_L1: 1.508 D_real: 0.575 D_fake: 0.773 \n",
      "End of epoch 77 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 18, time: 0.570, data: 0.001) G_GAN: 0.953 G_L1: 1.545 D_real: 0.482 D_fake: 0.778 \n",
      "(epoch: 78, iters: 118, time: 0.573, data: 0.001) G_GAN: 0.993 G_L1: 3.294 D_real: 0.238 D_fake: 1.231 \n",
      "(epoch: 78, iters: 218, time: 1.155, data: 0.001) G_GAN: 0.668 G_L1: 2.362 D_real: 0.574 D_fake: 0.575 \n",
      "(epoch: 78, iters: 318, time: 0.575, data: 0.001) G_GAN: 0.807 G_L1: 3.373 D_real: 0.703 D_fake: 0.432 \n",
      "End of epoch 78 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 52, time: 0.573, data: 0.001) G_GAN: 0.713 G_L1: 1.765 D_real: 0.554 D_fake: 0.804 \n",
      "(epoch: 79, iters: 152, time: 0.570, data: 0.001) G_GAN: 0.971 G_L1: 3.053 D_real: 0.446 D_fake: 0.635 \n",
      "(epoch: 79, iters: 252, time: 1.148, data: 0.001) G_GAN: 0.620 G_L1: 2.704 D_real: 1.016 D_fake: 0.358 \n",
      "(epoch: 79, iters: 352, time: 0.572, data: 0.002) G_GAN: 0.697 G_L1: 2.256 D_real: 0.834 D_fake: 0.522 \n",
      "End of epoch 79 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 86, time: 0.569, data: 0.001) G_GAN: 0.911 G_L1: 2.211 D_real: 0.707 D_fake: 0.549 \n",
      "(epoch: 80, iters: 186, time: 0.576, data: 0.001) G_GAN: 0.877 G_L1: 2.465 D_real: 0.318 D_fake: 1.126 \n",
      "(epoch: 80, iters: 286, time: 1.132, data: 0.001) G_GAN: 0.829 G_L1: 0.664 D_real: 0.588 D_fake: 0.727 \n",
      "saving the model at the end of epoch 80, iters 29280\n",
      "End of epoch 80 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 20, time: 0.574, data: 0.001) G_GAN: 0.831 G_L1: 2.106 D_real: 0.806 D_fake: 0.503 \n",
      "(epoch: 81, iters: 120, time: 0.570, data: 0.001) G_GAN: 0.660 G_L1: 1.975 D_real: 0.821 D_fake: 0.514 \n",
      "(epoch: 81, iters: 220, time: 0.574, data: 0.001) G_GAN: 0.746 G_L1: 2.899 D_real: 0.632 D_fake: 0.674 \n",
      "(epoch: 81, iters: 320, time: 1.167, data: 0.001) G_GAN: 0.909 G_L1: 2.633 D_real: 0.585 D_fake: 0.595 \n",
      "End of epoch 81 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 54, time: 0.572, data: 0.001) G_GAN: 0.860 G_L1: 3.561 D_real: 0.475 D_fake: 0.714 \n",
      "(epoch: 82, iters: 154, time: 0.572, data: 0.001) G_GAN: 0.779 G_L1: 2.768 D_real: 0.663 D_fake: 0.662 \n",
      "(epoch: 82, iters: 254, time: 0.573, data: 0.001) G_GAN: 0.734 G_L1: 1.994 D_real: 0.822 D_fake: 0.528 \n",
      "(epoch: 82, iters: 354, time: 1.183, data: 0.001) G_GAN: 0.611 G_L1: 2.552 D_real: 0.880 D_fake: 0.411 \n",
      "saving the latest model (epoch 82, total_iters 30000)\n",
      "End of epoch 82 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 88, time: 0.569, data: 0.001) G_GAN: 0.718 G_L1: 2.584 D_real: 0.917 D_fake: 0.532 \n",
      "(epoch: 83, iters: 188, time: 0.573, data: 0.001) G_GAN: 0.878 G_L1: 2.995 D_real: 0.567 D_fake: 0.688 \n",
      "(epoch: 83, iters: 288, time: 0.571, data: 0.002) G_GAN: 0.779 G_L1: 2.302 D_real: 0.590 D_fake: 0.698 \n",
      "End of epoch 83 / 200 \t Time Taken: 136 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 22, time: 1.126, data: 0.002) G_GAN: 0.640 G_L1: 2.246 D_real: 0.913 D_fake: 0.575 \n",
      "(epoch: 84, iters: 122, time: 0.574, data: 0.001) G_GAN: 0.823 G_L1: 2.676 D_real: 0.700 D_fake: 0.551 \n",
      "(epoch: 84, iters: 222, time: 0.576, data: 0.001) G_GAN: 1.011 G_L1: 2.512 D_real: 0.518 D_fake: 0.603 \n",
      "(epoch: 84, iters: 322, time: 0.573, data: 0.001) G_GAN: 1.017 G_L1: 3.625 D_real: 0.588 D_fake: 0.533 \n",
      "End of epoch 84 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 56, time: 1.170, data: 0.001) G_GAN: 0.835 G_L1: 3.415 D_real: 0.699 D_fake: 0.516 \n",
      "(epoch: 85, iters: 156, time: 0.574, data: 0.001) G_GAN: 1.309 G_L1: 2.262 D_real: 0.290 D_fake: 1.159 \n",
      "(epoch: 85, iters: 256, time: 0.571, data: 0.001) G_GAN: 0.693 G_L1: 2.026 D_real: 0.610 D_fake: 0.723 \n",
      "(epoch: 85, iters: 356, time: 0.574, data: 0.001) G_GAN: 0.648 G_L1: 2.904 D_real: 0.565 D_fake: 0.622 \n",
      "saving the model at the end of epoch 85, iters 31110\n",
      "End of epoch 85 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 90, time: 1.238, data: 0.001) G_GAN: 0.901 G_L1: 3.250 D_real: 0.428 D_fake: 0.814 \n",
      "(epoch: 86, iters: 190, time: 0.571, data: 0.001) G_GAN: 0.853 G_L1: 2.128 D_real: 0.531 D_fake: 0.805 \n",
      "(epoch: 86, iters: 290, time: 0.573, data: 0.001) G_GAN: 0.680 G_L1: 2.232 D_real: 0.741 D_fake: 0.589 \n",
      "End of epoch 86 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 24, time: 0.570, data: 0.001) G_GAN: 0.743 G_L1: 1.486 D_real: 0.814 D_fake: 0.562 \n",
      "(epoch: 87, iters: 124, time: 1.183, data: 0.001) G_GAN: 0.744 G_L1: 1.482 D_real: 0.792 D_fake: 0.605 \n",
      "(epoch: 87, iters: 224, time: 0.569, data: 0.001) G_GAN: 0.812 G_L1: 1.946 D_real: 0.404 D_fake: 1.000 \n",
      "(epoch: 87, iters: 324, time: 0.569, data: 0.001) G_GAN: 0.714 G_L1: 0.025 D_real: 0.763 D_fake: 0.631 \n",
      "End of epoch 87 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 58, time: 0.576, data: 0.001) G_GAN: 0.715 G_L1: 0.723 D_real: 0.599 D_fake: 0.733 \n",
      "(epoch: 88, iters: 158, time: 1.152, data: 0.001) G_GAN: 0.873 G_L1: 1.626 D_real: 0.486 D_fake: 0.877 \n",
      "(epoch: 88, iters: 258, time: 0.570, data: 0.001) G_GAN: 0.800 G_L1: 1.416 D_real: 1.211 D_fake: 0.369 \n",
      "(epoch: 88, iters: 358, time: 0.575, data: 0.001) G_GAN: 0.806 G_L1: 1.861 D_real: 0.586 D_fake: 0.665 \n",
      "End of epoch 88 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 92, time: 0.570, data: 0.002) G_GAN: 0.653 G_L1: 1.727 D_real: 0.862 D_fake: 0.495 \n",
      "(epoch: 89, iters: 192, time: 1.178, data: 0.001) G_GAN: 0.681 G_L1: 1.549 D_real: 0.831 D_fake: 0.599 \n",
      "(epoch: 89, iters: 292, time: 0.572, data: 0.001) G_GAN: 0.731 G_L1: 1.330 D_real: 0.742 D_fake: 0.628 \n",
      "End of epoch 89 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 26, time: 0.571, data: 0.001) G_GAN: 0.854 G_L1: 3.453 D_real: 0.682 D_fake: 0.396 \n",
      "(epoch: 90, iters: 126, time: 0.574, data: 0.001) G_GAN: 0.713 G_L1: 2.473 D_real: 0.807 D_fake: 0.570 \n",
      "(epoch: 90, iters: 226, time: 1.182, data: 0.001) G_GAN: 0.718 G_L1: 1.803 D_real: 0.836 D_fake: 0.534 \n",
      "(epoch: 90, iters: 326, time: 0.572, data: 0.001) G_GAN: 0.721 G_L1: 1.712 D_real: 0.594 D_fake: 0.720 \n",
      "saving the model at the end of epoch 90, iters 32940\n",
      "End of epoch 90 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 60, time: 0.576, data: 0.001) G_GAN: 0.707 G_L1: 2.090 D_real: 0.807 D_fake: 0.608 \n",
      "(epoch: 91, iters: 160, time: 0.572, data: 0.001) G_GAN: 0.721 G_L1: 2.760 D_real: 0.789 D_fake: 0.498 \n",
      "(epoch: 91, iters: 260, time: 1.199, data: 0.001) G_GAN: 0.947 G_L1: 3.578 D_real: 0.653 D_fake: 0.513 \n",
      "(epoch: 91, iters: 360, time: 0.575, data: 0.001) G_GAN: 0.527 G_L1: 2.034 D_real: 0.933 D_fake: 0.431 \n",
      "End of epoch 91 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 94, time: 0.571, data: 0.001) G_GAN: 0.881 G_L1: 2.062 D_real: 0.967 D_fake: 0.421 \n",
      "(epoch: 92, iters: 194, time: 0.574, data: 0.001) G_GAN: 0.878 G_L1: 1.825 D_real: 0.589 D_fake: 0.800 \n",
      "(epoch: 92, iters: 294, time: 1.212, data: 0.001) G_GAN: 1.064 G_L1: 2.312 D_real: 0.533 D_fake: 0.804 \n",
      "End of epoch 92 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 28, time: 0.570, data: 0.001) G_GAN: 0.839 G_L1: 1.723 D_real: 0.513 D_fake: 0.897 \n",
      "(epoch: 93, iters: 128, time: 0.571, data: 0.001) G_GAN: 0.825 G_L1: 2.114 D_real: 0.720 D_fake: 0.622 \n",
      "(epoch: 93, iters: 228, time: 0.572, data: 0.001) G_GAN: 0.713 G_L1: 2.257 D_real: 1.042 D_fake: 0.501 \n",
      "(epoch: 93, iters: 328, time: 1.216, data: 0.001) G_GAN: 0.809 G_L1: 2.356 D_real: 0.599 D_fake: 0.761 \n",
      "End of epoch 93 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 62, time: 0.573, data: 0.001) G_GAN: 0.790 G_L1: 2.435 D_real: 0.661 D_fake: 0.774 \n",
      "(epoch: 94, iters: 162, time: 0.573, data: 0.001) G_GAN: 0.837 G_L1: 2.687 D_real: 0.583 D_fake: 0.762 \n",
      "(epoch: 94, iters: 262, time: 0.571, data: 0.001) G_GAN: 0.658 G_L1: 2.207 D_real: 0.801 D_fake: 0.514 \n",
      "(epoch: 94, iters: 362, time: 1.261, data: 0.001) G_GAN: 0.681 G_L1: 2.475 D_real: 0.797 D_fake: 0.568 \n",
      "End of epoch 94 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 96, time: 0.573, data: 0.001) G_GAN: 0.743 G_L1: 1.893 D_real: 0.709 D_fake: 0.697 \n",
      "(epoch: 95, iters: 196, time: 0.572, data: 0.001) G_GAN: 0.817 G_L1: 2.644 D_real: 0.597 D_fake: 0.692 \n",
      "(epoch: 95, iters: 296, time: 0.577, data: 0.001) G_GAN: 0.837 G_L1: 0.784 D_real: 0.858 D_fake: 0.530 \n",
      "saving the model at the end of epoch 95, iters 34770\n",
      "End of epoch 95 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 30, time: 1.252, data: 0.001) G_GAN: 0.848 G_L1: 2.291 D_real: 0.545 D_fake: 0.750 \n",
      "(epoch: 96, iters: 130, time: 0.574, data: 0.002) G_GAN: 0.851 G_L1: 2.105 D_real: 0.444 D_fake: 0.973 \n",
      "(epoch: 96, iters: 230, time: 0.577, data: 0.001) G_GAN: 0.605 G_L1: 2.581 D_real: 0.660 D_fake: 0.661 \n",
      "saving the latest model (epoch 96, total_iters 35000)\n",
      "(epoch: 96, iters: 330, time: 0.571, data: 0.001) G_GAN: 0.756 G_L1: 1.609 D_real: 0.686 D_fake: 0.630 \n",
      "End of epoch 96 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 64, time: 1.265, data: 0.001) G_GAN: 0.696 G_L1: 2.574 D_real: 0.835 D_fake: 0.458 \n",
      "(epoch: 97, iters: 164, time: 0.572, data: 0.001) G_GAN: 0.720 G_L1: 0.029 D_real: 0.678 D_fake: 0.713 \n",
      "(epoch: 97, iters: 264, time: 0.573, data: 0.001) G_GAN: 1.020 G_L1: 2.226 D_real: 0.339 D_fake: 1.005 \n",
      "(epoch: 97, iters: 364, time: 0.575, data: 0.002) G_GAN: 0.900 G_L1: 2.346 D_real: 2.102 D_fake: 3.360 \n",
      "End of epoch 97 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 98, time: 1.217, data: 0.001) G_GAN: 0.790 G_L1: 2.213 D_real: 0.544 D_fake: 0.746 \n",
      "(epoch: 98, iters: 198, time: 0.574, data: 0.001) G_GAN: 0.771 G_L1: 1.548 D_real: 0.738 D_fake: 0.634 \n",
      "(epoch: 98, iters: 298, time: 0.572, data: 0.001) G_GAN: 0.775 G_L1: 1.627 D_real: 0.980 D_fake: 0.492 \n",
      "End of epoch 98 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 32, time: 0.571, data: 0.001) G_GAN: 0.796 G_L1: 1.310 D_real: 0.664 D_fake: 0.620 \n",
      "(epoch: 99, iters: 132, time: 1.249, data: 0.001) G_GAN: 0.988 G_L1: 2.137 D_real: 0.580 D_fake: 0.669 \n",
      "(epoch: 99, iters: 232, time: 0.571, data: 0.001) G_GAN: 1.255 G_L1: 2.135 D_real: 0.391 D_fake: 0.968 \n",
      "(epoch: 99, iters: 332, time: 0.574, data: 0.001) G_GAN: 0.757 G_L1: 2.597 D_real: 0.683 D_fake: 0.581 \n",
      "End of epoch 99 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 66, time: 0.570, data: 0.002) G_GAN: 1.059 G_L1: 1.934 D_real: 0.700 D_fake: 0.417 \n",
      "(epoch: 100, iters: 166, time: 1.177, data: 0.002) G_GAN: 0.551 G_L1: 2.212 D_real: 0.867 D_fake: 0.502 \n",
      "(epoch: 100, iters: 266, time: 0.574, data: 0.001) G_GAN: 0.524 G_L1: 1.831 D_real: 0.949 D_fake: 0.386 \n",
      "(epoch: 100, iters: 366, time: 0.577, data: 0.001) G_GAN: 0.842 G_L1: 3.913 D_real: 0.620 D_fake: 0.535 \n",
      "saving the model at the end of epoch 100, iters 36600\n",
      "End of epoch 100 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.575, data: 0.083) G_GAN: 1.007 G_L1: 2.197 D_real: 0.484 D_fake: 0.815 \n",
      "(epoch: 101, iters: 200, time: 1.241, data: 0.001) G_GAN: 0.701 G_L1: 2.322 D_real: 0.717 D_fake: 0.632 \n",
      "(epoch: 101, iters: 300, time: 0.574, data: 0.001) G_GAN: 0.739 G_L1: 2.093 D_real: 0.900 D_fake: 0.400 \n",
      "End of epoch 101 / 200 \t Time Taken: 137 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 34, time: 0.570, data: 0.001) G_GAN: 0.770 G_L1: 2.181 D_real: 0.665 D_fake: 0.604 \n",
      "(epoch: 102, iters: 134, time: 0.578, data: 0.001) G_GAN: 0.808 G_L1: 1.888 D_real: 0.724 D_fake: 0.617 \n",
      "(epoch: 102, iters: 234, time: 1.283, data: 0.001) G_GAN: 0.814 G_L1: 2.826 D_real: 0.653 D_fake: 0.509 \n",
      "(epoch: 102, iters: 334, time: 0.539, data: 0.001) G_GAN: 0.858 G_L1: 2.605 D_real: 0.709 D_fake: 0.598 \n",
      "End of epoch 102 / 200 \t Time Taken: 136 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 68, time: 0.543, data: 0.001) G_GAN: 0.661 G_L1: 0.814 D_real: 0.801 D_fake: 0.607 \n",
      "(epoch: 103, iters: 168, time: 0.541, data: 0.001) G_GAN: 0.915 G_L1: 2.021 D_real: 0.413 D_fake: 0.996 \n",
      "(epoch: 103, iters: 268, time: 1.162, data: 0.001) G_GAN: 0.985 G_L1: 2.112 D_real: 0.375 D_fake: 0.918 \n",
      "End of epoch 103 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 2, time: 0.540, data: 0.001) G_GAN: 0.778 G_L1: 2.264 D_real: 0.479 D_fake: 0.784 \n",
      "(epoch: 104, iters: 102, time: 0.537, data: 0.000) G_GAN: 0.819 G_L1: 1.959 D_real: 0.589 D_fake: 0.737 \n",
      "(epoch: 104, iters: 202, time: 0.538, data: 0.002) G_GAN: 0.693 G_L1: 2.437 D_real: 0.721 D_fake: 0.615 \n",
      "(epoch: 104, iters: 302, time: 1.158, data: 0.001) G_GAN: 0.858 G_L1: 1.798 D_real: 0.504 D_fake: 0.848 \n",
      "End of epoch 104 / 200 \t Time Taken: 154 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 36, time: 0.538, data: 0.002) G_GAN: 0.912 G_L1: 2.697 D_real: 0.503 D_fake: 0.774 \n",
      "(epoch: 105, iters: 136, time: 0.538, data: 0.001) G_GAN: 0.853 G_L1: 2.570 D_real: 0.438 D_fake: 0.973 \n",
      "(epoch: 105, iters: 236, time: 0.538, data: 0.001) G_GAN: 0.860 G_L1: 2.114 D_real: 0.697 D_fake: 0.664 \n",
      "(epoch: 105, iters: 336, time: 1.092, data: 0.001) G_GAN: 0.810 G_L1: 0.031 D_real: 0.786 D_fake: 0.590 \n",
      "saving the model at the end of epoch 105, iters 38430\n",
      "End of epoch 105 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 70, time: 0.537, data: 0.001) G_GAN: 0.100 G_L1: 2.758 D_real: 1.107 D_fake: 0.218 \n",
      "(epoch: 106, iters: 170, time: 0.539, data: 0.001) G_GAN: 1.021 G_L1: 1.977 D_real: 0.427 D_fake: 0.883 \n",
      "(epoch: 106, iters: 270, time: 0.540, data: 0.002) G_GAN: 0.577 G_L1: 1.770 D_real: 0.664 D_fake: 0.679 \n",
      "End of epoch 106 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 4, time: 1.205, data: 0.001) G_GAN: 0.641 G_L1: 1.686 D_real: 0.769 D_fake: 0.540 \n",
      "(epoch: 107, iters: 104, time: 0.538, data: 0.003) G_GAN: 0.793 G_L1: 1.891 D_real: 0.661 D_fake: 0.605 \n",
      "(epoch: 107, iters: 204, time: 0.539, data: 0.001) G_GAN: 0.755 G_L1: 1.774 D_real: 0.799 D_fake: 0.519 \n",
      "(epoch: 107, iters: 304, time: 0.539, data: 0.001) G_GAN: 0.741 G_L1: 1.883 D_real: 0.693 D_fake: 0.541 \n",
      "End of epoch 107 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 38, time: 1.136, data: 0.001) G_GAN: 0.730 G_L1: 1.694 D_real: 0.978 D_fake: 0.444 \n",
      "(epoch: 108, iters: 138, time: 0.538, data: 0.001) G_GAN: 0.676 G_L1: 1.747 D_real: 1.186 D_fake: 0.313 \n",
      "(epoch: 108, iters: 238, time: 0.539, data: 0.001) G_GAN: 0.715 G_L1: 1.936 D_real: 0.593 D_fake: 0.780 \n",
      "(epoch: 108, iters: 338, time: 0.541, data: 0.001) G_GAN: 0.880 G_L1: 2.077 D_real: 0.584 D_fake: 0.700 \n",
      "End of epoch 108 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 72, time: 1.151, data: 0.001) G_GAN: 0.630 G_L1: 1.395 D_real: 0.698 D_fake: 0.671 \n",
      "(epoch: 109, iters: 172, time: 0.541, data: 0.001) G_GAN: 0.605 G_L1: 3.169 D_real: 0.679 D_fake: 0.536 \n",
      "(epoch: 109, iters: 272, time: 0.541, data: 0.001) G_GAN: 0.921 G_L1: 1.886 D_real: 0.543 D_fake: 0.776 \n",
      "End of epoch 109 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 6, time: 0.540, data: 0.001) G_GAN: 0.704 G_L1: 2.313 D_real: 0.746 D_fake: 0.506 \n",
      "(epoch: 110, iters: 106, time: 1.246, data: 0.000) G_GAN: 0.584 G_L1: 2.027 D_real: 0.844 D_fake: 0.524 \n",
      "saving the latest model (epoch 110, total_iters 40000)\n",
      "(epoch: 110, iters: 206, time: 0.538, data: 0.001) G_GAN: 0.742 G_L1: 2.167 D_real: 0.509 D_fake: 0.773 \n",
      "(epoch: 110, iters: 306, time: 0.540, data: 0.002) G_GAN: 0.755 G_L1: 2.118 D_real: 0.699 D_fake: 0.629 \n",
      "saving the model at the end of epoch 110, iters 40260\n",
      "End of epoch 110 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 40, time: 0.540, data: 0.001) G_GAN: 0.615 G_L1: 2.171 D_real: 0.873 D_fake: 0.454 \n",
      "(epoch: 111, iters: 140, time: 1.217, data: 0.001) G_GAN: 0.951 G_L1: 1.938 D_real: 0.551 D_fake: 0.665 \n",
      "(epoch: 111, iters: 240, time: 0.538, data: 0.002) G_GAN: 0.710 G_L1: 1.587 D_real: 0.778 D_fake: 0.634 \n",
      "(epoch: 111, iters: 340, time: 0.540, data: 0.001) G_GAN: 0.739 G_L1: 1.996 D_real: 0.581 D_fake: 0.719 \n",
      "End of epoch 111 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 74, time: 0.538, data: 0.001) G_GAN: 0.865 G_L1: 2.500 D_real: 0.555 D_fake: 0.610 \n",
      "(epoch: 112, iters: 174, time: 1.172, data: 0.001) G_GAN: 0.816 G_L1: 1.678 D_real: 0.679 D_fake: 0.561 \n",
      "(epoch: 112, iters: 274, time: 0.539, data: 0.001) G_GAN: 0.726 G_L1: 1.854 D_real: 0.856 D_fake: 0.549 \n",
      "End of epoch 112 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 8, time: 0.540, data: 0.002) G_GAN: 0.730 G_L1: 0.850 D_real: 0.712 D_fake: 0.629 \n",
      "(epoch: 113, iters: 108, time: 0.540, data: 0.001) G_GAN: 0.937 G_L1: 2.111 D_real: 0.377 D_fake: 0.886 \n",
      "(epoch: 113, iters: 208, time: 1.182, data: 0.002) G_GAN: 0.786 G_L1: 2.053 D_real: 0.647 D_fake: 0.544 \n",
      "(epoch: 113, iters: 308, time: 0.540, data: 0.001) G_GAN: 0.786 G_L1: 2.091 D_real: 0.646 D_fake: 0.612 \n",
      "End of epoch 113 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 42, time: 0.541, data: 0.002) G_GAN: 1.307 G_L1: 1.838 D_real: 0.443 D_fake: 0.836 \n",
      "(epoch: 114, iters: 142, time: 0.540, data: 0.001) G_GAN: 0.781 G_L1: 1.887 D_real: 0.634 D_fake: 0.629 \n",
      "(epoch: 114, iters: 242, time: 1.219, data: 0.001) G_GAN: 0.999 G_L1: 2.470 D_real: 0.406 D_fake: 0.891 \n",
      "(epoch: 114, iters: 342, time: 0.540, data: 0.001) G_GAN: 0.640 G_L1: 1.887 D_real: 0.667 D_fake: 0.602 \n",
      "End of epoch 114 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 76, time: 0.540, data: 0.001) G_GAN: 0.877 G_L1: 2.770 D_real: 0.826 D_fake: 0.503 \n",
      "(epoch: 115, iters: 176, time: 0.542, data: 0.001) G_GAN: 0.728 G_L1: 2.207 D_real: 0.693 D_fake: 0.528 \n",
      "(epoch: 115, iters: 276, time: 1.203, data: 0.002) G_GAN: 1.550 G_L1: 2.351 D_real: 0.399 D_fake: 0.753 \n",
      "saving the model at the end of epoch 115, iters 42090\n",
      "End of epoch 115 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 10, time: 0.541, data: 0.002) G_GAN: 0.755 G_L1: 1.212 D_real: 0.739 D_fake: 0.546 \n",
      "(epoch: 116, iters: 110, time: 0.541, data: 0.001) G_GAN: 0.991 G_L1: 2.468 D_real: 0.431 D_fake: 0.841 \n",
      "(epoch: 116, iters: 210, time: 0.539, data: 0.001) G_GAN: 0.869 G_L1: 2.110 D_real: 0.737 D_fake: 0.552 \n",
      "(epoch: 116, iters: 310, time: 1.235, data: 0.002) G_GAN: 0.610 G_L1: 2.926 D_real: 0.660 D_fake: 0.550 \n",
      "End of epoch 116 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 44, time: 0.541, data: 0.001) G_GAN: 0.765 G_L1: 1.665 D_real: 0.659 D_fake: 0.580 \n",
      "(epoch: 117, iters: 144, time: 0.541, data: 0.001) G_GAN: 0.626 G_L1: 1.820 D_real: 0.910 D_fake: 0.506 \n",
      "(epoch: 117, iters: 244, time: 0.541, data: 0.001) G_GAN: 0.873 G_L1: 2.171 D_real: 0.720 D_fake: 0.557 \n",
      "(epoch: 117, iters: 344, time: 1.204, data: 0.002) G_GAN: 0.772 G_L1: 1.193 D_real: 0.652 D_fake: 0.611 \n",
      "End of epoch 117 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 78, time: 0.540, data: 0.001) G_GAN: 0.709 G_L1: 1.749 D_real: 0.930 D_fake: 0.395 \n",
      "(epoch: 118, iters: 178, time: 0.539, data: 0.001) G_GAN: 0.842 G_L1: 1.923 D_real: 0.576 D_fake: 0.685 \n",
      "(epoch: 118, iters: 278, time: 0.539, data: 0.002) G_GAN: 0.840 G_L1: 1.444 D_real: 0.917 D_fake: 0.426 \n",
      "End of epoch 118 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 12, time: 1.218, data: 0.001) G_GAN: 0.788 G_L1: 1.831 D_real: 0.827 D_fake: 0.413 \n",
      "(epoch: 119, iters: 112, time: 0.539, data: 0.001) G_GAN: 0.901 G_L1: 2.068 D_real: 0.707 D_fake: 0.553 \n",
      "(epoch: 119, iters: 212, time: 0.540, data: 0.001) G_GAN: 0.773 G_L1: 2.558 D_real: 0.756 D_fake: 0.509 \n",
      "(epoch: 119, iters: 312, time: 0.541, data: 0.002) G_GAN: 0.703 G_L1: 1.628 D_real: 0.851 D_fake: 0.429 \n",
      "End of epoch 119 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 46, time: 1.255, data: 0.002) G_GAN: 1.156 G_L1: 3.401 D_real: 0.406 D_fake: 0.873 \n",
      "(epoch: 120, iters: 146, time: 0.541, data: 0.001) G_GAN: 0.678 G_L1: 0.030 D_real: 0.806 D_fake: 0.579 \n",
      "(epoch: 120, iters: 246, time: 0.541, data: 0.001) G_GAN: 1.170 G_L1: 1.832 D_real: 0.412 D_fake: 0.734 \n",
      "(epoch: 120, iters: 346, time: 0.539, data: 0.001) G_GAN: 1.280 G_L1: 1.725 D_real: 0.284 D_fake: 1.080 \n",
      "saving the model at the end of epoch 120, iters 43920\n",
      "End of epoch 120 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 80, time: 1.248, data: 0.001) G_GAN: 0.838 G_L1: 2.026 D_real: 0.792 D_fake: 0.458 \n",
      "(epoch: 121, iters: 180, time: 0.539, data: 0.001) G_GAN: 0.865 G_L1: 1.741 D_real: 0.797 D_fake: 0.535 \n",
      "(epoch: 121, iters: 280, time: 0.540, data: 0.002) G_GAN: 0.398 G_L1: 2.838 D_real: 1.120 D_fake: 0.460 \n",
      "End of epoch 121 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 14, time: 0.540, data: 0.002) G_GAN: 0.497 G_L1: 1.631 D_real: 1.033 D_fake: 0.428 \n",
      "(epoch: 122, iters: 114, time: 1.248, data: 0.002) G_GAN: 0.539 G_L1: 1.940 D_real: 0.721 D_fake: 0.529 \n",
      "(epoch: 122, iters: 214, time: 0.540, data: 0.001) G_GAN: 1.130 G_L1: 3.149 D_real: 0.326 D_fake: 0.899 \n",
      "(epoch: 122, iters: 314, time: 0.540, data: 0.002) G_GAN: 1.374 G_L1: 2.511 D_real: 0.328 D_fake: 0.786 \n",
      "End of epoch 122 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 48, time: 0.540, data: 0.002) G_GAN: 0.849 G_L1: 1.605 D_real: 0.793 D_fake: 0.437 \n",
      "(epoch: 123, iters: 148, time: 1.299, data: 0.002) G_GAN: 0.786 G_L1: 2.184 D_real: 0.605 D_fake: 0.628 \n",
      "(epoch: 123, iters: 248, time: 0.540, data: 0.001) G_GAN: 0.494 G_L1: 1.843 D_real: 0.952 D_fake: 0.552 \n",
      "(epoch: 123, iters: 348, time: 0.541, data: 0.002) G_GAN: 0.883 G_L1: 3.075 D_real: 0.433 D_fake: 0.882 \n",
      "saving the latest model (epoch 123, total_iters 45000)\n",
      "End of epoch 123 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 82, time: 0.542, data: 0.001) G_GAN: 0.762 G_L1: 2.426 D_real: 0.714 D_fake: 0.565 \n",
      "(epoch: 124, iters: 182, time: 1.250, data: 0.001) G_GAN: 0.896 G_L1: 1.726 D_real: 0.967 D_fake: 0.551 \n",
      "(epoch: 124, iters: 282, time: 0.541, data: 0.001) G_GAN: 0.904 G_L1: 1.853 D_real: 0.548 D_fake: 0.657 \n",
      "End of epoch 124 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 16, time: 0.542, data: 0.002) G_GAN: 0.933 G_L1: 2.789 D_real: 0.468 D_fake: 0.641 \n",
      "(epoch: 125, iters: 116, time: 0.540, data: 0.001) G_GAN: 0.807 G_L1: 0.021 D_real: 0.731 D_fake: 0.711 \n",
      "(epoch: 125, iters: 216, time: 1.248, data: 0.001) G_GAN: 1.187 G_L1: 2.445 D_real: 0.388 D_fake: 0.913 \n",
      "(epoch: 125, iters: 316, time: 0.539, data: 0.001) G_GAN: 0.612 G_L1: 1.862 D_real: 1.300 D_fake: 0.252 \n",
      "saving the model at the end of epoch 125, iters 45750\n",
      "End of epoch 125 / 200 \t Time Taken: 130 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 50, time: 0.539, data: 0.001) G_GAN: 1.332 G_L1: 2.764 D_real: 0.421 D_fake: 0.718 \n",
      "(epoch: 126, iters: 150, time: 0.539, data: 0.001) G_GAN: 0.838 G_L1: 1.894 D_real: 0.468 D_fake: 0.798 \n",
      "(epoch: 126, iters: 250, time: 1.248, data: 0.001) G_GAN: 1.252 G_L1: 3.996 D_real: 0.274 D_fake: 1.186 \n",
      "(epoch: 126, iters: 350, time: 0.541, data: 0.001) G_GAN: 1.508 G_L1: 3.107 D_real: 0.254 D_fake: 0.759 \n",
      "End of epoch 126 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 84, time: 0.539, data: 0.002) G_GAN: 0.907 G_L1: 2.725 D_real: 0.550 D_fake: 0.547 \n",
      "(epoch: 127, iters: 184, time: 0.540, data: 0.001) G_GAN: 0.591 G_L1: 1.953 D_real: 1.090 D_fake: 0.275 \n",
      "(epoch: 127, iters: 284, time: 1.239, data: 0.002) G_GAN: 0.884 G_L1: 1.850 D_real: 0.517 D_fake: 0.559 \n",
      "End of epoch 127 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 18, time: 0.540, data: 0.001) G_GAN: 0.757 G_L1: 0.736 D_real: 0.735 D_fake: 0.555 \n",
      "(epoch: 128, iters: 118, time: 0.541, data: 0.001) G_GAN: 0.731 G_L1: 1.494 D_real: 0.736 D_fake: 0.497 \n",
      "(epoch: 128, iters: 218, time: 0.541, data: 0.001) G_GAN: 0.813 G_L1: 1.967 D_real: 0.625 D_fake: 0.539 \n",
      "(epoch: 128, iters: 318, time: 1.256, data: 0.001) G_GAN: 0.910 G_L1: 2.517 D_real: 0.442 D_fake: 0.641 \n",
      "End of epoch 128 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 52, time: 0.542, data: 0.001) G_GAN: 0.835 G_L1: 2.250 D_real: 0.463 D_fake: 0.786 \n",
      "(epoch: 129, iters: 152, time: 0.540, data: 0.001) G_GAN: 0.955 G_L1: 2.168 D_real: 0.480 D_fake: 0.596 \n",
      "(epoch: 129, iters: 252, time: 0.540, data: 0.002) G_GAN: 0.763 G_L1: 1.390 D_real: 0.750 D_fake: 0.412 \n",
      "(epoch: 129, iters: 352, time: 1.242, data: 0.001) G_GAN: 0.811 G_L1: 1.918 D_real: 0.775 D_fake: 0.507 \n",
      "End of epoch 129 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 86, time: 0.539, data: 0.001) G_GAN: 1.053 G_L1: 2.340 D_real: 0.493 D_fake: 0.506 \n",
      "(epoch: 130, iters: 186, time: 0.540, data: 0.002) G_GAN: 1.221 G_L1: 2.557 D_real: 0.382 D_fake: 0.620 \n",
      "(epoch: 130, iters: 286, time: 0.538, data: 0.002) G_GAN: 1.303 G_L1: 2.099 D_real: 0.282 D_fake: 0.847 \n",
      "saving the model at the end of epoch 130, iters 47580\n",
      "End of epoch 130 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 20, time: 1.273, data: 0.001) G_GAN: 0.753 G_L1: 1.770 D_real: 0.857 D_fake: 0.314 \n",
      "(epoch: 131, iters: 120, time: 0.540, data: 0.002) G_GAN: 0.495 G_L1: 1.723 D_real: 0.648 D_fake: 0.354 \n",
      "(epoch: 131, iters: 220, time: 0.537, data: 0.001) G_GAN: 0.720 G_L1: 1.866 D_real: 0.701 D_fake: 0.502 \n",
      "(epoch: 131, iters: 320, time: 0.540, data: 0.002) G_GAN: 1.400 G_L1: 2.404 D_real: 0.298 D_fake: 0.670 \n",
      "End of epoch 131 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 54, time: 1.238, data: 0.001) G_GAN: 1.036 G_L1: 2.482 D_real: 0.281 D_fake: 0.947 \n",
      "(epoch: 132, iters: 154, time: 0.538, data: 0.001) G_GAN: 0.875 G_L1: 1.606 D_real: 0.664 D_fake: 0.524 \n",
      "(epoch: 132, iters: 254, time: 0.537, data: 0.001) G_GAN: 0.973 G_L1: 1.675 D_real: 0.492 D_fake: 0.521 \n",
      "(epoch: 132, iters: 354, time: 0.539, data: 0.001) G_GAN: 1.214 G_L1: 2.333 D_real: 0.393 D_fake: 0.872 \n",
      "End of epoch 132 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 88, time: 1.264, data: 0.001) G_GAN: 1.617 G_L1: 2.489 D_real: 0.231 D_fake: 1.068 \n",
      "(epoch: 133, iters: 188, time: 0.538, data: 0.001) G_GAN: 0.710 G_L1: 1.980 D_real: 0.707 D_fake: 0.413 \n",
      "(epoch: 133, iters: 288, time: 0.539, data: 0.001) G_GAN: 0.931 G_L1: 1.879 D_real: 0.511 D_fake: 0.673 \n",
      "End of epoch 133 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 22, time: 0.539, data: 0.001) G_GAN: 0.891 G_L1: 3.213 D_real: 0.540 D_fake: 0.449 \n",
      "(epoch: 134, iters: 122, time: 1.217, data: 0.001) G_GAN: 1.268 G_L1: 1.693 D_real: 0.342 D_fake: 0.776 \n",
      "(epoch: 134, iters: 222, time: 0.537, data: 0.001) G_GAN: 0.630 G_L1: 1.654 D_real: 0.859 D_fake: 0.341 \n",
      "(epoch: 134, iters: 322, time: 0.540, data: 0.001) G_GAN: 0.937 G_L1: 2.544 D_real: 0.459 D_fake: 0.622 \n",
      "End of epoch 134 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 56, time: 0.537, data: 0.001) G_GAN: 1.856 G_L1: 1.811 D_real: 0.162 D_fake: 1.176 \n",
      "(epoch: 135, iters: 156, time: 1.285, data: 0.001) G_GAN: 0.929 G_L1: 2.485 D_real: 0.611 D_fake: 0.451 \n",
      "(epoch: 135, iters: 256, time: 0.537, data: 0.001) G_GAN: 1.590 G_L1: 1.915 D_real: 0.232 D_fake: 1.081 \n",
      "(epoch: 135, iters: 356, time: 0.538, data: 0.002) G_GAN: 1.175 G_L1: 1.680 D_real: 0.314 D_fake: 0.564 \n",
      "saving the model at the end of epoch 135, iters 49410\n",
      "End of epoch 135 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 90, time: 0.538, data: 0.001) G_GAN: 0.938 G_L1: 1.367 D_real: 0.661 D_fake: 0.564 \n",
      "(epoch: 136, iters: 190, time: 1.317, data: 0.001) G_GAN: 1.068 G_L1: 1.805 D_real: 0.455 D_fake: 0.602 \n",
      "(epoch: 136, iters: 290, time: 0.538, data: 0.001) G_GAN: 1.268 G_L1: 1.732 D_real: 0.476 D_fake: 0.587 \n",
      "End of epoch 136 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 24, time: 0.538, data: 0.001) G_GAN: 0.641 G_L1: 1.233 D_real: 0.976 D_fake: 0.427 \n",
      "(epoch: 137, iters: 124, time: 0.538, data: 0.001) G_GAN: 1.077 G_L1: 2.096 D_real: 0.558 D_fake: 0.603 \n",
      "(epoch: 137, iters: 224, time: 1.320, data: 0.002) G_GAN: 1.112 G_L1: 2.590 D_real: 0.415 D_fake: 0.535 \n",
      "saving the latest model (epoch 137, total_iters 50000)\n",
      "(epoch: 137, iters: 324, time: 0.539, data: 0.002) G_GAN: 0.960 G_L1: 2.056 D_real: 0.779 D_fake: 0.768 \n",
      "End of epoch 137 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 58, time: 0.538, data: 0.001) G_GAN: 0.843 G_L1: 1.807 D_real: 0.696 D_fake: 0.520 \n",
      "(epoch: 138, iters: 158, time: 0.539, data: 0.001) G_GAN: 1.363 G_L1: 1.008 D_real: 0.292 D_fake: 0.915 \n",
      "(epoch: 138, iters: 258, time: 1.291, data: 0.001) G_GAN: 0.958 G_L1: 1.323 D_real: 0.673 D_fake: 0.399 \n",
      "(epoch: 138, iters: 358, time: 0.539, data: 0.001) G_GAN: 2.333 G_L1: 2.107 D_real: 0.168 D_fake: 0.861 \n",
      "End of epoch 138 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 92, time: 0.538, data: 0.001) G_GAN: 1.034 G_L1: 1.902 D_real: 0.480 D_fake: 0.644 \n",
      "(epoch: 139, iters: 192, time: 0.539, data: 0.001) G_GAN: 1.057 G_L1: 2.170 D_real: 0.436 D_fake: 0.594 \n",
      "(epoch: 139, iters: 292, time: 1.273, data: 0.001) G_GAN: 0.765 G_L1: 1.983 D_real: 0.600 D_fake: 0.333 \n",
      "End of epoch 139 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 26, time: 0.538, data: 0.001) G_GAN: 1.139 G_L1: 2.408 D_real: 0.506 D_fake: 0.411 \n",
      "(epoch: 140, iters: 126, time: 0.540, data: 0.001) G_GAN: 1.647 G_L1: 2.260 D_real: 0.210 D_fake: 0.978 \n",
      "(epoch: 140, iters: 226, time: 0.539, data: 0.002) G_GAN: 1.000 G_L1: 2.516 D_real: 0.418 D_fake: 0.532 \n",
      "(epoch: 140, iters: 326, time: 1.181, data: 0.002) G_GAN: 0.627 G_L1: 0.023 D_real: 0.892 D_fake: 0.535 \n",
      "saving the model at the end of epoch 140, iters 51240\n",
      "End of epoch 140 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 60, time: 0.539, data: 0.001) G_GAN: 2.001 G_L1: 2.098 D_real: 0.246 D_fake: 0.868 \n",
      "(epoch: 141, iters: 160, time: 0.539, data: 0.001) G_GAN: 0.941 G_L1: 2.432 D_real: 0.527 D_fake: 0.584 \n",
      "(epoch: 141, iters: 260, time: 0.538, data: 0.002) G_GAN: 0.596 G_L1: 1.977 D_real: 0.806 D_fake: 0.317 \n",
      "(epoch: 141, iters: 360, time: 1.332, data: 0.001) G_GAN: 1.121 G_L1: 2.440 D_real: 0.370 D_fake: 0.632 \n",
      "End of epoch 141 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 94, time: 0.538, data: 0.001) G_GAN: 0.645 G_L1: 0.028 D_real: 0.676 D_fake: 0.753 \n",
      "(epoch: 142, iters: 194, time: 0.538, data: 0.001) G_GAN: 1.074 G_L1: 4.032 D_real: 0.522 D_fake: 0.899 \n",
      "(epoch: 142, iters: 294, time: 0.538, data: 0.001) G_GAN: 1.312 G_L1: 1.686 D_real: 0.367 D_fake: 0.591 \n",
      "End of epoch 142 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 28, time: 1.305, data: 0.001) G_GAN: 1.300 G_L1: 1.831 D_real: 0.369 D_fake: 0.885 \n",
      "(epoch: 143, iters: 128, time: 0.537, data: 0.001) G_GAN: 0.724 G_L1: 0.026 D_real: 0.788 D_fake: 0.597 \n",
      "(epoch: 143, iters: 228, time: 0.539, data: 0.001) G_GAN: 1.027 G_L1: 1.354 D_real: 1.003 D_fake: 0.368 \n",
      "(epoch: 143, iters: 328, time: 0.538, data: 0.001) G_GAN: 0.939 G_L1: 2.118 D_real: 0.574 D_fake: 0.373 \n",
      "End of epoch 143 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 62, time: 1.330, data: 0.001) G_GAN: 1.096 G_L1: 2.997 D_real: 0.550 D_fake: 0.748 \n",
      "(epoch: 144, iters: 162, time: 0.539, data: 0.001) G_GAN: 0.998 G_L1: 2.012 D_real: 0.880 D_fake: 0.402 \n",
      "(epoch: 144, iters: 262, time: 0.538, data: 0.001) G_GAN: 0.901 G_L1: 1.548 D_real: 0.457 D_fake: 0.436 \n",
      "(epoch: 144, iters: 362, time: 0.538, data: 0.002) G_GAN: 0.717 G_L1: 2.640 D_real: 1.291 D_fake: 0.416 \n",
      "End of epoch 144 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 96, time: 1.194, data: 0.001) G_GAN: 0.910 G_L1: 0.879 D_real: 0.727 D_fake: 0.482 \n",
      "(epoch: 145, iters: 196, time: 0.542, data: 0.001) G_GAN: 1.075 G_L1: 1.776 D_real: 0.736 D_fake: 0.418 \n",
      "(epoch: 145, iters: 296, time: 0.537, data: 0.002) G_GAN: 1.219 G_L1: 2.205 D_real: 0.392 D_fake: 0.507 \n",
      "saving the model at the end of epoch 145, iters 53070\n",
      "End of epoch 145 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 30, time: 0.537, data: 0.001) G_GAN: 1.195 G_L1: 1.881 D_real: 0.439 D_fake: 0.574 \n",
      "(epoch: 146, iters: 130, time: 1.339, data: 0.001) G_GAN: 1.000 G_L1: 2.490 D_real: 0.982 D_fake: 0.251 \n",
      "(epoch: 146, iters: 230, time: 0.538, data: 0.001) G_GAN: 0.806 G_L1: 1.518 D_real: 0.667 D_fake: 0.591 \n",
      "(epoch: 146, iters: 330, time: 0.538, data: 0.002) G_GAN: 0.785 G_L1: 1.646 D_real: 0.591 D_fake: 0.667 \n",
      "End of epoch 146 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 64, time: 0.536, data: 0.001) G_GAN: 1.024 G_L1: 1.967 D_real: 0.500 D_fake: 0.691 \n",
      "(epoch: 147, iters: 164, time: 1.360, data: 0.001) G_GAN: 0.922 G_L1: 2.491 D_real: 0.690 D_fake: 0.595 \n",
      "(epoch: 147, iters: 264, time: 0.537, data: 0.002) G_GAN: 1.140 G_L1: 1.365 D_real: 0.534 D_fake: 0.571 \n",
      "(epoch: 147, iters: 364, time: 0.537, data: 0.001) G_GAN: 1.803 G_L1: 1.842 D_real: 0.186 D_fake: 0.606 \n",
      "End of epoch 147 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 98, time: 0.538, data: 0.002) G_GAN: 0.824 G_L1: 1.479 D_real: 0.455 D_fake: 0.719 \n",
      "(epoch: 148, iters: 198, time: 1.299, data: 0.002) G_GAN: 0.783 G_L1: 1.685 D_real: 0.842 D_fake: 0.342 \n",
      "(epoch: 148, iters: 298, time: 0.538, data: 0.001) G_GAN: 0.890 G_L1: 0.027 D_real: 0.593 D_fake: 0.823 \n",
      "End of epoch 148 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 32, time: 0.537, data: 0.001) G_GAN: 0.989 G_L1: 2.483 D_real: 0.371 D_fake: 0.616 \n",
      "(epoch: 149, iters: 132, time: 0.537, data: 0.002) G_GAN: 1.334 G_L1: 2.500 D_real: 0.270 D_fake: 0.475 \n",
      "(epoch: 149, iters: 232, time: 1.338, data: 0.001) G_GAN: 1.150 G_L1: 2.288 D_real: 0.819 D_fake: 0.410 \n",
      "(epoch: 149, iters: 332, time: 0.538, data: 0.001) G_GAN: 0.953 G_L1: 2.243 D_real: 0.623 D_fake: 0.322 \n",
      "End of epoch 149 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 66, time: 0.540, data: 0.001) G_GAN: 1.025 G_L1: 2.161 D_real: 0.300 D_fake: 0.534 \n",
      "(epoch: 150, iters: 166, time: 0.538, data: 0.001) G_GAN: 0.869 G_L1: 1.651 D_real: 0.655 D_fake: 0.473 \n",
      "(epoch: 150, iters: 266, time: 1.315, data: 0.001) G_GAN: 1.315 G_L1: 2.262 D_real: 0.297 D_fake: 0.624 \n",
      "(epoch: 150, iters: 366, time: 0.537, data: 0.001) G_GAN: 1.344 G_L1: 2.326 D_real: 0.315 D_fake: 0.601 \n",
      "saving the model at the end of epoch 150, iters 54900\n",
      "End of epoch 150 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 100, time: 0.538, data: 0.076) G_GAN: 0.886 G_L1: 1.332 D_real: 0.675 D_fake: 0.374 \n",
      "saving the latest model (epoch 151, total_iters 55000)\n",
      "(epoch: 151, iters: 200, time: 0.539, data: 0.001) G_GAN: 1.694 G_L1: 2.007 D_real: 0.199 D_fake: 0.731 \n",
      "(epoch: 151, iters: 300, time: 1.333, data: 0.002) G_GAN: 1.164 G_L1: 1.889 D_real: 0.351 D_fake: 0.598 \n",
      "End of epoch 151 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 34, time: 0.537, data: 0.002) G_GAN: 0.958 G_L1: 2.481 D_real: 0.422 D_fake: 0.446 \n",
      "(epoch: 152, iters: 134, time: 0.538, data: 0.001) G_GAN: 1.994 G_L1: 2.014 D_real: 0.258 D_fake: 0.787 \n",
      "(epoch: 152, iters: 234, time: 0.536, data: 0.002) G_GAN: 0.943 G_L1: 2.854 D_real: 0.681 D_fake: 0.348 \n",
      "(epoch: 152, iters: 334, time: 1.373, data: 0.001) G_GAN: 1.023 G_L1: 2.235 D_real: 0.627 D_fake: 0.356 \n",
      "End of epoch 152 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 68, time: 0.538, data: 0.001) G_GAN: 0.611 G_L1: 0.025 D_real: 0.937 D_fake: 0.552 \n",
      "(epoch: 153, iters: 168, time: 0.538, data: 0.001) G_GAN: 1.096 G_L1: 2.268 D_real: 0.443 D_fake: 0.366 \n",
      "(epoch: 153, iters: 268, time: 0.537, data: 0.001) G_GAN: 1.769 G_L1: 2.447 D_real: 0.155 D_fake: 0.872 \n",
      "End of epoch 153 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 2, time: 1.341, data: 0.001) G_GAN: 1.225 G_L1: 1.712 D_real: 0.388 D_fake: 0.575 \n",
      "(epoch: 154, iters: 102, time: 0.539, data: 0.000) G_GAN: 0.982 G_L1: 1.606 D_real: 0.678 D_fake: 0.493 \n",
      "(epoch: 154, iters: 202, time: 0.536, data: 0.001) G_GAN: 0.933 G_L1: 1.752 D_real: 0.706 D_fake: 0.402 \n",
      "(epoch: 154, iters: 302, time: 0.537, data: 0.001) G_GAN: 1.235 G_L1: 2.125 D_real: 0.695 D_fake: 0.472 \n",
      "End of epoch 154 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 36, time: 1.335, data: 0.001) G_GAN: 0.915 G_L1: 0.602 D_real: 0.419 D_fake: 0.695 \n",
      "(epoch: 155, iters: 136, time: 0.535, data: 0.001) G_GAN: 1.203 G_L1: 2.136 D_real: 0.416 D_fake: 0.421 \n",
      "(epoch: 155, iters: 236, time: 0.538, data: 0.002) G_GAN: 0.941 G_L1: 2.048 D_real: 0.833 D_fake: 0.459 \n",
      "(epoch: 155, iters: 336, time: 0.534, data: 0.002) G_GAN: 0.877 G_L1: 0.872 D_real: 0.706 D_fake: 0.554 \n",
      "saving the model at the end of epoch 155, iters 56730\n",
      "End of epoch 155 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 70, time: 1.322, data: 0.001) G_GAN: 1.080 G_L1: 1.753 D_real: 0.769 D_fake: 0.467 \n",
      "(epoch: 156, iters: 170, time: 0.539, data: 0.002) G_GAN: 1.036 G_L1: 1.793 D_real: 0.305 D_fake: 0.830 \n",
      "(epoch: 156, iters: 270, time: 0.537, data: 0.001) G_GAN: 0.818 G_L1: 1.612 D_real: 0.744 D_fake: 0.637 \n",
      "End of epoch 156 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 4, time: 0.538, data: 0.001) G_GAN: 0.642 G_L1: 2.170 D_real: 0.757 D_fake: 0.445 \n",
      "(epoch: 157, iters: 104, time: 1.304, data: 0.003) G_GAN: 0.909 G_L1: 2.190 D_real: 1.075 D_fake: 0.307 \n",
      "(epoch: 157, iters: 204, time: 0.537, data: 0.001) G_GAN: 1.245 G_L1: 2.808 D_real: 0.305 D_fake: 0.493 \n",
      "(epoch: 157, iters: 304, time: 0.538, data: 0.002) G_GAN: 1.253 G_L1: 2.366 D_real: 0.319 D_fake: 0.570 \n",
      "End of epoch 157 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 38, time: 0.538, data: 0.002) G_GAN: 0.770 G_L1: 0.028 D_real: 0.714 D_fake: 0.668 \n",
      "(epoch: 158, iters: 138, time: 1.352, data: 0.001) G_GAN: 0.778 G_L1: 2.089 D_real: 0.874 D_fake: 0.435 \n",
      "(epoch: 158, iters: 238, time: 0.537, data: 0.002) G_GAN: 0.862 G_L1: 0.839 D_real: 0.856 D_fake: 0.582 \n",
      "(epoch: 158, iters: 338, time: 0.536, data: 0.001) G_GAN: 0.853 G_L1: 1.781 D_real: 0.387 D_fake: 0.687 \n",
      "End of epoch 158 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 72, time: 0.535, data: 0.001) G_GAN: 0.752 G_L1: 1.929 D_real: 0.724 D_fake: 0.519 \n",
      "(epoch: 159, iters: 172, time: 1.382, data: 0.001) G_GAN: 0.904 G_L1: 1.935 D_real: 0.839 D_fake: 0.363 \n",
      "(epoch: 159, iters: 272, time: 0.537, data: 0.002) G_GAN: 0.918 G_L1: 2.395 D_real: 0.308 D_fake: 0.677 \n",
      "End of epoch 159 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 6, time: 0.541, data: 0.001) G_GAN: 1.070 G_L1: 1.939 D_real: 0.486 D_fake: 0.729 \n",
      "(epoch: 160, iters: 106, time: 0.536, data: 0.000) G_GAN: 1.286 G_L1: 3.280 D_real: 0.355 D_fake: 0.738 \n",
      "(epoch: 160, iters: 206, time: 1.360, data: 0.002) G_GAN: 1.141 G_L1: 1.917 D_real: 0.375 D_fake: 0.755 \n",
      "(epoch: 160, iters: 306, time: 0.536, data: 0.001) G_GAN: 0.863 G_L1: 1.878 D_real: 0.525 D_fake: 0.572 \n",
      "saving the model at the end of epoch 160, iters 58560\n",
      "End of epoch 160 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 40, time: 0.538, data: 0.001) G_GAN: 0.692 G_L1: 0.026 D_real: 0.747 D_fake: 0.663 \n",
      "(epoch: 161, iters: 140, time: 0.538, data: 0.001) G_GAN: 0.863 G_L1: 1.973 D_real: 0.734 D_fake: 0.446 \n",
      "(epoch: 161, iters: 240, time: 1.378, data: 0.001) G_GAN: 1.015 G_L1: 2.886 D_real: 0.551 D_fake: 0.522 \n",
      "(epoch: 161, iters: 340, time: 0.536, data: 0.002) G_GAN: 0.998 G_L1: 1.861 D_real: 0.447 D_fake: 0.760 \n",
      "End of epoch 161 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 74, time: 0.538, data: 0.001) G_GAN: 1.151 G_L1: 1.987 D_real: 0.500 D_fake: 0.500 \n",
      "(epoch: 162, iters: 174, time: 0.537, data: 0.001) G_GAN: 0.913 G_L1: 2.524 D_real: 0.498 D_fake: 0.689 \n",
      "(epoch: 162, iters: 274, time: 1.385, data: 0.002) G_GAN: 1.449 G_L1: 2.219 D_real: 0.546 D_fake: 1.871 \n",
      "End of epoch 162 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 8, time: 0.540, data: 0.001) G_GAN: 1.025 G_L1: 1.892 D_real: 0.523 D_fake: 0.604 \n",
      "(epoch: 163, iters: 108, time: 0.538, data: 0.001) G_GAN: 0.921 G_L1: 2.324 D_real: 0.611 D_fake: 0.423 \n",
      "(epoch: 163, iters: 208, time: 0.536, data: 0.001) G_GAN: 0.907 G_L1: 2.119 D_real: 0.644 D_fake: 0.543 \n",
      "(epoch: 163, iters: 308, time: 1.351, data: 0.002) G_GAN: 1.027 G_L1: 0.926 D_real: 1.068 D_fake: 0.367 \n",
      "End of epoch 163 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 42, time: 0.537, data: 0.001) G_GAN: 1.237 G_L1: 2.405 D_real: 0.416 D_fake: 0.688 \n",
      "(epoch: 164, iters: 142, time: 0.537, data: 0.001) G_GAN: 0.981 G_L1: 2.280 D_real: 0.697 D_fake: 0.440 \n",
      "(epoch: 164, iters: 242, time: 0.537, data: 0.001) G_GAN: 0.705 G_L1: 0.029 D_real: 0.658 D_fake: 0.744 \n",
      "(epoch: 164, iters: 342, time: 1.333, data: 0.002) G_GAN: 0.717 G_L1: 1.571 D_real: 0.830 D_fake: 0.423 \n",
      "saving the latest model (epoch 164, total_iters 60000)\n",
      "End of epoch 164 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 76, time: 0.537, data: 0.001) G_GAN: 1.579 G_L1: 1.780 D_real: 0.424 D_fake: 0.972 \n",
      "(epoch: 165, iters: 176, time: 0.537, data: 0.001) G_GAN: 0.716 G_L1: 2.044 D_real: 1.063 D_fake: 0.375 \n",
      "(epoch: 165, iters: 276, time: 0.539, data: 0.001) G_GAN: 0.804 G_L1: 2.083 D_real: 0.964 D_fake: 0.305 \n",
      "saving the model at the end of epoch 165, iters 60390\n",
      "End of epoch 165 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 10, time: 1.349, data: 0.001) G_GAN: 1.147 G_L1: 2.364 D_real: 1.002 D_fake: 0.308 \n",
      "(epoch: 166, iters: 110, time: 0.537, data: 0.001) G_GAN: 0.728 G_L1: 0.026 D_real: 0.724 D_fake: 0.644 \n",
      "(epoch: 166, iters: 210, time: 0.539, data: 0.001) G_GAN: 0.873 G_L1: 1.803 D_real: 0.534 D_fake: 0.724 \n",
      "(epoch: 166, iters: 310, time: 0.537, data: 0.002) G_GAN: 0.893 G_L1: 1.586 D_real: 0.829 D_fake: 0.346 \n",
      "End of epoch 166 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 44, time: 1.368, data: 0.001) G_GAN: 0.902 G_L1: 2.199 D_real: 0.581 D_fake: 0.596 \n",
      "(epoch: 167, iters: 144, time: 0.538, data: 0.001) G_GAN: 0.979 G_L1: 1.904 D_real: 0.383 D_fake: 0.689 \n",
      "(epoch: 167, iters: 244, time: 0.536, data: 0.001) G_GAN: 0.481 G_L1: 1.940 D_real: 1.074 D_fake: 0.327 \n",
      "(epoch: 167, iters: 344, time: 0.534, data: 0.001) G_GAN: 1.140 G_L1: 2.689 D_real: 0.450 D_fake: 0.556 \n",
      "End of epoch 167 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 78, time: 1.447, data: 0.001) G_GAN: 1.179 G_L1: 2.266 D_real: 0.529 D_fake: 0.585 \n",
      "(epoch: 168, iters: 178, time: 0.539, data: 0.002) G_GAN: 0.881 G_L1: 1.930 D_real: 0.677 D_fake: 0.535 \n",
      "(epoch: 168, iters: 278, time: 0.539, data: 0.002) G_GAN: 0.999 G_L1: 3.164 D_real: 0.311 D_fake: 0.995 \n",
      "End of epoch 168 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 12, time: 0.538, data: 0.001) G_GAN: 0.730 G_L1: 1.671 D_real: 0.821 D_fake: 0.474 \n",
      "(epoch: 169, iters: 112, time: 1.368, data: 0.001) G_GAN: 0.919 G_L1: 1.828 D_real: 0.559 D_fake: 0.547 \n",
      "(epoch: 169, iters: 212, time: 0.537, data: 0.002) G_GAN: 1.641 G_L1: 1.927 D_real: 0.319 D_fake: 0.966 \n",
      "(epoch: 169, iters: 312, time: 0.537, data: 0.001) G_GAN: 0.831 G_L1: 1.684 D_real: 1.098 D_fake: 0.332 \n",
      "End of epoch 169 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 46, time: 0.537, data: 0.001) G_GAN: 0.965 G_L1: 2.477 D_real: 0.931 D_fake: 0.442 \n",
      "(epoch: 170, iters: 146, time: 1.313, data: 0.001) G_GAN: 0.724 G_L1: 0.025 D_real: 0.730 D_fake: 0.677 \n",
      "(epoch: 170, iters: 246, time: 0.538, data: 0.002) G_GAN: 0.862 G_L1: 1.795 D_real: 0.748 D_fake: 0.471 \n",
      "(epoch: 170, iters: 346, time: 0.538, data: 0.002) G_GAN: 0.915 G_L1: 1.751 D_real: 0.545 D_fake: 0.576 \n",
      "saving the model at the end of epoch 170, iters 62220\n",
      "End of epoch 170 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 80, time: 0.537, data: 0.001) G_GAN: 1.060 G_L1: 2.476 D_real: 0.447 D_fake: 0.606 \n",
      "(epoch: 171, iters: 180, time: 1.343, data: 0.002) G_GAN: 0.840 G_L1: 1.922 D_real: 0.666 D_fake: 0.623 \n",
      "(epoch: 171, iters: 280, time: 0.538, data: 0.001) G_GAN: 0.826 G_L1: 2.393 D_real: 0.538 D_fake: 0.896 \n",
      "End of epoch 171 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 14, time: 0.537, data: 0.002) G_GAN: 0.754 G_L1: 1.898 D_real: 0.642 D_fake: 0.651 \n",
      "(epoch: 172, iters: 114, time: 0.538, data: 0.002) G_GAN: 1.066 G_L1: 1.234 D_real: 0.493 D_fake: 0.674 \n",
      "(epoch: 172, iters: 214, time: 1.406, data: 0.002) G_GAN: 0.774 G_L1: 1.991 D_real: 0.527 D_fake: 0.680 \n",
      "(epoch: 172, iters: 314, time: 0.538, data: 0.001) G_GAN: 0.840 G_L1: 2.071 D_real: 0.689 D_fake: 0.594 \n",
      "End of epoch 172 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 48, time: 0.538, data: 0.001) G_GAN: 0.930 G_L1: 3.165 D_real: 0.554 D_fake: 0.603 \n",
      "(epoch: 173, iters: 148, time: 0.537, data: 0.001) G_GAN: 0.909 G_L1: 2.562 D_real: 0.532 D_fake: 0.614 \n",
      "(epoch: 173, iters: 248, time: 1.307, data: 0.002) G_GAN: 0.782 G_L1: 0.025 D_real: 0.700 D_fake: 0.755 \n",
      "(epoch: 173, iters: 348, time: 0.538, data: 0.001) G_GAN: 0.945 G_L1: 2.079 D_real: 0.529 D_fake: 0.677 \n",
      "End of epoch 173 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 82, time: 0.537, data: 0.001) G_GAN: 0.824 G_L1: 1.270 D_real: 0.768 D_fake: 0.611 \n",
      "(epoch: 174, iters: 182, time: 0.538, data: 0.001) G_GAN: 0.749 G_L1: 2.256 D_real: 0.539 D_fake: 0.816 \n",
      "(epoch: 174, iters: 282, time: 1.393, data: 0.001) G_GAN: 0.783 G_L1: 1.999 D_real: 0.536 D_fake: 0.660 \n",
      "End of epoch 174 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 16, time: 0.535, data: 0.001) G_GAN: 0.839 G_L1: 1.224 D_real: 0.661 D_fake: 0.553 \n",
      "(epoch: 175, iters: 116, time: 0.538, data: 0.001) G_GAN: 0.876 G_L1: 1.869 D_real: 0.592 D_fake: 0.602 \n",
      "(epoch: 175, iters: 216, time: 0.536, data: 0.001) G_GAN: 0.902 G_L1: 2.048 D_real: 0.654 D_fake: 0.637 \n",
      "(epoch: 175, iters: 316, time: 1.341, data: 0.001) G_GAN: 0.756 G_L1: 2.224 D_real: 0.496 D_fake: 0.878 \n",
      "saving the model at the end of epoch 175, iters 64050\n",
      "End of epoch 175 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 50, time: 0.539, data: 0.002) G_GAN: 0.936 G_L1: 1.727 D_real: 0.607 D_fake: 0.561 \n",
      "(epoch: 176, iters: 150, time: 0.535, data: 0.002) G_GAN: 0.827 G_L1: 1.582 D_real: 0.718 D_fake: 0.536 \n",
      "(epoch: 176, iters: 250, time: 0.536, data: 0.002) G_GAN: 0.718 G_L1: 0.031 D_real: 0.609 D_fake: 0.790 \n",
      "(epoch: 176, iters: 350, time: 1.452, data: 0.002) G_GAN: 0.908 G_L1: 2.376 D_real: 0.494 D_fake: 0.669 \n",
      "End of epoch 176 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 84, time: 0.538, data: 0.001) G_GAN: 0.824 G_L1: 0.854 D_real: 0.643 D_fake: 0.614 \n",
      "(epoch: 177, iters: 184, time: 0.537, data: 0.001) G_GAN: 0.853 G_L1: 1.896 D_real: 0.750 D_fake: 0.489 \n",
      "(epoch: 177, iters: 284, time: 0.538, data: 0.002) G_GAN: 0.598 G_L1: 1.958 D_real: 0.580 D_fake: 0.520 \n",
      "End of epoch 177 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 18, time: 1.424, data: 0.001) G_GAN: 0.691 G_L1: 2.964 D_real: 0.595 D_fake: 0.814 \n",
      "(epoch: 178, iters: 118, time: 0.536, data: 0.002) G_GAN: 0.865 G_L1: 2.147 D_real: 0.820 D_fake: 0.499 \n",
      "(epoch: 178, iters: 218, time: 0.538, data: 0.001) G_GAN: 0.935 G_L1: 1.947 D_real: 0.721 D_fake: 0.534 \n",
      "saving the latest model (epoch 178, total_iters 65000)\n",
      "(epoch: 178, iters: 318, time: 0.539, data: 0.001) G_GAN: 0.812 G_L1: 2.355 D_real: 0.443 D_fake: 0.757 \n",
      "End of epoch 178 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 52, time: 1.429, data: 0.001) G_GAN: 0.900 G_L1: 1.945 D_real: 0.540 D_fake: 0.648 \n",
      "(epoch: 179, iters: 152, time: 0.538, data: 0.001) G_GAN: 0.814 G_L1: 1.754 D_real: 0.864 D_fake: 0.467 \n",
      "(epoch: 179, iters: 252, time: 0.538, data: 0.002) G_GAN: 0.894 G_L1: 1.773 D_real: 0.603 D_fake: 0.600 \n",
      "(epoch: 179, iters: 352, time: 0.539, data: 0.001) G_GAN: 0.843 G_L1: 2.065 D_real: 0.491 D_fake: 0.665 \n",
      "End of epoch 179 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000416\n",
      "(epoch: 180, iters: 86, time: 1.412, data: 0.001) G_GAN: 0.838 G_L1: 2.019 D_real: 0.759 D_fake: 0.581 \n",
      "(epoch: 180, iters: 186, time: 0.540, data: 0.001) G_GAN: 0.802 G_L1: 2.797 D_real: 0.458 D_fake: 0.775 \n",
      "(epoch: 180, iters: 286, time: 0.538, data: 0.001) G_GAN: 0.709 G_L1: 0.035 D_real: 0.748 D_fake: 0.624 \n",
      "saving the model at the end of epoch 180, iters 65880\n",
      "End of epoch 180 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 20, time: 0.539, data: 0.001) G_GAN: 0.769 G_L1: 2.529 D_real: 0.709 D_fake: 0.568 \n",
      "(epoch: 181, iters: 120, time: 1.436, data: 0.001) G_GAN: 0.896 G_L1: 1.773 D_real: 0.891 D_fake: 0.485 \n",
      "(epoch: 181, iters: 220, time: 0.535, data: 0.001) G_GAN: 0.907 G_L1: 1.915 D_real: 0.782 D_fake: 0.484 \n",
      "(epoch: 181, iters: 320, time: 0.537, data: 0.001) G_GAN: 0.916 G_L1: 1.677 D_real: 0.819 D_fake: 0.468 \n",
      "End of epoch 181 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 54, time: 0.538, data: 0.001) G_GAN: 0.643 G_L1: 3.166 D_real: 0.528 D_fake: 0.902 \n",
      "(epoch: 182, iters: 154, time: 1.441, data: 0.001) G_GAN: 0.577 G_L1: 2.922 D_real: 0.431 D_fake: 1.099 \n",
      "(epoch: 182, iters: 254, time: 0.537, data: 0.001) G_GAN: 0.810 G_L1: 1.516 D_real: 0.780 D_fake: 0.576 \n",
      "(epoch: 182, iters: 354, time: 0.536, data: 0.001) G_GAN: 0.949 G_L1: 1.156 D_real: 0.913 D_fake: 0.457 \n",
      "End of epoch 182 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 88, time: 0.538, data: 0.001) G_GAN: 0.860 G_L1: 1.986 D_real: 1.125 D_fake: 0.408 \n",
      "(epoch: 183, iters: 188, time: 1.425, data: 0.001) G_GAN: 0.819 G_L1: 2.121 D_real: 0.607 D_fake: 0.664 \n",
      "(epoch: 183, iters: 288, time: 0.538, data: 0.001) G_GAN: 1.034 G_L1: 3.089 D_real: 0.712 D_fake: 0.477 \n",
      "End of epoch 183 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 22, time: 0.535, data: 0.001) G_GAN: 0.781 G_L1: 2.293 D_real: 0.538 D_fake: 0.704 \n",
      "(epoch: 184, iters: 122, time: 0.537, data: 0.001) G_GAN: 0.859 G_L1: 1.092 D_real: 0.631 D_fake: 0.605 \n",
      "(epoch: 184, iters: 222, time: 1.435, data: 0.001) G_GAN: 0.872 G_L1: 1.924 D_real: 0.672 D_fake: 0.653 \n",
      "(epoch: 184, iters: 322, time: 0.537, data: 0.001) G_GAN: 0.756 G_L1: 1.392 D_real: 0.751 D_fake: 0.640 \n",
      "End of epoch 184 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 56, time: 0.537, data: 0.001) G_GAN: 0.892 G_L1: 1.791 D_real: 0.994 D_fake: 0.456 \n",
      "(epoch: 185, iters: 156, time: 0.538, data: 0.001) G_GAN: 0.765 G_L1: 1.755 D_real: 0.695 D_fake: 0.652 \n",
      "(epoch: 185, iters: 256, time: 1.489, data: 0.001) G_GAN: 0.717 G_L1: 1.870 D_real: 0.657 D_fake: 0.593 \n",
      "(epoch: 185, iters: 356, time: 0.538, data: 0.002) G_GAN: 0.919 G_L1: 1.990 D_real: 0.537 D_fake: 0.615 \n",
      "saving the model at the end of epoch 185, iters 67710\n",
      "End of epoch 185 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 90, time: 0.538, data: 0.001) G_GAN: 0.735 G_L1: 2.407 D_real: 0.608 D_fake: 0.737 \n",
      "(epoch: 186, iters: 190, time: 0.536, data: 0.001) G_GAN: 0.771 G_L1: 1.767 D_real: 0.670 D_fake: 0.717 \n",
      "(epoch: 186, iters: 290, time: 1.429, data: 0.002) G_GAN: 0.760 G_L1: 2.163 D_real: 0.946 D_fake: 0.467 \n",
      "End of epoch 186 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 24, time: 0.536, data: 0.002) G_GAN: 0.821 G_L1: 1.312 D_real: 0.783 D_fake: 0.619 \n",
      "(epoch: 187, iters: 124, time: 0.537, data: 0.001) G_GAN: 0.823 G_L1: 0.474 D_real: 0.635 D_fake: 0.648 \n",
      "(epoch: 187, iters: 224, time: 0.538, data: 0.001) G_GAN: 0.853 G_L1: 2.288 D_real: 0.723 D_fake: 0.562 \n",
      "(epoch: 187, iters: 324, time: 1.439, data: 0.001) G_GAN: 0.833 G_L1: 2.026 D_real: 0.445 D_fake: 0.793 \n",
      "End of epoch 187 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 58, time: 0.535, data: 0.002) G_GAN: 0.918 G_L1: 2.064 D_real: 0.654 D_fake: 0.542 \n",
      "(epoch: 188, iters: 158, time: 0.539, data: 0.001) G_GAN: 0.797 G_L1: 1.774 D_real: 0.571 D_fake: 0.661 \n",
      "(epoch: 188, iters: 258, time: 0.536, data: 0.001) G_GAN: 0.775 G_L1: 2.359 D_real: 0.627 D_fake: 0.608 \n",
      "(epoch: 188, iters: 358, time: 1.403, data: 0.001) G_GAN: 0.820 G_L1: 1.821 D_real: 0.756 D_fake: 0.591 \n",
      "End of epoch 188 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 92, time: 0.535, data: 0.001) G_GAN: 0.751 G_L1: 1.604 D_real: 0.779 D_fake: 0.579 \n",
      "(epoch: 189, iters: 192, time: 0.537, data: 0.002) G_GAN: 0.692 G_L1: 1.228 D_real: 0.619 D_fake: 0.791 \n",
      "(epoch: 189, iters: 292, time: 0.537, data: 0.001) G_GAN: 0.883 G_L1: 2.267 D_real: 0.660 D_fake: 0.559 \n",
      "End of epoch 189 / 200 \t Time Taken: 128 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 26, time: 1.462, data: 0.002) G_GAN: 0.852 G_L1: 1.521 D_real: 0.829 D_fake: 0.532 \n",
      "(epoch: 190, iters: 126, time: 0.538, data: 0.001) G_GAN: 0.742 G_L1: 1.813 D_real: 0.635 D_fake: 0.730 \n",
      "(epoch: 190, iters: 226, time: 0.536, data: 0.001) G_GAN: 0.814 G_L1: 1.880 D_real: 0.688 D_fake: 0.626 \n",
      "(epoch: 190, iters: 326, time: 0.535, data: 0.001) G_GAN: 0.750 G_L1: 0.035 D_real: 0.713 D_fake: 0.638 \n",
      "saving the model at the end of epoch 190, iters 69540\n",
      "End of epoch 190 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 60, time: 1.429, data: 0.001) G_GAN: 0.946 G_L1: 1.309 D_real: 0.483 D_fake: 0.747 \n",
      "(epoch: 191, iters: 160, time: 0.535, data: 0.002) G_GAN: 0.756 G_L1: 2.361 D_real: 0.619 D_fake: 0.750 \n",
      "(epoch: 191, iters: 260, time: 0.537, data: 0.001) G_GAN: 0.790 G_L1: 1.558 D_real: 0.654 D_fake: 0.639 \n",
      "(epoch: 191, iters: 360, time: 0.538, data: 0.001) G_GAN: 0.843 G_L1: 2.267 D_real: 0.820 D_fake: 0.506 \n",
      "End of epoch 191 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 94, time: 1.440, data: 0.001) G_GAN: 0.790 G_L1: 1.129 D_real: 0.691 D_fake: 0.641 \n",
      "saving the latest model (epoch 192, total_iters 70000)\n",
      "(epoch: 192, iters: 194, time: 0.537, data: 0.001) G_GAN: 0.755 G_L1: 1.919 D_real: 0.541 D_fake: 0.705 \n",
      "(epoch: 192, iters: 294, time: 0.536, data: 0.002) G_GAN: 0.817 G_L1: 2.046 D_real: 0.847 D_fake: 0.577 \n",
      "End of epoch 192 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 28, time: 0.536, data: 0.002) G_GAN: 0.796 G_L1: 1.794 D_real: 0.741 D_fake: 0.556 \n",
      "(epoch: 193, iters: 128, time: 1.427, data: 0.002) G_GAN: 0.796 G_L1: 1.835 D_real: 0.749 D_fake: 0.602 \n",
      "(epoch: 193, iters: 228, time: 0.535, data: 0.001) G_GAN: 0.807 G_L1: 1.833 D_real: 0.627 D_fake: 0.666 \n",
      "(epoch: 193, iters: 328, time: 0.538, data: 0.001) G_GAN: 0.849 G_L1: 2.408 D_real: 0.770 D_fake: 0.555 \n",
      "End of epoch 193 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 62, time: 0.538, data: 0.001) G_GAN: 0.869 G_L1: 1.817 D_real: 0.605 D_fake: 0.580 \n",
      "(epoch: 194, iters: 162, time: 1.436, data: 0.001) G_GAN: 0.697 G_L1: 1.384 D_real: 0.708 D_fake: 0.743 \n",
      "(epoch: 194, iters: 262, time: 0.538, data: 0.001) G_GAN: 0.747 G_L1: 2.659 D_real: 0.358 D_fake: 0.943 \n",
      "(epoch: 194, iters: 362, time: 0.538, data: 0.001) G_GAN: 0.729 G_L1: 0.022 D_real: 0.687 D_fake: 0.674 \n",
      "End of epoch 194 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 96, time: 0.536, data: 0.002) G_GAN: 0.750 G_L1: 0.959 D_real: 0.700 D_fake: 0.698 \n",
      "(epoch: 195, iters: 196, time: 1.435, data: 0.001) G_GAN: 0.800 G_L1: 1.469 D_real: 0.779 D_fake: 0.601 \n",
      "(epoch: 195, iters: 296, time: 0.538, data: 0.001) G_GAN: 0.789 G_L1: 1.742 D_real: 0.534 D_fake: 0.625 \n",
      "saving the model at the end of epoch 195, iters 71370\n",
      "End of epoch 195 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 30, time: 0.538, data: 0.002) G_GAN: 0.787 G_L1: 2.134 D_real: 0.623 D_fake: 0.675 \n",
      "(epoch: 196, iters: 130, time: 0.536, data: 0.001) G_GAN: 0.784 G_L1: 1.721 D_real: 0.718 D_fake: 0.655 \n",
      "(epoch: 196, iters: 230, time: 1.458, data: 0.001) G_GAN: 0.849 G_L1: 1.634 D_real: 0.781 D_fake: 0.566 \n",
      "(epoch: 196, iters: 330, time: 0.536, data: 0.002) G_GAN: 1.475 G_L1: 1.550 D_real: 0.391 D_fake: 0.735 \n",
      "End of epoch 196 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 64, time: 0.540, data: 0.001) G_GAN: 0.764 G_L1: 1.939 D_real: 0.737 D_fake: 0.605 \n",
      "(epoch: 197, iters: 164, time: 0.539, data: 0.002) G_GAN: 0.750 G_L1: 1.772 D_real: 0.606 D_fake: 0.707 \n",
      "(epoch: 197, iters: 264, time: 1.453, data: 0.002) G_GAN: 0.870 G_L1: 1.749 D_real: 0.624 D_fake: 0.602 \n",
      "(epoch: 197, iters: 364, time: 0.538, data: 0.001) G_GAN: 0.706 G_L1: 1.758 D_real: 0.510 D_fake: 0.755 \n",
      "End of epoch 197 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 98, time: 0.537, data: 0.001) G_GAN: 0.781 G_L1: 2.215 D_real: 0.574 D_fake: 0.652 \n",
      "(epoch: 198, iters: 198, time: 0.540, data: 0.002) G_GAN: 0.804 G_L1: 2.197 D_real: 0.579 D_fake: 0.630 \n",
      "(epoch: 198, iters: 298, time: 1.513, data: 0.001) G_GAN: 0.784 G_L1: 1.833 D_real: 0.769 D_fake: 0.693 \n",
      "End of epoch 198 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 32, time: 0.537, data: 0.002) G_GAN: 0.763 G_L1: 2.995 D_real: 0.313 D_fake: 0.786 \n",
      "(epoch: 199, iters: 132, time: 0.538, data: 0.001) G_GAN: 0.580 G_L1: 2.869 D_real: 0.403 D_fake: 0.960 \n",
      "(epoch: 199, iters: 232, time: 0.539, data: 0.001) G_GAN: 0.919 G_L1: 1.506 D_real: 0.691 D_fake: 0.528 \n",
      "(epoch: 199, iters: 332, time: 1.509, data: 0.002) G_GAN: 0.750 G_L1: 1.851 D_real: 0.521 D_fake: 0.695 \n",
      "End of epoch 199 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 66, time: 0.538, data: 0.001) G_GAN: 0.741 G_L1: 1.829 D_real: 0.785 D_fake: 0.690 \n",
      "(epoch: 200, iters: 166, time: 0.537, data: 0.001) G_GAN: 0.696 G_L1: 1.677 D_real: 0.671 D_fake: 0.765 \n",
      "(epoch: 200, iters: 266, time: 0.537, data: 0.001) G_GAN: 0.760 G_L1: 1.983 D_real: 0.530 D_fake: 0.703 \n",
      "(epoch: 200, iters: 366, time: 1.477, data: 0.001) G_GAN: 0.884 G_L1: 1.520 D_real: 0.769 D_fake: 0.563 \n",
      "saving the model at the end of epoch 200, iters 73200\n",
      "End of epoch 200 / 200 \t Time Taken: 129 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot AB --model pix2pix --no_dropout --output_nc 1 --norm batch --niter 100 --niter_decay 100 --no_flip --checkpoints_dir may16 --netG resnet_9blocks --preprocess none --name test30train366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 2                             \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: may17                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: syndata                       \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: syndata868                    \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 50                            \t[default: 100]\n",
      "              niter_decay: 50                            \t[default: 100]\n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 868\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "[Network D] Total number of parameters : 2.767 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory may17/syndata868/web...\n",
      "(epoch: 1, iters: 100, time: 0.514, data: 0.102) G_GAN: 1.520 G_L1: 10.555 D_real: 0.600 D_fake: 0.344 \n",
      "(epoch: 1, iters: 200, time: 0.509, data: 0.002) G_GAN: 1.290 G_L1: 11.001 D_real: 0.298 D_fake: 0.572 \n",
      "(epoch: 1, iters: 300, time: 0.518, data: 0.001) G_GAN: 2.034 G_L1: 11.444 D_real: 0.230 D_fake: 0.266 \n",
      "(epoch: 1, iters: 400, time: 0.666, data: 0.001) G_GAN: 1.769 G_L1: 10.809 D_real: 0.091 D_fake: 0.514 \n",
      "(epoch: 1, iters: 500, time: 0.520, data: 0.001) G_GAN: 0.827 G_L1: 8.780 D_real: 0.114 D_fake: 1.158 \n",
      "(epoch: 1, iters: 600, time: 0.519, data: 0.002) G_GAN: 0.688 G_L1: 6.733 D_real: 0.220 D_fake: 1.640 \n",
      "(epoch: 1, iters: 700, time: 0.518, data: 0.001) G_GAN: 1.037 G_L1: 8.832 D_real: 0.313 D_fake: 0.451 \n",
      "(epoch: 1, iters: 800, time: 0.646, data: 0.001) G_GAN: 1.182 G_L1: 7.867 D_real: 0.119 D_fake: 0.789 \n",
      "End of epoch 1 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 32, time: 0.518, data: 0.001) G_GAN: 0.644 G_L1: 7.300 D_real: 0.759 D_fake: 0.459 \n",
      "(epoch: 2, iters: 132, time: 0.517, data: 0.001) G_GAN: 1.202 G_L1: 6.981 D_real: 1.388 D_fake: 0.225 \n",
      "(epoch: 2, iters: 232, time: 0.517, data: 0.001) G_GAN: 0.912 G_L1: 8.105 D_real: 0.667 D_fake: 0.303 \n",
      "(epoch: 2, iters: 332, time: 0.668, data: 0.002) G_GAN: 0.815 G_L1: 6.308 D_real: 1.685 D_fake: 0.399 \n",
      "(epoch: 2, iters: 432, time: 0.520, data: 0.002) G_GAN: 0.701 G_L1: 7.445 D_real: 0.639 D_fake: 0.735 \n",
      "(epoch: 2, iters: 532, time: 0.518, data: 0.002) G_GAN: 1.303 G_L1: 9.693 D_real: 0.290 D_fake: 0.354 \n",
      "(epoch: 2, iters: 632, time: 0.517, data: 0.002) G_GAN: 0.893 G_L1: 7.207 D_real: 0.518 D_fake: 0.495 \n",
      "(epoch: 2, iters: 732, time: 0.660, data: 0.002) G_GAN: 0.764 G_L1: 8.068 D_real: 0.178 D_fake: 0.998 \n",
      "(epoch: 2, iters: 832, time: 0.517, data: 0.002) G_GAN: 0.784 G_L1: 7.425 D_real: 0.380 D_fake: 0.586 \n",
      "End of epoch 2 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 64, time: 0.516, data: 0.002) G_GAN: 0.876 G_L1: 5.739 D_real: 0.857 D_fake: 0.464 \n",
      "(epoch: 3, iters: 164, time: 0.518, data: 0.001) G_GAN: 0.745 G_L1: 5.422 D_real: 0.812 D_fake: 0.428 \n",
      "(epoch: 3, iters: 264, time: 0.655, data: 0.002) G_GAN: 1.176 G_L1: 5.624 D_real: 0.693 D_fake: 0.257 \n",
      "(epoch: 3, iters: 364, time: 0.515, data: 0.001) G_GAN: 0.701 G_L1: 6.793 D_real: 0.166 D_fake: 1.655 \n",
      "(epoch: 3, iters: 464, time: 0.518, data: 0.001) G_GAN: 0.680 G_L1: 6.739 D_real: 0.994 D_fake: 0.468 \n",
      "(epoch: 3, iters: 564, time: 0.519, data: 0.002) G_GAN: 0.545 G_L1: 5.630 D_real: 0.266 D_fake: 1.181 \n",
      "(epoch: 3, iters: 664, time: 0.669, data: 0.001) G_GAN: 1.045 G_L1: 6.855 D_real: 0.363 D_fake: 0.849 \n",
      "(epoch: 3, iters: 764, time: 0.517, data: 0.002) G_GAN: 1.054 G_L1: 5.435 D_real: 1.546 D_fake: 0.253 \n",
      "(epoch: 3, iters: 864, time: 0.517, data: 0.002) G_GAN: 0.854 G_L1: 6.013 D_real: 0.354 D_fake: 0.939 \n",
      "End of epoch 3 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 96, time: 0.519, data: 0.002) G_GAN: 1.121 G_L1: 5.805 D_real: 0.654 D_fake: 0.299 \n",
      "(epoch: 4, iters: 196, time: 0.672, data: 0.001) G_GAN: 1.186 G_L1: 7.854 D_real: 0.233 D_fake: 0.528 \n",
      "(epoch: 4, iters: 296, time: 0.515, data: 0.001) G_GAN: 0.923 G_L1: 7.156 D_real: 0.759 D_fake: 0.381 \n",
      "(epoch: 4, iters: 396, time: 0.514, data: 0.001) G_GAN: 0.603 G_L1: 3.070 D_real: 1.336 D_fake: 0.348 \n",
      "(epoch: 4, iters: 496, time: 0.514, data: 0.001) G_GAN: 1.037 G_L1: 4.984 D_real: 0.883 D_fake: 0.439 \n",
      "(epoch: 4, iters: 596, time: 0.654, data: 0.002) G_GAN: 0.797 G_L1: 6.808 D_real: 0.868 D_fake: 0.459 \n",
      "(epoch: 4, iters: 696, time: 0.517, data: 0.002) G_GAN: 0.994 G_L1: 7.135 D_real: 0.332 D_fake: 0.388 \n",
      "(epoch: 4, iters: 796, time: 0.516, data: 0.001) G_GAN: 1.118 G_L1: 5.890 D_real: 0.884 D_fake: 0.414 \n",
      "End of epoch 4 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 28, time: 0.517, data: 0.002) G_GAN: 0.624 G_L1: 5.494 D_real: 0.778 D_fake: 0.647 \n",
      "(epoch: 5, iters: 128, time: 0.679, data: 0.001) G_GAN: 0.553 G_L1: 5.349 D_real: 0.791 D_fake: 0.683 \n",
      "(epoch: 5, iters: 228, time: 0.518, data: 0.002) G_GAN: 0.861 G_L1: 5.704 D_real: 0.479 D_fake: 0.575 \n",
      "(epoch: 5, iters: 328, time: 0.518, data: 0.001) G_GAN: 0.892 G_L1: 4.802 D_real: 1.189 D_fake: 0.347 \n",
      "(epoch: 5, iters: 428, time: 0.519, data: 0.001) G_GAN: 0.486 G_L1: 5.005 D_real: 0.943 D_fake: 0.406 \n",
      "(epoch: 5, iters: 528, time: 0.658, data: 0.001) G_GAN: 0.969 G_L1: 7.257 D_real: 0.162 D_fake: 0.737 \n",
      "(epoch: 5, iters: 628, time: 0.518, data: 0.001) G_GAN: 0.728 G_L1: 5.340 D_real: 0.449 D_fake: 0.824 \n",
      "(epoch: 5, iters: 728, time: 0.516, data: 0.001) G_GAN: 0.888 G_L1: 6.257 D_real: 0.731 D_fake: 0.610 \n",
      "(epoch: 5, iters: 828, time: 0.517, data: 0.001) G_GAN: 0.849 G_L1: 5.453 D_real: 0.786 D_fake: 0.453 \n",
      "saving the model at the end of epoch 5, iters 4340\n",
      "End of epoch 5 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 60, time: 0.684, data: 0.002) G_GAN: 0.872 G_L1: 7.818 D_real: 0.100 D_fake: 1.138 \n",
      "(epoch: 6, iters: 160, time: 0.519, data: 0.001) G_GAN: 1.153 G_L1: 7.721 D_real: 0.730 D_fake: 0.363 \n",
      "(epoch: 6, iters: 260, time: 0.517, data: 0.002) G_GAN: 0.917 G_L1: 7.393 D_real: 0.484 D_fake: 0.353 \n",
      "(epoch: 6, iters: 360, time: 0.517, data: 0.001) G_GAN: 0.779 G_L1: 5.255 D_real: 0.656 D_fake: 0.560 \n",
      "(epoch: 6, iters: 460, time: 0.637, data: 0.002) G_GAN: 0.854 G_L1: 3.682 D_real: 1.020 D_fake: 0.437 \n",
      "(epoch: 6, iters: 560, time: 0.513, data: 0.002) G_GAN: 0.845 G_L1: 5.487 D_real: 0.827 D_fake: 0.524 \n",
      "(epoch: 6, iters: 660, time: 0.514, data: 0.001) G_GAN: 0.841 G_L1: 3.079 D_real: 0.897 D_fake: 0.473 \n",
      "saving the latest model (epoch 6, total_iters 5000)\n",
      "(epoch: 6, iters: 760, time: 0.517, data: 0.002) G_GAN: 0.758 G_L1: 5.270 D_real: 0.239 D_fake: 1.127 \n",
      "(epoch: 6, iters: 860, time: 0.660, data: 0.002) G_GAN: 0.668 G_L1: 5.138 D_real: 0.553 D_fake: 0.700 \n",
      "End of epoch 6 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 92, time: 0.518, data: 0.002) G_GAN: 0.788 G_L1: 5.791 D_real: 0.398 D_fake: 0.738 \n",
      "(epoch: 7, iters: 192, time: 0.518, data: 0.001) G_GAN: 1.025 G_L1: 8.675 D_real: 0.132 D_fake: 0.600 \n",
      "(epoch: 7, iters: 292, time: 0.517, data: 0.001) G_GAN: 0.941 G_L1: 6.377 D_real: 0.433 D_fake: 0.695 \n",
      "(epoch: 7, iters: 392, time: 0.674, data: 0.001) G_GAN: 0.743 G_L1: 5.083 D_real: 0.422 D_fake: 0.853 \n",
      "(epoch: 7, iters: 492, time: 0.517, data: 0.002) G_GAN: 0.938 G_L1: 5.501 D_real: 0.870 D_fake: 0.412 \n",
      "(epoch: 7, iters: 592, time: 0.514, data: 0.002) G_GAN: 1.217 G_L1: 5.777 D_real: 0.620 D_fake: 0.491 \n",
      "(epoch: 7, iters: 692, time: 0.517, data: 0.002) G_GAN: 0.831 G_L1: 4.903 D_real: 0.943 D_fake: 0.365 \n",
      "(epoch: 7, iters: 792, time: 0.673, data: 0.001) G_GAN: 0.597 G_L1: 5.060 D_real: 0.633 D_fake: 0.721 \n",
      "End of epoch 7 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 24, time: 0.519, data: 0.001) G_GAN: 0.912 G_L1: 5.569 D_real: 0.943 D_fake: 0.449 \n",
      "(epoch: 8, iters: 124, time: 0.516, data: 0.002) G_GAN: 0.847 G_L1: 5.172 D_real: 0.658 D_fake: 0.647 \n",
      "(epoch: 8, iters: 224, time: 0.517, data: 0.002) G_GAN: 1.033 G_L1: 5.714 D_real: 0.682 D_fake: 0.369 \n",
      "(epoch: 8, iters: 324, time: 0.652, data: 0.001) G_GAN: 0.680 G_L1: 5.125 D_real: 0.533 D_fake: 0.693 \n",
      "(epoch: 8, iters: 424, time: 0.518, data: 0.002) G_GAN: 0.670 G_L1: 4.721 D_real: 0.708 D_fake: 0.798 \n",
      "(epoch: 8, iters: 524, time: 0.517, data: 0.001) G_GAN: 0.960 G_L1: 6.660 D_real: 0.387 D_fake: 0.585 \n",
      "(epoch: 8, iters: 624, time: 0.521, data: 0.002) G_GAN: 0.778 G_L1: 4.737 D_real: 0.379 D_fake: 0.686 \n",
      "(epoch: 8, iters: 724, time: 0.667, data: 0.002) G_GAN: 0.988 G_L1: 5.461 D_real: 0.992 D_fake: 0.401 \n",
      "(epoch: 8, iters: 824, time: 0.517, data: 0.002) G_GAN: 1.051 G_L1: 4.665 D_real: 0.950 D_fake: 0.383 \n",
      "End of epoch 8 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 56, time: 0.517, data: 0.001) G_GAN: 0.777 G_L1: 4.781 D_real: 0.708 D_fake: 0.521 \n",
      "(epoch: 9, iters: 156, time: 0.517, data: 0.001) G_GAN: 0.645 G_L1: 4.056 D_real: 1.333 D_fake: 0.379 \n",
      "(epoch: 9, iters: 256, time: 0.674, data: 0.002) G_GAN: 0.760 G_L1: 4.725 D_real: 0.863 D_fake: 0.470 \n",
      "(epoch: 9, iters: 356, time: 0.517, data: 0.002) G_GAN: 0.805 G_L1: 5.367 D_real: 0.717 D_fake: 0.422 \n",
      "(epoch: 9, iters: 456, time: 0.520, data: 0.002) G_GAN: 0.869 G_L1: 4.996 D_real: 0.448 D_fake: 0.905 \n",
      "(epoch: 9, iters: 556, time: 0.519, data: 0.002) G_GAN: 0.955 G_L1: 6.609 D_real: 0.637 D_fake: 0.689 \n",
      "(epoch: 9, iters: 656, time: 0.667, data: 0.002) G_GAN: 0.708 G_L1: 4.650 D_real: 0.535 D_fake: 0.674 \n",
      "(epoch: 9, iters: 756, time: 0.517, data: 0.001) G_GAN: 0.858 G_L1: 5.905 D_real: 0.605 D_fake: 0.520 \n",
      "(epoch: 9, iters: 856, time: 0.517, data: 0.002) G_GAN: 1.358 G_L1: 10.345 D_real: 0.243 D_fake: 0.799 \n",
      "End of epoch 9 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 88, time: 0.518, data: 0.001) G_GAN: 0.891 G_L1: 6.158 D_real: 0.375 D_fake: 0.832 \n",
      "(epoch: 10, iters: 188, time: 0.686, data: 0.001) G_GAN: 0.692 G_L1: 4.907 D_real: 0.780 D_fake: 0.625 \n",
      "(epoch: 10, iters: 288, time: 0.517, data: 0.002) G_GAN: 0.873 G_L1: 6.407 D_real: 0.462 D_fake: 0.562 \n",
      "(epoch: 10, iters: 388, time: 0.520, data: 0.001) G_GAN: 0.842 G_L1: 4.377 D_real: 1.006 D_fake: 0.391 \n",
      "(epoch: 10, iters: 488, time: 0.516, data: 0.001) G_GAN: 0.600 G_L1: 4.865 D_real: 0.567 D_fake: 0.664 \n",
      "(epoch: 10, iters: 588, time: 0.691, data: 0.002) G_GAN: 0.791 G_L1: 4.339 D_real: 0.838 D_fake: 0.429 \n",
      "(epoch: 10, iters: 688, time: 0.517, data: 0.002) G_GAN: 0.733 G_L1: 3.904 D_real: 0.536 D_fake: 0.673 \n",
      "(epoch: 10, iters: 788, time: 0.517, data: 0.002) G_GAN: 0.713 G_L1: 5.892 D_real: 0.852 D_fake: 0.386 \n",
      "saving the model at the end of epoch 10, iters 8680\n",
      "End of epoch 10 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 20, time: 0.518, data: 0.001) G_GAN: 0.916 G_L1: 4.175 D_real: 0.280 D_fake: 1.045 \n",
      "(epoch: 11, iters: 120, time: 0.680, data: 0.002) G_GAN: 1.172 G_L1: 6.559 D_real: 0.465 D_fake: 0.478 \n",
      "(epoch: 11, iters: 220, time: 0.518, data: 0.001) G_GAN: 1.101 G_L1: 5.463 D_real: 0.263 D_fake: 1.102 \n",
      "(epoch: 11, iters: 320, time: 0.520, data: 0.002) G_GAN: 0.828 G_L1: 4.672 D_real: 0.604 D_fake: 0.511 \n",
      "(epoch: 11, iters: 420, time: 0.517, data: 0.002) G_GAN: 0.695 G_L1: 5.178 D_real: 0.570 D_fake: 0.511 \n",
      "(epoch: 11, iters: 520, time: 0.661, data: 0.001) G_GAN: 1.416 G_L1: 6.369 D_real: 0.199 D_fake: 1.047 \n",
      "(epoch: 11, iters: 620, time: 0.520, data: 0.002) G_GAN: 0.881 G_L1: 4.534 D_real: 0.440 D_fake: 0.806 \n",
      "(epoch: 11, iters: 720, time: 0.520, data: 0.002) G_GAN: 0.824 G_L1: 4.674 D_real: 0.633 D_fake: 0.687 \n",
      "(epoch: 11, iters: 820, time: 0.519, data: 0.001) G_GAN: 0.731 G_L1: 4.454 D_real: 0.386 D_fake: 1.014 \n",
      "End of epoch 11 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 52, time: 0.659, data: 0.001) G_GAN: 0.707 G_L1: 4.797 D_real: 1.037 D_fake: 0.419 \n",
      "(epoch: 12, iters: 152, time: 0.519, data: 0.001) G_GAN: 0.748 G_L1: 3.880 D_real: 0.436 D_fake: 0.743 \n",
      "(epoch: 12, iters: 252, time: 0.529, data: 0.002) G_GAN: 0.401 G_L1: 4.602 D_real: 1.113 D_fake: 0.399 \n",
      "(epoch: 12, iters: 352, time: 0.518, data: 0.001) G_GAN: 0.724 G_L1: 3.841 D_real: 0.864 D_fake: 0.574 \n",
      "(epoch: 12, iters: 452, time: 0.668, data: 0.001) G_GAN: 1.394 G_L1: 5.400 D_real: 0.402 D_fake: 1.008 \n",
      "saving the latest model (epoch 12, total_iters 10000)\n",
      "(epoch: 12, iters: 552, time: 0.517, data: 0.002) G_GAN: 1.064 G_L1: 5.297 D_real: 0.576 D_fake: 0.620 \n",
      "(epoch: 12, iters: 652, time: 0.519, data: 0.002) G_GAN: 0.733 G_L1: 4.209 D_real: 1.263 D_fake: 0.278 \n",
      "(epoch: 12, iters: 752, time: 0.516, data: 0.002) G_GAN: 0.866 G_L1: 6.457 D_real: 0.332 D_fake: 0.827 \n",
      "(epoch: 12, iters: 852, time: 0.669, data: 0.002) G_GAN: 0.956 G_L1: 5.734 D_real: 0.786 D_fake: 0.373 \n",
      "End of epoch 12 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 84, time: 0.514, data: 0.001) G_GAN: 0.868 G_L1: 4.600 D_real: 0.592 D_fake: 0.564 \n",
      "(epoch: 13, iters: 184, time: 0.517, data: 0.001) G_GAN: 0.745 G_L1: 4.189 D_real: 0.832 D_fake: 0.527 \n",
      "(epoch: 13, iters: 284, time: 0.518, data: 0.001) G_GAN: 0.808 G_L1: 5.028 D_real: 0.266 D_fake: 1.149 \n",
      "(epoch: 13, iters: 384, time: 0.672, data: 0.001) G_GAN: 0.852 G_L1: 4.704 D_real: 1.109 D_fake: 0.471 \n",
      "(epoch: 13, iters: 484, time: 0.515, data: 0.002) G_GAN: 0.660 G_L1: 4.902 D_real: 0.558 D_fake: 0.629 \n",
      "(epoch: 13, iters: 584, time: 0.518, data: 0.001) G_GAN: 0.906 G_L1: 4.343 D_real: 0.646 D_fake: 0.651 \n",
      "(epoch: 13, iters: 684, time: 0.516, data: 0.001) G_GAN: 0.814 G_L1: 5.273 D_real: 0.524 D_fake: 0.536 \n",
      "(epoch: 13, iters: 784, time: 0.664, data: 0.001) G_GAN: 0.780 G_L1: 4.380 D_real: 1.108 D_fake: 0.351 \n",
      "End of epoch 13 / 100 \t Time Taken: 294 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 16, time: 0.518, data: 0.001) G_GAN: 0.884 G_L1: 5.246 D_real: 0.563 D_fake: 0.556 \n",
      "(epoch: 14, iters: 116, time: 0.520, data: 0.002) G_GAN: 0.857 G_L1: 7.279 D_real: 0.508 D_fake: 0.600 \n",
      "(epoch: 14, iters: 216, time: 0.519, data: 0.002) G_GAN: 0.817 G_L1: 3.873 D_real: 0.769 D_fake: 0.619 \n",
      "(epoch: 14, iters: 316, time: 0.652, data: 0.001) G_GAN: 0.952 G_L1: 2.170 D_real: 0.890 D_fake: 0.407 \n",
      "(epoch: 14, iters: 416, time: 0.524, data: 0.001) G_GAN: 0.941 G_L1: 4.540 D_real: 0.313 D_fake: 0.906 \n",
      "(epoch: 14, iters: 516, time: 0.518, data: 0.002) G_GAN: 0.701 G_L1: 4.091 D_real: 0.680 D_fake: 0.810 \n",
      "(epoch: 14, iters: 616, time: 0.516, data: 0.002) G_GAN: 0.727 G_L1: 4.898 D_real: 1.128 D_fake: 0.367 \n",
      "(epoch: 14, iters: 716, time: 0.702, data: 0.001) G_GAN: 0.669 G_L1: 5.006 D_real: 0.755 D_fake: 0.480 \n",
      "(epoch: 14, iters: 816, time: 0.520, data: 0.002) G_GAN: 0.581 G_L1: 3.398 D_real: 0.744 D_fake: 0.629 \n",
      "End of epoch 14 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 48, time: 0.516, data: 0.002) G_GAN: 1.142 G_L1: 5.448 D_real: 0.224 D_fake: 0.927 \n",
      "(epoch: 15, iters: 148, time: 0.517, data: 0.001) G_GAN: 0.792 G_L1: 4.452 D_real: 0.683 D_fake: 0.653 \n",
      "(epoch: 15, iters: 248, time: 0.690, data: 0.001) G_GAN: 0.730 G_L1: 3.991 D_real: 0.906 D_fake: 0.705 \n",
      "(epoch: 15, iters: 348, time: 0.516, data: 0.002) G_GAN: 0.590 G_L1: 3.366 D_real: 0.924 D_fake: 0.602 \n",
      "(epoch: 15, iters: 448, time: 0.517, data: 0.002) G_GAN: 0.616 G_L1: 4.490 D_real: 0.833 D_fake: 0.549 \n",
      "(epoch: 15, iters: 548, time: 0.519, data: 0.001) G_GAN: 0.825 G_L1: 4.602 D_real: 0.517 D_fake: 0.638 \n",
      "(epoch: 15, iters: 648, time: 0.687, data: 0.001) G_GAN: 0.687 G_L1: 4.190 D_real: 0.571 D_fake: 0.934 \n",
      "(epoch: 15, iters: 748, time: 0.521, data: 0.001) G_GAN: 0.690 G_L1: 5.023 D_real: 0.875 D_fake: 0.474 \n",
      "(epoch: 15, iters: 848, time: 0.515, data: 0.002) G_GAN: 0.759 G_L1: 5.181 D_real: 0.628 D_fake: 0.514 \n",
      "saving the model at the end of epoch 15, iters 13020\n",
      "End of epoch 15 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 80, time: 0.517, data: 0.001) G_GAN: 0.973 G_L1: 2.628 D_real: 1.439 D_fake: 0.289 \n",
      "(epoch: 16, iters: 180, time: 0.694, data: 0.002) G_GAN: 0.683 G_L1: 3.703 D_real: 0.773 D_fake: 0.628 \n",
      "(epoch: 16, iters: 280, time: 0.517, data: 0.001) G_GAN: 1.018 G_L1: 4.121 D_real: 0.285 D_fake: 1.092 \n",
      "(epoch: 16, iters: 380, time: 0.517, data: 0.002) G_GAN: 0.790 G_L1: 4.342 D_real: 0.983 D_fake: 0.520 \n",
      "(epoch: 16, iters: 480, time: 0.518, data: 0.002) G_GAN: 0.773 G_L1: 4.063 D_real: 0.549 D_fake: 0.636 \n",
      "(epoch: 16, iters: 580, time: 0.693, data: 0.001) G_GAN: 0.736 G_L1: 4.517 D_real: 0.914 D_fake: 0.505 \n",
      "(epoch: 16, iters: 680, time: 0.517, data: 0.002) G_GAN: 0.770 G_L1: 4.602 D_real: 0.778 D_fake: 0.488 \n",
      "(epoch: 16, iters: 780, time: 0.518, data: 0.001) G_GAN: 0.780 G_L1: 2.084 D_real: 0.668 D_fake: 0.677 \n",
      "End of epoch 16 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 12, time: 0.520, data: 0.002) G_GAN: 0.793 G_L1: 4.175 D_real: 0.772 D_fake: 0.430 \n",
      "(epoch: 17, iters: 112, time: 0.673, data: 0.001) G_GAN: 0.850 G_L1: 3.819 D_real: 0.358 D_fake: 1.001 \n",
      "(epoch: 17, iters: 212, time: 0.517, data: 0.002) G_GAN: 1.522 G_L1: 6.228 D_real: 0.162 D_fake: 1.222 \n",
      "(epoch: 17, iters: 312, time: 0.520, data: 0.002) G_GAN: 0.792 G_L1: 4.069 D_real: 0.616 D_fake: 0.629 \n",
      "(epoch: 17, iters: 412, time: 0.527, data: 0.002) G_GAN: 0.667 G_L1: 4.792 D_real: 0.611 D_fake: 0.373 \n",
      "(epoch: 17, iters: 512, time: 0.698, data: 0.002) G_GAN: 0.854 G_L1: 4.391 D_real: 0.643 D_fake: 0.650 \n",
      "(epoch: 17, iters: 612, time: 0.517, data: 0.001) G_GAN: 0.722 G_L1: 5.140 D_real: 0.633 D_fake: 0.428 \n",
      "(epoch: 17, iters: 712, time: 0.516, data: 0.001) G_GAN: 0.678 G_L1: 4.330 D_real: 0.689 D_fake: 0.601 \n",
      "(epoch: 17, iters: 812, time: 0.518, data: 0.002) G_GAN: 0.822 G_L1: 3.721 D_real: 0.394 D_fake: 0.897 \n",
      "End of epoch 17 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 44, time: 0.688, data: 0.001) G_GAN: 0.925 G_L1: 4.350 D_real: 0.925 D_fake: 0.456 \n",
      "(epoch: 18, iters: 144, time: 0.516, data: 0.001) G_GAN: 0.720 G_L1: 3.235 D_real: 0.670 D_fake: 0.660 \n",
      "(epoch: 18, iters: 244, time: 0.518, data: 0.002) G_GAN: 0.743 G_L1: 4.221 D_real: 0.969 D_fake: 0.491 \n",
      "saving the latest model (epoch 18, total_iters 15000)\n",
      "(epoch: 18, iters: 344, time: 0.519, data: 0.003) G_GAN: 1.000 G_L1: 5.652 D_real: 0.365 D_fake: 0.760 \n",
      "(epoch: 18, iters: 444, time: 0.713, data: 0.001) G_GAN: 0.621 G_L1: 3.836 D_real: 0.768 D_fake: 0.546 \n",
      "(epoch: 18, iters: 544, time: 0.519, data: 0.002) G_GAN: 0.787 G_L1: 3.364 D_real: 0.950 D_fake: 0.453 \n",
      "(epoch: 18, iters: 644, time: 0.520, data: 0.002) G_GAN: 0.892 G_L1: 4.123 D_real: 0.410 D_fake: 0.901 \n",
      "(epoch: 18, iters: 744, time: 0.517, data: 0.002) G_GAN: 0.739 G_L1: 3.636 D_real: 0.455 D_fake: 0.981 \n",
      "(epoch: 18, iters: 844, time: 0.705, data: 0.002) G_GAN: 1.061 G_L1: 5.023 D_real: 0.569 D_fake: 0.401 \n",
      "End of epoch 18 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 76, time: 0.517, data: 0.002) G_GAN: 1.005 G_L1: 3.913 D_real: 0.411 D_fake: 0.812 \n",
      "(epoch: 19, iters: 176, time: 0.518, data: 0.002) G_GAN: 0.824 G_L1: 3.659 D_real: 0.680 D_fake: 0.817 \n",
      "(epoch: 19, iters: 276, time: 0.520, data: 0.002) G_GAN: 0.914 G_L1: 2.791 D_real: 0.921 D_fake: 0.454 \n",
      "(epoch: 19, iters: 376, time: 0.684, data: 0.002) G_GAN: 1.355 G_L1: 6.167 D_real: 0.190 D_fake: 1.022 \n",
      "(epoch: 19, iters: 476, time: 0.517, data: 0.002) G_GAN: 0.949 G_L1: 4.687 D_real: 0.176 D_fake: 1.665 \n",
      "(epoch: 19, iters: 576, time: 0.519, data: 0.002) G_GAN: 1.011 G_L1: 4.629 D_real: 0.401 D_fake: 0.894 \n",
      "(epoch: 19, iters: 676, time: 0.518, data: 0.002) G_GAN: 0.820 G_L1: 3.795 D_real: 0.662 D_fake: 0.589 \n",
      "(epoch: 19, iters: 776, time: 0.664, data: 0.001) G_GAN: 0.709 G_L1: 1.782 D_real: 0.826 D_fake: 0.524 \n",
      "End of epoch 19 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 8, time: 0.519, data: 0.002) G_GAN: 0.747 G_L1: 3.344 D_real: 0.692 D_fake: 0.762 \n",
      "(epoch: 20, iters: 108, time: 0.517, data: 0.002) G_GAN: 0.760 G_L1: 3.491 D_real: 0.616 D_fake: 0.774 \n",
      "(epoch: 20, iters: 208, time: 0.517, data: 0.001) G_GAN: 0.700 G_L1: 3.241 D_real: 0.667 D_fake: 0.644 \n",
      "(epoch: 20, iters: 308, time: 0.708, data: 0.002) G_GAN: 0.873 G_L1: 4.044 D_real: 0.718 D_fake: 0.462 \n",
      "(epoch: 20, iters: 408, time: 0.515, data: 0.002) G_GAN: 0.703 G_L1: 1.930 D_real: 1.148 D_fake: 0.429 \n",
      "(epoch: 20, iters: 508, time: 0.516, data: 0.002) G_GAN: 0.789 G_L1: 3.985 D_real: 0.681 D_fake: 0.744 \n",
      "(epoch: 20, iters: 608, time: 0.520, data: 0.002) G_GAN: 0.946 G_L1: 4.301 D_real: 0.588 D_fake: 0.569 \n",
      "(epoch: 20, iters: 708, time: 0.700, data: 0.002) G_GAN: 0.638 G_L1: 3.385 D_real: 0.813 D_fake: 0.724 \n",
      "(epoch: 20, iters: 808, time: 0.515, data: 0.002) G_GAN: 0.766 G_L1: 4.329 D_real: 0.443 D_fake: 0.680 \n",
      "saving the model at the end of epoch 20, iters 17360\n",
      "End of epoch 20 / 100 \t Time Taken: 292 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 40, time: 0.516, data: 0.001) G_GAN: 0.873 G_L1: 4.242 D_real: 0.233 D_fake: 1.397 \n",
      "(epoch: 21, iters: 140, time: 0.519, data: 0.002) G_GAN: 0.892 G_L1: 2.860 D_real: 0.882 D_fake: 0.520 \n",
      "(epoch: 21, iters: 240, time: 0.721, data: 0.002) G_GAN: 0.788 G_L1: 2.535 D_real: 1.080 D_fake: 0.371 \n",
      "(epoch: 21, iters: 340, time: 0.516, data: 0.001) G_GAN: 1.051 G_L1: 5.295 D_real: 0.814 D_fake: 0.364 \n",
      "(epoch: 21, iters: 440, time: 0.519, data: 0.002) G_GAN: 0.690 G_L1: 3.578 D_real: 0.727 D_fake: 0.560 \n",
      "(epoch: 21, iters: 540, time: 0.519, data: 0.001) G_GAN: 0.748 G_L1: 3.917 D_real: 0.696 D_fake: 0.844 \n",
      "(epoch: 21, iters: 640, time: 0.677, data: 0.002) G_GAN: 0.692 G_L1: 3.376 D_real: 0.768 D_fake: 0.863 \n",
      "(epoch: 21, iters: 740, time: 0.517, data: 0.002) G_GAN: 0.796 G_L1: 3.105 D_real: 0.688 D_fake: 0.678 \n",
      "(epoch: 21, iters: 840, time: 0.518, data: 0.002) G_GAN: 0.830 G_L1: 3.294 D_real: 1.147 D_fake: 0.316 \n",
      "End of epoch 21 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 72, time: 0.520, data: 0.002) G_GAN: 0.967 G_L1: 4.456 D_real: 0.454 D_fake: 0.626 \n",
      "(epoch: 22, iters: 172, time: 0.693, data: 0.002) G_GAN: 1.007 G_L1: 4.484 D_real: 0.771 D_fake: 0.451 \n",
      "(epoch: 22, iters: 272, time: 0.518, data: 0.001) G_GAN: 1.208 G_L1: 5.479 D_real: 0.474 D_fake: 0.467 \n",
      "(epoch: 22, iters: 372, time: 0.519, data: 0.002) G_GAN: 0.872 G_L1: 3.631 D_real: 0.971 D_fake: 0.419 \n",
      "(epoch: 22, iters: 472, time: 0.520, data: 0.002) G_GAN: 0.772 G_L1: 3.813 D_real: 0.716 D_fake: 0.616 \n",
      "(epoch: 22, iters: 572, time: 0.705, data: 0.002) G_GAN: 0.745 G_L1: 3.514 D_real: 0.670 D_fake: 0.738 \n",
      "(epoch: 22, iters: 672, time: 0.519, data: 0.002) G_GAN: 1.114 G_L1: 4.220 D_real: 0.913 D_fake: 0.251 \n",
      "(epoch: 22, iters: 772, time: 0.520, data: 0.002) G_GAN: 0.720 G_L1: 3.425 D_real: 0.719 D_fake: 0.598 \n",
      "End of epoch 22 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 4, time: 0.516, data: 0.002) G_GAN: 0.651 G_L1: 3.631 D_real: 0.700 D_fake: 0.756 \n",
      "(epoch: 23, iters: 104, time: 0.719, data: 0.001) G_GAN: 1.537 G_L1: 6.065 D_real: 0.126 D_fake: 1.237 \n",
      "(epoch: 23, iters: 204, time: 0.529, data: 0.002) G_GAN: 0.788 G_L1: 4.332 D_real: 0.494 D_fake: 0.627 \n",
      "(epoch: 23, iters: 304, time: 0.520, data: 0.001) G_GAN: 0.758 G_L1: 2.826 D_real: 0.706 D_fake: 0.677 \n",
      "(epoch: 23, iters: 404, time: 0.518, data: 0.002) G_GAN: 1.567 G_L1: 5.374 D_real: 0.112 D_fake: 1.069 \n",
      "(epoch: 23, iters: 504, time: 0.688, data: 0.002) G_GAN: 0.840 G_L1: 3.696 D_real: 0.599 D_fake: 0.533 \n",
      "(epoch: 23, iters: 604, time: 0.518, data: 0.002) G_GAN: 0.818 G_L1: 4.194 D_real: 0.838 D_fake: 0.483 \n",
      "(epoch: 23, iters: 704, time: 0.518, data: 0.002) G_GAN: 0.822 G_L1: 4.647 D_real: 0.803 D_fake: 0.454 \n",
      "(epoch: 23, iters: 804, time: 0.542, data: 0.002) G_GAN: 0.804 G_L1: 3.705 D_real: 0.738 D_fake: 0.625 \n",
      "End of epoch 23 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 36, time: 0.689, data: 0.002) G_GAN: 0.943 G_L1: 4.154 D_real: 0.447 D_fake: 0.670 \n",
      "saving the latest model (epoch 24, total_iters 20000)\n",
      "(epoch: 24, iters: 136, time: 0.518, data: 0.001) G_GAN: 0.701 G_L1: 2.895 D_real: 0.789 D_fake: 0.592 \n",
      "(epoch: 24, iters: 236, time: 0.520, data: 0.002) G_GAN: 0.229 G_L1: 3.979 D_real: 1.080 D_fake: 0.471 \n",
      "(epoch: 24, iters: 336, time: 0.520, data: 0.002) G_GAN: 1.011 G_L1: 3.898 D_real: 0.808 D_fake: 0.378 \n",
      "(epoch: 24, iters: 436, time: 0.684, data: 0.001) G_GAN: 0.805 G_L1: 3.961 D_real: 0.786 D_fake: 0.511 \n",
      "(epoch: 24, iters: 536, time: 0.519, data: 0.001) G_GAN: 1.220 G_L1: 3.695 D_real: 1.576 D_fake: 0.155 \n",
      "(epoch: 24, iters: 636, time: 0.519, data: 0.002) G_GAN: 0.847 G_L1: 4.151 D_real: 0.421 D_fake: 0.762 \n",
      "(epoch: 24, iters: 736, time: 0.519, data: 0.002) G_GAN: 0.971 G_L1: 4.776 D_real: 0.631 D_fake: 0.586 \n",
      "(epoch: 24, iters: 836, time: 0.703, data: 0.002) G_GAN: 0.779 G_L1: 3.321 D_real: 0.536 D_fake: 0.819 \n",
      "End of epoch 24 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 68, time: 0.518, data: 0.002) G_GAN: 0.742 G_L1: 3.407 D_real: 0.539 D_fake: 0.948 \n",
      "(epoch: 25, iters: 168, time: 0.521, data: 0.002) G_GAN: 0.626 G_L1: 4.232 D_real: 0.923 D_fake: 0.446 \n",
      "(epoch: 25, iters: 268, time: 0.516, data: 0.001) G_GAN: 0.794 G_L1: 3.710 D_real: 0.713 D_fake: 0.576 \n",
      "(epoch: 25, iters: 368, time: 0.722, data: 0.002) G_GAN: 0.682 G_L1: 3.285 D_real: 0.485 D_fake: 0.997 \n",
      "(epoch: 25, iters: 468, time: 0.518, data: 0.002) G_GAN: 0.669 G_L1: 2.928 D_real: 0.530 D_fake: 0.874 \n",
      "(epoch: 25, iters: 568, time: 0.517, data: 0.001) G_GAN: 0.581 G_L1: 2.755 D_real: 0.959 D_fake: 0.456 \n",
      "(epoch: 25, iters: 668, time: 0.519, data: 0.002) G_GAN: 0.807 G_L1: 2.637 D_real: 0.429 D_fake: 1.040 \n",
      "(epoch: 25, iters: 768, time: 0.714, data: 0.001) G_GAN: 0.807 G_L1: 3.788 D_real: 0.535 D_fake: 0.550 \n",
      "(epoch: 25, iters: 868, time: 0.516, data: 0.002) G_GAN: 1.135 G_L1: 5.060 D_real: 0.456 D_fake: 0.659 \n",
      "saving the model at the end of epoch 25, iters 21700\n",
      "End of epoch 25 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.532, data: 0.093) G_GAN: 1.465 G_L1: 4.934 D_real: 0.171 D_fake: 1.125 \n",
      "(epoch: 26, iters: 200, time: 0.521, data: 0.001) G_GAN: 1.185 G_L1: 4.496 D_real: 0.308 D_fake: 0.882 \n",
      "(epoch: 26, iters: 300, time: 0.695, data: 0.002) G_GAN: 0.987 G_L1: 4.434 D_real: 0.282 D_fake: 0.924 \n",
      "(epoch: 26, iters: 400, time: 0.516, data: 0.001) G_GAN: 0.912 G_L1: 3.835 D_real: 0.561 D_fake: 0.585 \n",
      "(epoch: 26, iters: 500, time: 0.518, data: 0.002) G_GAN: 0.495 G_L1: 4.208 D_real: 1.070 D_fake: 0.453 \n",
      "(epoch: 26, iters: 600, time: 0.519, data: 0.001) G_GAN: 1.025 G_L1: 4.016 D_real: 0.391 D_fake: 0.950 \n",
      "(epoch: 26, iters: 700, time: 0.707, data: 0.002) G_GAN: 0.834 G_L1: 3.064 D_real: 0.592 D_fake: 0.753 \n",
      "(epoch: 26, iters: 800, time: 0.518, data: 0.002) G_GAN: 0.752 G_L1: 3.803 D_real: 1.158 D_fake: 0.451 \n",
      "End of epoch 26 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 32, time: 0.521, data: 0.002) G_GAN: 1.058 G_L1: 3.731 D_real: 0.459 D_fake: 0.971 \n",
      "(epoch: 27, iters: 132, time: 0.520, data: 0.002) G_GAN: 0.844 G_L1: 4.106 D_real: 0.648 D_fake: 0.568 \n",
      "(epoch: 27, iters: 232, time: 0.704, data: 0.001) G_GAN: 1.035 G_L1: 4.621 D_real: 0.451 D_fake: 0.691 \n",
      "(epoch: 27, iters: 332, time: 0.518, data: 0.002) G_GAN: 0.842 G_L1: 4.390 D_real: 0.477 D_fake: 0.743 \n",
      "(epoch: 27, iters: 432, time: 0.518, data: 0.002) G_GAN: 0.920 G_L1: 2.977 D_real: 0.674 D_fake: 0.530 \n",
      "(epoch: 27, iters: 532, time: 0.520, data: 0.002) G_GAN: 0.921 G_L1: 4.092 D_real: 0.584 D_fake: 0.600 \n",
      "(epoch: 27, iters: 632, time: 0.705, data: 0.002) G_GAN: 0.721 G_L1: 3.438 D_real: 0.568 D_fake: 0.777 \n",
      "(epoch: 27, iters: 732, time: 0.518, data: 0.002) G_GAN: 0.823 G_L1: 3.023 D_real: 0.656 D_fake: 0.640 \n",
      "(epoch: 27, iters: 832, time: 0.515, data: 0.002) G_GAN: 0.984 G_L1: 3.852 D_real: 0.480 D_fake: 0.730 \n",
      "End of epoch 27 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 64, time: 0.515, data: 0.001) G_GAN: 0.528 G_L1: 3.448 D_real: 0.941 D_fake: 0.402 \n",
      "(epoch: 28, iters: 164, time: 0.741, data: 0.002) G_GAN: 0.737 G_L1: 3.414 D_real: 0.812 D_fake: 0.668 \n",
      "(epoch: 28, iters: 264, time: 0.519, data: 0.001) G_GAN: 0.953 G_L1: 3.844 D_real: 0.411 D_fake: 0.778 \n",
      "(epoch: 28, iters: 364, time: 0.520, data: 0.002) G_GAN: 0.776 G_L1: 4.004 D_real: 0.609 D_fake: 0.576 \n",
      "(epoch: 28, iters: 464, time: 0.516, data: 0.002) G_GAN: 0.971 G_L1: 3.577 D_real: 0.749 D_fake: 0.667 \n",
      "(epoch: 28, iters: 564, time: 0.719, data: 0.001) G_GAN: 0.758 G_L1: 3.703 D_real: 0.676 D_fake: 0.564 \n",
      "(epoch: 28, iters: 664, time: 0.518, data: 0.002) G_GAN: 0.676 G_L1: 1.864 D_real: 0.616 D_fake: 0.725 \n",
      "(epoch: 28, iters: 764, time: 0.519, data: 0.002) G_GAN: 0.745 G_L1: 3.142 D_real: 0.622 D_fake: 0.657 \n",
      "(epoch: 28, iters: 864, time: 0.515, data: 0.002) G_GAN: 0.731 G_L1: 2.642 D_real: 0.671 D_fake: 0.831 \n",
      "End of epoch 28 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 96, time: 0.715, data: 0.001) G_GAN: 1.085 G_L1: 4.161 D_real: 0.983 D_fake: 0.421 \n",
      "(epoch: 29, iters: 196, time: 0.519, data: 0.002) G_GAN: 0.829 G_L1: 1.816 D_real: 0.985 D_fake: 0.534 \n",
      "(epoch: 29, iters: 296, time: 0.517, data: 0.002) G_GAN: 0.960 G_L1: 2.495 D_real: 0.758 D_fake: 0.646 \n",
      "(epoch: 29, iters: 396, time: 0.517, data: 0.002) G_GAN: 0.720 G_L1: 2.323 D_real: 0.586 D_fake: 0.861 \n",
      "(epoch: 29, iters: 496, time: 0.724, data: 0.002) G_GAN: 0.635 G_L1: 3.046 D_real: 0.834 D_fake: 0.537 \n",
      "(epoch: 29, iters: 596, time: 0.516, data: 0.002) G_GAN: 0.667 G_L1: 2.692 D_real: 0.791 D_fake: 0.668 \n",
      "(epoch: 29, iters: 696, time: 0.514, data: 0.002) G_GAN: 0.754 G_L1: 3.155 D_real: 0.708 D_fake: 0.608 \n",
      "saving the latest model (epoch 29, total_iters 25000)\n",
      "(epoch: 29, iters: 796, time: 0.514, data: 0.001) G_GAN: 0.950 G_L1: 4.392 D_real: 0.452 D_fake: 0.620 \n",
      "End of epoch 29 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 28, time: 0.731, data: 0.002) G_GAN: 0.870 G_L1: 2.432 D_real: 0.649 D_fake: 0.823 \n",
      "(epoch: 30, iters: 128, time: 0.518, data: 0.002) G_GAN: 0.688 G_L1: 3.445 D_real: 0.619 D_fake: 0.887 \n",
      "(epoch: 30, iters: 228, time: 0.519, data: 0.002) G_GAN: 0.806 G_L1: 2.872 D_real: 0.802 D_fake: 0.530 \n",
      "(epoch: 30, iters: 328, time: 0.517, data: 0.002) G_GAN: 0.751 G_L1: 3.974 D_real: 0.577 D_fake: 0.578 \n",
      "(epoch: 30, iters: 428, time: 0.725, data: 0.002) G_GAN: 0.708 G_L1: 2.102 D_real: 0.702 D_fake: 0.654 \n",
      "(epoch: 30, iters: 528, time: 0.517, data: 0.001) G_GAN: 0.993 G_L1: 4.258 D_real: 0.502 D_fake: 0.775 \n",
      "(epoch: 30, iters: 628, time: 0.517, data: 0.002) G_GAN: 0.729 G_L1: 2.811 D_real: 0.800 D_fake: 0.645 \n",
      "(epoch: 30, iters: 728, time: 0.519, data: 0.001) G_GAN: 1.135 G_L1: 4.385 D_real: 0.115 D_fake: 1.439 \n",
      "(epoch: 30, iters: 828, time: 0.740, data: 0.002) G_GAN: 0.672 G_L1: 3.321 D_real: 0.849 D_fake: 0.514 \n",
      "saving the model at the end of epoch 30, iters 26040\n",
      "End of epoch 30 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 60, time: 0.518, data: 0.002) G_GAN: 0.689 G_L1: 3.297 D_real: 0.588 D_fake: 0.735 \n",
      "(epoch: 31, iters: 160, time: 0.519, data: 0.002) G_GAN: 0.646 G_L1: 3.510 D_real: 0.682 D_fake: 0.666 \n",
      "(epoch: 31, iters: 260, time: 0.516, data: 0.002) G_GAN: 0.797 G_L1: 3.303 D_real: 0.636 D_fake: 0.786 \n",
      "(epoch: 31, iters: 360, time: 0.725, data: 0.002) G_GAN: 0.724 G_L1: 3.599 D_real: 0.902 D_fake: 0.549 \n",
      "(epoch: 31, iters: 460, time: 0.516, data: 0.002) G_GAN: 0.744 G_L1: 2.968 D_real: 0.858 D_fake: 0.575 \n",
      "(epoch: 31, iters: 560, time: 0.516, data: 0.002) G_GAN: 0.996 G_L1: 3.783 D_real: 0.508 D_fake: 0.793 \n",
      "(epoch: 31, iters: 660, time: 0.516, data: 0.002) G_GAN: 1.263 G_L1: 4.845 D_real: 0.322 D_fake: 1.271 \n",
      "(epoch: 31, iters: 760, time: 0.706, data: 0.002) G_GAN: 0.886 G_L1: 3.361 D_real: 0.626 D_fake: 0.708 \n",
      "(epoch: 31, iters: 860, time: 0.517, data: 0.002) G_GAN: 0.705 G_L1: 2.712 D_real: 0.526 D_fake: 0.861 \n",
      "End of epoch 31 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 92, time: 0.516, data: 0.002) G_GAN: 0.959 G_L1: 4.361 D_real: 0.478 D_fake: 0.610 \n",
      "(epoch: 32, iters: 192, time: 0.518, data: 0.001) G_GAN: 0.879 G_L1: 3.464 D_real: 0.547 D_fake: 0.672 \n",
      "(epoch: 32, iters: 292, time: 0.721, data: 0.002) G_GAN: 0.729 G_L1: 3.975 D_real: 0.662 D_fake: 0.539 \n",
      "(epoch: 32, iters: 392, time: 0.516, data: 0.002) G_GAN: 0.676 G_L1: 3.323 D_real: 0.623 D_fake: 0.788 \n",
      "(epoch: 32, iters: 492, time: 0.516, data: 0.002) G_GAN: 0.921 G_L1: 4.708 D_real: 0.745 D_fake: 0.499 \n",
      "(epoch: 32, iters: 592, time: 0.521, data: 0.002) G_GAN: 0.514 G_L1: 2.556 D_real: 0.875 D_fake: 0.539 \n",
      "(epoch: 32, iters: 692, time: 0.724, data: 0.002) G_GAN: 0.774 G_L1: 2.558 D_real: 0.614 D_fake: 0.766 \n",
      "(epoch: 32, iters: 792, time: 0.516, data: 0.001) G_GAN: 1.043 G_L1: 3.973 D_real: 0.334 D_fake: 0.967 \n",
      "End of epoch 32 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 24, time: 0.517, data: 0.002) G_GAN: 0.761 G_L1: 2.559 D_real: 0.740 D_fake: 0.582 \n",
      "(epoch: 33, iters: 124, time: 0.517, data: 0.002) G_GAN: 0.739 G_L1: 2.488 D_real: 0.557 D_fake: 0.784 \n",
      "(epoch: 33, iters: 224, time: 0.728, data: 0.001) G_GAN: 0.706 G_L1: 3.110 D_real: 0.558 D_fake: 0.796 \n",
      "(epoch: 33, iters: 324, time: 0.517, data: 0.002) G_GAN: 0.561 G_L1: 2.171 D_real: 0.646 D_fake: 0.750 \n",
      "(epoch: 33, iters: 424, time: 0.517, data: 0.002) G_GAN: 0.806 G_L1: 2.457 D_real: 0.638 D_fake: 0.705 \n",
      "(epoch: 33, iters: 524, time: 0.519, data: 0.002) G_GAN: 0.788 G_L1: 3.606 D_real: 1.099 D_fake: 0.356 \n",
      "(epoch: 33, iters: 624, time: 0.743, data: 0.002) G_GAN: 0.705 G_L1: 3.000 D_real: 0.880 D_fake: 0.482 \n",
      "(epoch: 33, iters: 724, time: 0.515, data: 0.002) G_GAN: 0.967 G_L1: 4.472 D_real: 0.422 D_fake: 0.762 \n",
      "(epoch: 33, iters: 824, time: 0.515, data: 0.002) G_GAN: 0.835 G_L1: 3.002 D_real: 0.644 D_fake: 0.624 \n",
      "End of epoch 33 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 56, time: 0.517, data: 0.001) G_GAN: 0.662 G_L1: 2.762 D_real: 0.791 D_fake: 0.517 \n",
      "(epoch: 34, iters: 156, time: 0.750, data: 0.002) G_GAN: 0.744 G_L1: 2.502 D_real: 0.830 D_fake: 0.566 \n",
      "(epoch: 34, iters: 256, time: 0.517, data: 0.002) G_GAN: 0.784 G_L1: 4.753 D_real: 0.463 D_fake: 0.647 \n",
      "(epoch: 34, iters: 356, time: 0.516, data: 0.002) G_GAN: 0.711 G_L1: 2.891 D_real: 0.661 D_fake: 0.642 \n",
      "(epoch: 34, iters: 456, time: 0.517, data: 0.001) G_GAN: 0.889 G_L1: 4.157 D_real: 0.384 D_fake: 0.692 \n",
      "(epoch: 34, iters: 556, time: 0.713, data: 0.002) G_GAN: 0.728 G_L1: 3.082 D_real: 0.782 D_fake: 0.461 \n",
      "(epoch: 34, iters: 656, time: 0.515, data: 0.002) G_GAN: 0.656 G_L1: 2.808 D_real: 0.733 D_fake: 0.699 \n",
      "(epoch: 34, iters: 756, time: 0.519, data: 0.002) G_GAN: 1.123 G_L1: 3.323 D_real: 0.420 D_fake: 0.834 \n",
      "(epoch: 34, iters: 856, time: 0.518, data: 0.002) G_GAN: 0.682 G_L1: 3.571 D_real: 0.716 D_fake: 0.598 \n",
      "End of epoch 34 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 88, time: 0.725, data: 0.002) G_GAN: 0.687 G_L1: 2.806 D_real: 0.847 D_fake: 0.511 \n",
      "(epoch: 35, iters: 188, time: 0.536, data: 0.002) G_GAN: 0.712 G_L1: 3.393 D_real: 0.563 D_fake: 0.601 \n",
      "(epoch: 35, iters: 288, time: 0.518, data: 0.001) G_GAN: 0.751 G_L1: 2.826 D_real: 0.647 D_fake: 0.581 \n",
      "(epoch: 35, iters: 388, time: 0.519, data: 0.002) G_GAN: 0.830 G_L1: 2.505 D_real: 0.586 D_fake: 0.759 \n",
      "(epoch: 35, iters: 488, time: 0.715, data: 0.002) G_GAN: 0.854 G_L1: 4.208 D_real: 0.433 D_fake: 0.806 \n",
      "saving the latest model (epoch 35, total_iters 30000)\n",
      "(epoch: 35, iters: 588, time: 0.519, data: 0.002) G_GAN: 0.855 G_L1: 3.795 D_real: 0.441 D_fake: 0.814 \n",
      "(epoch: 35, iters: 688, time: 0.518, data: 0.002) G_GAN: 0.968 G_L1: 4.579 D_real: 0.511 D_fake: 0.586 \n",
      "(epoch: 35, iters: 788, time: 0.517, data: 0.001) G_GAN: 0.780 G_L1: 2.724 D_real: 0.654 D_fake: 0.687 \n",
      "saving the model at the end of epoch 35, iters 30380\n",
      "End of epoch 35 / 100 \t Time Taken: 293 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 20, time: 0.710, data: 0.001) G_GAN: 0.747 G_L1: 2.484 D_real: 0.803 D_fake: 0.486 \n",
      "(epoch: 36, iters: 120, time: 0.519, data: 0.002) G_GAN: 0.501 G_L1: 3.261 D_real: 1.119 D_fake: 0.393 \n",
      "(epoch: 36, iters: 220, time: 0.519, data: 0.002) G_GAN: 0.827 G_L1: 3.020 D_real: 0.469 D_fake: 0.983 \n",
      "(epoch: 36, iters: 320, time: 0.520, data: 0.001) G_GAN: 0.815 G_L1: 2.842 D_real: 0.576 D_fake: 0.787 \n",
      "(epoch: 36, iters: 420, time: 0.727, data: 0.002) G_GAN: 0.785 G_L1: 2.493 D_real: 0.680 D_fake: 0.630 \n",
      "(epoch: 36, iters: 520, time: 0.521, data: 0.001) G_GAN: 0.685 G_L1: 2.280 D_real: 0.803 D_fake: 0.616 \n",
      "(epoch: 36, iters: 620, time: 0.519, data: 0.002) G_GAN: 0.789 G_L1: 2.826 D_real: 0.481 D_fake: 0.879 \n",
      "(epoch: 36, iters: 720, time: 0.517, data: 0.001) G_GAN: 0.715 G_L1: 2.292 D_real: 0.781 D_fake: 0.503 \n",
      "(epoch: 36, iters: 820, time: 0.753, data: 0.002) G_GAN: 0.815 G_L1: 3.324 D_real: 0.491 D_fake: 0.819 \n",
      "End of epoch 36 / 100 \t Time Taken: 292 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 52, time: 0.520, data: 0.002) G_GAN: 0.648 G_L1: 2.513 D_real: 0.608 D_fake: 0.778 \n",
      "(epoch: 37, iters: 152, time: 0.520, data: 0.002) G_GAN: 0.717 G_L1: 2.550 D_real: 0.861 D_fake: 0.491 \n",
      "(epoch: 37, iters: 252, time: 0.517, data: 0.002) G_GAN: 0.891 G_L1: 2.971 D_real: 0.492 D_fake: 0.809 \n",
      "(epoch: 37, iters: 352, time: 0.726, data: 0.002) G_GAN: 0.679 G_L1: 2.583 D_real: 0.704 D_fake: 0.702 \n",
      "(epoch: 37, iters: 452, time: 0.520, data: 0.002) G_GAN: 0.811 G_L1: 2.590 D_real: 0.681 D_fake: 0.560 \n",
      "(epoch: 37, iters: 552, time: 0.518, data: 0.002) G_GAN: 0.766 G_L1: 3.154 D_real: 0.650 D_fake: 0.711 \n",
      "(epoch: 37, iters: 652, time: 0.518, data: 0.002) G_GAN: 0.727 G_L1: 3.786 D_real: 0.881 D_fake: 0.446 \n",
      "(epoch: 37, iters: 752, time: 0.722, data: 0.002) G_GAN: 0.717 G_L1: 1.482 D_real: 0.813 D_fake: 0.582 \n",
      "(epoch: 37, iters: 852, time: 0.518, data: 0.002) G_GAN: 0.773 G_L1: 4.116 D_real: 0.525 D_fake: 0.691 \n",
      "End of epoch 37 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 84, time: 0.519, data: 0.002) G_GAN: 1.049 G_L1: 3.755 D_real: 0.358 D_fake: 1.164 \n",
      "(epoch: 38, iters: 184, time: 0.520, data: 0.002) G_GAN: 0.729 G_L1: 2.156 D_real: 0.796 D_fake: 0.613 \n",
      "(epoch: 38, iters: 284, time: 0.750, data: 0.002) G_GAN: 0.752 G_L1: 3.182 D_real: 0.605 D_fake: 0.679 \n",
      "(epoch: 38, iters: 384, time: 0.520, data: 0.001) G_GAN: 0.688 G_L1: 2.279 D_real: 0.727 D_fake: 0.601 \n",
      "(epoch: 38, iters: 484, time: 0.518, data: 0.002) G_GAN: 0.695 G_L1: 2.673 D_real: 0.716 D_fake: 0.574 \n",
      "(epoch: 38, iters: 584, time: 0.520, data: 0.002) G_GAN: 0.761 G_L1: 2.549 D_real: 0.808 D_fake: 0.598 \n",
      "(epoch: 38, iters: 684, time: 0.730, data: 0.002) G_GAN: 0.709 G_L1: 3.189 D_real: 0.627 D_fake: 0.590 \n",
      "(epoch: 38, iters: 784, time: 0.524, data: 0.002) G_GAN: 0.826 G_L1: 4.068 D_real: 0.949 D_fake: 0.398 \n",
      "End of epoch 38 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 16, time: 0.519, data: 0.002) G_GAN: 0.677 G_L1: 2.439 D_real: 0.709 D_fake: 0.671 \n",
      "(epoch: 39, iters: 116, time: 0.519, data: 0.002) G_GAN: 0.839 G_L1: 2.767 D_real: 0.492 D_fake: 0.654 \n",
      "(epoch: 39, iters: 216, time: 0.724, data: 0.002) G_GAN: 0.722 G_L1: 2.170 D_real: 0.638 D_fake: 0.707 \n",
      "(epoch: 39, iters: 316, time: 0.517, data: 0.002) G_GAN: 0.788 G_L1: 2.667 D_real: 0.579 D_fake: 0.697 \n",
      "(epoch: 39, iters: 416, time: 0.519, data: 0.002) G_GAN: 0.827 G_L1: 3.102 D_real: 0.827 D_fake: 0.482 \n",
      "(epoch: 39, iters: 516, time: 0.519, data: 0.002) G_GAN: 0.951 G_L1: 3.499 D_real: 0.460 D_fake: 0.792 \n",
      "(epoch: 39, iters: 616, time: 0.749, data: 0.002) G_GAN: 0.772 G_L1: 2.464 D_real: 0.535 D_fake: 0.827 \n",
      "(epoch: 39, iters: 716, time: 0.519, data: 0.002) G_GAN: 0.673 G_L1: 2.035 D_real: 0.657 D_fake: 0.745 \n",
      "(epoch: 39, iters: 816, time: 0.517, data: 0.002) G_GAN: 0.783 G_L1: 3.134 D_real: 0.796 D_fake: 0.465 \n",
      "End of epoch 39 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 48, time: 0.518, data: 0.002) G_GAN: 0.786 G_L1: 3.048 D_real: 0.748 D_fake: 0.587 \n",
      "(epoch: 40, iters: 148, time: 0.738, data: 0.002) G_GAN: 0.688 G_L1: 1.364 D_real: 0.681 D_fake: 0.703 \n",
      "(epoch: 40, iters: 248, time: 0.517, data: 0.002) G_GAN: 0.539 G_L1: 3.388 D_real: 0.804 D_fake: 0.476 \n",
      "(epoch: 40, iters: 348, time: 0.517, data: 0.002) G_GAN: 0.760 G_L1: 2.407 D_real: 0.475 D_fake: 0.849 \n",
      "(epoch: 40, iters: 448, time: 0.520, data: 0.002) G_GAN: 0.864 G_L1: 2.893 D_real: 0.589 D_fake: 0.694 \n",
      "(epoch: 40, iters: 548, time: 0.693, data: 0.002) G_GAN: 0.610 G_L1: 1.235 D_real: 0.965 D_fake: 0.516 \n",
      "(epoch: 40, iters: 648, time: 0.518, data: 0.001) G_GAN: 0.630 G_L1: 3.797 D_real: 0.833 D_fake: 0.634 \n",
      "(epoch: 40, iters: 748, time: 0.517, data: 0.002) G_GAN: 1.419 G_L1: 5.418 D_real: 0.244 D_fake: 1.010 \n",
      "(epoch: 40, iters: 848, time: 0.517, data: 0.002) G_GAN: 0.818 G_L1: 1.778 D_real: 0.752 D_fake: 0.601 \n",
      "saving the model at the end of epoch 40, iters 34720\n",
      "End of epoch 40 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 80, time: 0.737, data: 0.002) G_GAN: 0.618 G_L1: 2.491 D_real: 0.615 D_fake: 0.744 \n",
      "(epoch: 41, iters: 180, time: 0.515, data: 0.002) G_GAN: 0.699 G_L1: 2.107 D_real: 0.857 D_fake: 0.541 \n",
      "(epoch: 41, iters: 280, time: 0.514, data: 0.002) G_GAN: 0.862 G_L1: 2.308 D_real: 1.047 D_fake: 0.386 \n",
      "saving the latest model (epoch 41, total_iters 35000)\n",
      "(epoch: 41, iters: 380, time: 0.517, data: 0.001) G_GAN: 0.749 G_L1: 1.980 D_real: 0.594 D_fake: 0.805 \n",
      "(epoch: 41, iters: 480, time: 0.745, data: 0.001) G_GAN: 0.730 G_L1: 3.183 D_real: 0.703 D_fake: 0.704 \n",
      "(epoch: 41, iters: 580, time: 0.516, data: 0.002) G_GAN: 0.736 G_L1: 3.281 D_real: 0.552 D_fake: 0.706 \n",
      "(epoch: 41, iters: 680, time: 0.521, data: 0.001) G_GAN: 0.845 G_L1: 3.175 D_real: 0.607 D_fake: 0.594 \n",
      "(epoch: 41, iters: 780, time: 0.516, data: 0.002) G_GAN: 0.720 G_L1: 2.005 D_real: 0.726 D_fake: 0.703 \n",
      "End of epoch 41 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 12, time: 0.731, data: 0.002) G_GAN: 0.675 G_L1: 3.675 D_real: 0.682 D_fake: 0.760 \n",
      "(epoch: 42, iters: 112, time: 0.517, data: 0.002) G_GAN: 0.742 G_L1: 2.793 D_real: 0.682 D_fake: 0.692 \n",
      "(epoch: 42, iters: 212, time: 0.517, data: 0.002) G_GAN: 0.719 G_L1: 2.143 D_real: 0.683 D_fake: 0.607 \n",
      "(epoch: 42, iters: 312, time: 0.514, data: 0.002) G_GAN: 0.529 G_L1: 2.551 D_real: 0.753 D_fake: 0.626 \n",
      "(epoch: 42, iters: 412, time: 0.744, data: 0.001) G_GAN: 1.076 G_L1: 4.674 D_real: 0.359 D_fake: 0.883 \n",
      "(epoch: 42, iters: 512, time: 0.516, data: 0.002) G_GAN: 0.731 G_L1: 2.708 D_real: 0.641 D_fake: 0.621 \n",
      "(epoch: 42, iters: 612, time: 0.518, data: 0.002) G_GAN: 0.733 G_L1: 3.101 D_real: 0.791 D_fake: 0.470 \n",
      "(epoch: 42, iters: 712, time: 0.517, data: 0.002) G_GAN: 0.678 G_L1: 2.523 D_real: 0.589 D_fake: 0.744 \n",
      "(epoch: 42, iters: 812, time: 0.724, data: 0.002) G_GAN: 0.651 G_L1: 3.678 D_real: 1.036 D_fake: 0.381 \n",
      "End of epoch 42 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 44, time: 0.518, data: 0.002) G_GAN: 0.793 G_L1: 3.204 D_real: 0.560 D_fake: 0.776 \n",
      "(epoch: 43, iters: 144, time: 0.517, data: 0.002) G_GAN: 0.576 G_L1: 2.945 D_real: 1.009 D_fake: 0.442 \n",
      "(epoch: 43, iters: 244, time: 0.519, data: 0.002) G_GAN: 0.794 G_L1: 2.501 D_real: 0.787 D_fake: 0.564 \n",
      "(epoch: 43, iters: 344, time: 0.741, data: 0.002) G_GAN: 0.621 G_L1: 2.579 D_real: 0.653 D_fake: 0.691 \n",
      "(epoch: 43, iters: 444, time: 0.519, data: 0.002) G_GAN: 0.764 G_L1: 2.889 D_real: 0.616 D_fake: 0.563 \n",
      "(epoch: 43, iters: 544, time: 0.518, data: 0.002) G_GAN: 0.738 G_L1: 2.359 D_real: 0.811 D_fake: 0.612 \n",
      "(epoch: 43, iters: 644, time: 0.520, data: 0.002) G_GAN: 0.563 G_L1: 2.762 D_real: 0.886 D_fake: 0.485 \n",
      "(epoch: 43, iters: 744, time: 0.734, data: 0.002) G_GAN: 0.721 G_L1: 2.740 D_real: 0.882 D_fake: 0.455 \n",
      "(epoch: 43, iters: 844, time: 0.515, data: 0.002) G_GAN: 0.920 G_L1: 3.225 D_real: 0.511 D_fake: 0.668 \n",
      "End of epoch 43 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 76, time: 0.518, data: 0.002) G_GAN: 0.754 G_L1: 1.963 D_real: 0.894 D_fake: 0.538 \n",
      "(epoch: 44, iters: 176, time: 0.520, data: 0.002) G_GAN: 0.797 G_L1: 2.912 D_real: 0.778 D_fake: 0.533 \n",
      "(epoch: 44, iters: 276, time: 0.721, data: 0.001) G_GAN: 0.783 G_L1: 2.154 D_real: 0.880 D_fake: 0.600 \n",
      "(epoch: 44, iters: 376, time: 0.514, data: 0.002) G_GAN: 0.951 G_L1: 3.286 D_real: 0.748 D_fake: 0.531 \n",
      "(epoch: 44, iters: 476, time: 0.516, data: 0.002) G_GAN: 0.672 G_L1: 1.243 D_real: 0.960 D_fake: 0.474 \n",
      "(epoch: 44, iters: 576, time: 0.518, data: 0.002) G_GAN: 0.629 G_L1: 2.080 D_real: 0.601 D_fake: 0.769 \n",
      "(epoch: 44, iters: 676, time: 0.751, data: 0.002) G_GAN: 1.011 G_L1: 4.370 D_real: 0.573 D_fake: 0.696 \n",
      "(epoch: 44, iters: 776, time: 0.516, data: 0.002) G_GAN: 0.755 G_L1: 2.448 D_real: 0.614 D_fake: 0.741 \n",
      "End of epoch 44 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 8, time: 0.518, data: 0.001) G_GAN: 0.777 G_L1: 2.823 D_real: 0.928 D_fake: 0.443 \n",
      "(epoch: 45, iters: 108, time: 0.518, data: 0.002) G_GAN: 0.815 G_L1: 1.593 D_real: 0.495 D_fake: 0.799 \n",
      "(epoch: 45, iters: 208, time: 0.736, data: 0.002) G_GAN: 0.741 G_L1: 2.097 D_real: 0.610 D_fake: 0.742 \n",
      "(epoch: 45, iters: 308, time: 0.518, data: 0.002) G_GAN: 0.799 G_L1: 2.513 D_real: 0.525 D_fake: 0.856 \n",
      "(epoch: 45, iters: 408, time: 0.518, data: 0.002) G_GAN: 0.796 G_L1: 3.998 D_real: 0.627 D_fake: 0.516 \n",
      "(epoch: 45, iters: 508, time: 0.517, data: 0.002) G_GAN: 0.842 G_L1: 2.558 D_real: 0.764 D_fake: 0.551 \n",
      "(epoch: 45, iters: 608, time: 0.742, data: 0.002) G_GAN: 0.830 G_L1: 2.365 D_real: 0.444 D_fake: 0.903 \n",
      "(epoch: 45, iters: 708, time: 0.510, data: 0.002) G_GAN: 0.625 G_L1: 1.993 D_real: 0.889 D_fake: 0.574 \n",
      "(epoch: 45, iters: 808, time: 0.513, data: 0.002) G_GAN: 0.816 G_L1: 2.681 D_real: 0.617 D_fake: 0.635 \n",
      "saving the model at the end of epoch 45, iters 39060\n",
      "End of epoch 45 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 40, time: 0.517, data: 0.002) G_GAN: 0.685 G_L1: 2.448 D_real: 0.781 D_fake: 0.594 \n",
      "(epoch: 46, iters: 140, time: 0.702, data: 0.002) G_GAN: 0.800 G_L1: 0.263 D_real: 0.793 D_fake: 0.638 \n",
      "(epoch: 46, iters: 240, time: 0.520, data: 0.002) G_GAN: 0.780 G_L1: 3.235 D_real: 0.773 D_fake: 0.657 \n",
      "(epoch: 46, iters: 340, time: 0.516, data: 0.002) G_GAN: 0.598 G_L1: 2.722 D_real: 0.846 D_fake: 0.517 \n",
      "(epoch: 46, iters: 440, time: 0.516, data: 0.002) G_GAN: 0.637 G_L1: 2.182 D_real: 0.579 D_fake: 0.721 \n",
      "(epoch: 46, iters: 540, time: 0.723, data: 0.002) G_GAN: 1.052 G_L1: 2.188 D_real: 0.457 D_fake: 0.928 \n",
      "(epoch: 46, iters: 640, time: 0.531, data: 0.002) G_GAN: 0.871 G_L1: 2.840 D_real: 0.505 D_fake: 0.812 \n",
      "(epoch: 46, iters: 740, time: 0.516, data: 0.002) G_GAN: 0.754 G_L1: 1.877 D_real: 0.934 D_fake: 0.477 \n",
      "(epoch: 46, iters: 840, time: 0.517, data: 0.001) G_GAN: 0.844 G_L1: 2.148 D_real: 0.517 D_fake: 0.890 \n",
      "End of epoch 46 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 72, time: 0.747, data: 0.001) G_GAN: 0.740 G_L1: 2.254 D_real: 0.759 D_fake: 0.594 \n",
      "saving the latest model (epoch 47, total_iters 40000)\n",
      "(epoch: 47, iters: 172, time: 0.517, data: 0.001) G_GAN: 0.689 G_L1: 2.166 D_real: 0.652 D_fake: 0.703 \n",
      "(epoch: 47, iters: 272, time: 0.514, data: 0.002) G_GAN: 0.644 G_L1: 2.449 D_real: 0.920 D_fake: 0.466 \n",
      "(epoch: 47, iters: 372, time: 0.516, data: 0.002) G_GAN: 0.724 G_L1: 2.551 D_real: 0.701 D_fake: 0.603 \n",
      "(epoch: 47, iters: 472, time: 0.732, data: 0.002) G_GAN: 0.721 G_L1: 1.756 D_real: 0.773 D_fake: 0.517 \n",
      "(epoch: 47, iters: 572, time: 0.517, data: 0.002) G_GAN: 0.898 G_L1: 1.925 D_real: 0.480 D_fake: 0.905 \n",
      "(epoch: 47, iters: 672, time: 0.519, data: 0.002) G_GAN: 0.692 G_L1: 3.116 D_real: 0.684 D_fake: 0.644 \n",
      "(epoch: 47, iters: 772, time: 0.519, data: 0.002) G_GAN: 0.670 G_L1: 2.068 D_real: 0.618 D_fake: 0.821 \n",
      "End of epoch 47 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 4, time: 0.749, data: 0.002) G_GAN: 0.665 G_L1: 1.997 D_real: 0.606 D_fake: 0.721 \n",
      "(epoch: 48, iters: 104, time: 0.516, data: 0.001) G_GAN: 1.234 G_L1: 4.528 D_real: 0.307 D_fake: 1.218 \n",
      "(epoch: 48, iters: 204, time: 0.519, data: 0.002) G_GAN: 0.708 G_L1: 3.198 D_real: 0.693 D_fake: 0.635 \n",
      "(epoch: 48, iters: 304, time: 0.520, data: 0.002) G_GAN: 1.220 G_L1: 2.768 D_real: 0.439 D_fake: 0.816 \n",
      "(epoch: 48, iters: 404, time: 0.730, data: 0.002) G_GAN: 0.839 G_L1: 2.628 D_real: 0.706 D_fake: 0.597 \n",
      "(epoch: 48, iters: 504, time: 0.518, data: 0.002) G_GAN: 0.655 G_L1: 2.749 D_real: 0.683 D_fake: 0.610 \n",
      "(epoch: 48, iters: 604, time: 0.513, data: 0.002) G_GAN: 0.792 G_L1: 3.172 D_real: 0.583 D_fake: 0.574 \n",
      "(epoch: 48, iters: 704, time: 0.524, data: 0.002) G_GAN: 1.035 G_L1: 3.912 D_real: 0.424 D_fake: 0.756 \n",
      "(epoch: 48, iters: 804, time: 0.719, data: 0.002) G_GAN: 0.828 G_L1: 3.364 D_real: 0.585 D_fake: 0.617 \n",
      "End of epoch 48 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 36, time: 0.517, data: 0.002) G_GAN: 0.777 G_L1: 2.120 D_real: 0.638 D_fake: 0.696 \n",
      "(epoch: 49, iters: 136, time: 0.520, data: 0.001) G_GAN: 0.688 G_L1: 2.430 D_real: 0.840 D_fake: 0.528 \n",
      "(epoch: 49, iters: 236, time: 0.519, data: 0.002) G_GAN: 0.631 G_L1: 2.380 D_real: 0.742 D_fake: 0.606 \n",
      "(epoch: 49, iters: 336, time: 0.742, data: 0.002) G_GAN: 0.857 G_L1: 1.956 D_real: 0.831 D_fake: 0.566 \n",
      "(epoch: 49, iters: 436, time: 0.574, data: 0.001) G_GAN: 0.659 G_L1: 2.281 D_real: 0.843 D_fake: 0.483 \n",
      "(epoch: 49, iters: 536, time: 0.515, data: 0.002) G_GAN: 0.833 G_L1: 3.239 D_real: 0.614 D_fake: 0.582 \n",
      "(epoch: 49, iters: 636, time: 0.515, data: 0.002) G_GAN: 0.766 G_L1: 2.711 D_real: 0.441 D_fake: 0.971 \n",
      "(epoch: 49, iters: 736, time: 0.757, data: 0.002) G_GAN: 0.675 G_L1: 2.371 D_real: 0.689 D_fake: 0.624 \n",
      "(epoch: 49, iters: 836, time: 0.578, data: 0.002) G_GAN: 0.667 G_L1: 2.370 D_real: 0.835 D_fake: 0.512 \n",
      "End of epoch 49 / 100 \t Time Taken: 296 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 68, time: 0.515, data: 0.002) G_GAN: 0.709 G_L1: 1.798 D_real: 0.723 D_fake: 0.604 \n",
      "(epoch: 50, iters: 168, time: 0.514, data: 0.002) G_GAN: 1.108 G_L1: 3.682 D_real: 0.433 D_fake: 0.786 \n",
      "(epoch: 50, iters: 268, time: 0.754, data: 0.002) G_GAN: 0.608 G_L1: 3.525 D_real: 0.886 D_fake: 0.409 \n",
      "(epoch: 50, iters: 368, time: 0.517, data: 0.002) G_GAN: 0.795 G_L1: 2.563 D_real: 0.609 D_fake: 0.713 \n",
      "(epoch: 50, iters: 468, time: 0.517, data: 0.001) G_GAN: 0.995 G_L1: 2.388 D_real: 0.449 D_fake: 0.772 \n",
      "(epoch: 50, iters: 568, time: 0.519, data: 0.001) G_GAN: 0.942 G_L1: 2.758 D_real: 0.550 D_fake: 0.650 \n",
      "(epoch: 50, iters: 668, time: 0.722, data: 0.002) G_GAN: 0.806 G_L1: 2.818 D_real: 0.506 D_fake: 0.634 \n",
      "(epoch: 50, iters: 768, time: 0.516, data: 0.002) G_GAN: 0.867 G_L1: 2.531 D_real: 0.599 D_fake: 0.700 \n",
      "(epoch: 50, iters: 868, time: 0.517, data: 0.002) G_GAN: 0.887 G_L1: 2.080 D_real: 0.455 D_fake: 0.941 \n",
      "saving the model at the end of epoch 50, iters 43400\n",
      "End of epoch 50 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0001961\n",
      "(epoch: 51, iters: 100, time: 0.516, data: 0.097) G_GAN: 1.178 G_L1: 3.539 D_real: 0.266 D_fake: 1.050 \n",
      "(epoch: 51, iters: 200, time: 0.768, data: 0.002) G_GAN: 0.956 G_L1: 2.523 D_real: 0.295 D_fake: 1.148 \n",
      "(epoch: 51, iters: 300, time: 0.518, data: 0.002) G_GAN: 0.897 G_L1: 2.897 D_real: 0.538 D_fake: 0.630 \n",
      "(epoch: 51, iters: 400, time: 0.515, data: 0.002) G_GAN: 0.737 G_L1: 1.357 D_real: 0.813 D_fake: 0.591 \n",
      "(epoch: 51, iters: 500, time: 0.517, data: 0.002) G_GAN: 0.809 G_L1: 2.333 D_real: 0.579 D_fake: 0.686 \n",
      "(epoch: 51, iters: 600, time: 0.747, data: 0.002) G_GAN: 0.736 G_L1: 2.420 D_real: 0.757 D_fake: 0.528 \n",
      "(epoch: 51, iters: 700, time: 0.516, data: 0.001) G_GAN: 0.578 G_L1: 2.543 D_real: 0.873 D_fake: 0.481 \n",
      "(epoch: 51, iters: 800, time: 0.517, data: 0.002) G_GAN: 0.838 G_L1: 2.551 D_real: 0.771 D_fake: 0.606 \n",
      "End of epoch 51 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0001922\n",
      "(epoch: 52, iters: 32, time: 0.518, data: 0.002) G_GAN: 0.679 G_L1: 2.132 D_real: 0.672 D_fake: 0.701 \n",
      "(epoch: 52, iters: 132, time: 0.770, data: 0.001) G_GAN: 0.685 G_L1: 2.692 D_real: 0.696 D_fake: 0.679 \n",
      "(epoch: 52, iters: 232, time: 0.517, data: 0.002) G_GAN: 0.807 G_L1: 3.112 D_real: 0.560 D_fake: 0.720 \n",
      "(epoch: 52, iters: 332, time: 0.517, data: 0.002) G_GAN: 1.105 G_L1: 2.333 D_real: 0.274 D_fake: 1.583 \n",
      "(epoch: 52, iters: 432, time: 0.521, data: 0.002) G_GAN: 0.824 G_L1: 2.314 D_real: 0.470 D_fake: 0.933 \n",
      "(epoch: 52, iters: 532, time: 0.752, data: 0.001) G_GAN: 0.711 G_L1: 1.969 D_real: 0.846 D_fake: 0.605 \n",
      "(epoch: 52, iters: 632, time: 0.517, data: 0.002) G_GAN: 0.708 G_L1: 2.089 D_real: 0.878 D_fake: 0.483 \n",
      "(epoch: 52, iters: 732, time: 0.518, data: 0.002) G_GAN: 0.777 G_L1: 2.546 D_real: 0.722 D_fake: 0.482 \n",
      "saving the latest model (epoch 52, total_iters 45000)\n",
      "(epoch: 52, iters: 832, time: 0.519, data: 0.001) G_GAN: 0.783 G_L1: 3.087 D_real: 0.730 D_fake: 0.544 \n",
      "End of epoch 52 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0001882\n",
      "(epoch: 53, iters: 64, time: 0.730, data: 0.002) G_GAN: 0.766 G_L1: 2.285 D_real: 0.728 D_fake: 0.465 \n",
      "(epoch: 53, iters: 164, time: 0.513, data: 0.002) G_GAN: 0.859 G_L1: 2.531 D_real: 0.663 D_fake: 0.764 \n",
      "(epoch: 53, iters: 264, time: 0.516, data: 0.002) G_GAN: 0.755 G_L1: 2.056 D_real: 0.749 D_fake: 0.555 \n",
      "(epoch: 53, iters: 364, time: 0.517, data: 0.002) G_GAN: 0.813 G_L1: 2.898 D_real: 0.453 D_fake: 0.818 \n",
      "(epoch: 53, iters: 464, time: 0.762, data: 0.002) G_GAN: 0.679 G_L1: 2.429 D_real: 0.880 D_fake: 0.488 \n",
      "(epoch: 53, iters: 564, time: 0.519, data: 0.001) G_GAN: 0.784 G_L1: 2.788 D_real: 0.621 D_fake: 0.768 \n",
      "(epoch: 53, iters: 664, time: 0.517, data: 0.002) G_GAN: 0.743 G_L1: 2.255 D_real: 0.653 D_fake: 0.716 \n",
      "(epoch: 53, iters: 764, time: 0.516, data: 0.002) G_GAN: 0.936 G_L1: 3.116 D_real: 0.392 D_fake: 0.982 \n",
      "(epoch: 53, iters: 864, time: 0.763, data: 0.002) G_GAN: 0.791 G_L1: 3.804 D_real: 0.641 D_fake: 0.498 \n",
      "End of epoch 53 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0001843\n",
      "(epoch: 54, iters: 96, time: 0.518, data: 0.002) G_GAN: 0.854 G_L1: 2.274 D_real: 0.400 D_fake: 1.034 \n",
      "(epoch: 54, iters: 196, time: 0.516, data: 0.002) G_GAN: 0.651 G_L1: 2.496 D_real: 0.595 D_fake: 0.738 \n",
      "(epoch: 54, iters: 296, time: 0.518, data: 0.002) G_GAN: 1.039 G_L1: 3.236 D_real: 0.442 D_fake: 0.702 \n",
      "(epoch: 54, iters: 396, time: 0.743, data: 0.001) G_GAN: 1.032 G_L1: 3.180 D_real: 0.429 D_fake: 0.825 \n",
      "(epoch: 54, iters: 496, time: 0.519, data: 0.002) G_GAN: 0.561 G_L1: 2.973 D_real: 0.778 D_fake: 0.543 \n",
      "(epoch: 54, iters: 596, time: 0.518, data: 0.002) G_GAN: 0.676 G_L1: 2.223 D_real: 0.673 D_fake: 0.571 \n",
      "(epoch: 54, iters: 696, time: 0.514, data: 0.002) G_GAN: 0.853 G_L1: 2.121 D_real: 0.614 D_fake: 0.675 \n",
      "(epoch: 54, iters: 796, time: 0.772, data: 0.002) G_GAN: 0.750 G_L1: 3.260 D_real: 0.522 D_fake: 0.718 \n",
      "End of epoch 54 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0001804\n",
      "(epoch: 55, iters: 28, time: 0.518, data: 0.002) G_GAN: 0.823 G_L1: 2.945 D_real: 0.759 D_fake: 0.451 \n",
      "(epoch: 55, iters: 128, time: 0.519, data: 0.002) G_GAN: 0.626 G_L1: 1.922 D_real: 0.861 D_fake: 0.532 \n",
      "(epoch: 55, iters: 228, time: 0.519, data: 0.002) G_GAN: 0.720 G_L1: 1.566 D_real: 0.795 D_fake: 0.524 \n",
      "(epoch: 55, iters: 328, time: 0.763, data: 0.002) G_GAN: 0.936 G_L1: 2.115 D_real: 0.510 D_fake: 0.812 \n",
      "(epoch: 55, iters: 428, time: 0.517, data: 0.002) G_GAN: 0.674 G_L1: 2.204 D_real: 0.998 D_fake: 0.432 \n",
      "(epoch: 55, iters: 528, time: 0.520, data: 0.002) G_GAN: 0.838 G_L1: 2.759 D_real: 0.485 D_fake: 0.677 \n",
      "(epoch: 55, iters: 628, time: 0.518, data: 0.002) G_GAN: 0.778 G_L1: 2.745 D_real: 0.457 D_fake: 0.894 \n",
      "(epoch: 55, iters: 728, time: 0.751, data: 0.002) G_GAN: 0.738 G_L1: 1.993 D_real: 1.063 D_fake: 0.406 \n",
      "(epoch: 55, iters: 828, time: 0.520, data: 0.002) G_GAN: 0.932 G_L1: 3.079 D_real: 0.390 D_fake: 0.916 \n",
      "saving the model at the end of epoch 55, iters 47740\n",
      "End of epoch 55 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0001765\n",
      "(epoch: 56, iters: 60, time: 0.518, data: 0.002) G_GAN: 0.856 G_L1: 2.476 D_real: 0.414 D_fake: 0.891 \n",
      "(epoch: 56, iters: 160, time: 0.519, data: 0.001) G_GAN: 0.801 G_L1: 1.930 D_real: 0.574 D_fake: 0.793 \n",
      "(epoch: 56, iters: 260, time: 0.796, data: 0.002) G_GAN: 0.772 G_L1: 2.148 D_real: 0.733 D_fake: 0.549 \n",
      "(epoch: 56, iters: 360, time: 0.549, data: 0.001) G_GAN: 0.877 G_L1: 2.304 D_real: 0.468 D_fake: 0.830 \n",
      "(epoch: 56, iters: 460, time: 0.563, data: 0.002) G_GAN: 0.797 G_L1: 1.655 D_real: 0.686 D_fake: 0.678 \n",
      "(epoch: 56, iters: 560, time: 0.606, data: 0.002) G_GAN: 0.757 G_L1: 2.351 D_real: 0.701 D_fake: 0.619 \n",
      "(epoch: 56, iters: 660, time: 0.852, data: 0.001) G_GAN: 0.947 G_L1: 2.506 D_real: 0.523 D_fake: 0.818 \n",
      "(epoch: 56, iters: 760, time: 0.583, data: 0.002) G_GAN: 0.703 G_L1: 3.298 D_real: 0.756 D_fake: 0.534 \n",
      "(epoch: 56, iters: 860, time: 0.606, data: 0.002) G_GAN: 1.063 G_L1: 2.481 D_real: 0.307 D_fake: 1.167 \n",
      "End of epoch 56 / 100 \t Time Taken: 312 sec\n",
      "learning rate = 0.0001725\n",
      "(epoch: 57, iters: 92, time: 0.558, data: 0.002) G_GAN: 0.721 G_L1: 1.201 D_real: 0.652 D_fake: 0.715 \n",
      "(epoch: 57, iters: 192, time: 0.803, data: 0.002) G_GAN: 0.401 G_L1: 1.750 D_real: 1.040 D_fake: 0.467 \n",
      "(epoch: 57, iters: 292, time: 0.612, data: 0.002) G_GAN: 0.760 G_L1: 2.398 D_real: 0.888 D_fake: 0.463 \n",
      "(epoch: 57, iters: 392, time: 0.577, data: 0.002) G_GAN: 0.620 G_L1: 2.344 D_real: 0.821 D_fake: 0.552 \n",
      "(epoch: 57, iters: 492, time: 0.530, data: 0.002) G_GAN: 1.060 G_L1: 3.244 D_real: 0.549 D_fake: 0.995 \n",
      "(epoch: 57, iters: 592, time: 0.860, data: 0.002) G_GAN: 0.817 G_L1: 2.426 D_real: 0.492 D_fake: 0.826 \n",
      "(epoch: 57, iters: 692, time: 0.596, data: 0.002) G_GAN: 0.528 G_L1: 2.031 D_real: 1.130 D_fake: 0.353 \n",
      "(epoch: 57, iters: 792, time: 0.544, data: 0.002) G_GAN: 0.735 G_L1: 2.232 D_real: 0.691 D_fake: 0.588 \n",
      "End of epoch 57 / 100 \t Time Taken: 321 sec\n",
      "learning rate = 0.0001686\n",
      "(epoch: 58, iters: 24, time: 0.550, data: 0.002) G_GAN: 0.779 G_L1: 2.067 D_real: 0.563 D_fake: 0.769 \n",
      "(epoch: 58, iters: 124, time: 0.867, data: 0.001) G_GAN: 0.756 G_L1: 3.005 D_real: 0.550 D_fake: 0.689 \n",
      "(epoch: 58, iters: 224, time: 0.563, data: 0.002) G_GAN: 0.769 G_L1: 2.089 D_real: 0.692 D_fake: 0.606 \n",
      "(epoch: 58, iters: 324, time: 0.524, data: 0.002) G_GAN: 0.753 G_L1: 1.949 D_real: 0.710 D_fake: 0.625 \n",
      "(epoch: 58, iters: 424, time: 0.581, data: 0.002) G_GAN: 0.710 G_L1: 1.801 D_real: 0.613 D_fake: 0.794 \n",
      "(epoch: 58, iters: 524, time: 0.856, data: 0.002) G_GAN: 0.625 G_L1: 1.627 D_real: 0.605 D_fake: 0.793 \n",
      "saving the latest model (epoch 58, total_iters 50000)\n",
      "(epoch: 58, iters: 624, time: 0.544, data: 0.001) G_GAN: 0.707 G_L1: 2.307 D_real: 0.817 D_fake: 0.510 \n",
      "(epoch: 58, iters: 724, time: 0.551, data: 0.002) G_GAN: 0.711 G_L1: 0.751 D_real: 0.611 D_fake: 0.464 \n",
      "(epoch: 58, iters: 824, time: 0.597, data: 0.002) G_GAN: 0.860 G_L1: 2.313 D_real: 0.541 D_fake: 0.784 \n",
      "End of epoch 58 / 100 \t Time Taken: 320 sec\n",
      "learning rate = 0.0001647\n",
      "(epoch: 59, iters: 56, time: 0.861, data: 0.002) G_GAN: 0.905 G_L1: 3.150 D_real: 0.666 D_fake: 0.555 \n",
      "(epoch: 59, iters: 156, time: 0.527, data: 0.002) G_GAN: 0.690 G_L1: 1.738 D_real: 0.646 D_fake: 0.761 \n",
      "(epoch: 59, iters: 256, time: 0.570, data: 0.002) G_GAN: 0.749 G_L1: 3.128 D_real: 0.759 D_fake: 0.495 \n",
      "(epoch: 59, iters: 356, time: 0.605, data: 0.002) G_GAN: 0.706 G_L1: 1.848 D_real: 0.627 D_fake: 0.714 \n",
      "(epoch: 59, iters: 456, time: 0.876, data: 0.002) G_GAN: 0.703 G_L1: 2.949 D_real: 0.520 D_fake: 0.735 \n",
      "(epoch: 59, iters: 556, time: 0.526, data: 0.002) G_GAN: 1.458 G_L1: 0.625 D_real: 0.353 D_fake: 1.086 \n",
      "(epoch: 59, iters: 656, time: 0.577, data: 0.002) G_GAN: 0.766 G_L1: 2.128 D_real: 0.403 D_fake: 0.915 \n",
      "(epoch: 59, iters: 756, time: 0.605, data: 0.001) G_GAN: 1.510 G_L1: 4.168 D_real: 0.214 D_fake: 1.134 \n",
      "(epoch: 59, iters: 856, time: 0.849, data: 0.002) G_GAN: 0.742 G_L1: 2.487 D_real: 0.745 D_fake: 0.490 \n",
      "End of epoch 59 / 100 \t Time Taken: 321 sec\n",
      "learning rate = 0.0001608\n",
      "(epoch: 60, iters: 88, time: 0.559, data: 0.002) G_GAN: 0.831 G_L1: 2.263 D_real: 0.632 D_fake: 0.673 \n",
      "(epoch: 60, iters: 188, time: 0.606, data: 0.002) G_GAN: 0.662 G_L1: 2.409 D_real: 0.584 D_fake: 0.634 \n",
      "(epoch: 60, iters: 288, time: 0.591, data: 0.002) G_GAN: 1.160 G_L1: 2.589 D_real: 0.430 D_fake: 0.948 \n",
      "(epoch: 60, iters: 388, time: 0.806, data: 0.002) G_GAN: 0.637 G_L1: 2.303 D_real: 0.707 D_fake: 0.597 \n",
      "(epoch: 60, iters: 488, time: 0.590, data: 0.002) G_GAN: 0.831 G_L1: 1.697 D_real: 0.596 D_fake: 0.674 \n",
      "(epoch: 60, iters: 588, time: 0.604, data: 0.002) G_GAN: 0.723 G_L1: 1.794 D_real: 0.602 D_fake: 0.798 \n",
      "(epoch: 60, iters: 688, time: 0.562, data: 0.002) G_GAN: 0.820 G_L1: 2.798 D_real: 0.597 D_fake: 0.701 \n",
      "(epoch: 60, iters: 788, time: 0.787, data: 0.001) G_GAN: 0.644 G_L1: 1.094 D_real: 0.774 D_fake: 0.544 \n",
      "saving the model at the end of epoch 60, iters 52080\n",
      "End of epoch 60 / 100 \t Time Taken: 322 sec\n",
      "learning rate = 0.0001569\n",
      "(epoch: 61, iters: 20, time: 0.603, data: 0.002) G_GAN: 0.696 G_L1: 2.742 D_real: 0.740 D_fake: 0.471 \n",
      "(epoch: 61, iters: 120, time: 0.561, data: 0.002) G_GAN: 1.096 G_L1: 2.666 D_real: 0.403 D_fake: 0.724 \n",
      "(epoch: 61, iters: 220, time: 0.529, data: 0.002) G_GAN: 0.829 G_L1: 2.964 D_real: 0.423 D_fake: 0.787 \n",
      "(epoch: 61, iters: 320, time: 0.744, data: 0.002) G_GAN: 0.740 G_L1: 2.173 D_real: 0.455 D_fake: 0.805 \n",
      "(epoch: 61, iters: 420, time: 0.513, data: 0.002) G_GAN: 0.723 G_L1: 2.380 D_real: 0.671 D_fake: 0.529 \n",
      "(epoch: 61, iters: 520, time: 0.515, data: 0.002) G_GAN: 0.737 G_L1: 2.312 D_real: 0.899 D_fake: 0.474 \n",
      "(epoch: 61, iters: 620, time: 0.518, data: 0.002) G_GAN: 0.660 G_L1: 1.595 D_real: 0.626 D_fake: 0.745 \n",
      "(epoch: 61, iters: 720, time: 0.769, data: 0.002) G_GAN: 0.770 G_L1: 2.642 D_real: 0.530 D_fake: 0.655 \n",
      "(epoch: 61, iters: 820, time: 0.514, data: 0.002) G_GAN: 0.729 G_L1: 2.208 D_real: 0.840 D_fake: 0.511 \n",
      "End of epoch 61 / 100 \t Time Taken: 298 sec\n",
      "learning rate = 0.0001529\n",
      "(epoch: 62, iters: 52, time: 0.517, data: 0.002) G_GAN: 0.854 G_L1: 2.386 D_real: 0.472 D_fake: 0.821 \n",
      "(epoch: 62, iters: 152, time: 0.519, data: 0.002) G_GAN: 1.035 G_L1: 3.423 D_real: 0.615 D_fake: 0.611 \n",
      "(epoch: 62, iters: 252, time: 0.773, data: 0.002) G_GAN: 0.650 G_L1: 2.247 D_real: 0.925 D_fake: 0.412 \n",
      "(epoch: 62, iters: 352, time: 0.516, data: 0.002) G_GAN: 0.615 G_L1: 2.781 D_real: 0.649 D_fake: 0.635 \n",
      "(epoch: 62, iters: 452, time: 0.518, data: 0.001) G_GAN: 0.740 G_L1: 1.670 D_real: 0.929 D_fake: 0.543 \n",
      "(epoch: 62, iters: 552, time: 0.517, data: 0.002) G_GAN: 0.728 G_L1: 2.000 D_real: 0.810 D_fake: 0.535 \n",
      "(epoch: 62, iters: 652, time: 0.845, data: 0.002) G_GAN: 0.874 G_L1: 3.191 D_real: 0.882 D_fake: 0.395 \n",
      "(epoch: 62, iters: 752, time: 0.518, data: 0.002) G_GAN: 0.618 G_L1: 2.925 D_real: 0.981 D_fake: 0.508 \n",
      "(epoch: 62, iters: 852, time: 0.518, data: 0.002) G_GAN: 0.811 G_L1: 2.371 D_real: 0.527 D_fake: 0.751 \n",
      "End of epoch 62 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0001490\n",
      "(epoch: 63, iters: 84, time: 0.517, data: 0.002) G_GAN: 0.661 G_L1: 1.510 D_real: 1.002 D_fake: 0.416 \n",
      "(epoch: 63, iters: 184, time: 0.705, data: 0.002) G_GAN: 0.680 G_L1: 1.583 D_real: 0.682 D_fake: 0.728 \n",
      "(epoch: 63, iters: 284, time: 0.519, data: 0.002) G_GAN: 0.710 G_L1: 1.878 D_real: 0.559 D_fake: 0.834 \n",
      "(epoch: 63, iters: 384, time: 0.520, data: 0.002) G_GAN: 0.696 G_L1: 1.634 D_real: 0.764 D_fake: 0.687 \n",
      "(epoch: 63, iters: 484, time: 0.520, data: 0.002) G_GAN: 0.813 G_L1: 2.210 D_real: 0.590 D_fake: 0.762 \n",
      "(epoch: 63, iters: 584, time: 0.798, data: 0.002) G_GAN: 0.704 G_L1: 2.287 D_real: 0.651 D_fake: 0.681 \n",
      "(epoch: 63, iters: 684, time: 0.520, data: 0.002) G_GAN: 0.751 G_L1: 2.160 D_real: 0.619 D_fake: 0.545 \n",
      "(epoch: 63, iters: 784, time: 0.518, data: 0.002) G_GAN: 1.387 G_L1: 2.931 D_real: 0.319 D_fake: 1.127 \n",
      "End of epoch 63 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0001451\n",
      "(epoch: 64, iters: 16, time: 0.516, data: 0.002) G_GAN: 0.868 G_L1: 1.638 D_real: 1.203 D_fake: 0.349 \n",
      "(epoch: 64, iters: 116, time: 0.787, data: 0.002) G_GAN: 0.677 G_L1: 1.630 D_real: 0.725 D_fake: 0.659 \n",
      "(epoch: 64, iters: 216, time: 0.521, data: 0.002) G_GAN: 0.552 G_L1: 2.277 D_real: 0.701 D_fake: 0.655 \n",
      "(epoch: 64, iters: 316, time: 0.521, data: 0.002) G_GAN: 0.751 G_L1: 1.797 D_real: 0.774 D_fake: 0.591 \n",
      "saving the latest model (epoch 64, total_iters 55000)\n",
      "(epoch: 64, iters: 416, time: 0.521, data: 0.002) G_GAN: 0.781 G_L1: 2.687 D_real: 0.664 D_fake: 0.523 \n",
      "(epoch: 64, iters: 516, time: 0.779, data: 0.002) G_GAN: 0.709 G_L1: 2.387 D_real: 0.603 D_fake: 0.710 \n",
      "(epoch: 64, iters: 616, time: 0.516, data: 0.002) G_GAN: 0.724 G_L1: 2.339 D_real: 0.872 D_fake: 0.518 \n",
      "(epoch: 64, iters: 716, time: 0.519, data: 0.002) G_GAN: 0.832 G_L1: 1.994 D_real: 1.041 D_fake: 0.409 \n",
      "(epoch: 64, iters: 816, time: 0.519, data: 0.002) G_GAN: 1.046 G_L1: 2.412 D_real: 0.353 D_fake: 1.113 \n",
      "End of epoch 64 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0001412\n",
      "(epoch: 65, iters: 48, time: 0.782, data: 0.002) G_GAN: 0.786 G_L1: 1.493 D_real: 0.615 D_fake: 0.702 \n",
      "(epoch: 65, iters: 148, time: 0.523, data: 0.002) G_GAN: 0.792 G_L1: 1.803 D_real: 0.707 D_fake: 0.632 \n",
      "(epoch: 65, iters: 248, time: 0.519, data: 0.002) G_GAN: 0.749 G_L1: 2.187 D_real: 0.559 D_fake: 0.806 \n",
      "(epoch: 65, iters: 348, time: 0.516, data: 0.002) G_GAN: 0.674 G_L1: 2.625 D_real: 0.657 D_fake: 0.607 \n",
      "(epoch: 65, iters: 448, time: 0.756, data: 0.002) G_GAN: 0.856 G_L1: 2.433 D_real: 0.601 D_fake: 0.726 \n",
      "(epoch: 65, iters: 548, time: 0.516, data: 0.002) G_GAN: 0.853 G_L1: 1.716 D_real: 0.834 D_fake: 0.518 \n",
      "(epoch: 65, iters: 648, time: 0.518, data: 0.002) G_GAN: 0.695 G_L1: 2.639 D_real: 0.498 D_fake: 0.735 \n",
      "(epoch: 65, iters: 748, time: 0.517, data: 0.002) G_GAN: 0.684 G_L1: 1.747 D_real: 0.717 D_fake: 0.632 \n",
      "(epoch: 65, iters: 848, time: 0.851, data: 0.002) G_GAN: 0.766 G_L1: 2.171 D_real: 0.586 D_fake: 0.668 \n",
      "saving the model at the end of epoch 65, iters 56420\n",
      "End of epoch 65 / 100 \t Time Taken: 292 sec\n",
      "learning rate = 0.0001373\n",
      "(epoch: 66, iters: 80, time: 0.520, data: 0.002) G_GAN: 0.740 G_L1: 2.168 D_real: 0.679 D_fake: 0.615 \n",
      "(epoch: 66, iters: 180, time: 0.514, data: 0.002) G_GAN: 0.800 G_L1: 2.156 D_real: 0.669 D_fake: 0.621 \n",
      "(epoch: 66, iters: 280, time: 0.517, data: 0.002) G_GAN: 0.797 G_L1: 1.696 D_real: 0.632 D_fake: 0.763 \n",
      "(epoch: 66, iters: 380, time: 0.830, data: 0.002) G_GAN: 0.761 G_L1: 1.951 D_real: 0.655 D_fake: 0.523 \n",
      "(epoch: 66, iters: 480, time: 0.519, data: 0.002) G_GAN: 0.677 G_L1: 1.731 D_real: 0.679 D_fake: 0.716 \n",
      "(epoch: 66, iters: 580, time: 0.516, data: 0.002) G_GAN: 0.766 G_L1: 1.967 D_real: 0.843 D_fake: 0.479 \n",
      "(epoch: 66, iters: 680, time: 0.516, data: 0.002) G_GAN: 0.743 G_L1: 1.930 D_real: 0.789 D_fake: 0.587 \n",
      "(epoch: 66, iters: 780, time: 0.791, data: 0.002) G_GAN: 0.778 G_L1: 1.993 D_real: 0.497 D_fake: 0.845 \n",
      "End of epoch 66 / 100 \t Time Taken: 292 sec\n",
      "learning rate = 0.0001333\n",
      "(epoch: 67, iters: 12, time: 0.517, data: 0.002) G_GAN: 0.758 G_L1: 1.242 D_real: 0.730 D_fake: 0.571 \n",
      "(epoch: 67, iters: 112, time: 0.519, data: 0.001) G_GAN: 0.689 G_L1: 1.105 D_real: 0.561 D_fake: 0.822 \n",
      "(epoch: 67, iters: 212, time: 0.519, data: 0.002) G_GAN: 0.635 G_L1: 2.564 D_real: 0.739 D_fake: 0.659 \n",
      "(epoch: 67, iters: 312, time: 0.785, data: 0.002) G_GAN: 0.787 G_L1: 2.314 D_real: 0.630 D_fake: 0.647 \n",
      "(epoch: 67, iters: 412, time: 0.520, data: 0.002) G_GAN: 0.840 G_L1: 1.513 D_real: 0.633 D_fake: 0.623 \n",
      "(epoch: 67, iters: 512, time: 0.516, data: 0.002) G_GAN: 0.750 G_L1: 2.713 D_real: 0.667 D_fake: 0.592 \n",
      "(epoch: 67, iters: 612, time: 0.515, data: 0.002) G_GAN: 0.647 G_L1: 1.406 D_real: 1.107 D_fake: 0.353 \n",
      "(epoch: 67, iters: 712, time: 0.807, data: 0.002) G_GAN: 0.809 G_L1: 1.948 D_real: 0.606 D_fake: 0.702 \n",
      "(epoch: 67, iters: 812, time: 0.516, data: 0.002) G_GAN: 0.730 G_L1: 1.900 D_real: 0.742 D_fake: 0.585 \n",
      "End of epoch 67 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0001294\n",
      "(epoch: 68, iters: 44, time: 0.521, data: 0.002) G_GAN: 0.576 G_L1: 1.887 D_real: 0.911 D_fake: 0.468 \n",
      "(epoch: 68, iters: 144, time: 0.522, data: 0.002) G_GAN: 0.770 G_L1: 2.123 D_real: 0.548 D_fake: 0.765 \n",
      "(epoch: 68, iters: 244, time: 0.791, data: 0.002) G_GAN: 0.807 G_L1: 1.668 D_real: 0.838 D_fake: 0.860 \n",
      "(epoch: 68, iters: 344, time: 0.513, data: 0.002) G_GAN: 0.835 G_L1: 1.545 D_real: 0.487 D_fake: 0.665 \n",
      "(epoch: 68, iters: 444, time: 0.519, data: 0.002) G_GAN: 0.725 G_L1: 2.473 D_real: 0.868 D_fake: 0.429 \n",
      "(epoch: 68, iters: 544, time: 0.517, data: 0.002) G_GAN: 0.690 G_L1: 1.900 D_real: 0.721 D_fake: 0.636 \n",
      "(epoch: 68, iters: 644, time: 0.788, data: 0.002) G_GAN: 0.817 G_L1: 1.704 D_real: 0.958 D_fake: 0.508 \n",
      "(epoch: 68, iters: 744, time: 0.517, data: 0.001) G_GAN: 0.731 G_L1: 1.949 D_real: 0.982 D_fake: 0.416 \n",
      "(epoch: 68, iters: 844, time: 0.519, data: 0.002) G_GAN: 0.965 G_L1: 2.640 D_real: 0.422 D_fake: 0.816 \n",
      "End of epoch 68 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0001255\n",
      "(epoch: 69, iters: 76, time: 0.519, data: 0.002) G_GAN: 0.649 G_L1: 2.090 D_real: 0.742 D_fake: 0.657 \n",
      "(epoch: 69, iters: 176, time: 0.783, data: 0.002) G_GAN: 0.729 G_L1: 2.088 D_real: 0.567 D_fake: 0.825 \n",
      "(epoch: 69, iters: 276, time: 0.516, data: 0.002) G_GAN: 0.770 G_L1: 1.773 D_real: 0.574 D_fake: 0.751 \n",
      "(epoch: 69, iters: 376, time: 0.518, data: 0.002) G_GAN: 1.196 G_L1: 1.943 D_real: 0.432 D_fake: 0.747 \n",
      "(epoch: 69, iters: 476, time: 0.520, data: 0.002) G_GAN: 0.702 G_L1: 1.921 D_real: 0.771 D_fake: 0.599 \n",
      "(epoch: 69, iters: 576, time: 0.773, data: 0.002) G_GAN: 0.627 G_L1: 1.765 D_real: 0.762 D_fake: 0.604 \n",
      "(epoch: 69, iters: 676, time: 0.517, data: 0.002) G_GAN: 0.753 G_L1: 1.995 D_real: 0.841 D_fake: 0.535 \n",
      "(epoch: 69, iters: 776, time: 0.519, data: 0.002) G_GAN: 0.729 G_L1: 2.126 D_real: 0.752 D_fake: 0.546 \n",
      "End of epoch 69 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0001216\n",
      "(epoch: 70, iters: 8, time: 0.518, data: 0.002) G_GAN: 0.785 G_L1: 1.862 D_real: 0.707 D_fake: 0.641 \n",
      "(epoch: 70, iters: 108, time: 0.794, data: 0.002) G_GAN: 0.814 G_L1: 1.655 D_real: 0.898 D_fake: 0.499 \n",
      "saving the latest model (epoch 70, total_iters 60000)\n",
      "(epoch: 70, iters: 208, time: 0.518, data: 0.002) G_GAN: 0.731 G_L1: 1.938 D_real: 0.970 D_fake: 0.481 \n",
      "(epoch: 70, iters: 308, time: 0.519, data: 0.002) G_GAN: 0.712 G_L1: 1.631 D_real: 0.656 D_fake: 0.560 \n",
      "(epoch: 70, iters: 408, time: 0.517, data: 0.002) G_GAN: 0.792 G_L1: 2.210 D_real: 0.632 D_fake: 0.616 \n",
      "(epoch: 70, iters: 508, time: 0.779, data: 0.002) G_GAN: 0.678 G_L1: 1.660 D_real: 0.618 D_fake: 0.695 \n",
      "(epoch: 70, iters: 608, time: 0.520, data: 0.002) G_GAN: 0.883 G_L1: 2.175 D_real: 0.397 D_fake: 0.900 \n",
      "(epoch: 70, iters: 708, time: 0.518, data: 0.002) G_GAN: 0.915 G_L1: 1.900 D_real: 0.329 D_fake: 1.203 \n",
      "(epoch: 70, iters: 808, time: 0.516, data: 0.002) G_GAN: 1.028 G_L1: 2.087 D_real: 0.415 D_fake: 0.978 \n",
      "saving the model at the end of epoch 70, iters 60760\n",
      "End of epoch 70 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0001176\n",
      "(epoch: 71, iters: 40, time: 0.761, data: 0.002) G_GAN: 0.643 G_L1: 2.593 D_real: 0.833 D_fake: 0.526 \n",
      "(epoch: 71, iters: 140, time: 0.517, data: 0.002) G_GAN: 0.979 G_L1: 1.952 D_real: 0.633 D_fake: 0.543 \n",
      "(epoch: 71, iters: 240, time: 0.518, data: 0.002) G_GAN: 0.689 G_L1: 2.152 D_real: 0.579 D_fake: 0.716 \n",
      "(epoch: 71, iters: 340, time: 0.517, data: 0.002) G_GAN: 0.705 G_L1: 1.531 D_real: 0.747 D_fake: 0.614 \n",
      "(epoch: 71, iters: 440, time: 0.753, data: 0.001) G_GAN: 0.824 G_L1: 1.209 D_real: 0.730 D_fake: 0.522 \n",
      "(epoch: 71, iters: 540, time: 0.519, data: 0.002) G_GAN: 1.089 G_L1: 2.842 D_real: 0.458 D_fake: 0.593 \n",
      "(epoch: 71, iters: 640, time: 0.519, data: 0.002) G_GAN: 0.813 G_L1: 2.015 D_real: 0.345 D_fake: 0.991 \n",
      "(epoch: 71, iters: 740, time: 0.520, data: 0.002) G_GAN: 0.735 G_L1: 2.025 D_real: 0.441 D_fake: 0.810 \n",
      "(epoch: 71, iters: 840, time: 0.818, data: 0.002) G_GAN: 0.609 G_L1: 1.699 D_real: 0.763 D_fake: 0.592 \n",
      "End of epoch 71 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0001137\n",
      "(epoch: 72, iters: 72, time: 0.517, data: 0.002) G_GAN: 0.714 G_L1: 1.851 D_real: 0.726 D_fake: 0.622 \n",
      "(epoch: 72, iters: 172, time: 0.520, data: 0.002) G_GAN: 0.777 G_L1: 1.531 D_real: 0.614 D_fake: 0.767 \n",
      "(epoch: 72, iters: 272, time: 0.517, data: 0.002) G_GAN: 0.820 G_L1: 2.441 D_real: 0.573 D_fake: 0.726 \n",
      "(epoch: 72, iters: 372, time: 4.141, data: 0.002) G_GAN: 0.687 G_L1: 1.838 D_real: 0.805 D_fake: 0.625 \n",
      "(epoch: 72, iters: 472, time: 3.858, data: 0.002) G_GAN: 0.776 G_L1: 2.215 D_real: 0.734 D_fake: 0.610 \n",
      "(epoch: 72, iters: 572, time: 3.859, data: 0.002) G_GAN: 1.032 G_L1: 1.990 D_real: 0.314 D_fake: 1.211 \n",
      "(epoch: 72, iters: 672, time: 3.862, data: 0.005) G_GAN: 0.901 G_L1: 3.080 D_real: 0.677 D_fake: 0.477 \n",
      "(epoch: 72, iters: 772, time: 4.143, data: 0.002) G_GAN: 0.709 G_L1: 2.116 D_real: 0.642 D_fake: 0.628 \n",
      "End of epoch 72 / 100 \t Time Taken: 1440 sec\n",
      "learning rate = 0.0001098\n",
      "(epoch: 73, iters: 4, time: 3.858, data: 0.002) G_GAN: 0.822 G_L1: 2.349 D_real: 0.536 D_fake: 0.842 \n",
      "(epoch: 73, iters: 104, time: 3.858, data: 0.001) G_GAN: 0.864 G_L1: 2.531 D_real: 0.464 D_fake: 0.974 \n",
      "(epoch: 73, iters: 204, time: 3.433, data: 0.002) G_GAN: 0.857 G_L1: 2.483 D_real: 0.524 D_fake: 0.681 \n",
      "(epoch: 73, iters: 304, time: 3.716, data: 0.010) G_GAN: 0.754 G_L1: 2.181 D_real: 0.640 D_fake: 0.677 \n",
      "(epoch: 73, iters: 404, time: 2.989, data: 0.002) G_GAN: 0.973 G_L1: 1.695 D_real: 0.486 D_fake: 0.848 \n",
      "(epoch: 73, iters: 504, time: 2.987, data: 0.007) G_GAN: 0.750 G_L1: 2.007 D_real: 0.488 D_fake: 0.851 \n",
      "(epoch: 73, iters: 604, time: 2.935, data: 0.007) G_GAN: 0.728 G_L1: 2.110 D_real: 0.495 D_fake: 0.902 \n",
      "(epoch: 73, iters: 704, time: 3.349, data: 0.007) G_GAN: 0.886 G_L1: 1.996 D_real: 0.583 D_fake: 0.583 \n",
      "(epoch: 73, iters: 804, time: 2.909, data: 0.002) G_GAN: 0.770 G_L1: 2.740 D_real: 0.519 D_fake: 0.738 \n",
      "End of epoch 73 / 100 \t Time Taken: 1874 sec\n",
      "learning rate = 0.0001059\n",
      "(epoch: 74, iters: 36, time: 2.944, data: 0.003) G_GAN: 0.936 G_L1: 2.513 D_real: 0.622 D_fake: 0.632 \n",
      "(epoch: 74, iters: 136, time: 0.488, data: 0.004) G_GAN: 0.786 G_L1: 2.058 D_real: 0.632 D_fake: 0.549 \n",
      "(epoch: 74, iters: 236, time: 0.795, data: 0.002) G_GAN: 0.709 G_L1: 1.800 D_real: 0.722 D_fake: 0.687 \n",
      "(epoch: 74, iters: 336, time: 0.513, data: 0.002) G_GAN: 0.720 G_L1: 1.681 D_real: 0.622 D_fake: 0.744 \n",
      "(epoch: 74, iters: 436, time: 0.517, data: 0.002) G_GAN: 0.732 G_L1: 1.696 D_real: 0.660 D_fake: 0.691 \n",
      "(epoch: 74, iters: 536, time: 0.528, data: 0.002) G_GAN: 0.678 G_L1: 1.564 D_real: 0.798 D_fake: 0.612 \n",
      "(epoch: 74, iters: 636, time: 0.772, data: 0.001) G_GAN: 0.795 G_L1: 2.165 D_real: 0.546 D_fake: 0.732 \n",
      "(epoch: 74, iters: 736, time: 0.513, data: 0.002) G_GAN: 0.748 G_L1: 2.414 D_real: 0.733 D_fake: 0.509 \n",
      "(epoch: 74, iters: 836, time: 0.514, data: 0.002) G_GAN: 0.793 G_L1: 2.016 D_real: 0.685 D_fake: 0.635 \n",
      "End of epoch 74 / 100 \t Time Taken: 565 sec\n",
      "learning rate = 0.0001020\n",
      "(epoch: 75, iters: 68, time: 0.577, data: 0.002) G_GAN: 0.732 G_L1: 1.705 D_real: 0.641 D_fake: 0.739 \n",
      "(epoch: 75, iters: 168, time: 0.785, data: 0.001) G_GAN: 0.846 G_L1: 2.097 D_real: 0.910 D_fake: 0.409 \n",
      "(epoch: 75, iters: 268, time: 0.511, data: 0.002) G_GAN: 0.777 G_L1: 1.954 D_real: 0.755 D_fake: 0.604 \n",
      "(epoch: 75, iters: 368, time: 0.515, data: 0.002) G_GAN: 0.726 G_L1: 1.430 D_real: 0.765 D_fake: 0.669 \n",
      "(epoch: 75, iters: 468, time: 0.517, data: 0.002) G_GAN: 0.741 G_L1: 1.716 D_real: 0.601 D_fake: 0.689 \n",
      "(epoch: 75, iters: 568, time: 0.796, data: 0.002) G_GAN: 1.049 G_L1: 2.736 D_real: 0.350 D_fake: 0.898 \n",
      "(epoch: 75, iters: 668, time: 0.515, data: 0.002) G_GAN: 1.213 G_L1: 1.893 D_real: 0.339 D_fake: 1.010 \n",
      "(epoch: 75, iters: 768, time: 0.516, data: 0.002) G_GAN: 0.750 G_L1: 1.644 D_real: 0.682 D_fake: 0.588 \n",
      "saving the latest model (epoch 75, total_iters 65000)\n",
      "(epoch: 75, iters: 868, time: 0.515, data: 0.002) G_GAN: 0.789 G_L1: 2.150 D_real: 0.443 D_fake: 0.949 \n",
      "saving the model at the end of epoch 75, iters 65100\n",
      "End of epoch 75 / 100 \t Time Taken: 294 sec\n",
      "learning rate = 0.0000980\n",
      "(epoch: 76, iters: 100, time: 0.804, data: 0.096) G_GAN: 0.704 G_L1: 1.501 D_real: 0.792 D_fake: 0.534 \n",
      "(epoch: 76, iters: 200, time: 0.517, data: 0.002) G_GAN: 0.668 G_L1: 2.169 D_real: 0.733 D_fake: 0.673 \n",
      "(epoch: 76, iters: 300, time: 0.514, data: 0.002) G_GAN: 0.719 G_L1: 1.495 D_real: 0.723 D_fake: 0.679 \n",
      "(epoch: 76, iters: 400, time: 0.516, data: 0.002) G_GAN: 0.785 G_L1: 1.904 D_real: 0.490 D_fake: 0.913 \n",
      "(epoch: 76, iters: 500, time: 0.830, data: 0.002) G_GAN: 0.663 G_L1: 1.615 D_real: 0.850 D_fake: 0.572 \n",
      "(epoch: 76, iters: 600, time: 0.515, data: 0.002) G_GAN: 0.788 G_L1: 1.299 D_real: 0.815 D_fake: 0.486 \n",
      "(epoch: 76, iters: 700, time: 0.513, data: 0.002) G_GAN: 0.634 G_L1: 1.370 D_real: 0.752 D_fake: 0.660 \n",
      "(epoch: 76, iters: 800, time: 0.515, data: 0.002) G_GAN: 0.753 G_L1: 1.744 D_real: 0.752 D_fake: 0.591 \n",
      "End of epoch 76 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000941\n",
      "(epoch: 77, iters: 32, time: 0.816, data: 0.002) G_GAN: 0.684 G_L1: 2.026 D_real: 0.738 D_fake: 0.474 \n",
      "(epoch: 77, iters: 132, time: 0.514, data: 0.002) G_GAN: 0.603 G_L1: 2.594 D_real: 0.972 D_fake: 0.367 \n",
      "(epoch: 77, iters: 232, time: 0.514, data: 0.002) G_GAN: 0.739 G_L1: 2.130 D_real: 0.634 D_fake: 0.768 \n",
      "(epoch: 77, iters: 332, time: 0.517, data: 0.002) G_GAN: 0.682 G_L1: 1.382 D_real: 0.572 D_fake: 0.636 \n",
      "(epoch: 77, iters: 432, time: 0.762, data: 0.002) G_GAN: 0.752 G_L1: 0.267 D_real: 0.567 D_fake: 0.666 \n",
      "(epoch: 77, iters: 532, time: 0.515, data: 0.002) G_GAN: 0.818 G_L1: 2.349 D_real: 0.482 D_fake: 0.829 \n",
      "(epoch: 77, iters: 632, time: 0.516, data: 0.002) G_GAN: 0.768 G_L1: 2.274 D_real: 0.961 D_fake: 0.458 \n",
      "(epoch: 77, iters: 732, time: 0.516, data: 0.002) G_GAN: 0.688 G_L1: 1.888 D_real: 0.814 D_fake: 0.540 \n",
      "(epoch: 77, iters: 832, time: 0.789, data: 0.002) G_GAN: 0.898 G_L1: 1.405 D_real: 1.190 D_fake: 0.369 \n",
      "End of epoch 77 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0000902\n",
      "(epoch: 78, iters: 64, time: 0.514, data: 0.001) G_GAN: 0.724 G_L1: 1.485 D_real: 0.872 D_fake: 0.601 \n",
      "(epoch: 78, iters: 164, time: 0.516, data: 0.002) G_GAN: 0.787 G_L1: 2.236 D_real: 0.679 D_fake: 0.574 \n",
      "(epoch: 78, iters: 264, time: 0.517, data: 0.002) G_GAN: 0.746 G_L1: 1.846 D_real: 1.007 D_fake: 0.453 \n",
      "(epoch: 78, iters: 364, time: 0.781, data: 0.002) G_GAN: 0.677 G_L1: 1.684 D_real: 0.553 D_fake: 0.821 \n",
      "(epoch: 78, iters: 464, time: 0.514, data: 0.002) G_GAN: 0.769 G_L1: 2.076 D_real: 0.455 D_fake: 0.930 \n",
      "(epoch: 78, iters: 564, time: 0.516, data: 0.002) G_GAN: 0.762 G_L1: 1.578 D_real: 0.588 D_fake: 0.713 \n",
      "(epoch: 78, iters: 664, time: 0.516, data: 0.002) G_GAN: 0.721 G_L1: 1.527 D_real: 0.788 D_fake: 0.595 \n",
      "(epoch: 78, iters: 764, time: 0.780, data: 0.002) G_GAN: 0.720 G_L1: 1.757 D_real: 0.730 D_fake: 0.585 \n",
      "(epoch: 78, iters: 864, time: 0.516, data: 0.002) G_GAN: 0.746 G_L1: 2.219 D_real: 0.459 D_fake: 0.961 \n",
      "End of epoch 78 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000863\n",
      "(epoch: 79, iters: 96, time: 0.516, data: 0.002) G_GAN: 0.773 G_L1: 2.207 D_real: 0.561 D_fake: 0.668 \n",
      "(epoch: 79, iters: 196, time: 0.514, data: 0.002) G_GAN: 0.748 G_L1: 1.306 D_real: 0.837 D_fake: 0.592 \n",
      "(epoch: 79, iters: 296, time: 0.797, data: 0.002) G_GAN: 0.813 G_L1: 2.021 D_real: 0.478 D_fake: 0.907 \n",
      "(epoch: 79, iters: 396, time: 0.516, data: 0.002) G_GAN: 0.717 G_L1: 2.582 D_real: 0.720 D_fake: 0.668 \n",
      "(epoch: 79, iters: 496, time: 0.519, data: 0.002) G_GAN: 0.682 G_L1: 1.987 D_real: 0.949 D_fake: 0.461 \n",
      "(epoch: 79, iters: 596, time: 0.512, data: 0.002) G_GAN: 0.850 G_L1: 2.439 D_real: 0.554 D_fake: 0.638 \n",
      "(epoch: 79, iters: 696, time: 0.803, data: 0.002) G_GAN: 0.867 G_L1: 1.949 D_real: 0.552 D_fake: 0.727 \n",
      "(epoch: 79, iters: 796, time: 0.516, data: 0.002) G_GAN: 0.719 G_L1: 1.577 D_real: 0.834 D_fake: 0.605 \n",
      "End of epoch 79 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0000824\n",
      "(epoch: 80, iters: 28, time: 0.516, data: 0.002) G_GAN: 0.716 G_L1: 2.453 D_real: 0.733 D_fake: 0.594 \n",
      "(epoch: 80, iters: 128, time: 0.515, data: 0.001) G_GAN: 0.702 G_L1: 2.001 D_real: 0.705 D_fake: 0.635 \n",
      "(epoch: 80, iters: 228, time: 0.787, data: 0.002) G_GAN: 0.676 G_L1: 1.407 D_real: 0.634 D_fake: 0.698 \n",
      "(epoch: 80, iters: 328, time: 0.513, data: 0.002) G_GAN: 0.755 G_L1: 2.252 D_real: 0.562 D_fake: 0.793 \n",
      "(epoch: 80, iters: 428, time: 0.515, data: 0.002) G_GAN: 0.819 G_L1: 2.183 D_real: 0.489 D_fake: 0.743 \n",
      "(epoch: 80, iters: 528, time: 0.513, data: 0.002) G_GAN: 0.817 G_L1: 1.562 D_real: 0.873 D_fake: 0.478 \n",
      "(epoch: 80, iters: 628, time: 0.807, data: 0.002) G_GAN: 0.687 G_L1: 1.421 D_real: 0.597 D_fake: 0.718 \n",
      "(epoch: 80, iters: 728, time: 0.516, data: 0.002) G_GAN: 0.810 G_L1: 1.454 D_real: 0.742 D_fake: 0.508 \n",
      "(epoch: 80, iters: 828, time: 0.514, data: 0.002) G_GAN: 0.768 G_L1: 1.604 D_real: 0.706 D_fake: 0.631 \n",
      "saving the model at the end of epoch 80, iters 69440\n",
      "End of epoch 80 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0000784\n",
      "(epoch: 81, iters: 60, time: 0.515, data: 0.002) G_GAN: 0.776 G_L1: 1.514 D_real: 0.547 D_fake: 0.804 \n",
      "(epoch: 81, iters: 160, time: 0.797, data: 0.001) G_GAN: 0.690 G_L1: 1.587 D_real: 0.630 D_fake: 0.654 \n",
      "(epoch: 81, iters: 260, time: 0.514, data: 0.002) G_GAN: 0.810 G_L1: 2.378 D_real: 0.656 D_fake: 0.582 \n",
      "(epoch: 81, iters: 360, time: 0.513, data: 0.002) G_GAN: 0.786 G_L1: 2.014 D_real: 0.490 D_fake: 0.865 \n",
      "(epoch: 81, iters: 460, time: 0.517, data: 0.002) G_GAN: 0.832 G_L1: 2.142 D_real: 0.499 D_fake: 0.663 \n",
      "(epoch: 81, iters: 560, time: 0.812, data: 0.002) G_GAN: 0.776 G_L1: 1.621 D_real: 0.537 D_fake: 0.838 \n",
      "saving the latest model (epoch 81, total_iters 70000)\n",
      "(epoch: 81, iters: 660, time: 0.517, data: 0.002) G_GAN: 0.715 G_L1: 1.922 D_real: 0.612 D_fake: 0.664 \n",
      "(epoch: 81, iters: 760, time: 0.513, data: 0.002) G_GAN: 0.769 G_L1: 2.089 D_real: 0.852 D_fake: 0.445 \n",
      "(epoch: 81, iters: 860, time: 0.514, data: 0.002) G_GAN: 0.794 G_L1: 2.420 D_real: 0.429 D_fake: 0.897 \n",
      "End of epoch 81 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000745\n",
      "(epoch: 82, iters: 92, time: 0.789, data: 0.002) G_GAN: 0.664 G_L1: 1.762 D_real: 0.687 D_fake: 0.604 \n",
      "(epoch: 82, iters: 192, time: 0.515, data: 0.002) G_GAN: 0.744 G_L1: 1.541 D_real: 0.646 D_fake: 0.706 \n",
      "(epoch: 82, iters: 292, time: 0.514, data: 0.002) G_GAN: 0.759 G_L1: 2.052 D_real: 0.642 D_fake: 0.604 \n",
      "(epoch: 82, iters: 392, time: 0.512, data: 0.002) G_GAN: 0.799 G_L1: 1.979 D_real: 0.664 D_fake: 0.569 \n",
      "(epoch: 82, iters: 492, time: 0.781, data: 0.002) G_GAN: 0.788 G_L1: 1.762 D_real: 0.704 D_fake: 0.608 \n",
      "(epoch: 82, iters: 592, time: 0.517, data: 0.002) G_GAN: 0.682 G_L1: 1.421 D_real: 0.626 D_fake: 0.716 \n",
      "(epoch: 82, iters: 692, time: 0.511, data: 0.002) G_GAN: 0.741 G_L1: 1.664 D_real: 0.570 D_fake: 0.791 \n",
      "(epoch: 82, iters: 792, time: 0.513, data: 0.002) G_GAN: 0.862 G_L1: 1.700 D_real: 0.923 D_fake: 0.477 \n",
      "End of epoch 82 / 100 \t Time Taken: 288 sec\n",
      "learning rate = 0.0000706\n",
      "(epoch: 83, iters: 24, time: 0.829, data: 0.002) G_GAN: 0.733 G_L1: 1.810 D_real: 0.733 D_fake: 0.636 \n",
      "(epoch: 83, iters: 124, time: 0.515, data: 0.002) G_GAN: 0.765 G_L1: 1.677 D_real: 0.691 D_fake: 0.684 \n",
      "(epoch: 83, iters: 224, time: 0.513, data: 0.002) G_GAN: 0.790 G_L1: 1.726 D_real: 0.893 D_fake: 0.467 \n",
      "(epoch: 83, iters: 324, time: 0.514, data: 0.001) G_GAN: 0.680 G_L1: 1.473 D_real: 0.520 D_fake: 0.882 \n",
      "(epoch: 83, iters: 424, time: 0.812, data: 0.002) G_GAN: 0.708 G_L1: 1.484 D_real: 0.689 D_fake: 0.699 \n",
      "(epoch: 83, iters: 524, time: 0.514, data: 0.002) G_GAN: 0.794 G_L1: 1.424 D_real: 0.614 D_fake: 0.737 \n",
      "(epoch: 83, iters: 624, time: 0.517, data: 0.002) G_GAN: 0.710 G_L1: 1.238 D_real: 0.660 D_fake: 0.678 \n",
      "(epoch: 83, iters: 724, time: 0.516, data: 0.002) G_GAN: 0.676 G_L1: 2.068 D_real: 0.730 D_fake: 0.601 \n",
      "(epoch: 83, iters: 824, time: 0.827, data: 0.002) G_GAN: 0.719 G_L1: 1.599 D_real: 0.841 D_fake: 0.569 \n",
      "End of epoch 83 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000667\n",
      "(epoch: 84, iters: 56, time: 0.517, data: 0.002) G_GAN: 0.763 G_L1: 2.149 D_real: 0.817 D_fake: 0.535 \n",
      "(epoch: 84, iters: 156, time: 0.515, data: 0.002) G_GAN: 0.694 G_L1: 1.957 D_real: 0.680 D_fake: 0.700 \n",
      "(epoch: 84, iters: 256, time: 0.515, data: 0.002) G_GAN: 0.707 G_L1: 1.669 D_real: 0.667 D_fake: 0.720 \n",
      "(epoch: 84, iters: 356, time: 0.808, data: 0.002) G_GAN: 0.727 G_L1: 1.805 D_real: 0.657 D_fake: 0.681 \n",
      "(epoch: 84, iters: 456, time: 0.516, data: 0.002) G_GAN: 0.737 G_L1: 1.287 D_real: 0.738 D_fake: 0.623 \n",
      "(epoch: 84, iters: 556, time: 0.515, data: 0.002) G_GAN: 0.760 G_L1: 1.955 D_real: 0.812 D_fake: 0.455 \n",
      "(epoch: 84, iters: 656, time: 0.515, data: 0.002) G_GAN: 0.732 G_L1: 1.503 D_real: 0.797 D_fake: 0.612 \n",
      "(epoch: 84, iters: 756, time: 0.830, data: 0.002) G_GAN: 0.710 G_L1: 1.503 D_real: 0.618 D_fake: 0.753 \n",
      "(epoch: 84, iters: 856, time: 0.514, data: 0.002) G_GAN: 0.778 G_L1: 1.716 D_real: 0.680 D_fake: 0.618 \n",
      "End of epoch 84 / 100 \t Time Taken: 291 sec\n",
      "learning rate = 0.0000627\n",
      "(epoch: 85, iters: 88, time: 0.515, data: 0.002) G_GAN: 0.783 G_L1: 1.730 D_real: 0.676 D_fake: 0.682 \n",
      "(epoch: 85, iters: 188, time: 0.515, data: 0.002) G_GAN: 0.605 G_L1: 1.076 D_real: 0.749 D_fake: 0.535 \n",
      "(epoch: 85, iters: 288, time: 0.807, data: 0.002) G_GAN: 0.507 G_L1: 2.480 D_real: 0.565 D_fake: 0.555 \n",
      "(epoch: 85, iters: 388, time: 0.518, data: 0.001) G_GAN: 0.824 G_L1: 2.538 D_real: 0.402 D_fake: 0.895 \n",
      "(epoch: 85, iters: 488, time: 0.516, data: 0.002) G_GAN: 0.762 G_L1: 1.415 D_real: 0.732 D_fake: 0.608 \n",
      "(epoch: 85, iters: 588, time: 0.516, data: 0.002) G_GAN: 0.741 G_L1: 2.103 D_real: 0.718 D_fake: 0.545 \n",
      "(epoch: 85, iters: 688, time: 0.778, data: 0.002) G_GAN: 0.922 G_L1: 2.167 D_real: 0.486 D_fake: 0.715 \n",
      "(epoch: 85, iters: 788, time: 0.516, data: 0.002) G_GAN: 0.764 G_L1: 1.597 D_real: 0.720 D_fake: 0.591 \n",
      "saving the model at the end of epoch 85, iters 73780\n",
      "End of epoch 85 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0000588\n",
      "(epoch: 86, iters: 20, time: 0.513, data: 0.002) G_GAN: 0.762 G_L1: 1.883 D_real: 0.826 D_fake: 0.590 \n",
      "(epoch: 86, iters: 120, time: 0.513, data: 0.002) G_GAN: 1.050 G_L1: 1.662 D_real: 1.349 D_fake: 0.289 \n",
      "(epoch: 86, iters: 220, time: 0.817, data: 0.002) G_GAN: 0.701 G_L1: 1.344 D_real: 0.614 D_fake: 0.741 \n",
      "(epoch: 86, iters: 320, time: 0.516, data: 0.002) G_GAN: 0.738 G_L1: 1.959 D_real: 0.705 D_fake: 0.651 \n",
      "(epoch: 86, iters: 420, time: 0.514, data: 0.002) G_GAN: 0.807 G_L1: 1.509 D_real: 0.741 D_fake: 0.568 \n",
      "(epoch: 86, iters: 520, time: 0.513, data: 0.002) G_GAN: 0.695 G_L1: 1.332 D_real: 0.657 D_fake: 0.746 \n",
      "(epoch: 86, iters: 620, time: 0.798, data: 0.002) G_GAN: 0.718 G_L1: 1.725 D_real: 0.625 D_fake: 0.616 \n",
      "(epoch: 86, iters: 720, time: 0.515, data: 0.002) G_GAN: 0.743 G_L1: 1.218 D_real: 0.578 D_fake: 0.668 \n",
      "(epoch: 86, iters: 820, time: 0.515, data: 0.002) G_GAN: 0.751 G_L1: 2.311 D_real: 0.473 D_fake: 0.945 \n",
      "End of epoch 86 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000549\n",
      "(epoch: 87, iters: 52, time: 0.516, data: 0.002) G_GAN: 0.713 G_L1: 1.521 D_real: 0.476 D_fake: 0.787 \n",
      "(epoch: 87, iters: 152, time: 0.832, data: 0.003) G_GAN: 0.775 G_L1: 1.543 D_real: 0.949 D_fake: 0.495 \n",
      "(epoch: 87, iters: 252, time: 0.514, data: 0.002) G_GAN: 0.667 G_L1: 1.675 D_real: 0.605 D_fake: 0.739 \n",
      "(epoch: 87, iters: 352, time: 0.516, data: 0.002) G_GAN: 0.795 G_L1: 2.621 D_real: 0.590 D_fake: 0.591 \n",
      "saving the latest model (epoch 87, total_iters 75000)\n",
      "(epoch: 87, iters: 452, time: 0.517, data: 0.002) G_GAN: 0.872 G_L1: 2.232 D_real: 0.562 D_fake: 0.579 \n",
      "(epoch: 87, iters: 552, time: 0.806, data: 0.002) G_GAN: 1.290 G_L1: 1.624 D_real: 0.397 D_fake: 0.872 \n",
      "(epoch: 87, iters: 652, time: 0.515, data: 0.002) G_GAN: 0.802 G_L1: 1.993 D_real: 0.792 D_fake: 0.538 \n",
      "(epoch: 87, iters: 752, time: 0.514, data: 0.002) G_GAN: 0.763 G_L1: 2.026 D_real: 0.667 D_fake: 0.623 \n",
      "(epoch: 87, iters: 852, time: 0.513, data: 0.002) G_GAN: 0.810 G_L1: 1.869 D_real: 0.448 D_fake: 0.845 \n",
      "End of epoch 87 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000510\n",
      "(epoch: 88, iters: 84, time: 0.838, data: 0.002) G_GAN: 0.742 G_L1: 1.358 D_real: 0.600 D_fake: 0.749 \n",
      "(epoch: 88, iters: 184, time: 0.516, data: 0.002) G_GAN: 0.588 G_L1: 1.674 D_real: 0.887 D_fake: 0.466 \n",
      "(epoch: 88, iters: 284, time: 0.513, data: 0.002) G_GAN: 0.765 G_L1: 1.342 D_real: 0.795 D_fake: 0.572 \n",
      "(epoch: 88, iters: 384, time: 0.515, data: 0.002) G_GAN: 0.909 G_L1: 2.712 D_real: 0.443 D_fake: 0.671 \n",
      "(epoch: 88, iters: 484, time: 0.829, data: 0.002) G_GAN: 0.727 G_L1: 1.885 D_real: 0.645 D_fake: 0.681 \n",
      "(epoch: 88, iters: 584, time: 0.515, data: 0.002) G_GAN: 0.679 G_L1: 1.300 D_real: 0.626 D_fake: 0.774 \n",
      "(epoch: 88, iters: 684, time: 0.516, data: 0.002) G_GAN: 0.719 G_L1: 1.593 D_real: 0.677 D_fake: 0.669 \n",
      "(epoch: 88, iters: 784, time: 0.513, data: 0.002) G_GAN: 0.765 G_L1: 1.538 D_real: 0.736 D_fake: 0.573 \n",
      "End of epoch 88 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000471\n",
      "(epoch: 89, iters: 16, time: 0.838, data: 0.002) G_GAN: 0.736 G_L1: 1.630 D_real: 0.707 D_fake: 0.657 \n",
      "(epoch: 89, iters: 116, time: 0.515, data: 0.002) G_GAN: 0.752 G_L1: 1.520 D_real: 0.788 D_fake: 0.573 \n",
      "(epoch: 89, iters: 216, time: 0.514, data: 0.002) G_GAN: 0.704 G_L1: 1.403 D_real: 0.674 D_fake: 0.714 \n",
      "(epoch: 89, iters: 316, time: 0.512, data: 0.002) G_GAN: 0.825 G_L1: 1.816 D_real: 0.500 D_fake: 0.706 \n",
      "(epoch: 89, iters: 416, time: 0.804, data: 0.002) G_GAN: 0.715 G_L1: 1.799 D_real: 0.639 D_fake: 0.682 \n",
      "(epoch: 89, iters: 516, time: 0.515, data: 0.002) G_GAN: 0.739 G_L1: 2.141 D_real: 0.675 D_fake: 0.638 \n",
      "(epoch: 89, iters: 616, time: 0.514, data: 0.002) G_GAN: 0.736 G_L1: 2.572 D_real: 0.487 D_fake: 0.934 \n",
      "(epoch: 89, iters: 716, time: 0.516, data: 0.002) G_GAN: 0.759 G_L1: 2.866 D_real: 0.681 D_fake: 0.640 \n",
      "(epoch: 89, iters: 816, time: 0.832, data: 0.002) G_GAN: 0.763 G_L1: 1.442 D_real: 0.572 D_fake: 0.808 \n",
      "End of epoch 89 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0000431\n",
      "(epoch: 90, iters: 48, time: 0.513, data: 0.002) G_GAN: 0.742 G_L1: 1.409 D_real: 0.736 D_fake: 0.649 \n",
      "(epoch: 90, iters: 148, time: 0.511, data: 0.002) G_GAN: 0.755 G_L1: 2.022 D_real: 0.578 D_fake: 0.725 \n",
      "(epoch: 90, iters: 248, time: 0.514, data: 0.002) G_GAN: 0.752 G_L1: 1.997 D_real: 0.642 D_fake: 0.672 \n",
      "(epoch: 90, iters: 348, time: 0.824, data: 0.002) G_GAN: 0.840 G_L1: 2.199 D_real: 0.475 D_fake: 0.837 \n",
      "(epoch: 90, iters: 448, time: 0.515, data: 0.002) G_GAN: 0.711 G_L1: 1.764 D_real: 0.706 D_fake: 0.647 \n",
      "(epoch: 90, iters: 548, time: 0.516, data: 0.002) G_GAN: 0.719 G_L1: 1.151 D_real: 0.597 D_fake: 0.753 \n",
      "(epoch: 90, iters: 648, time: 0.515, data: 0.002) G_GAN: 0.694 G_L1: 1.731 D_real: 0.583 D_fake: 0.760 \n",
      "(epoch: 90, iters: 748, time: 0.822, data: 0.002) G_GAN: 0.694 G_L1: 1.771 D_real: 0.626 D_fake: 0.724 \n",
      "(epoch: 90, iters: 848, time: 0.515, data: 0.002) G_GAN: 0.774 G_L1: 1.822 D_real: 0.565 D_fake: 0.689 \n",
      "saving the model at the end of epoch 90, iters 78120\n",
      "End of epoch 90 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0000392\n",
      "(epoch: 91, iters: 80, time: 0.515, data: 0.002) G_GAN: 0.723 G_L1: 1.504 D_real: 0.567 D_fake: 0.758 \n",
      "(epoch: 91, iters: 180, time: 0.516, data: 0.002) G_GAN: 0.744 G_L1: 1.344 D_real: 0.847 D_fake: 0.596 \n",
      "(epoch: 91, iters: 280, time: 0.810, data: 0.002) G_GAN: 0.841 G_L1: 1.556 D_real: 0.808 D_fake: 0.550 \n",
      "(epoch: 91, iters: 380, time: 0.516, data: 0.002) G_GAN: 0.728 G_L1: 2.289 D_real: 0.621 D_fake: 0.685 \n",
      "(epoch: 91, iters: 480, time: 0.516, data: 0.002) G_GAN: 0.772 G_L1: 2.016 D_real: 0.678 D_fake: 0.607 \n",
      "(epoch: 91, iters: 580, time: 0.516, data: 0.001) G_GAN: 0.768 G_L1: 1.891 D_real: 0.813 D_fake: 0.572 \n",
      "(epoch: 91, iters: 680, time: 0.828, data: 0.002) G_GAN: 0.763 G_L1: 1.744 D_real: 0.679 D_fake: 0.578 \n",
      "(epoch: 91, iters: 780, time: 0.516, data: 0.001) G_GAN: 0.721 G_L1: 2.296 D_real: 0.738 D_fake: 0.632 \n",
      "End of epoch 91 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000353\n",
      "(epoch: 92, iters: 12, time: 0.516, data: 0.002) G_GAN: 1.252 G_L1: 2.824 D_real: 0.294 D_fake: 0.916 \n",
      "(epoch: 92, iters: 112, time: 0.514, data: 0.001) G_GAN: 0.722 G_L1: 2.025 D_real: 0.659 D_fake: 0.702 \n",
      "(epoch: 92, iters: 212, time: 0.839, data: 0.002) G_GAN: 0.726 G_L1: 1.547 D_real: 0.707 D_fake: 0.685 \n",
      "(epoch: 92, iters: 312, time: 0.513, data: 0.002) G_GAN: 0.649 G_L1: 1.304 D_real: 0.626 D_fake: 0.793 \n",
      "(epoch: 92, iters: 412, time: 0.514, data: 0.002) G_GAN: 0.792 G_L1: 2.438 D_real: 0.558 D_fake: 0.694 \n",
      "(epoch: 92, iters: 512, time: 0.515, data: 0.002) G_GAN: 0.636 G_L1: 1.549 D_real: 0.626 D_fake: 0.798 \n",
      "(epoch: 92, iters: 612, time: 0.837, data: 0.002) G_GAN: 0.871 G_L1: 2.108 D_real: 0.537 D_fake: 0.636 \n",
      "(epoch: 92, iters: 712, time: 0.528, data: 0.001) G_GAN: 0.764 G_L1: 1.763 D_real: 0.595 D_fake: 0.673 \n",
      "(epoch: 92, iters: 812, time: 0.514, data: 0.002) G_GAN: 0.791 G_L1: 1.495 D_real: 0.558 D_fake: 0.709 \n",
      "End of epoch 92 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000314\n",
      "(epoch: 93, iters: 44, time: 0.517, data: 0.002) G_GAN: 0.768 G_L1: 2.395 D_real: 0.601 D_fake: 0.767 \n",
      "(epoch: 93, iters: 144, time: 0.814, data: 0.002) G_GAN: 0.709 G_L1: 2.141 D_real: 0.729 D_fake: 0.622 \n",
      "saving the latest model (epoch 93, total_iters 80000)\n",
      "(epoch: 93, iters: 244, time: 0.516, data: 0.003) G_GAN: 0.775 G_L1: 1.237 D_real: 0.891 D_fake: 0.552 \n",
      "(epoch: 93, iters: 344, time: 0.518, data: 0.002) G_GAN: 0.801 G_L1: 2.059 D_real: 0.725 D_fake: 0.581 \n",
      "(epoch: 93, iters: 444, time: 0.513, data: 0.002) G_GAN: 0.722 G_L1: 1.623 D_real: 0.687 D_fake: 0.700 \n",
      "(epoch: 93, iters: 544, time: 0.845, data: 0.002) G_GAN: 0.740 G_L1: 1.328 D_real: 0.780 D_fake: 0.618 \n",
      "(epoch: 93, iters: 644, time: 0.514, data: 0.002) G_GAN: 0.730 G_L1: 1.710 D_real: 0.717 D_fake: 0.667 \n",
      "(epoch: 93, iters: 744, time: 0.514, data: 0.002) G_GAN: 0.710 G_L1: 1.981 D_real: 0.613 D_fake: 0.752 \n",
      "(epoch: 93, iters: 844, time: 0.515, data: 0.002) G_GAN: 0.846 G_L1: 2.081 D_real: 0.817 D_fake: 0.441 \n",
      "End of epoch 93 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0000275\n",
      "(epoch: 94, iters: 76, time: 0.833, data: 0.002) G_GAN: 0.684 G_L1: 1.378 D_real: 0.749 D_fake: 0.480 \n",
      "(epoch: 94, iters: 176, time: 0.520, data: 0.002) G_GAN: 0.758 G_L1: 1.585 D_real: 0.541 D_fake: 0.742 \n",
      "(epoch: 94, iters: 276, time: 0.514, data: 0.002) G_GAN: 0.806 G_L1: 1.337 D_real: 0.680 D_fake: 0.602 \n",
      "(epoch: 94, iters: 376, time: 0.513, data: 0.002) G_GAN: 0.794 G_L1: 1.419 D_real: 0.789 D_fake: 0.586 \n",
      "(epoch: 94, iters: 476, time: 0.813, data: 0.002) G_GAN: 0.678 G_L1: 2.646 D_real: 0.509 D_fake: 0.865 \n",
      "(epoch: 94, iters: 576, time: 0.515, data: 0.001) G_GAN: 0.775 G_L1: 2.294 D_real: 0.501 D_fake: 0.855 \n",
      "(epoch: 94, iters: 676, time: 0.513, data: 0.002) G_GAN: 0.725 G_L1: 1.679 D_real: 0.654 D_fake: 0.660 \n",
      "(epoch: 94, iters: 776, time: 0.514, data: 0.002) G_GAN: 0.792 G_L1: 1.971 D_real: 0.683 D_fake: 0.575 \n",
      "End of epoch 94 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0000235\n",
      "(epoch: 95, iters: 8, time: 0.824, data: 0.002) G_GAN: 0.674 G_L1: 1.624 D_real: 0.641 D_fake: 0.779 \n",
      "(epoch: 95, iters: 108, time: 0.514, data: 0.003) G_GAN: 0.702 G_L1: 1.979 D_real: 0.714 D_fake: 0.502 \n",
      "(epoch: 95, iters: 208, time: 0.513, data: 0.002) G_GAN: 0.713 G_L1: 1.191 D_real: 0.699 D_fake: 0.679 \n",
      "(epoch: 95, iters: 308, time: 0.516, data: 0.002) G_GAN: 0.784 G_L1: 1.665 D_real: 0.831 D_fake: 0.583 \n",
      "(epoch: 95, iters: 408, time: 0.816, data: 0.002) G_GAN: 0.780 G_L1: 2.145 D_real: 0.620 D_fake: 0.634 \n",
      "(epoch: 95, iters: 508, time: 0.515, data: 0.002) G_GAN: 0.809 G_L1: 2.084 D_real: 0.742 D_fake: 0.551 \n",
      "(epoch: 95, iters: 608, time: 0.513, data: 0.002) G_GAN: 0.744 G_L1: 1.576 D_real: 0.675 D_fake: 0.653 \n",
      "(epoch: 95, iters: 708, time: 0.516, data: 0.002) G_GAN: 0.765 G_L1: 1.917 D_real: 0.563 D_fake: 0.732 \n",
      "(epoch: 95, iters: 808, time: 0.803, data: 0.002) G_GAN: 0.818 G_L1: 1.744 D_real: 0.783 D_fake: 0.532 \n",
      "saving the model at the end of epoch 95, iters 82460\n",
      "End of epoch 95 / 100 \t Time Taken: 290 sec\n",
      "learning rate = 0.0000196\n",
      "(epoch: 96, iters: 40, time: 0.516, data: 0.002) G_GAN: 0.698 G_L1: 2.028 D_real: 0.528 D_fake: 0.775 \n",
      "(epoch: 96, iters: 140, time: 0.514, data: 0.001) G_GAN: 0.723 G_L1: 1.664 D_real: 0.676 D_fake: 0.676 \n",
      "(epoch: 96, iters: 240, time: 0.515, data: 0.002) G_GAN: 0.717 G_L1: 1.614 D_real: 0.631 D_fake: 0.707 \n",
      "(epoch: 96, iters: 340, time: 0.824, data: 0.002) G_GAN: 0.899 G_L1: 1.437 D_real: 0.781 D_fake: 0.452 \n",
      "(epoch: 96, iters: 440, time: 0.513, data: 0.002) G_GAN: 0.700 G_L1: 1.318 D_real: 0.619 D_fake: 0.730 \n",
      "(epoch: 96, iters: 540, time: 0.514, data: 0.002) G_GAN: 0.751 G_L1: 1.521 D_real: 0.722 D_fake: 0.652 \n",
      "(epoch: 96, iters: 640, time: 0.513, data: 0.002) G_GAN: 0.789 G_L1: 2.394 D_real: 0.701 D_fake: 0.588 \n",
      "(epoch: 96, iters: 740, time: 0.827, data: 0.002) G_GAN: 0.693 G_L1: 1.735 D_real: 0.668 D_fake: 0.737 \n",
      "(epoch: 96, iters: 840, time: 0.514, data: 0.002) G_GAN: 0.759 G_L1: 1.242 D_real: 0.762 D_fake: 0.589 \n",
      "End of epoch 96 / 100 \t Time Taken: 288 sec\n",
      "learning rate = 0.0000157\n",
      "(epoch: 97, iters: 72, time: 0.514, data: 0.001) G_GAN: 0.708 G_L1: 1.503 D_real: 0.658 D_fake: 0.716 \n",
      "(epoch: 97, iters: 172, time: 0.517, data: 0.001) G_GAN: 0.728 G_L1: 1.438 D_real: 0.594 D_fake: 0.716 \n",
      "(epoch: 97, iters: 272, time: 0.776, data: 0.002) G_GAN: 0.884 G_L1: 1.389 D_real: 0.509 D_fake: 0.648 \n",
      "(epoch: 97, iters: 372, time: 0.512, data: 0.002) G_GAN: 0.782 G_L1: 1.389 D_real: 0.750 D_fake: 0.605 \n",
      "(epoch: 97, iters: 472, time: 0.514, data: 0.002) G_GAN: 0.796 G_L1: 2.148 D_real: 0.661 D_fake: 0.618 \n",
      "(epoch: 97, iters: 572, time: 0.514, data: 0.002) G_GAN: 0.769 G_L1: 1.920 D_real: 0.682 D_fake: 0.658 \n",
      "(epoch: 97, iters: 672, time: 0.812, data: 0.002) G_GAN: 0.715 G_L1: 2.257 D_real: 0.621 D_fake: 0.772 \n",
      "(epoch: 97, iters: 772, time: 0.515, data: 0.002) G_GAN: 0.789 G_L1: 3.040 D_real: 0.377 D_fake: 0.782 \n",
      "End of epoch 97 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000118\n",
      "(epoch: 98, iters: 4, time: 0.515, data: 0.002) G_GAN: 0.783 G_L1: 2.270 D_real: 0.623 D_fake: 0.674 \n",
      "(epoch: 98, iters: 104, time: 0.516, data: 0.001) G_GAN: 0.685 G_L1: 1.363 D_real: 0.656 D_fake: 0.735 \n",
      "(epoch: 98, iters: 204, time: 0.834, data: 0.002) G_GAN: 0.737 G_L1: 1.573 D_real: 0.620 D_fake: 0.695 \n",
      "(epoch: 98, iters: 304, time: 0.514, data: 0.002) G_GAN: 0.726 G_L1: 2.236 D_real: 0.515 D_fake: 0.689 \n",
      "(epoch: 98, iters: 404, time: 0.514, data: 0.002) G_GAN: 0.692 G_L1: 1.789 D_real: 0.580 D_fake: 0.754 \n",
      "(epoch: 98, iters: 504, time: 0.515, data: 0.002) G_GAN: 0.607 G_L1: 2.118 D_real: 0.531 D_fake: 0.858 \n",
      "(epoch: 98, iters: 604, time: 0.828, data: 0.002) G_GAN: 0.781 G_L1: 1.493 D_real: 0.751 D_fake: 0.617 \n",
      "(epoch: 98, iters: 704, time: 0.515, data: 0.002) G_GAN: 0.734 G_L1: 1.404 D_real: 0.712 D_fake: 0.673 \n",
      "(epoch: 98, iters: 804, time: 0.515, data: 0.002) G_GAN: 0.737 G_L1: 1.775 D_real: 0.667 D_fake: 0.682 \n",
      "saving the latest model (epoch 98, total_iters 85000)\n",
      "End of epoch 98 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000078\n",
      "(epoch: 99, iters: 36, time: 0.512, data: 0.002) G_GAN: 0.743 G_L1: 1.717 D_real: 0.706 D_fake: 0.661 \n",
      "(epoch: 99, iters: 136, time: 0.839, data: 0.002) G_GAN: 0.709 G_L1: 1.400 D_real: 0.654 D_fake: 0.694 \n",
      "(epoch: 99, iters: 236, time: 0.514, data: 0.002) G_GAN: 0.799 G_L1: 1.526 D_real: 0.669 D_fake: 0.611 \n",
      "(epoch: 99, iters: 336, time: 0.514, data: 0.002) G_GAN: 0.680 G_L1: 1.456 D_real: 0.670 D_fake: 0.723 \n",
      "(epoch: 99, iters: 436, time: 0.515, data: 0.002) G_GAN: 0.740 G_L1: 1.105 D_real: 0.719 D_fake: 0.659 \n",
      "(epoch: 99, iters: 536, time: 0.858, data: 0.002) G_GAN: 0.785 G_L1: 1.465 D_real: 0.735 D_fake: 0.613 \n",
      "(epoch: 99, iters: 636, time: 0.513, data: 0.002) G_GAN: 0.801 G_L1: 1.591 D_real: 0.679 D_fake: 0.612 \n",
      "(epoch: 99, iters: 736, time: 0.514, data: 0.002) G_GAN: 0.691 G_L1: 1.353 D_real: 0.625 D_fake: 0.719 \n",
      "(epoch: 99, iters: 836, time: 0.515, data: 0.002) G_GAN: 0.749 G_L1: 0.765 D_real: 0.742 D_fake: 0.646 \n",
      "End of epoch 99 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000039\n",
      "(epoch: 100, iters: 68, time: 0.834, data: 0.002) G_GAN: 0.847 G_L1: 2.831 D_real: 0.693 D_fake: 0.564 \n",
      "(epoch: 100, iters: 168, time: 0.512, data: 0.002) G_GAN: 0.934 G_L1: 1.114 D_real: 0.623 D_fake: 0.527 \n",
      "(epoch: 100, iters: 268, time: 0.515, data: 0.002) G_GAN: 0.746 G_L1: 1.863 D_real: 0.560 D_fake: 0.674 \n",
      "(epoch: 100, iters: 368, time: 0.511, data: 0.001) G_GAN: 0.724 G_L1: 1.278 D_real: 0.626 D_fake: 0.683 \n",
      "(epoch: 100, iters: 468, time: 0.803, data: 0.002) G_GAN: 0.701 G_L1: 1.739 D_real: 0.654 D_fake: 0.708 \n",
      "(epoch: 100, iters: 568, time: 0.513, data: 0.002) G_GAN: 0.732 G_L1: 1.318 D_real: 0.744 D_fake: 0.666 \n",
      "(epoch: 100, iters: 668, time: 0.512, data: 0.002) G_GAN: 0.774 G_L1: 1.780 D_real: 0.741 D_fake: 0.636 \n",
      "(epoch: 100, iters: 768, time: 0.513, data: 0.002) G_GAN: 0.717 G_L1: 1.477 D_real: 0.673 D_fake: 0.692 \n",
      "(epoch: 100, iters: 868, time: 0.824, data: 0.002) G_GAN: 0.741 G_L1: 1.687 D_real: 0.692 D_fake: 0.676 \n",
      "saving the model at the end of epoch 100, iters 86800\n",
      "End of epoch 100 / 100 \t Time Taken: 289 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot syndata --model pix2pix --batch_size 2 --no_dropout --output_nc 1 --norm batch --niter 50 --niter_decay 50 --no_flip --checkpoints_dir may17 --netG resnet_9blocks --preprocess none --name syndata868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: may17                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: testA/                        \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: syndata868                    \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: True                          \t[default: False]\n",
      "                     norm: batch                         \t[default: instance]\n",
      "                    ntest: inf                           \n",
      "                 num_test: 120                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: resu                          \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from may17/syndata868/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "DataParallel(\n",
      "  (module): ResnetGenerator(\n",
      "    (model): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (18): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (26): Conv2d(64, 1, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (27): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['testA/251.jpg']\n",
      "processing (0005)-th image... ['testA/256.jpg']\n",
      "processing (0010)-th image... ['testA/261.jpg']\n",
      "processing (0015)-th image... ['testA/266.jpg']\n",
      "processing (0020)-th image... ['testA/271.jpg']\n",
      "processing (0025)-th image... ['testA/276.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot testA/ --num_test 120 --dataset_mode single --model test --results_dir resu --netG resnet_9blocks --preprocess none --no_flip --name syndata868  --norm batch --checkpoints_dir may17 --output_nc 1 --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: may21                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: testimages                    \t[default: None]\n",
      "             dataset_mode: single                        \t[default: aligned]\n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: crop256                       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: True                          \t[default: False]\n",
      "                     norm: batch                         \n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_jun22                 \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from may21/crop256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.377 M\n",
      "DataParallel(\n",
      "  (module): ResnetGenerator(\n",
      "    (model): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (18): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (26): Conv2d(64, 1, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (27): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-----------------------------------------------\n",
      "Traceback (most recent call last):\r\n",
      "  File \"test.py\", line 59, in <module>\r\n",
      "    model.set_input(data)  # unpack data from data loader\r\n",
      "  File \"/home/kalai/exp/pytorch-CycleGAN-and-pix2pix/models/pix2pix_model.py\", line 83, in set_input\r\n",
      "    self.real_B = input['B' if AtoB else 'A'].to(self.device)\r\n",
      "KeyError: 'B'\r\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot  --results_dir results_jun22 --model pix2pix --dataset_mode single --netG resnet_9blocks --no_dropout --preprocess none --no_flip --output_nc 1 --name crop256 --checkpoints_dir may21"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pix2pix.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
