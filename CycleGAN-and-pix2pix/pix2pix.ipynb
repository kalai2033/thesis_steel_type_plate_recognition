{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimg --results_dir results_mar24_300 --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name pix2pixKSB --input_nc 1 --no_flip --output_nc 1 --norm instance --checkpoints_dir mar24_300 --batch_size 4 --preprocess none --name mar24_300_noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train AB dir 300 images with no preprocess and default flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dB3MY2iwUQmQ",
    "outputId": "b74bcfca-5edf-4e21-d469-d226b42eaf78"
   },
   "outputs": [],
   "source": [
    "!python train.py --dataroot AB --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4  --netG resnet_9blocks --preprocess none --name img300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train AB dir 300 images with no preprocess and noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot AB --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4  --netG resnet_9blocks --preprocess none --no_flip --name img300_noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train AB dir 300 images with crop and default flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot AB --netG resnet_9blocks --preprocess crop  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --name img300_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train AB dir 300 images with crop and noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot AB --netG resnet_9blocks --preprocess crop  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --no_flip --name img300_crop_noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train diff 300 images with crop and default flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot diff --netG resnet_9blocks --preprocess crop  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28_300 --gpu_ids 0,1 --batch_size 4 --name mar28_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train diff 300 images with no preprocess  and no flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot diff --netG resnet_9blocks --preprocess none  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28_300 --gpu_ids 0,1 --batch_size 4 --name mar28_diff_noflip --no_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train nov 1300 images with no preprocess and default flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot nov/AB --netG resnet_9blocks --preprocess none  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --name img1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train nov 1300 images with no preprocess and noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot nov/AB --netG resnet_9blocks --preprocess none  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --name img1300_noflip --no_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train nov 1300 images with crop and default flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot nov/AB --netG resnet_9blocks --crop_size 400 --preprocess crop  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --name img1300_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train nov 1300 images with crop and noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot nov/AB --crop_size 384 --netG resnet_9blocks --preprocess crop  --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar28 --gpu_ids 0,1 --batch_size 4 --name img1300_crop300_noflip --no_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot syn_real_diff_1000/AB --netG resnet_9blocks --preprocess none --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar30 --gpu_ids 0,1 --batch_size 4 --no_flip --name img1000_noflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot syn_real_diff_1000/AB --netG resnet_9blocks --preprocess none --model pix2pix --input_nc 1 --norm instance --checkpoints_dir mar30 --gpu_ids 0,1 --batch_size 4 --name img1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img1000 --input_nc 1 --norm instance --checkpoints_dir mar30 --batch_size 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img1000_noflip --no_flip --input_nc 1 --norm instance --checkpoints_dir mar30 --batch_size 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SnH_jgPke48o"
   },
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img1300 --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --no_flip --name img1300_noflip --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --no_flip --name img1300_crop_noflip --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img1300_crop --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img300 --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --no_flip --name img300_crop_noflip --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --no_flip --name img300_noflip --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --results_dir results_lpe --model test --dataset_mode single --netG resnet_9blocks --preprocess none --name img300_crop --input_nc 1 --norm instance --checkpoints_dir mar28 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot lp --results_dir results_lp --model test --dataset_mode single --netG resnet_9blocks --preprocess none --no_flip --name mar28_diff --input_nc 1 --norm instance --checkpoints_dir mar28_300 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot lp --results_dir results_lp --model test --dataset_mode single --netG resnet_9blocks --preprocess none --no_flip --name mar28_diff_noflip --input_nc 1 --norm instance --checkpoints_dir mar28_300 --batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot kalai-cyclegan  --name cyclebw --gpu_ids 0,1 --batch_size 2 --netG resnet_9blocks --preprocess resize_and_crop --load_size 400 --crop_size 300 --input_nc 1 --output_nc 1 --norm instance  --checkpoints_dir apr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot testimages --no_dropout --dataset_mode single --model test --results_dir results_cyc --netG resnet_9blocks --preprocess none --name cyclebw  --norm instance --checkpoints_dir apr6 --input_nc 1 --output_nc 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 2                             \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 300                           \t[default: 256]\n",
      "                 dataroot: cycleGANrealsyn               \t[default: None]\n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: True                          \t[default: None]\n",
      "                 lambda_A: 10.0                          \n",
      "                 lambda_B: 10.0                          \n",
      "          lambda_identity: 0.5                           \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 400                           \t[default: 286]\n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \n",
      "               n_layers_D: 3                             \n",
      "                     name: cyclerealsyn                  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [UnalignedDataset] was created\n",
      "The number of training images = 500\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [CycleGANModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G_A] Total number of parameters : 11.366 M\n",
      "[Network G_B] Total number of parameters : 11.366 M\n",
      "[Network D_A] Total number of parameters : 2.763 M\n",
      "[Network D_B] Total number of parameters : 2.763 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory Apr17/cyclerealsyn/web...\n",
      "(epoch: 1, iters: 100, time: 0.234, data: 0.086) D_A: 0.368 G_A: 0.357 cycle_A: 2.344 idt_A: 0.518 D_B: 0.381 G_B: 0.471 cycle_B: 1.186 idt_B: 0.824 \n",
      "(epoch: 1, iters: 200, time: 0.226, data: 0.002) D_A: 0.483 G_A: 0.420 cycle_A: 2.719 idt_A: 0.396 D_B: 0.373 G_B: 0.361 cycle_B: 0.874 idt_B: 1.256 \n",
      "(epoch: 1, iters: 300, time: 0.235, data: 0.002) D_A: 0.365 G_A: 0.667 cycle_A: 2.193 idt_A: 0.431 D_B: 0.426 G_B: 0.571 cycle_B: 0.780 idt_B: 0.938 \n",
      "(epoch: 1, iters: 400, time: 0.401, data: 0.002) D_A: 0.282 G_A: 0.301 cycle_A: 1.962 idt_A: 0.378 D_B: 0.308 G_B: 0.386 cycle_B: 0.814 idt_B: 0.700 \n",
      "(epoch: 1, iters: 500, time: 0.231, data: 0.002) D_A: 0.278 G_A: 0.266 cycle_A: 1.467 idt_A: 0.461 D_B: 0.234 G_B: 0.254 cycle_B: 0.981 idt_B: 0.643 \n",
      "End of epoch 1 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 100, time: 0.228, data: 0.116) D_A: 0.235 G_A: 0.357 cycle_A: 2.620 idt_A: 0.211 D_B: 0.227 G_B: 0.434 cycle_B: 0.480 idt_B: 1.194 \n",
      "(epoch: 2, iters: 200, time: 0.229, data: 0.002) D_A: 0.188 G_A: 0.452 cycle_A: 2.332 idt_A: 0.262 D_B: 0.327 G_B: 0.401 cycle_B: 0.575 idt_B: 1.274 \n",
      "(epoch: 2, iters: 300, time: 0.394, data: 0.001) D_A: 0.240 G_A: 0.316 cycle_A: 1.859 idt_A: 0.300 D_B: 0.221 G_B: 0.263 cycle_B: 0.634 idt_B: 0.464 \n",
      "(epoch: 2, iters: 400, time: 0.229, data: 0.001) D_A: 0.241 G_A: 0.516 cycle_A: 2.691 idt_A: 0.252 D_B: 0.256 G_B: 0.358 cycle_B: 0.514 idt_B: 1.180 \n",
      "(epoch: 2, iters: 500, time: 0.229, data: 0.002) D_A: 0.201 G_A: 0.344 cycle_A: 1.579 idt_A: 0.278 D_B: 0.245 G_B: 0.390 cycle_B: 0.583 idt_B: 0.662 \n",
      "End of epoch 2 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 100, time: 0.232, data: 0.109) D_A: 0.143 G_A: 0.393 cycle_A: 1.844 idt_A: 0.218 D_B: 0.208 G_B: 0.344 cycle_B: 0.469 idt_B: 0.809 \n",
      "(epoch: 3, iters: 200, time: 0.404, data: 0.002) D_A: 0.152 G_A: 0.548 cycle_A: 2.461 idt_A: 0.202 D_B: 0.246 G_B: 0.383 cycle_B: 0.450 idt_B: 1.151 \n",
      "(epoch: 3, iters: 300, time: 0.231, data: 0.001) D_A: 0.175 G_A: 0.392 cycle_A: 1.847 idt_A: 0.249 D_B: 0.230 G_B: 0.243 cycle_B: 0.547 idt_B: 1.206 \n",
      "(epoch: 3, iters: 400, time: 0.229, data: 0.002) D_A: 0.267 G_A: 0.544 cycle_A: 1.667 idt_A: 0.254 D_B: 0.241 G_B: 0.381 cycle_B: 0.643 idt_B: 0.572 \n",
      "(epoch: 3, iters: 500, time: 0.236, data: 0.002) D_A: 0.172 G_A: 0.516 cycle_A: 1.157 idt_A: 0.225 D_B: 0.214 G_B: 0.327 cycle_B: 0.491 idt_B: 0.385 \n",
      "End of epoch 3 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 100, time: 0.409, data: 0.105) D_A: 0.160 G_A: 0.375 cycle_A: 3.241 idt_A: 0.237 D_B: 0.228 G_B: 0.383 cycle_B: 0.496 idt_B: 1.070 \n",
      "(epoch: 4, iters: 200, time: 0.231, data: 0.001) D_A: 0.183 G_A: 0.316 cycle_A: 2.843 idt_A: 0.259 D_B: 0.220 G_B: 0.257 cycle_B: 0.487 idt_B: 1.325 \n",
      "(epoch: 4, iters: 300, time: 0.237, data: 0.002) D_A: 0.261 G_A: 0.427 cycle_A: 3.956 idt_A: 0.362 D_B: 0.255 G_B: 0.338 cycle_B: 0.753 idt_B: 2.128 \n",
      "(epoch: 4, iters: 400, time: 0.248, data: 0.002) D_A: 0.320 G_A: 0.103 cycle_A: 1.453 idt_A: 0.337 D_B: 0.285 G_B: 0.252 cycle_B: 0.682 idt_B: 0.653 \n",
      "(epoch: 4, iters: 500, time: 0.380, data: 0.002) D_A: 0.278 G_A: 0.821 cycle_A: 1.843 idt_A: 0.310 D_B: 0.220 G_B: 0.262 cycle_B: 0.640 idt_B: 0.706 \n",
      "End of epoch 4 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 100, time: 0.239, data: 0.101) D_A: 0.158 G_A: 0.564 cycle_A: 2.647 idt_A: 0.175 D_B: 0.231 G_B: 0.216 cycle_B: 0.333 idt_B: 1.241 \n",
      "(epoch: 5, iters: 200, time: 0.246, data: 0.002) D_A: 0.204 G_A: 0.550 cycle_A: 1.285 idt_A: 0.365 D_B: 0.225 G_B: 0.180 cycle_B: 0.680 idt_B: 0.560 \n",
      "(epoch: 5, iters: 300, time: 0.229, data: 0.001) D_A: 0.169 G_A: 0.859 cycle_A: 4.075 idt_A: 0.160 D_B: 0.197 G_B: 0.587 cycle_B: 0.389 idt_B: 1.584 \n",
      "(epoch: 5, iters: 400, time: 0.387, data: 0.001) D_A: 0.188 G_A: 0.234 cycle_A: 1.680 idt_A: 0.189 D_B: 0.300 G_B: 0.261 cycle_B: 0.448 idt_B: 0.698 \n",
      "(epoch: 5, iters: 500, time: 0.229, data: 0.001) D_A: 0.225 G_A: 0.380 cycle_A: 1.502 idt_A: 0.387 D_B: 0.270 G_B: 0.310 cycle_B: 0.895 idt_B: 0.571 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model at the end of epoch 5, iters 2500\n",
      "End of epoch 5 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.232, data: 0.093) D_A: 0.356 G_A: 0.100 cycle_A: 2.760 idt_A: 0.208 D_B: 0.219 G_B: 0.394 cycle_B: 0.490 idt_B: 1.335 \n",
      "(epoch: 6, iters: 200, time: 0.232, data: 0.002) D_A: 0.274 G_A: 1.241 cycle_A: 2.470 idt_A: 0.223 D_B: 0.206 G_B: 0.323 cycle_B: 0.514 idt_B: 1.089 \n",
      "(epoch: 6, iters: 300, time: 0.401, data: 0.001) D_A: 0.173 G_A: 0.725 cycle_A: 2.047 idt_A: 0.450 D_B: 0.222 G_B: 0.243 cycle_B: 0.895 idt_B: 0.801 \n",
      "(epoch: 6, iters: 400, time: 0.238, data: 0.001) D_A: 0.159 G_A: 0.428 cycle_A: 2.301 idt_A: 0.251 D_B: 0.174 G_B: 0.389 cycle_B: 0.539 idt_B: 1.288 \n",
      "(epoch: 6, iters: 500, time: 0.238, data: 0.002) D_A: 0.213 G_A: 0.492 cycle_A: 1.448 idt_A: 0.235 D_B: 0.213 G_B: 0.401 cycle_B: 0.468 idt_B: 0.882 \n",
      "End of epoch 6 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 100, time: 0.247, data: 0.097) D_A: 0.152 G_A: 0.305 cycle_A: 2.200 idt_A: 0.503 D_B: 0.230 G_B: 0.270 cycle_B: 1.129 idt_B: 0.706 \n",
      "(epoch: 7, iters: 200, time: 0.385, data: 0.001) D_A: 0.135 G_A: 0.411 cycle_A: 3.057 idt_A: 0.139 D_B: 0.222 G_B: 0.204 cycle_B: 0.325 idt_B: 1.358 \n",
      "(epoch: 7, iters: 300, time: 0.230, data: 0.001) D_A: 0.185 G_A: 0.385 cycle_A: 1.693 idt_A: 0.222 D_B: 0.223 G_B: 0.567 cycle_B: 0.630 idt_B: 0.577 \n",
      "(epoch: 7, iters: 400, time: 0.232, data: 0.001) D_A: 0.216 G_A: 0.294 cycle_A: 2.208 idt_A: 0.354 D_B: 0.256 G_B: 0.537 cycle_B: 0.719 idt_B: 0.513 \n",
      "(epoch: 7, iters: 500, time: 0.234, data: 0.001) D_A: 0.195 G_A: 0.420 cycle_A: 1.630 idt_A: 0.483 D_B: 0.163 G_B: 0.544 cycle_B: 1.020 idt_B: 0.545 \n",
      "End of epoch 7 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 100, time: 0.387, data: 0.100) D_A: 0.327 G_A: 0.204 cycle_A: 1.516 idt_A: 0.354 D_B: 0.179 G_B: 0.334 cycle_B: 0.718 idt_B: 0.446 \n",
      "(epoch: 8, iters: 200, time: 0.229, data: 0.001) D_A: 0.277 G_A: 0.215 cycle_A: 2.108 idt_A: 0.193 D_B: 0.262 G_B: 0.547 cycle_B: 0.473 idt_B: 0.678 \n",
      "(epoch: 8, iters: 300, time: 0.231, data: 0.001) D_A: 0.106 G_A: 0.591 cycle_A: 1.556 idt_A: 0.186 D_B: 0.175 G_B: 0.361 cycle_B: 0.428 idt_B: 0.541 \n",
      "(epoch: 8, iters: 400, time: 0.233, data: 0.001) D_A: 0.281 G_A: 0.167 cycle_A: 1.503 idt_A: 0.455 D_B: 0.284 G_B: 0.854 cycle_B: 0.901 idt_B: 0.586 \n",
      "(epoch: 8, iters: 500, time: 0.382, data: 0.001) D_A: 0.241 G_A: 0.395 cycle_A: 1.350 idt_A: 0.390 D_B: 0.238 G_B: 0.375 cycle_B: 0.815 idt_B: 0.454 \n",
      "End of epoch 8 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 100, time: 0.233, data: 0.121) D_A: 0.194 G_A: 0.460 cycle_A: 3.156 idt_A: 0.373 D_B: 0.283 G_B: 0.263 cycle_B: 0.783 idt_B: 1.342 \n",
      "(epoch: 9, iters: 200, time: 0.231, data: 0.002) D_A: 0.131 G_A: 0.802 cycle_A: 1.681 idt_A: 0.186 D_B: 0.202 G_B: 0.469 cycle_B: 0.396 idt_B: 0.654 \n",
      "(epoch: 9, iters: 300, time: 0.231, data: 0.001) D_A: 0.142 G_A: 0.640 cycle_A: 1.675 idt_A: 0.252 D_B: 0.183 G_B: 0.726 cycle_B: 0.502 idt_B: 0.566 \n",
      "(epoch: 9, iters: 400, time: 0.412, data: 0.001) D_A: 0.142 G_A: 0.409 cycle_A: 2.073 idt_A: 0.332 D_B: 0.214 G_B: 0.213 cycle_B: 0.773 idt_B: 0.908 \n",
      "(epoch: 9, iters: 500, time: 0.233, data: 0.001) D_A: 0.144 G_A: 0.365 cycle_A: 1.757 idt_A: 0.321 D_B: 0.171 G_B: 0.580 cycle_B: 0.759 idt_B: 1.077 \n",
      "End of epoch 9 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 100, time: 0.235, data: 0.098) D_A: 0.084 G_A: 0.331 cycle_A: 1.445 idt_A: 0.359 D_B: 0.232 G_B: 0.282 cycle_B: 0.770 idt_B: 0.430 \n",
      "(epoch: 10, iters: 200, time: 0.231, data: 0.002) D_A: 0.112 G_A: 0.646 cycle_A: 1.738 idt_A: 0.516 D_B: 0.299 G_B: 0.274 cycle_B: 0.941 idt_B: 0.557 \n",
      "(epoch: 10, iters: 300, time: 0.401, data: 0.002) D_A: 0.137 G_A: 0.441 cycle_A: 1.458 idt_A: 0.311 D_B: 0.064 G_B: 1.059 cycle_B: 0.615 idt_B: 0.400 \n",
      "(epoch: 10, iters: 400, time: 0.231, data: 0.001) D_A: 0.152 G_A: 0.501 cycle_A: 1.434 idt_A: 0.142 D_B: 0.205 G_B: 0.391 cycle_B: 0.592 idt_B: 0.469 \n",
      "(epoch: 10, iters: 500, time: 0.232, data: 0.002) D_A: 0.112 G_A: 0.213 cycle_A: 2.630 idt_A: 0.260 D_B: 0.363 G_B: 0.596 cycle_B: 0.582 idt_B: 1.547 \n",
      "saving the latest model (epoch 10, total_iters 5000)\n",
      "saving the model at the end of epoch 10, iters 5000\n",
      "End of epoch 10 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.230, data: 0.096) D_A: 0.137 G_A: 0.281 cycle_A: 1.600 idt_A: 0.494 D_B: 0.165 G_B: 0.339 cycle_B: 1.032 idt_B: 0.579 \n",
      "(epoch: 11, iters: 200, time: 0.388, data: 0.002) D_A: 0.099 G_A: 0.326 cycle_A: 1.704 idt_A: 0.384 D_B: 0.130 G_B: 0.201 cycle_B: 0.818 idt_B: 0.508 \n",
      "(epoch: 11, iters: 300, time: 0.230, data: 0.001) D_A: 0.130 G_A: 0.449 cycle_A: 2.246 idt_A: 0.228 D_B: 0.179 G_B: 0.218 cycle_B: 0.547 idt_B: 0.796 \n",
      "(epoch: 11, iters: 400, time: 0.228, data: 0.001) D_A: 0.160 G_A: 0.304 cycle_A: 1.969 idt_A: 0.334 D_B: 0.244 G_B: 0.214 cycle_B: 0.665 idt_B: 0.462 \n",
      "(epoch: 11, iters: 500, time: 0.232, data: 0.001) D_A: 0.621 G_A: 0.094 cycle_A: 1.624 idt_A: 0.235 D_B: 0.311 G_B: 0.414 cycle_B: 0.453 idt_B: 0.524 \n",
      "End of epoch 11 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 100, time: 0.388, data: 0.091) D_A: 0.176 G_A: 0.427 cycle_A: 1.576 idt_A: 0.163 D_B: 0.196 G_B: 0.201 cycle_B: 0.366 idt_B: 0.608 \n",
      "(epoch: 12, iters: 200, time: 0.232, data: 0.001) D_A: 0.202 G_A: 0.153 cycle_A: 2.248 idt_A: 0.295 D_B: 0.176 G_B: 0.668 cycle_B: 0.683 idt_B: 1.103 \n",
      "(epoch: 12, iters: 300, time: 0.231, data: 0.001) D_A: 0.076 G_A: 1.110 cycle_A: 1.461 idt_A: 0.378 D_B: 0.098 G_B: 0.750 cycle_B: 0.812 idt_B: 0.579 \n",
      "(epoch: 12, iters: 400, time: 0.233, data: 0.001) D_A: 0.105 G_A: 0.555 cycle_A: 4.525 idt_A: 0.432 D_B: 0.210 G_B: 0.711 cycle_B: 0.992 idt_B: 1.566 \n",
      "(epoch: 12, iters: 500, time: 0.384, data: 0.002) D_A: 0.069 G_A: 0.559 cycle_A: 2.919 idt_A: 0.374 D_B: 0.133 G_B: 0.297 cycle_B: 0.661 idt_B: 1.254 \n",
      "End of epoch 12 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 100, time: 0.234, data: 0.101) D_A: 0.097 G_A: 0.886 cycle_A: 2.055 idt_A: 0.375 D_B: 0.311 G_B: 0.536 cycle_B: 0.836 idt_B: 0.656 \n",
      "(epoch: 13, iters: 200, time: 0.233, data: 0.002) D_A: 0.078 G_A: 0.569 cycle_A: 1.712 idt_A: 0.212 D_B: 0.224 G_B: 0.234 cycle_B: 0.503 idt_B: 0.446 \n",
      "(epoch: 13, iters: 300, time: 0.230, data: 0.002) D_A: 0.143 G_A: 0.451 cycle_A: 1.635 idt_A: 0.053 D_B: 0.618 G_B: 1.206 cycle_B: 0.185 idt_B: 0.715 \n",
      "(epoch: 13, iters: 400, time: 0.413, data: 0.001) D_A: 0.100 G_A: 0.488 cycle_A: 2.156 idt_A: 0.329 D_B: 0.250 G_B: 0.162 cycle_B: 0.677 idt_B: 0.823 \n",
      "(epoch: 13, iters: 500, time: 0.231, data: 0.001) D_A: 0.110 G_A: 0.557 cycle_A: 1.876 idt_A: 0.331 D_B: 0.252 G_B: 0.632 cycle_B: 0.709 idt_B: 0.578 \n",
      "End of epoch 13 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 100, time: 0.235, data: 0.101) D_A: 0.081 G_A: 0.311 cycle_A: 1.771 idt_A: 0.224 D_B: 0.222 G_B: 0.295 cycle_B: 0.514 idt_B: 0.489 \n",
      "(epoch: 14, iters: 200, time: 0.231, data: 0.002) D_A: 0.070 G_A: 0.771 cycle_A: 2.021 idt_A: 0.254 D_B: 0.279 G_B: 0.594 cycle_B: 0.513 idt_B: 0.649 \n",
      "(epoch: 14, iters: 300, time: 0.378, data: 0.001) D_A: 0.099 G_A: 0.830 cycle_A: 3.715 idt_A: 0.255 D_B: 0.234 G_B: 0.244 cycle_B: 0.592 idt_B: 1.586 \n",
      "(epoch: 14, iters: 400, time: 0.232, data: 0.001) D_A: 0.170 G_A: 0.428 cycle_A: 1.320 idt_A: 0.334 D_B: 0.208 G_B: 0.135 cycle_B: 0.711 idt_B: 0.356 \n",
      "(epoch: 14, iters: 500, time: 0.230, data: 0.002) D_A: 0.120 G_A: 0.611 cycle_A: 1.658 idt_A: 0.247 D_B: 0.185 G_B: 0.660 cycle_B: 0.573 idt_B: 0.902 \n",
      "End of epoch 14 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 100, time: 0.233, data: 0.125) D_A: 0.192 G_A: 0.290 cycle_A: 1.952 idt_A: 0.245 D_B: 0.219 G_B: 0.507 cycle_B: 0.575 idt_B: 0.516 \n",
      "(epoch: 15, iters: 200, time: 0.394, data: 0.001) D_A: 0.166 G_A: 0.293 cycle_A: 1.441 idt_A: 0.258 D_B: 0.260 G_B: 0.126 cycle_B: 0.536 idt_B: 0.403 \n",
      "(epoch: 15, iters: 300, time: 0.233, data: 0.001) D_A: 0.240 G_A: 1.093 cycle_A: 2.130 idt_A: 0.281 D_B: 0.193 G_B: 0.341 cycle_B: 0.642 idt_B: 0.696 \n",
      "(epoch: 15, iters: 400, time: 0.230, data: 0.002) D_A: 0.119 G_A: 1.232 cycle_A: 2.869 idt_A: 0.329 D_B: 0.207 G_B: 0.376 cycle_B: 0.686 idt_B: 0.655 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 15, iters: 500, time: 0.229, data: 0.002) D_A: 0.138 G_A: 0.380 cycle_A: 1.451 idt_A: 0.570 D_B: 0.130 G_B: 0.364 cycle_B: 1.184 idt_B: 0.460 \n",
      "saving the model at the end of epoch 15, iters 7500\n",
      "End of epoch 15 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 100, time: 0.417, data: 0.100) D_A: 0.461 G_A: 0.030 cycle_A: 2.172 idt_A: 0.173 D_B: 0.217 G_B: 0.276 cycle_B: 0.396 idt_B: 0.977 \n",
      "(epoch: 16, iters: 200, time: 0.229, data: 0.001) D_A: 0.130 G_A: 1.125 cycle_A: 1.558 idt_A: 0.220 D_B: 0.127 G_B: 0.427 cycle_B: 0.520 idt_B: 0.490 \n",
      "(epoch: 16, iters: 300, time: 0.229, data: 0.002) D_A: 0.105 G_A: 0.428 cycle_A: 1.330 idt_A: 0.253 D_B: 0.128 G_B: 0.360 cycle_B: 0.530 idt_B: 0.606 \n",
      "(epoch: 16, iters: 400, time: 0.229, data: 0.002) D_A: 0.195 G_A: 0.209 cycle_A: 0.889 idt_A: 0.286 D_B: 0.074 G_B: 0.279 cycle_B: 0.584 idt_B: 0.398 \n",
      "(epoch: 16, iters: 500, time: 0.399, data: 0.001) D_A: 0.117 G_A: 0.706 cycle_A: 1.352 idt_A: 0.363 D_B: 0.179 G_B: 0.636 cycle_B: 0.692 idt_B: 0.558 \n",
      "End of epoch 16 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 100, time: 0.232, data: 0.123) D_A: 0.195 G_A: 0.258 cycle_A: 1.635 idt_A: 0.178 D_B: 0.230 G_B: 0.586 cycle_B: 0.404 idt_B: 0.492 \n",
      "(epoch: 17, iters: 200, time: 0.231, data: 0.002) D_A: 0.079 G_A: 0.505 cycle_A: 3.744 idt_A: 0.283 D_B: 0.297 G_B: 0.131 cycle_B: 0.644 idt_B: 1.684 \n",
      "(epoch: 17, iters: 300, time: 0.230, data: 0.001) D_A: 0.190 G_A: 0.260 cycle_A: 3.392 idt_A: 0.285 D_B: 0.164 G_B: 0.399 cycle_B: 0.638 idt_B: 1.058 \n",
      "(epoch: 17, iters: 400, time: 0.374, data: 0.002) D_A: 0.121 G_A: 1.113 cycle_A: 1.742 idt_A: 0.084 D_B: 0.235 G_B: 0.237 cycle_B: 0.271 idt_B: 0.711 \n",
      "(epoch: 17, iters: 500, time: 0.228, data: 0.001) D_A: 0.074 G_A: 0.557 cycle_A: 2.273 idt_A: 0.538 D_B: 0.208 G_B: 0.242 cycle_B: 1.097 idt_B: 0.536 \n",
      "End of epoch 17 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 100, time: 0.230, data: 0.115) D_A: 0.129 G_A: 0.559 cycle_A: 1.568 idt_A: 0.324 D_B: 0.295 G_B: 0.904 cycle_B: 0.668 idt_B: 0.451 \n",
      "(epoch: 18, iters: 200, time: 0.231, data: 0.002) D_A: 0.289 G_A: 0.283 cycle_A: 4.512 idt_A: 0.266 D_B: 0.185 G_B: 0.212 cycle_B: 0.553 idt_B: 1.074 \n",
      "(epoch: 18, iters: 300, time: 0.399, data: 0.001) D_A: 0.179 G_A: 0.466 cycle_A: 1.467 idt_A: 0.252 D_B: 0.229 G_B: 0.312 cycle_B: 0.554 idt_B: 0.542 \n",
      "(epoch: 18, iters: 400, time: 0.228, data: 0.001) D_A: 0.180 G_A: 0.479 cycle_A: 1.431 idt_A: 0.251 D_B: 0.239 G_B: 0.105 cycle_B: 0.630 idt_B: 0.434 \n",
      "(epoch: 18, iters: 500, time: 0.232, data: 0.001) D_A: 0.094 G_A: 0.359 cycle_A: 2.039 idt_A: 0.261 D_B: 0.265 G_B: 0.537 cycle_B: 0.586 idt_B: 0.804 \n",
      "End of epoch 18 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 100, time: 0.229, data: 0.099) D_A: 0.049 G_A: 0.544 cycle_A: 1.888 idt_A: 0.215 D_B: 0.283 G_B: 0.447 cycle_B: 0.515 idt_B: 0.785 \n",
      "(epoch: 19, iters: 200, time: 0.409, data: 0.001) D_A: 0.108 G_A: 0.384 cycle_A: 1.711 idt_A: 0.368 D_B: 0.166 G_B: 0.200 cycle_B: 0.751 idt_B: 0.584 \n",
      "(epoch: 19, iters: 300, time: 0.229, data: 0.001) D_A: 0.157 G_A: 0.282 cycle_A: 1.542 idt_A: 0.221 D_B: 0.217 G_B: 0.437 cycle_B: 0.491 idt_B: 0.588 \n",
      "(epoch: 19, iters: 400, time: 0.230, data: 0.002) D_A: 0.131 G_A: 0.817 cycle_A: 2.834 idt_A: 0.255 D_B: 0.202 G_B: 0.543 cycle_B: 0.586 idt_B: 1.077 \n",
      "(epoch: 19, iters: 500, time: 0.228, data: 0.001) D_A: 0.265 G_A: 0.594 cycle_A: 2.642 idt_A: 0.266 D_B: 0.189 G_B: 0.261 cycle_B: 0.585 idt_B: 1.380 \n",
      "End of epoch 19 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 100, time: 0.411, data: 0.103) D_A: 0.124 G_A: 0.720 cycle_A: 1.782 idt_A: 0.163 D_B: 0.227 G_B: 0.465 cycle_B: 0.413 idt_B: 0.932 \n",
      "(epoch: 20, iters: 200, time: 0.229, data: 0.001) D_A: 0.175 G_A: 0.546 cycle_A: 2.032 idt_A: 0.264 D_B: 0.079 G_B: 0.642 cycle_B: 0.571 idt_B: 0.703 \n",
      "(epoch: 20, iters: 300, time: 0.228, data: 0.002) D_A: 0.076 G_A: 0.657 cycle_A: 2.045 idt_A: 0.101 D_B: 0.114 G_B: 0.444 cycle_B: 0.264 idt_B: 0.565 \n",
      "(epoch: 20, iters: 400, time: 0.229, data: 0.001) D_A: 0.153 G_A: 0.389 cycle_A: 1.407 idt_A: 0.203 D_B: 0.197 G_B: 0.533 cycle_B: 0.510 idt_B: 0.557 \n",
      "(epoch: 20, iters: 500, time: 0.427, data: 0.001) D_A: 0.080 G_A: 0.632 cycle_A: 1.028 idt_A: 0.428 D_B: 0.127 G_B: 0.210 cycle_B: 0.907 idt_B: 0.614 \n",
      "saving the latest model (epoch 20, total_iters 10000)\n",
      "saving the model at the end of epoch 20, iters 10000\n",
      "End of epoch 20 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 100, time: 0.228, data: 0.108) D_A: 0.141 G_A: 0.520 cycle_A: 1.364 idt_A: 0.401 D_B: 0.222 G_B: 0.343 cycle_B: 0.910 idt_B: 0.447 \n",
      "(epoch: 21, iters: 200, time: 0.230, data: 0.002) D_A: 0.233 G_A: 1.395 cycle_A: 1.654 idt_A: 0.164 D_B: 0.146 G_B: 0.143 cycle_B: 0.379 idt_B: 0.351 \n",
      "(epoch: 21, iters: 300, time: 0.228, data: 0.001) D_A: 0.082 G_A: 0.644 cycle_A: 1.307 idt_A: 0.262 D_B: 0.104 G_B: 0.479 cycle_B: 0.593 idt_B: 0.351 \n",
      "(epoch: 21, iters: 400, time: 0.399, data: 0.002) D_A: 0.110 G_A: 0.466 cycle_A: 2.255 idt_A: 0.283 D_B: 0.163 G_B: 0.301 cycle_B: 0.671 idt_B: 0.751 \n",
      "(epoch: 21, iters: 500, time: 0.229, data: 0.001) D_A: 0.159 G_A: 0.979 cycle_A: 1.204 idt_A: 0.190 D_B: 0.095 G_B: 0.500 cycle_B: 0.666 idt_B: 0.387 \n",
      "End of epoch 21 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 100, time: 0.230, data: 0.110) D_A: 0.135 G_A: 0.447 cycle_A: 1.212 idt_A: 0.154 D_B: 0.186 G_B: 0.571 cycle_B: 0.409 idt_B: 0.331 \n",
      "(epoch: 22, iters: 200, time: 0.230, data: 0.001) D_A: 0.056 G_A: 0.791 cycle_A: 1.535 idt_A: 0.192 D_B: 0.331 G_B: 0.830 cycle_B: 0.509 idt_B: 0.692 \n",
      "(epoch: 22, iters: 300, time: 0.403, data: 0.002) D_A: 0.110 G_A: 0.786 cycle_A: 1.506 idt_A: 0.239 D_B: 0.147 G_B: 0.996 cycle_B: 0.525 idt_B: 0.621 \n",
      "(epoch: 22, iters: 400, time: 0.230, data: 0.001) D_A: 0.074 G_A: 0.707 cycle_A: 2.266 idt_A: 0.171 D_B: 0.153 G_B: 0.672 cycle_B: 0.415 idt_B: 0.927 \n",
      "(epoch: 22, iters: 500, time: 0.230, data: 0.002) D_A: 0.106 G_A: 0.673 cycle_A: 2.121 idt_A: 0.195 D_B: 0.136 G_B: 0.520 cycle_B: 0.411 idt_B: 0.497 \n",
      "End of epoch 22 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 100, time: 0.232, data: 0.097) D_A: 0.132 G_A: 0.625 cycle_A: 1.453 idt_A: 0.394 D_B: 0.147 G_B: 0.263 cycle_B: 0.837 idt_B: 0.503 \n",
      "(epoch: 23, iters: 200, time: 0.425, data: 0.002) D_A: 0.214 G_A: 0.226 cycle_A: 1.356 idt_A: 0.515 D_B: 0.187 G_B: 0.395 cycle_B: 0.997 idt_B: 0.483 \n",
      "(epoch: 23, iters: 300, time: 0.228, data: 0.001) D_A: 0.075 G_A: 0.690 cycle_A: 1.582 idt_A: 0.086 D_B: 0.334 G_B: 0.390 cycle_B: 0.372 idt_B: 0.681 \n",
      "(epoch: 23, iters: 400, time: 0.229, data: 0.001) D_A: 0.178 G_A: 0.287 cycle_A: 1.723 idt_A: 0.205 D_B: 0.175 G_B: 0.746 cycle_B: 0.542 idt_B: 0.457 \n",
      "(epoch: 23, iters: 500, time: 0.228, data: 0.001) D_A: 0.122 G_A: 0.636 cycle_A: 2.597 idt_A: 0.311 D_B: 0.251 G_B: 0.202 cycle_B: 0.702 idt_B: 0.610 \n",
      "End of epoch 23 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 100, time: 0.403, data: 0.110) D_A: 0.158 G_A: 0.464 cycle_A: 2.608 idt_A: 0.205 D_B: 0.141 G_B: 0.296 cycle_B: 0.556 idt_B: 0.674 \n",
      "(epoch: 24, iters: 200, time: 0.231, data: 0.001) D_A: 0.100 G_A: 0.395 cycle_A: 1.407 idt_A: 0.237 D_B: 0.159 G_B: 0.623 cycle_B: 0.511 idt_B: 0.443 \n",
      "(epoch: 24, iters: 300, time: 0.231, data: 0.001) D_A: 0.131 G_A: 0.619 cycle_A: 1.169 idt_A: 0.164 D_B: 0.141 G_B: 0.250 cycle_B: 0.436 idt_B: 0.599 \n",
      "(epoch: 24, iters: 400, time: 0.229, data: 0.001) D_A: 0.065 G_A: 0.768 cycle_A: 1.284 idt_A: 0.201 D_B: 0.486 G_B: 0.055 cycle_B: 0.489 idt_B: 0.469 \n",
      "(epoch: 24, iters: 500, time: 0.403, data: 0.002) D_A: 0.225 G_A: 1.156 cycle_A: 2.468 idt_A: 0.215 D_B: 0.149 G_B: 0.320 cycle_B: 0.462 idt_B: 0.862 \n",
      "End of epoch 24 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 100, time: 0.227, data: 0.096) D_A: 0.446 G_A: 2.114 cycle_A: 2.575 idt_A: 0.182 D_B: 0.246 G_B: 0.469 cycle_B: 0.369 idt_B: 0.729 \n",
      "(epoch: 25, iters: 200, time: 0.230, data: 0.002) D_A: 0.121 G_A: 1.237 cycle_A: 1.500 idt_A: 0.237 D_B: 0.189 G_B: 0.568 cycle_B: 0.553 idt_B: 0.530 \n",
      "(epoch: 25, iters: 300, time: 0.229, data: 0.002) D_A: 0.067 G_A: 0.361 cycle_A: 1.235 idt_A: 0.207 D_B: 0.215 G_B: 0.461 cycle_B: 0.485 idt_B: 0.328 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 25, iters: 400, time: 0.407, data: 0.001) D_A: 0.096 G_A: 0.723 cycle_A: 1.991 idt_A: 0.180 D_B: 0.225 G_B: 0.290 cycle_B: 0.471 idt_B: 1.142 \n",
      "(epoch: 25, iters: 500, time: 0.228, data: 0.001) D_A: 0.316 G_A: 0.144 cycle_A: 1.579 idt_A: 0.171 D_B: 0.125 G_B: 0.357 cycle_B: 0.448 idt_B: 0.626 \n",
      "saving the model at the end of epoch 25, iters 12500\n",
      "End of epoch 25 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.228, data: 0.115) D_A: 0.179 G_A: 0.220 cycle_A: 1.073 idt_A: 0.232 D_B: 0.195 G_B: 0.453 cycle_B: 0.518 idt_B: 0.305 \n",
      "(epoch: 26, iters: 200, time: 0.231, data: 0.001) D_A: 0.143 G_A: 0.879 cycle_A: 1.288 idt_A: 0.247 D_B: 0.136 G_B: 0.397 cycle_B: 0.558 idt_B: 0.738 \n",
      "(epoch: 26, iters: 300, time: 0.429, data: 0.001) D_A: 0.146 G_A: 0.722 cycle_A: 1.357 idt_A: 0.187 D_B: 0.161 G_B: 0.387 cycle_B: 0.502 idt_B: 0.470 \n",
      "(epoch: 26, iters: 400, time: 0.229, data: 0.001) D_A: 0.060 G_A: 1.030 cycle_A: 1.470 idt_A: 0.220 D_B: 0.126 G_B: 0.570 cycle_B: 0.469 idt_B: 0.698 \n",
      "(epoch: 26, iters: 500, time: 0.228, data: 0.001) D_A: 0.145 G_A: 0.426 cycle_A: 1.897 idt_A: 0.133 D_B: 0.276 G_B: 0.202 cycle_B: 0.318 idt_B: 0.757 \n",
      "End of epoch 26 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 100, time: 0.229, data: 0.098) D_A: 0.244 G_A: 0.920 cycle_A: 0.864 idt_A: 0.225 D_B: 0.139 G_B: 0.477 cycle_B: 0.516 idt_B: 0.301 \n",
      "(epoch: 27, iters: 200, time: 0.436, data: 0.001) D_A: 0.171 G_A: 0.368 cycle_A: 1.496 idt_A: 0.288 D_B: 0.298 G_B: 0.209 cycle_B: 0.708 idt_B: 0.616 \n",
      "(epoch: 27, iters: 300, time: 0.228, data: 0.001) D_A: 0.115 G_A: 0.753 cycle_A: 1.533 idt_A: 0.191 D_B: 0.119 G_B: 0.524 cycle_B: 0.443 idt_B: 0.396 \n",
      "(epoch: 27, iters: 400, time: 0.229, data: 0.002) D_A: 0.064 G_A: 0.905 cycle_A: 1.783 idt_A: 0.099 D_B: 0.118 G_B: 0.622 cycle_B: 0.249 idt_B: 0.565 \n",
      "(epoch: 27, iters: 500, time: 0.229, data: 0.001) D_A: 0.071 G_A: 0.435 cycle_A: 1.569 idt_A: 0.241 D_B: 0.167 G_B: 0.645 cycle_B: 0.536 idt_B: 0.748 \n",
      "End of epoch 27 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 100, time: 0.414, data: 0.102) D_A: 0.126 G_A: 0.330 cycle_A: 1.743 idt_A: 0.295 D_B: 0.146 G_B: 0.510 cycle_B: 0.635 idt_B: 0.614 \n",
      "(epoch: 28, iters: 200, time: 0.229, data: 0.001) D_A: 0.198 G_A: 0.210 cycle_A: 1.654 idt_A: 0.170 D_B: 0.234 G_B: 0.417 cycle_B: 0.436 idt_B: 0.885 \n",
      "(epoch: 28, iters: 300, time: 0.230, data: 0.002) D_A: 0.141 G_A: 0.195 cycle_A: 1.611 idt_A: 0.220 D_B: 0.281 G_B: 0.381 cycle_B: 0.539 idt_B: 0.474 \n",
      "(epoch: 28, iters: 400, time: 0.228, data: 0.001) D_A: 0.091 G_A: 0.773 cycle_A: 1.986 idt_A: 0.239 D_B: 0.195 G_B: 0.286 cycle_B: 0.588 idt_B: 0.607 \n",
      "(epoch: 28, iters: 500, time: 0.403, data: 0.002) D_A: 0.148 G_A: 0.841 cycle_A: 1.767 idt_A: 0.166 D_B: 0.072 G_B: 0.429 cycle_B: 0.406 idt_B: 0.496 \n",
      "End of epoch 28 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 100, time: 0.227, data: 0.101) D_A: 0.104 G_A: 0.495 cycle_A: 2.034 idt_A: 0.150 D_B: 0.260 G_B: 0.515 cycle_B: 0.394 idt_B: 0.997 \n",
      "(epoch: 29, iters: 200, time: 0.227, data: 0.002) D_A: 0.197 G_A: 0.620 cycle_A: 1.078 idt_A: 0.108 D_B: 0.067 G_B: 0.219 cycle_B: 0.308 idt_B: 0.338 \n",
      "(epoch: 29, iters: 300, time: 0.229, data: 0.001) D_A: 0.134 G_A: 0.631 cycle_A: 2.033 idt_A: 0.122 D_B: 0.304 G_B: 0.579 cycle_B: 0.287 idt_B: 0.771 \n",
      "(epoch: 29, iters: 400, time: 0.422, data: 0.001) D_A: 0.237 G_A: 0.179 cycle_A: 1.515 idt_A: 0.350 D_B: 0.241 G_B: 0.299 cycle_B: 0.805 idt_B: 0.584 \n",
      "(epoch: 29, iters: 500, time: 0.230, data: 0.001) D_A: 0.139 G_A: 1.109 cycle_A: 1.326 idt_A: 0.084 D_B: 0.090 G_B: 0.538 cycle_B: 0.483 idt_B: 0.431 \n",
      "End of epoch 29 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 100, time: 0.230, data: 0.100) D_A: 0.108 G_A: 0.318 cycle_A: 2.350 idt_A: 0.206 D_B: 0.160 G_B: 0.281 cycle_B: 0.488 idt_B: 0.503 \n",
      "(epoch: 30, iters: 200, time: 0.229, data: 0.001) D_A: 0.072 G_A: 0.749 cycle_A: 1.321 idt_A: 0.272 D_B: 0.211 G_B: 0.583 cycle_B: 0.600 idt_B: 0.569 \n",
      "(epoch: 30, iters: 300, time: 0.418, data: 0.001) D_A: 0.251 G_A: 0.165 cycle_A: 2.742 idt_A: 0.433 D_B: 0.215 G_B: 0.429 cycle_B: 0.964 idt_B: 1.021 \n",
      "(epoch: 30, iters: 400, time: 0.232, data: 0.001) D_A: 0.126 G_A: 0.844 cycle_A: 1.262 idt_A: 0.198 D_B: 0.162 G_B: 0.382 cycle_B: 0.445 idt_B: 0.500 \n",
      "(epoch: 30, iters: 500, time: 0.228, data: 0.002) D_A: 0.186 G_A: 0.879 cycle_A: 1.709 idt_A: 0.152 D_B: 0.200 G_B: 0.274 cycle_B: 0.414 idt_B: 0.760 \n",
      "saving the latest model (epoch 30, total_iters 15000)\n",
      "saving the model at the end of epoch 30, iters 15000\n",
      "End of epoch 30 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 100, time: 0.228, data: 0.106) D_A: 0.077 G_A: 0.766 cycle_A: 1.836 idt_A: 0.128 D_B: 0.089 G_B: 0.483 cycle_B: 0.318 idt_B: 0.618 \n",
      "(epoch: 31, iters: 200, time: 0.432, data: 0.002) D_A: 0.162 G_A: 0.419 cycle_A: 2.718 idt_A: 0.228 D_B: 0.199 G_B: 0.232 cycle_B: 0.497 idt_B: 0.761 \n",
      "(epoch: 31, iters: 300, time: 0.230, data: 0.002) D_A: 0.135 G_A: 1.216 cycle_A: 1.690 idt_A: 0.136 D_B: 0.234 G_B: 0.235 cycle_B: 0.298 idt_B: 0.502 \n",
      "(epoch: 31, iters: 400, time: 0.228, data: 0.002) D_A: 0.199 G_A: 0.235 cycle_A: 1.194 idt_A: 0.121 D_B: 0.179 G_B: 0.516 cycle_B: 0.331 idt_B: 0.531 \n",
      "(epoch: 31, iters: 500, time: 0.231, data: 0.001) D_A: 0.266 G_A: 0.219 cycle_A: 1.752 idt_A: 0.193 D_B: 0.209 G_B: 0.268 cycle_B: 0.490 idt_B: 0.847 \n",
      "End of epoch 31 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 100, time: 0.426, data: 0.108) D_A: 0.223 G_A: 0.722 cycle_A: 2.395 idt_A: 0.207 D_B: 0.309 G_B: 0.264 cycle_B: 0.482 idt_B: 0.764 \n",
      "(epoch: 32, iters: 200, time: 0.230, data: 0.001) D_A: 0.176 G_A: 0.500 cycle_A: 5.157 idt_A: 0.265 D_B: 0.167 G_B: 0.614 cycle_B: 0.611 idt_B: 2.325 \n",
      "(epoch: 32, iters: 300, time: 0.229, data: 0.001) D_A: 0.170 G_A: 0.551 cycle_A: 1.872 idt_A: 0.140 D_B: 0.144 G_B: 0.469 cycle_B: 0.389 idt_B: 0.632 \n",
      "(epoch: 32, iters: 400, time: 0.229, data: 0.001) D_A: 0.112 G_A: 0.265 cycle_A: 1.677 idt_A: 0.356 D_B: 0.070 G_B: 0.450 cycle_B: 0.815 idt_B: 0.565 \n",
      "(epoch: 32, iters: 500, time: 0.436, data: 0.001) D_A: 0.090 G_A: 0.411 cycle_A: 2.014 idt_A: 0.134 D_B: 0.188 G_B: 0.406 cycle_B: 0.363 idt_B: 0.555 \n",
      "End of epoch 32 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 100, time: 0.229, data: 0.118) D_A: 0.095 G_A: 0.471 cycle_A: 1.022 idt_A: 0.264 D_B: 0.516 G_B: 0.876 cycle_B: 0.623 idt_B: 0.284 \n",
      "(epoch: 33, iters: 200, time: 0.230, data: 0.001) D_A: 0.127 G_A: 0.503 cycle_A: 1.939 idt_A: 0.200 D_B: 0.251 G_B: 0.172 cycle_B: 0.493 idt_B: 0.647 \n",
      "(epoch: 33, iters: 300, time: 0.227, data: 0.002) D_A: 0.186 G_A: 0.318 cycle_A: 1.878 idt_A: 0.206 D_B: 0.209 G_B: 0.140 cycle_B: 0.474 idt_B: 0.995 \n",
      "(epoch: 33, iters: 400, time: 0.419, data: 0.002) D_A: 0.268 G_A: 0.875 cycle_A: 0.920 idt_A: 0.169 D_B: 0.224 G_B: 0.735 cycle_B: 0.409 idt_B: 0.369 \n",
      "(epoch: 33, iters: 500, time: 0.229, data: 0.001) D_A: 0.071 G_A: 0.601 cycle_A: 1.840 idt_A: 0.178 D_B: 0.191 G_B: 0.675 cycle_B: 0.426 idt_B: 0.837 \n",
      "End of epoch 33 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 100, time: 0.227, data: 0.115) D_A: 0.237 G_A: 0.808 cycle_A: 2.109 idt_A: 0.284 D_B: 0.243 G_B: 0.176 cycle_B: 0.703 idt_B: 1.009 \n",
      "(epoch: 34, iters: 200, time: 0.229, data: 0.002) D_A: 0.222 G_A: 1.503 cycle_A: 2.861 idt_A: 0.410 D_B: 0.193 G_B: 0.217 cycle_B: 0.905 idt_B: 1.514 \n",
      "(epoch: 34, iters: 300, time: 0.438, data: 0.001) D_A: 0.135 G_A: 0.581 cycle_A: 1.049 idt_A: 0.290 D_B: 0.170 G_B: 0.126 cycle_B: 0.753 idt_B: 0.350 \n",
      "(epoch: 34, iters: 400, time: 0.229, data: 0.001) D_A: 0.187 G_A: 0.298 cycle_A: 1.653 idt_A: 0.215 D_B: 0.097 G_B: 0.384 cycle_B: 0.481 idt_B: 0.784 \n",
      "(epoch: 34, iters: 500, time: 0.231, data: 0.001) D_A: 0.141 G_A: 0.674 cycle_A: 2.150 idt_A: 0.245 D_B: 0.188 G_B: 0.358 cycle_B: 0.573 idt_B: 0.792 \n",
      "End of epoch 34 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 100, time: 0.233, data: 0.115) D_A: 0.243 G_A: 0.164 cycle_A: 1.939 idt_A: 0.182 D_B: 0.334 G_B: 0.115 cycle_B: 0.511 idt_B: 0.579 \n",
      "(epoch: 35, iters: 200, time: 0.423, data: 0.001) D_A: 0.195 G_A: 0.363 cycle_A: 1.586 idt_A: 0.243 D_B: 0.190 G_B: 0.386 cycle_B: 0.513 idt_B: 0.922 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 35, iters: 300, time: 0.231, data: 0.001) D_A: 0.081 G_A: 0.489 cycle_A: 1.829 idt_A: 0.313 D_B: 0.173 G_B: 0.340 cycle_B: 0.662 idt_B: 0.673 \n",
      "(epoch: 35, iters: 400, time: 0.230, data: 0.002) D_A: 0.167 G_A: 0.165 cycle_A: 1.786 idt_A: 0.155 D_B: 0.282 G_B: 0.301 cycle_B: 0.403 idt_B: 0.698 \n",
      "(epoch: 35, iters: 500, time: 0.230, data: 0.002) D_A: 0.101 G_A: 0.322 cycle_A: 1.864 idt_A: 0.314 D_B: 0.211 G_B: 0.257 cycle_B: 0.753 idt_B: 0.809 \n",
      "saving the model at the end of epoch 35, iters 17500\n",
      "End of epoch 35 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 100, time: 0.436, data: 0.101) D_A: 0.096 G_A: 0.709 cycle_A: 1.668 idt_A: 0.175 D_B: 0.263 G_B: 0.598 cycle_B: 0.404 idt_B: 0.766 \n",
      "(epoch: 36, iters: 200, time: 0.229, data: 0.001) D_A: 0.093 G_A: 0.397 cycle_A: 1.965 idt_A: 0.153 D_B: 0.135 G_B: 0.356 cycle_B: 0.400 idt_B: 0.794 \n",
      "(epoch: 36, iters: 300, time: 0.230, data: 0.001) D_A: 0.082 G_A: 0.682 cycle_A: 1.157 idt_A: 0.196 D_B: 0.198 G_B: 0.481 cycle_B: 0.543 idt_B: 0.509 \n",
      "(epoch: 36, iters: 400, time: 0.231, data: 0.001) D_A: 0.036 G_A: 0.643 cycle_A: 1.140 idt_A: 0.248 D_B: 0.125 G_B: 0.566 cycle_B: 0.621 idt_B: 0.405 \n",
      "(epoch: 36, iters: 500, time: 0.422, data: 0.001) D_A: 0.127 G_A: 0.392 cycle_A: 1.393 idt_A: 0.231 D_B: 0.239 G_B: 0.643 cycle_B: 0.594 idt_B: 1.004 \n",
      "End of epoch 36 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 100, time: 0.229, data: 0.103) D_A: 0.127 G_A: 0.259 cycle_A: 1.263 idt_A: 0.340 D_B: 0.164 G_B: 0.283 cycle_B: 0.779 idt_B: 0.492 \n",
      "(epoch: 37, iters: 200, time: 0.232, data: 0.002) D_A: 0.136 G_A: 0.365 cycle_A: 2.355 idt_A: 0.178 D_B: 0.162 G_B: 0.328 cycle_B: 0.445 idt_B: 0.848 \n",
      "(epoch: 37, iters: 300, time: 0.231, data: 0.002) D_A: 0.175 G_A: 0.886 cycle_A: 1.571 idt_A: 0.180 D_B: 0.236 G_B: 0.537 cycle_B: 0.427 idt_B: 0.479 \n",
      "(epoch: 37, iters: 400, time: 0.425, data: 0.001) D_A: 0.066 G_A: 0.428 cycle_A: 2.538 idt_A: 0.279 D_B: 0.290 G_B: 0.131 cycle_B: 0.616 idt_B: 0.838 \n",
      "(epoch: 37, iters: 500, time: 0.229, data: 0.001) D_A: 0.156 G_A: 0.453 cycle_A: 1.181 idt_A: 0.094 D_B: 0.105 G_B: 0.771 cycle_B: 0.324 idt_B: 0.621 \n",
      "End of epoch 37 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 100, time: 0.229, data: 0.102) D_A: 0.249 G_A: 0.263 cycle_A: 1.690 idt_A: 0.277 D_B: 0.126 G_B: 0.374 cycle_B: 0.636 idt_B: 0.689 \n",
      "(epoch: 38, iters: 200, time: 0.229, data: 0.002) D_A: 0.105 G_A: 0.520 cycle_A: 1.437 idt_A: 0.172 D_B: 0.190 G_B: 0.164 cycle_B: 0.471 idt_B: 0.494 \n",
      "(epoch: 38, iters: 300, time: 0.439, data: 0.001) D_A: 0.074 G_A: 0.408 cycle_A: 1.358 idt_A: 0.185 D_B: 0.210 G_B: 0.212 cycle_B: 0.559 idt_B: 0.464 \n",
      "(epoch: 38, iters: 400, time: 0.230, data: 0.002) D_A: 0.059 G_A: 0.625 cycle_A: 0.974 idt_A: 0.111 D_B: 0.079 G_B: 0.435 cycle_B: 0.311 idt_B: 0.262 \n",
      "(epoch: 38, iters: 500, time: 0.230, data: 0.001) D_A: 0.164 G_A: 0.609 cycle_A: 1.754 idt_A: 0.077 D_B: 0.199 G_B: 0.201 cycle_B: 0.239 idt_B: 0.445 \n",
      "End of epoch 38 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 100, time: 0.229, data: 0.117) D_A: 0.132 G_A: 0.309 cycle_A: 2.025 idt_A: 0.213 D_B: 0.129 G_B: 0.526 cycle_B: 0.529 idt_B: 0.560 \n",
      "(epoch: 39, iters: 200, time: 0.449, data: 0.001) D_A: 0.166 G_A: 0.137 cycle_A: 1.823 idt_A: 0.296 D_B: 0.072 G_B: 0.877 cycle_B: 0.683 idt_B: 0.586 \n",
      "(epoch: 39, iters: 300, time: 0.229, data: 0.001) D_A: 0.074 G_A: 0.443 cycle_A: 1.145 idt_A: 0.161 D_B: 0.161 G_B: 0.275 cycle_B: 0.374 idt_B: 0.389 \n",
      "(epoch: 39, iters: 400, time: 0.228, data: 0.001) D_A: 0.057 G_A: 0.695 cycle_A: 1.314 idt_A: 0.121 D_B: 0.081 G_B: 0.427 cycle_B: 0.309 idt_B: 0.342 \n",
      "(epoch: 39, iters: 500, time: 0.230, data: 0.001) D_A: 0.112 G_A: 0.592 cycle_A: 1.021 idt_A: 0.290 D_B: 0.138 G_B: 0.616 cycle_B: 0.723 idt_B: 0.308 \n",
      "End of epoch 39 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 100, time: 0.437, data: 0.090) D_A: 0.245 G_A: 0.206 cycle_A: 1.204 idt_A: 0.257 D_B: 0.276 G_B: 0.140 cycle_B: 0.663 idt_B: 0.510 \n",
      "(epoch: 40, iters: 200, time: 0.229, data: 0.001) D_A: 0.244 G_A: 1.191 cycle_A: 0.886 idt_A: 0.119 D_B: 0.182 G_B: 0.419 cycle_B: 0.355 idt_B: 0.512 \n",
      "(epoch: 40, iters: 300, time: 0.230, data: 0.001) D_A: 0.149 G_A: 0.241 cycle_A: 1.522 idt_A: 0.171 D_B: 0.123 G_B: 0.588 cycle_B: 0.402 idt_B: 0.533 \n",
      "(epoch: 40, iters: 400, time: 0.228, data: 0.001) D_A: 0.104 G_A: 0.242 cycle_A: 1.952 idt_A: 0.131 D_B: 0.120 G_B: 0.333 cycle_B: 0.356 idt_B: 0.835 \n",
      "(epoch: 40, iters: 500, time: 0.450, data: 0.001) D_A: 0.090 G_A: 0.723 cycle_A: 1.409 idt_A: 0.245 D_B: 0.115 G_B: 0.554 cycle_B: 0.620 idt_B: 0.266 \n",
      "saving the latest model (epoch 40, total_iters 20000)\n",
      "saving the model at the end of epoch 40, iters 20000\n",
      "End of epoch 40 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 100, time: 0.229, data: 0.093) D_A: 0.031 G_A: 0.872 cycle_A: 1.935 idt_A: 0.158 D_B: 0.132 G_B: 0.361 cycle_B: 0.478 idt_B: 0.390 \n",
      "(epoch: 41, iters: 200, time: 0.230, data: 0.001) D_A: 0.080 G_A: 0.521 cycle_A: 1.072 idt_A: 0.213 D_B: 0.152 G_B: 0.272 cycle_B: 0.472 idt_B: 0.522 \n",
      "(epoch: 41, iters: 300, time: 0.229, data: 0.001) D_A: 0.231 G_A: 0.162 cycle_A: 1.115 idt_A: 0.257 D_B: 0.109 G_B: 0.453 cycle_B: 0.568 idt_B: 0.293 \n",
      "(epoch: 41, iters: 400, time: 0.459, data: 0.001) D_A: 0.076 G_A: 0.718 cycle_A: 1.757 idt_A: 0.227 D_B: 0.144 G_B: 0.264 cycle_B: 0.550 idt_B: 0.577 \n",
      "(epoch: 41, iters: 500, time: 0.231, data: 0.001) D_A: 0.070 G_A: 0.674 cycle_A: 1.969 idt_A: 0.240 D_B: 0.176 G_B: 0.507 cycle_B: 0.625 idt_B: 0.380 \n",
      "End of epoch 41 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 100, time: 0.228, data: 0.118) D_A: 0.035 G_A: 0.881 cycle_A: 1.575 idt_A: 0.348 D_B: 0.173 G_B: 0.183 cycle_B: 0.789 idt_B: 0.406 \n",
      "(epoch: 42, iters: 200, time: 0.228, data: 0.002) D_A: 0.054 G_A: 0.169 cycle_A: 1.941 idt_A: 0.166 D_B: 0.137 G_B: 0.278 cycle_B: 0.462 idt_B: 0.364 \n",
      "(epoch: 42, iters: 300, time: 0.443, data: 0.002) D_A: 0.120 G_A: 0.302 cycle_A: 1.523 idt_A: 0.308 D_B: 0.126 G_B: 0.392 cycle_B: 0.617 idt_B: 0.471 \n",
      "(epoch: 42, iters: 400, time: 0.228, data: 0.001) D_A: 0.093 G_A: 1.098 cycle_A: 1.253 idt_A: 0.223 D_B: 0.161 G_B: 0.440 cycle_B: 0.571 idt_B: 0.441 \n",
      "(epoch: 42, iters: 500, time: 0.230, data: 0.001) D_A: 0.067 G_A: 0.943 cycle_A: 1.186 idt_A: 0.214 D_B: 0.263 G_B: 0.253 cycle_B: 0.555 idt_B: 0.274 \n",
      "End of epoch 42 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 100, time: 0.228, data: 0.111) D_A: 0.060 G_A: 0.312 cycle_A: 1.323 idt_A: 0.193 D_B: 0.232 G_B: 0.173 cycle_B: 0.429 idt_B: 0.294 \n",
      "(epoch: 43, iters: 200, time: 0.474, data: 0.001) D_A: 0.049 G_A: 0.739 cycle_A: 1.120 idt_A: 0.188 D_B: 0.262 G_B: 0.272 cycle_B: 0.473 idt_B: 0.378 \n",
      "(epoch: 43, iters: 300, time: 0.232, data: 0.001) D_A: 0.132 G_A: 0.403 cycle_A: 1.308 idt_A: 0.280 D_B: 0.267 G_B: 0.441 cycle_B: 0.798 idt_B: 0.398 \n",
      "(epoch: 43, iters: 400, time: 0.229, data: 0.001) D_A: 0.133 G_A: 0.767 cycle_A: 1.932 idt_A: 0.199 D_B: 0.223 G_B: 0.210 cycle_B: 0.529 idt_B: 0.708 \n",
      "(epoch: 43, iters: 500, time: 0.229, data: 0.001) D_A: 0.181 G_A: 0.642 cycle_A: 1.366 idt_A: 0.251 D_B: 0.077 G_B: 0.188 cycle_B: 0.624 idt_B: 0.445 \n",
      "End of epoch 43 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 100, time: 0.449, data: 0.098) D_A: 0.298 G_A: 0.937 cycle_A: 1.906 idt_A: 0.115 D_B: 0.401 G_B: 0.089 cycle_B: 0.332 idt_B: 0.703 \n",
      "(epoch: 44, iters: 200, time: 0.228, data: 0.001) D_A: 0.052 G_A: 0.813 cycle_A: 1.292 idt_A: 0.079 D_B: 0.067 G_B: 0.203 cycle_B: 0.238 idt_B: 0.643 \n",
      "(epoch: 44, iters: 300, time: 0.228, data: 0.001) D_A: 0.088 G_A: 0.372 cycle_A: 2.761 idt_A: 0.238 D_B: 0.128 G_B: 0.461 cycle_B: 0.744 idt_B: 1.168 \n",
      "(epoch: 44, iters: 400, time: 0.232, data: 0.001) D_A: 0.182 G_A: 0.393 cycle_A: 1.168 idt_A: 0.197 D_B: 0.173 G_B: 0.257 cycle_B: 0.496 idt_B: 0.508 \n",
      "(epoch: 44, iters: 500, time: 0.450, data: 0.001) D_A: 0.084 G_A: 0.305 cycle_A: 1.534 idt_A: 0.262 D_B: 0.223 G_B: 0.227 cycle_B: 0.690 idt_B: 0.496 \n",
      "End of epoch 44 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 100, time: 0.229, data: 0.132) D_A: 0.046 G_A: 0.763 cycle_A: 1.250 idt_A: 0.168 D_B: 0.144 G_B: 0.749 cycle_B: 0.458 idt_B: 0.269 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 45, iters: 200, time: 0.228, data: 0.002) D_A: 0.180 G_A: 0.279 cycle_A: 1.353 idt_A: 0.054 D_B: 0.137 G_B: 0.375 cycle_B: 0.185 idt_B: 0.570 \n",
      "(epoch: 45, iters: 300, time: 0.229, data: 0.001) D_A: 0.060 G_A: 1.014 cycle_A: 2.211 idt_A: 0.356 D_B: 0.168 G_B: 0.163 cycle_B: 0.832 idt_B: 0.708 \n",
      "(epoch: 45, iters: 400, time: 0.458, data: 0.001) D_A: 0.179 G_A: 0.201 cycle_A: 1.588 idt_A: 0.208 D_B: 0.129 G_B: 0.705 cycle_B: 0.510 idt_B: 0.528 \n",
      "(epoch: 45, iters: 500, time: 0.230, data: 0.001) D_A: 0.050 G_A: 0.575 cycle_A: 1.259 idt_A: 0.180 D_B: 0.253 G_B: 0.187 cycle_B: 0.466 idt_B: 0.349 \n",
      "saving the model at the end of epoch 45, iters 22500\n",
      "End of epoch 45 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 100, time: 0.228, data: 0.094) D_A: 0.148 G_A: 0.760 cycle_A: 1.580 idt_A: 0.099 D_B: 0.210 G_B: 0.573 cycle_B: 0.245 idt_B: 0.592 \n",
      "(epoch: 46, iters: 200, time: 0.230, data: 0.001) D_A: 0.121 G_A: 0.376 cycle_A: 0.971 idt_A: 0.202 D_B: 0.187 G_B: 0.267 cycle_B: 0.549 idt_B: 0.377 \n",
      "(epoch: 46, iters: 300, time: 0.449, data: 0.001) D_A: 0.193 G_A: 0.264 cycle_A: 0.990 idt_A: 0.210 D_B: 0.189 G_B: 0.364 cycle_B: 0.449 idt_B: 0.245 \n",
      "(epoch: 46, iters: 400, time: 0.228, data: 0.001) D_A: 0.151 G_A: 0.286 cycle_A: 1.062 idt_A: 0.354 D_B: 0.197 G_B: 0.214 cycle_B: 0.747 idt_B: 0.267 \n",
      "(epoch: 46, iters: 500, time: 0.228, data: 0.002) D_A: 0.123 G_A: 0.900 cycle_A: 1.205 idt_A: 0.219 D_B: 0.126 G_B: 0.248 cycle_B: 0.503 idt_B: 0.683 \n",
      "End of epoch 46 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 100, time: 0.228, data: 0.123) D_A: 0.053 G_A: 0.530 cycle_A: 1.620 idt_A: 0.301 D_B: 0.216 G_B: 0.218 cycle_B: 1.019 idt_B: 0.525 \n",
      "(epoch: 47, iters: 200, time: 0.465, data: 0.002) D_A: 0.070 G_A: 0.586 cycle_A: 1.726 idt_A: 0.339 D_B: 0.236 G_B: 0.372 cycle_B: 0.834 idt_B: 0.846 \n",
      "(epoch: 47, iters: 300, time: 0.231, data: 0.001) D_A: 0.140 G_A: 0.371 cycle_A: 0.982 idt_A: 0.240 D_B: 0.135 G_B: 0.448 cycle_B: 0.618 idt_B: 0.331 \n",
      "(epoch: 47, iters: 400, time: 0.230, data: 0.001) D_A: 0.319 G_A: 1.198 cycle_A: 1.877 idt_A: 0.247 D_B: 0.086 G_B: 0.382 cycle_B: 0.605 idt_B: 0.785 \n",
      "(epoch: 47, iters: 500, time: 0.228, data: 0.002) D_A: 0.105 G_A: 0.566 cycle_A: 1.098 idt_A: 0.168 D_B: 0.182 G_B: 0.313 cycle_B: 0.507 idt_B: 0.538 \n",
      "End of epoch 47 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 100, time: 0.454, data: 0.096) D_A: 0.097 G_A: 0.912 cycle_A: 1.589 idt_A: 0.226 D_B: 0.174 G_B: 0.482 cycle_B: 0.502 idt_B: 0.717 \n",
      "(epoch: 48, iters: 200, time: 0.229, data: 0.001) D_A: 0.149 G_A: 0.728 cycle_A: 1.021 idt_A: 0.211 D_B: 0.173 G_B: 0.302 cycle_B: 0.587 idt_B: 0.441 \n",
      "(epoch: 48, iters: 300, time: 0.230, data: 0.001) D_A: 0.057 G_A: 0.619 cycle_A: 1.181 idt_A: 0.183 D_B: 0.188 G_B: 0.411 cycle_B: 0.471 idt_B: 0.415 \n",
      "(epoch: 48, iters: 400, time: 0.230, data: 0.002) D_A: 0.182 G_A: 0.664 cycle_A: 1.313 idt_A: 0.196 D_B: 0.174 G_B: 0.331 cycle_B: 0.510 idt_B: 0.372 \n",
      "(epoch: 48, iters: 500, time: 0.456, data: 0.002) D_A: 0.106 G_A: 0.720 cycle_A: 1.231 idt_A: 0.340 D_B: 0.202 G_B: 0.511 cycle_B: 0.696 idt_B: 0.548 \n",
      "End of epoch 48 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 100, time: 0.229, data: 0.097) D_A: 0.045 G_A: 0.903 cycle_A: 1.641 idt_A: 0.334 D_B: 0.176 G_B: 0.118 cycle_B: 0.814 idt_B: 0.562 \n",
      "(epoch: 49, iters: 200, time: 0.229, data: 0.001) D_A: 0.148 G_A: 0.937 cycle_A: 1.840 idt_A: 0.304 D_B: 0.183 G_B: 0.418 cycle_B: 0.710 idt_B: 0.797 \n",
      "(epoch: 49, iters: 300, time: 0.229, data: 0.002) D_A: 0.070 G_A: 0.527 cycle_A: 1.164 idt_A: 0.341 D_B: 0.200 G_B: 0.250 cycle_B: 0.798 idt_B: 0.342 \n",
      "(epoch: 49, iters: 400, time: 0.465, data: 0.002) D_A: 0.101 G_A: 0.490 cycle_A: 2.362 idt_A: 0.297 D_B: 0.176 G_B: 0.348 cycle_B: 0.737 idt_B: 1.655 \n",
      "(epoch: 49, iters: 500, time: 0.228, data: 0.001) D_A: 0.107 G_A: 0.513 cycle_A: 1.088 idt_A: 0.178 D_B: 0.147 G_B: 0.247 cycle_B: 0.543 idt_B: 0.395 \n",
      "End of epoch 49 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 100, time: 0.229, data: 0.097) D_A: 0.103 G_A: 0.572 cycle_A: 0.799 idt_A: 0.236 D_B: 0.164 G_B: 0.272 cycle_B: 0.517 idt_B: 0.405 \n",
      "(epoch: 50, iters: 200, time: 0.231, data: 0.002) D_A: 0.075 G_A: 0.326 cycle_A: 1.488 idt_A: 0.195 D_B: 0.239 G_B: 0.720 cycle_B: 0.520 idt_B: 0.531 \n",
      "(epoch: 50, iters: 300, time: 0.464, data: 0.001) D_A: 0.192 G_A: 0.329 cycle_A: 1.354 idt_A: 0.288 D_B: 0.286 G_B: 0.537 cycle_B: 0.685 idt_B: 0.413 \n",
      "(epoch: 50, iters: 400, time: 0.227, data: 0.001) D_A: 0.100 G_A: 0.997 cycle_A: 1.351 idt_A: 0.254 D_B: 0.104 G_B: 0.405 cycle_B: 0.511 idt_B: 0.516 \n",
      "(epoch: 50, iters: 500, time: 0.228, data: 0.001) D_A: 0.172 G_A: 0.731 cycle_A: 2.416 idt_A: 0.179 D_B: 0.158 G_B: 0.501 cycle_B: 0.447 idt_B: 0.943 \n",
      "saving the latest model (epoch 50, total_iters 25000)\n",
      "saving the model at the end of epoch 50, iters 25000\n",
      "End of epoch 50 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.229, data: 0.101) D_A: 0.109 G_A: 0.605 cycle_A: 0.993 idt_A: 0.122 D_B: 0.090 G_B: 0.350 cycle_B: 0.337 idt_B: 0.277 \n",
      "(epoch: 51, iters: 200, time: 0.466, data: 0.001) D_A: 0.074 G_A: 0.606 cycle_A: 1.558 idt_A: 0.102 D_B: 0.195 G_B: 0.104 cycle_B: 0.332 idt_B: 0.407 \n",
      "(epoch: 51, iters: 300, time: 0.230, data: 0.001) D_A: 0.142 G_A: 0.440 cycle_A: 1.386 idt_A: 0.237 D_B: 0.222 G_B: 0.559 cycle_B: 0.541 idt_B: 0.482 \n",
      "(epoch: 51, iters: 400, time: 0.232, data: 0.001) D_A: 0.180 G_A: 0.900 cycle_A: 1.944 idt_A: 0.194 D_B: 0.243 G_B: 0.186 cycle_B: 0.517 idt_B: 0.884 \n",
      "(epoch: 51, iters: 500, time: 0.228, data: 0.001) D_A: 0.141 G_A: 0.312 cycle_A: 1.055 idt_A: 0.181 D_B: 0.231 G_B: 0.354 cycle_B: 0.464 idt_B: 0.348 \n",
      "End of epoch 51 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 100, time: 0.464, data: 0.119) D_A: 0.197 G_A: 1.250 cycle_A: 0.930 idt_A: 0.186 D_B: 0.159 G_B: 0.286 cycle_B: 0.440 idt_B: 0.284 \n",
      "(epoch: 52, iters: 200, time: 0.228, data: 0.001) D_A: 0.136 G_A: 0.679 cycle_A: 1.514 idt_A: 0.161 D_B: 0.163 G_B: 0.337 cycle_B: 0.414 idt_B: 0.299 \n",
      "(epoch: 52, iters: 300, time: 0.229, data: 0.001) D_A: 0.201 G_A: 0.084 cycle_A: 1.589 idt_A: 0.087 D_B: 0.248 G_B: 0.468 cycle_B: 0.259 idt_B: 0.535 \n",
      "(epoch: 52, iters: 400, time: 0.230, data: 0.001) D_A: 0.173 G_A: 0.295 cycle_A: 1.167 idt_A: 0.186 D_B: 0.161 G_B: 0.599 cycle_B: 0.571 idt_B: 0.329 \n",
      "(epoch: 52, iters: 500, time: 0.463, data: 0.001) D_A: 0.170 G_A: 0.744 cycle_A: 1.480 idt_A: 0.267 D_B: 0.134 G_B: 0.269 cycle_B: 0.650 idt_B: 0.604 \n",
      "End of epoch 52 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 100, time: 0.230, data: 0.101) D_A: 0.130 G_A: 0.372 cycle_A: 1.106 idt_A: 0.215 D_B: 0.125 G_B: 0.421 cycle_B: 0.452 idt_B: 0.449 \n",
      "(epoch: 53, iters: 200, time: 0.231, data: 0.001) D_A: 0.101 G_A: 0.470 cycle_A: 2.298 idt_A: 0.295 D_B: 0.210 G_B: 0.837 cycle_B: 0.729 idt_B: 0.977 \n",
      "(epoch: 53, iters: 300, time: 0.231, data: 0.001) D_A: 0.069 G_A: 0.503 cycle_A: 1.369 idt_A: 0.171 D_B: 0.133 G_B: 0.475 cycle_B: 0.446 idt_B: 0.456 \n",
      "(epoch: 53, iters: 400, time: 0.474, data: 0.001) D_A: 0.202 G_A: 1.230 cycle_A: 1.578 idt_A: 0.209 D_B: 0.073 G_B: 0.337 cycle_B: 0.588 idt_B: 0.647 \n",
      "(epoch: 53, iters: 500, time: 0.228, data: 0.001) D_A: 0.105 G_A: 0.835 cycle_A: 1.089 idt_A: 0.343 D_B: 0.214 G_B: 0.063 cycle_B: 0.907 idt_B: 0.345 \n",
      "End of epoch 53 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 100, time: 0.229, data: 0.096) D_A: 0.147 G_A: 0.317 cycle_A: 0.993 idt_A: 0.051 D_B: 0.084 G_B: 0.383 cycle_B: 0.268 idt_B: 0.250 \n",
      "(epoch: 54, iters: 200, time: 0.228, data: 0.002) D_A: 0.065 G_A: 0.356 cycle_A: 1.363 idt_A: 0.173 D_B: 0.175 G_B: 0.273 cycle_B: 0.512 idt_B: 0.373 \n",
      "(epoch: 54, iters: 300, time: 0.478, data: 0.001) D_A: 0.116 G_A: 0.841 cycle_A: 1.374 idt_A: 0.233 D_B: 0.215 G_B: 0.574 cycle_B: 0.593 idt_B: 0.581 \n",
      "(epoch: 54, iters: 400, time: 0.230, data: 0.001) D_A: 0.156 G_A: 0.317 cycle_A: 1.140 idt_A: 0.135 D_B: 0.227 G_B: 0.990 cycle_B: 0.355 idt_B: 0.511 \n",
      "(epoch: 54, iters: 500, time: 0.228, data: 0.001) D_A: 0.142 G_A: 0.370 cycle_A: 0.888 idt_A: 0.315 D_B: 0.369 G_B: 0.191 cycle_B: 0.759 idt_B: 0.312 \n",
      "End of epoch 54 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 55, iters: 100, time: 0.231, data: 0.117) D_A: 0.112 G_A: 0.796 cycle_A: 1.775 idt_A: 0.291 D_B: 0.135 G_B: 0.482 cycle_B: 0.706 idt_B: 0.699 \n",
      "(epoch: 55, iters: 200, time: 0.466, data: 0.002) D_A: 0.149 G_A: 0.947 cycle_A: 1.324 idt_A: 0.157 D_B: 0.295 G_B: 0.486 cycle_B: 0.482 idt_B: 0.766 \n",
      "(epoch: 55, iters: 300, time: 0.230, data: 0.001) D_A: 0.057 G_A: 0.846 cycle_A: 1.727 idt_A: 0.250 D_B: 0.074 G_B: 0.621 cycle_B: 0.662 idt_B: 0.551 \n",
      "(epoch: 55, iters: 400, time: 0.228, data: 0.002) D_A: 0.220 G_A: 0.144 cycle_A: 1.365 idt_A: 0.229 D_B: 0.130 G_B: 0.402 cycle_B: 0.572 idt_B: 0.252 \n",
      "(epoch: 55, iters: 500, time: 0.230, data: 0.001) D_A: 0.361 G_A: 0.074 cycle_A: 1.146 idt_A: 0.230 D_B: 0.150 G_B: 0.534 cycle_B: 0.565 idt_B: 0.353 \n",
      "saving the model at the end of epoch 55, iters 27500\n",
      "End of epoch 55 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 100, time: 0.467, data: 0.117) D_A: 0.122 G_A: 0.834 cycle_A: 1.267 idt_A: 0.155 D_B: 0.235 G_B: 0.858 cycle_B: 0.494 idt_B: 0.701 \n",
      "(epoch: 56, iters: 200, time: 0.229, data: 0.001) D_A: 0.049 G_A: 1.060 cycle_A: 1.819 idt_A: 0.275 D_B: 0.257 G_B: 0.280 cycle_B: 0.715 idt_B: 0.880 \n",
      "(epoch: 56, iters: 300, time: 0.229, data: 0.001) D_A: 0.127 G_A: 0.796 cycle_A: 1.093 idt_A: 0.239 D_B: 0.285 G_B: 0.549 cycle_B: 0.624 idt_B: 0.373 \n",
      "(epoch: 56, iters: 400, time: 0.229, data: 0.001) D_A: 0.204 G_A: 0.443 cycle_A: 1.679 idt_A: 0.210 D_B: 0.377 G_B: 0.368 cycle_B: 0.517 idt_B: 0.569 \n",
      "(epoch: 56, iters: 500, time: 0.457, data: 0.002) D_A: 0.090 G_A: 0.697 cycle_A: 1.194 idt_A: 0.150 D_B: 0.188 G_B: 0.179 cycle_B: 0.427 idt_B: 0.327 \n",
      "End of epoch 56 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 100, time: 0.227, data: 0.093) D_A: 0.140 G_A: 0.357 cycle_A: 1.468 idt_A: 0.089 D_B: 0.264 G_B: 0.401 cycle_B: 0.246 idt_B: 0.258 \n",
      "(epoch: 57, iters: 200, time: 0.231, data: 0.001) D_A: 0.115 G_A: 0.611 cycle_A: 1.982 idt_A: 0.195 D_B: 0.161 G_B: 0.313 cycle_B: 0.473 idt_B: 0.754 \n",
      "(epoch: 57, iters: 300, time: 0.231, data: 0.001) D_A: 0.126 G_A: 0.407 cycle_A: 1.534 idt_A: 0.172 D_B: 0.094 G_B: 0.408 cycle_B: 0.543 idt_B: 0.712 \n",
      "(epoch: 57, iters: 400, time: 0.464, data: 0.001) D_A: 0.203 G_A: 0.895 cycle_A: 1.882 idt_A: 0.132 D_B: 0.157 G_B: 0.258 cycle_B: 0.341 idt_B: 0.491 \n",
      "(epoch: 57, iters: 500, time: 0.230, data: 0.001) D_A: 0.124 G_A: 0.473 cycle_A: 1.399 idt_A: 0.128 D_B: 0.068 G_B: 0.381 cycle_B: 0.366 idt_B: 0.462 \n",
      "End of epoch 57 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 100, time: 0.229, data: 0.118) D_A: 0.254 G_A: 0.122 cycle_A: 1.486 idt_A: 0.177 D_B: 0.248 G_B: 0.752 cycle_B: 0.470 idt_B: 0.861 \n",
      "(epoch: 58, iters: 200, time: 0.229, data: 0.002) D_A: 0.217 G_A: 0.485 cycle_A: 1.070 idt_A: 0.122 D_B: 0.186 G_B: 0.337 cycle_B: 0.394 idt_B: 0.401 \n",
      "(epoch: 58, iters: 300, time: 0.471, data: 0.001) D_A: 0.152 G_A: 0.548 cycle_A: 1.035 idt_A: 0.155 D_B: 0.060 G_B: 0.557 cycle_B: 0.402 idt_B: 0.422 \n",
      "(epoch: 58, iters: 400, time: 0.228, data: 0.001) D_A: 0.059 G_A: 0.511 cycle_A: 1.142 idt_A: 0.157 D_B: 0.122 G_B: 0.307 cycle_B: 0.464 idt_B: 0.343 \n",
      "(epoch: 58, iters: 500, time: 0.229, data: 0.001) D_A: 0.142 G_A: 0.607 cycle_A: 1.993 idt_A: 0.146 D_B: 0.229 G_B: 0.248 cycle_B: 0.367 idt_B: 0.859 \n",
      "End of epoch 58 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 100, time: 0.228, data: 0.096) D_A: 0.162 G_A: 0.437 cycle_A: 1.869 idt_A: 0.118 D_B: 0.225 G_B: 0.244 cycle_B: 0.269 idt_B: 0.583 \n",
      "(epoch: 59, iters: 200, time: 0.471, data: 0.002) D_A: 0.150 G_A: 0.118 cycle_A: 1.914 idt_A: 0.200 D_B: 0.221 G_B: 0.489 cycle_B: 0.454 idt_B: 0.454 \n",
      "(epoch: 59, iters: 300, time: 0.229, data: 0.001) D_A: 0.125 G_A: 0.435 cycle_A: 1.577 idt_A: 0.203 D_B: 0.238 G_B: 0.289 cycle_B: 0.625 idt_B: 0.643 \n",
      "(epoch: 59, iters: 400, time: 0.230, data: 0.002) D_A: 0.204 G_A: 0.275 cycle_A: 1.515 idt_A: 0.266 D_B: 0.103 G_B: 0.355 cycle_B: 0.603 idt_B: 0.540 \n",
      "(epoch: 59, iters: 500, time: 0.230, data: 0.002) D_A: 0.122 G_A: 0.365 cycle_A: 1.172 idt_A: 0.139 D_B: 0.060 G_B: 0.484 cycle_B: 0.401 idt_B: 0.308 \n",
      "End of epoch 59 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 100, time: 0.497, data: 0.099) D_A: 0.171 G_A: 0.449 cycle_A: 1.674 idt_A: 0.211 D_B: 0.213 G_B: 0.460 cycle_B: 0.425 idt_B: 0.500 \n",
      "(epoch: 60, iters: 200, time: 0.229, data: 0.001) D_A: 0.071 G_A: 0.827 cycle_A: 1.225 idt_A: 0.199 D_B: 0.110 G_B: 0.225 cycle_B: 0.589 idt_B: 0.386 \n",
      "(epoch: 60, iters: 300, time: 0.227, data: 0.001) D_A: 0.060 G_A: 0.823 cycle_A: 1.141 idt_A: 0.257 D_B: 0.109 G_B: 0.453 cycle_B: 0.645 idt_B: 0.544 \n",
      "(epoch: 60, iters: 400, time: 0.231, data: 0.001) D_A: 0.057 G_A: 0.901 cycle_A: 0.919 idt_A: 0.079 D_B: 0.216 G_B: 0.244 cycle_B: 0.302 idt_B: 0.396 \n",
      "(epoch: 60, iters: 500, time: 0.497, data: 0.001) D_A: 0.062 G_A: 0.472 cycle_A: 1.313 idt_A: 0.259 D_B: 0.165 G_B: 0.575 cycle_B: 0.677 idt_B: 0.471 \n",
      "saving the latest model (epoch 60, total_iters 30000)\n",
      "saving the model at the end of epoch 60, iters 30000\n",
      "End of epoch 60 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 100, time: 0.230, data: 0.117) D_A: 0.099 G_A: 0.655 cycle_A: 2.256 idt_A: 0.226 D_B: 0.102 G_B: 0.188 cycle_B: 0.589 idt_B: 1.150 \n",
      "(epoch: 61, iters: 200, time: 0.228, data: 0.002) D_A: 0.056 G_A: 0.748 cycle_A: 0.920 idt_A: 0.193 D_B: 0.185 G_B: 0.485 cycle_B: 0.535 idt_B: 0.612 \n",
      "(epoch: 61, iters: 300, time: 0.229, data: 0.001) D_A: 0.053 G_A: 0.661 cycle_A: 1.111 idt_A: 0.227 D_B: 0.217 G_B: 0.231 cycle_B: 0.569 idt_B: 0.341 \n",
      "(epoch: 61, iters: 400, time: 0.498, data: 0.002) D_A: 0.088 G_A: 0.775 cycle_A: 1.814 idt_A: 0.181 D_B: 0.197 G_B: 0.805 cycle_B: 0.482 idt_B: 0.928 \n",
      "(epoch: 61, iters: 500, time: 0.229, data: 0.002) D_A: 0.267 G_A: 1.244 cycle_A: 1.200 idt_A: 0.184 D_B: 0.127 G_B: 0.265 cycle_B: 0.441 idt_B: 0.649 \n",
      "End of epoch 61 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 100, time: 0.228, data: 0.100) D_A: 0.108 G_A: 0.306 cycle_A: 1.202 idt_A: 0.277 D_B: 0.236 G_B: 0.659 cycle_B: 0.658 idt_B: 0.323 \n",
      "(epoch: 62, iters: 200, time: 0.232, data: 0.001) D_A: 0.177 G_A: 0.233 cycle_A: 1.588 idt_A: 0.169 D_B: 0.112 G_B: 0.553 cycle_B: 0.465 idt_B: 0.368 \n",
      "(epoch: 62, iters: 300, time: 0.509, data: 0.001) D_A: 0.079 G_A: 0.407 cycle_A: 0.926 idt_A: 0.211 D_B: 0.177 G_B: 0.293 cycle_B: 0.614 idt_B: 0.288 \n",
      "(epoch: 62, iters: 400, time: 0.229, data: 0.001) D_A: 0.117 G_A: 0.737 cycle_A: 1.153 idt_A: 0.228 D_B: 0.097 G_B: 0.664 cycle_B: 0.568 idt_B: 0.321 \n",
      "(epoch: 62, iters: 500, time: 0.229, data: 0.001) D_A: 0.134 G_A: 0.567 cycle_A: 2.456 idt_A: 0.305 D_B: 0.326 G_B: 0.456 cycle_B: 0.940 idt_B: 0.526 \n",
      "End of epoch 62 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 100, time: 0.232, data: 0.118) D_A: 0.127 G_A: 0.779 cycle_A: 1.793 idt_A: 0.216 D_B: 0.169 G_B: 0.296 cycle_B: 0.501 idt_B: 0.557 \n",
      "(epoch: 63, iters: 200, time: 0.520, data: 0.001) D_A: 0.266 G_A: 0.175 cycle_A: 1.194 idt_A: 0.191 D_B: 0.214 G_B: 0.483 cycle_B: 0.474 idt_B: 0.346 \n",
      "(epoch: 63, iters: 300, time: 0.229, data: 0.001) D_A: 0.174 G_A: 1.138 cycle_A: 1.872 idt_A: 0.225 D_B: 0.140 G_B: 0.365 cycle_B: 0.590 idt_B: 0.594 \n",
      "(epoch: 63, iters: 400, time: 0.228, data: 0.001) D_A: 0.144 G_A: 0.529 cycle_A: 1.720 idt_A: 0.231 D_B: 0.158 G_B: 0.340 cycle_B: 0.516 idt_B: 0.965 \n",
      "(epoch: 63, iters: 500, time: 0.229, data: 0.001) D_A: 0.072 G_A: 0.772 cycle_A: 1.411 idt_A: 0.294 D_B: 0.159 G_B: 0.321 cycle_B: 0.763 idt_B: 0.481 \n",
      "End of epoch 63 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 100, time: 0.493, data: 0.096) D_A: 0.106 G_A: 1.019 cycle_A: 1.783 idt_A: 0.189 D_B: 0.106 G_B: 0.615 cycle_B: 0.587 idt_B: 0.745 \n",
      "(epoch: 64, iters: 200, time: 0.231, data: 0.001) D_A: 0.180 G_A: 0.245 cycle_A: 1.463 idt_A: 0.124 D_B: 0.244 G_B: 0.132 cycle_B: 0.324 idt_B: 0.398 \n",
      "(epoch: 64, iters: 300, time: 0.231, data: 0.002) D_A: 0.076 G_A: 0.505 cycle_A: 1.239 idt_A: 0.184 D_B: 0.194 G_B: 0.191 cycle_B: 0.482 idt_B: 0.373 \n",
      "(epoch: 64, iters: 400, time: 0.228, data: 0.001) D_A: 0.066 G_A: 0.632 cycle_A: 1.103 idt_A: 0.180 D_B: 0.213 G_B: 0.468 cycle_B: 0.509 idt_B: 0.376 \n",
      "(epoch: 64, iters: 500, time: 0.478, data: 0.002) D_A: 0.090 G_A: 1.398 cycle_A: 2.153 idt_A: 0.293 D_B: 0.138 G_B: 0.508 cycle_B: 0.796 idt_B: 1.091 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 64 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 100, time: 0.229, data: 0.102) D_A: 0.063 G_A: 0.616 cycle_A: 0.907 idt_A: 0.095 D_B: 0.121 G_B: 0.525 cycle_B: 0.218 idt_B: 0.577 \n",
      "(epoch: 65, iters: 200, time: 0.229, data: 0.001) D_A: 0.142 G_A: 0.354 cycle_A: 1.575 idt_A: 0.185 D_B: 0.187 G_B: 0.446 cycle_B: 0.526 idt_B: 0.464 \n",
      "(epoch: 65, iters: 300, time: 0.227, data: 0.001) D_A: 0.175 G_A: 0.415 cycle_A: 1.094 idt_A: 0.067 D_B: 0.125 G_B: 0.439 cycle_B: 0.358 idt_B: 0.495 \n",
      "(epoch: 65, iters: 400, time: 0.489, data: 0.001) D_A: 0.036 G_A: 0.513 cycle_A: 1.692 idt_A: 0.301 D_B: 0.190 G_B: 0.245 cycle_B: 0.662 idt_B: 0.459 \n",
      "(epoch: 65, iters: 500, time: 0.229, data: 0.001) D_A: 0.133 G_A: 0.573 cycle_A: 1.013 idt_A: 0.085 D_B: 0.187 G_B: 0.464 cycle_B: 0.233 idt_B: 0.422 \n",
      "saving the model at the end of epoch 65, iters 32500\n",
      "End of epoch 65 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 100, time: 0.227, data: 0.095) D_A: 0.136 G_A: 0.381 cycle_A: 1.483 idt_A: 0.241 D_B: 0.115 G_B: 0.356 cycle_B: 0.606 idt_B: 0.429 \n",
      "(epoch: 66, iters: 200, time: 0.232, data: 0.001) D_A: 0.080 G_A: 0.359 cycle_A: 2.184 idt_A: 0.143 D_B: 0.140 G_B: 0.398 cycle_B: 0.353 idt_B: 0.971 \n",
      "(epoch: 66, iters: 300, time: 0.483, data: 0.002) D_A: 0.104 G_A: 0.790 cycle_A: 1.116 idt_A: 0.156 D_B: 0.259 G_B: 0.157 cycle_B: 0.359 idt_B: 0.410 \n",
      "(epoch: 66, iters: 400, time: 0.229, data: 0.001) D_A: 0.202 G_A: 0.294 cycle_A: 2.008 idt_A: 0.175 D_B: 0.147 G_B: 0.424 cycle_B: 0.421 idt_B: 0.699 \n",
      "(epoch: 66, iters: 500, time: 0.229, data: 0.001) D_A: 0.086 G_A: 0.793 cycle_A: 0.911 idt_A: 0.201 D_B: 0.222 G_B: 0.185 cycle_B: 0.547 idt_B: 0.331 \n",
      "End of epoch 66 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 100, time: 0.228, data: 0.099) D_A: 0.122 G_A: 0.538 cycle_A: 1.343 idt_A: 0.290 D_B: 0.209 G_B: 0.188 cycle_B: 0.633 idt_B: 0.533 \n",
      "(epoch: 67, iters: 200, time: 0.505, data: 0.002) D_A: 0.274 G_A: 1.264 cycle_A: 1.208 idt_A: 0.179 D_B: 0.233 G_B: 0.334 cycle_B: 0.514 idt_B: 0.467 \n",
      "(epoch: 67, iters: 300, time: 0.229, data: 0.001) D_A: 0.115 G_A: 0.600 cycle_A: 2.498 idt_A: 0.210 D_B: 0.128 G_B: 0.435 cycle_B: 0.546 idt_B: 0.799 \n",
      "(epoch: 67, iters: 400, time: 0.228, data: 0.001) D_A: 0.136 G_A: 0.602 cycle_A: 1.804 idt_A: 0.219 D_B: 0.132 G_B: 0.409 cycle_B: 0.483 idt_B: 0.606 \n",
      "(epoch: 67, iters: 500, time: 0.229, data: 0.002) D_A: 0.052 G_A: 0.510 cycle_A: 1.278 idt_A: 0.141 D_B: 0.056 G_B: 0.548 cycle_B: 0.445 idt_B: 0.325 \n",
      "End of epoch 67 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 100, time: 0.485, data: 0.100) D_A: 0.204 G_A: 1.110 cycle_A: 0.718 idt_A: 0.186 D_B: 0.109 G_B: 0.279 cycle_B: 0.510 idt_B: 0.387 \n",
      "(epoch: 68, iters: 200, time: 0.230, data: 0.002) D_A: 0.056 G_A: 0.454 cycle_A: 1.040 idt_A: 0.237 D_B: 0.116 G_B: 0.710 cycle_B: 0.501 idt_B: 0.408 \n",
      "(epoch: 68, iters: 300, time: 0.229, data: 0.001) D_A: 0.075 G_A: 0.980 cycle_A: 1.818 idt_A: 0.155 D_B: 0.089 G_B: 0.509 cycle_B: 1.324 idt_B: 0.503 \n",
      "(epoch: 68, iters: 400, time: 0.228, data: 0.001) D_A: 0.018 G_A: 0.864 cycle_A: 1.668 idt_A: 0.164 D_B: 0.128 G_B: 0.511 cycle_B: 0.400 idt_B: 0.294 \n",
      "(epoch: 68, iters: 500, time: 0.479, data: 0.001) D_A: 0.057 G_A: 1.000 cycle_A: 0.858 idt_A: 0.141 D_B: 0.108 G_B: 0.297 cycle_B: 0.524 idt_B: 0.482 \n",
      "End of epoch 68 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 100, time: 0.229, data: 0.113) D_A: 0.039 G_A: 0.450 cycle_A: 1.398 idt_A: 0.165 D_B: 0.182 G_B: 0.522 cycle_B: 0.493 idt_B: 0.389 \n",
      "(epoch: 69, iters: 200, time: 0.228, data: 0.002) D_A: 0.037 G_A: 0.523 cycle_A: 1.126 idt_A: 0.179 D_B: 0.192 G_B: 0.307 cycle_B: 0.448 idt_B: 0.475 \n",
      "(epoch: 69, iters: 300, time: 0.229, data: 0.002) D_A: 0.057 G_A: 0.436 cycle_A: 1.231 idt_A: 0.299 D_B: 0.100 G_B: 0.409 cycle_B: 0.700 idt_B: 0.588 \n",
      "(epoch: 69, iters: 400, time: 0.502, data: 0.001) D_A: 0.086 G_A: 0.268 cycle_A: 2.170 idt_A: 0.205 D_B: 0.263 G_B: 0.090 cycle_B: 0.509 idt_B: 0.679 \n",
      "(epoch: 69, iters: 500, time: 0.227, data: 0.001) D_A: 0.159 G_A: 0.745 cycle_A: 2.203 idt_A: 0.131 D_B: 0.172 G_B: 0.512 cycle_B: 0.267 idt_B: 1.005 \n",
      "End of epoch 69 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 100, time: 0.230, data: 0.102) D_A: 0.146 G_A: 0.783 cycle_A: 0.966 idt_A: 0.163 D_B: 0.094 G_B: 0.550 cycle_B: 0.410 idt_B: 0.430 \n",
      "(epoch: 70, iters: 200, time: 0.233, data: 0.001) D_A: 0.106 G_A: 0.487 cycle_A: 1.394 idt_A: 0.156 D_B: 0.130 G_B: 0.556 cycle_B: 0.369 idt_B: 0.363 \n",
      "(epoch: 70, iters: 300, time: 0.520, data: 0.001) D_A: 0.128 G_A: 1.172 cycle_A: 2.627 idt_A: 0.222 D_B: 0.139 G_B: 0.322 cycle_B: 0.607 idt_B: 1.016 \n",
      "(epoch: 70, iters: 400, time: 0.228, data: 0.001) D_A: 0.102 G_A: 0.331 cycle_A: 1.070 idt_A: 0.242 D_B: 0.121 G_B: 0.444 cycle_B: 0.557 idt_B: 0.338 \n",
      "(epoch: 70, iters: 500, time: 0.228, data: 0.001) D_A: 0.106 G_A: 0.854 cycle_A: 1.173 idt_A: 0.290 D_B: 0.201 G_B: 0.282 cycle_B: 0.744 idt_B: 0.307 \n",
      "saving the latest model (epoch 70, total_iters 35000)\n",
      "saving the model at the end of epoch 70, iters 35000\n",
      "End of epoch 70 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 100, time: 0.231, data: 0.110) D_A: 0.043 G_A: 0.561 cycle_A: 1.097 idt_A: 0.255 D_B: 0.104 G_B: 0.552 cycle_B: 0.593 idt_B: 0.449 \n",
      "(epoch: 71, iters: 200, time: 0.526, data: 0.002) D_A: 0.168 G_A: 0.845 cycle_A: 1.227 idt_A: 0.292 D_B: 0.109 G_B: 0.957 cycle_B: 0.809 idt_B: 0.410 \n",
      "(epoch: 71, iters: 300, time: 0.229, data: 0.002) D_A: 0.047 G_A: 0.989 cycle_A: 1.914 idt_A: 0.218 D_B: 0.226 G_B: 0.606 cycle_B: 0.569 idt_B: 0.614 \n",
      "(epoch: 71, iters: 400, time: 0.231, data: 0.001) D_A: 0.095 G_A: 0.204 cycle_A: 1.254 idt_A: 0.161 D_B: 0.112 G_B: 0.351 cycle_B: 0.402 idt_B: 0.311 \n",
      "(epoch: 71, iters: 500, time: 0.228, data: 0.002) D_A: 0.104 G_A: 0.339 cycle_A: 1.125 idt_A: 0.177 D_B: 0.151 G_B: 0.588 cycle_B: 0.507 idt_B: 0.577 \n",
      "End of epoch 71 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 100, time: 0.519, data: 0.097) D_A: 0.202 G_A: 1.302 cycle_A: 0.807 idt_A: 0.149 D_B: 0.158 G_B: 0.235 cycle_B: 0.482 idt_B: 0.389 \n",
      "(epoch: 72, iters: 200, time: 0.228, data: 0.001) D_A: 0.206 G_A: 0.588 cycle_A: 1.059 idt_A: 0.100 D_B: 0.185 G_B: 0.553 cycle_B: 0.293 idt_B: 0.648 \n",
      "(epoch: 72, iters: 300, time: 0.229, data: 0.001) D_A: 0.070 G_A: 0.384 cycle_A: 0.871 idt_A: 0.329 D_B: 0.175 G_B: 0.425 cycle_B: 0.762 idt_B: 0.345 \n",
      "(epoch: 72, iters: 400, time: 0.229, data: 0.001) D_A: 0.062 G_A: 0.631 cycle_A: 1.681 idt_A: 0.182 D_B: 0.112 G_B: 0.340 cycle_B: 0.481 idt_B: 0.445 \n",
      "(epoch: 72, iters: 500, time: 0.504, data: 0.001) D_A: 0.170 G_A: 0.288 cycle_A: 1.566 idt_A: 0.252 D_B: 0.081 G_B: 0.574 cycle_B: 0.734 idt_B: 0.350 \n",
      "End of epoch 72 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 100, time: 0.231, data: 0.099) D_A: 0.138 G_A: 0.484 cycle_A: 0.859 idt_A: 0.152 D_B: 0.279 G_B: 0.581 cycle_B: 0.492 idt_B: 0.303 \n",
      "(epoch: 73, iters: 200, time: 0.231, data: 0.001) D_A: 0.271 G_A: 0.254 cycle_A: 1.734 idt_A: 0.171 D_B: 0.080 G_B: 0.555 cycle_B: 0.435 idt_B: 0.747 \n",
      "(epoch: 73, iters: 300, time: 0.229, data: 0.002) D_A: 0.083 G_A: 0.917 cycle_A: 2.485 idt_A: 0.167 D_B: 0.159 G_B: 0.374 cycle_B: 0.527 idt_B: 0.733 \n",
      "(epoch: 73, iters: 400, time: 0.519, data: 0.002) D_A: 0.161 G_A: 0.267 cycle_A: 1.173 idt_A: 0.260 D_B: 0.355 G_B: 0.078 cycle_B: 0.571 idt_B: 0.256 \n",
      "(epoch: 73, iters: 500, time: 0.229, data: 0.001) D_A: 0.052 G_A: 0.708 cycle_A: 1.218 idt_A: 0.235 D_B: 0.215 G_B: 0.238 cycle_B: 0.577 idt_B: 0.466 \n",
      "End of epoch 73 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 100, time: 0.231, data: 0.098) D_A: 0.245 G_A: 0.536 cycle_A: 1.498 idt_A: 0.213 D_B: 0.079 G_B: 0.556 cycle_B: 0.496 idt_B: 0.303 \n",
      "(epoch: 74, iters: 200, time: 0.240, data: 0.002) D_A: 0.140 G_A: 0.692 cycle_A: 1.427 idt_A: 0.135 D_B: 0.244 G_B: 0.381 cycle_B: 0.383 idt_B: 0.849 \n",
      "(epoch: 74, iters: 300, time: 0.513, data: 0.001) D_A: 0.072 G_A: 0.915 cycle_A: 0.810 idt_A: 0.158 D_B: 0.222 G_B: 0.611 cycle_B: 0.500 idt_B: 0.342 \n",
      "(epoch: 74, iters: 400, time: 0.231, data: 0.002) D_A: 0.084 G_A: 0.727 cycle_A: 1.159 idt_A: 0.423 D_B: 0.177 G_B: 0.701 cycle_B: 1.338 idt_B: 0.351 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 74, iters: 500, time: 0.229, data: 0.002) D_A: 0.100 G_A: 0.501 cycle_A: 1.899 idt_A: 0.157 D_B: 0.345 G_B: 0.399 cycle_B: 0.450 idt_B: 0.658 \n",
      "End of epoch 74 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 100, time: 0.228, data: 0.120) D_A: 0.158 G_A: 0.297 cycle_A: 1.125 idt_A: 0.249 D_B: 0.198 G_B: 0.433 cycle_B: 0.557 idt_B: 0.388 \n",
      "(epoch: 75, iters: 200, time: 0.501, data: 0.001) D_A: 0.121 G_A: 1.001 cycle_A: 0.941 idt_A: 0.103 D_B: 0.164 G_B: 0.238 cycle_B: 0.304 idt_B: 0.278 \n",
      "(epoch: 75, iters: 300, time: 0.230, data: 0.001) D_A: 0.143 G_A: 0.422 cycle_A: 1.548 idt_A: 0.144 D_B: 0.070 G_B: 0.713 cycle_B: 0.444 idt_B: 0.550 \n",
      "(epoch: 75, iters: 400, time: 0.228, data: 0.002) D_A: 0.103 G_A: 0.269 cycle_A: 1.865 idt_A: 0.184 D_B: 0.133 G_B: 0.356 cycle_B: 0.496 idt_B: 0.943 \n",
      "(epoch: 75, iters: 500, time: 0.228, data: 0.001) D_A: 0.081 G_A: 0.723 cycle_A: 1.156 idt_A: 0.185 D_B: 0.074 G_B: 0.730 cycle_B: 0.536 idt_B: 0.316 \n",
      "saving the model at the end of epoch 75, iters 37500\n",
      "End of epoch 75 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 100, time: 0.517, data: 0.098) D_A: 0.138 G_A: 0.611 cycle_A: 0.932 idt_A: 0.341 D_B: 0.207 G_B: 0.487 cycle_B: 0.747 idt_B: 0.255 \n",
      "(epoch: 76, iters: 200, time: 0.228, data: 0.001) D_A: 0.150 G_A: 0.666 cycle_A: 1.103 idt_A: 0.096 D_B: 0.142 G_B: 0.554 cycle_B: 0.327 idt_B: 0.211 \n",
      "(epoch: 76, iters: 300, time: 0.229, data: 0.002) D_A: 0.110 G_A: 0.563 cycle_A: 1.145 idt_A: 0.325 D_B: 0.205 G_B: 0.639 cycle_B: 0.802 idt_B: 0.466 \n",
      "(epoch: 76, iters: 400, time: 0.229, data: 0.001) D_A: 0.036 G_A: 0.749 cycle_A: 0.943 idt_A: 0.247 D_B: 0.132 G_B: 0.251 cycle_B: 0.638 idt_B: 0.341 \n",
      "(epoch: 76, iters: 500, time: 0.511, data: 0.002) D_A: 0.075 G_A: 1.004 cycle_A: 1.333 idt_A: 0.379 D_B: 0.072 G_B: 0.357 cycle_B: 0.826 idt_B: 0.458 \n",
      "End of epoch 76 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 100, time: 0.229, data: 0.119) D_A: 0.087 G_A: 0.495 cycle_A: 0.921 idt_A: 0.157 D_B: 0.249 G_B: 0.553 cycle_B: 0.427 idt_B: 0.409 \n",
      "(epoch: 77, iters: 200, time: 0.229, data: 0.002) D_A: 0.064 G_A: 0.668 cycle_A: 1.059 idt_A: 0.200 D_B: 0.166 G_B: 0.656 cycle_B: 0.540 idt_B: 0.427 \n",
      "(epoch: 77, iters: 300, time: 0.231, data: 0.002) D_A: 0.174 G_A: 1.350 cycle_A: 0.978 idt_A: 0.230 D_B: 0.100 G_B: 0.370 cycle_B: 0.584 idt_B: 0.230 \n",
      "(epoch: 77, iters: 400, time: 0.534, data: 0.002) D_A: 0.508 G_A: 1.486 cycle_A: 1.224 idt_A: 0.185 D_B: 0.173 G_B: 0.963 cycle_B: 0.537 idt_B: 0.503 \n",
      "(epoch: 77, iters: 500, time: 0.228, data: 0.001) D_A: 0.093 G_A: 0.661 cycle_A: 1.971 idt_A: 0.177 D_B: 0.200 G_B: 0.420 cycle_B: 0.518 idt_B: 0.525 \n",
      "End of epoch 77 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 100, time: 0.229, data: 0.100) D_A: 0.048 G_A: 0.573 cycle_A: 0.961 idt_A: 0.214 D_B: 0.252 G_B: 0.222 cycle_B: 0.553 idt_B: 0.430 \n",
      "(epoch: 78, iters: 200, time: 0.229, data: 0.001) D_A: 0.176 G_A: 0.584 cycle_A: 1.196 idt_A: 0.093 D_B: 0.239 G_B: 0.325 cycle_B: 0.308 idt_B: 0.318 \n",
      "(epoch: 78, iters: 300, time: 0.531, data: 0.001) D_A: 0.154 G_A: 0.164 cycle_A: 1.114 idt_A: 0.422 D_B: 0.297 G_B: 0.326 cycle_B: 0.911 idt_B: 0.465 \n",
      "(epoch: 78, iters: 400, time: 0.230, data: 0.001) D_A: 0.088 G_A: 0.453 cycle_A: 1.578 idt_A: 0.312 D_B: 0.159 G_B: 0.402 cycle_B: 0.741 idt_B: 0.556 \n",
      "(epoch: 78, iters: 500, time: 0.228, data: 0.002) D_A: 0.103 G_A: 0.488 cycle_A: 1.912 idt_A: 0.149 D_B: 0.079 G_B: 0.477 cycle_B: 0.423 idt_B: 1.215 \n",
      "End of epoch 78 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 100, time: 0.227, data: 0.105) D_A: 0.062 G_A: 0.361 cycle_A: 1.340 idt_A: 0.125 D_B: 0.147 G_B: 0.345 cycle_B: 0.385 idt_B: 0.434 \n",
      "(epoch: 79, iters: 200, time: 0.507, data: 0.001) D_A: 0.286 G_A: 1.104 cycle_A: 1.295 idt_A: 0.287 D_B: 0.361 G_B: 0.179 cycle_B: 0.672 idt_B: 0.317 \n",
      "(epoch: 79, iters: 300, time: 0.229, data: 0.001) D_A: 0.151 G_A: 0.610 cycle_A: 1.134 idt_A: 0.124 D_B: 0.205 G_B: 0.420 cycle_B: 0.330 idt_B: 0.548 \n",
      "(epoch: 79, iters: 400, time: 0.229, data: 0.001) D_A: 0.137 G_A: 0.576 cycle_A: 1.406 idt_A: 0.220 D_B: 0.329 G_B: 0.251 cycle_B: 0.608 idt_B: 0.300 \n",
      "(epoch: 79, iters: 500, time: 0.230, data: 0.001) D_A: 0.214 G_A: 0.324 cycle_A: 1.098 idt_A: 0.096 D_B: 0.149 G_B: 0.308 cycle_B: 0.253 idt_B: 0.408 \n",
      "End of epoch 79 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 100, time: 0.496, data: 0.108) D_A: 0.069 G_A: 0.682 cycle_A: 1.210 idt_A: 0.098 D_B: 0.087 G_B: 0.506 cycle_B: 0.196 idt_B: 0.349 \n",
      "(epoch: 80, iters: 200, time: 0.231, data: 0.001) D_A: 0.159 G_A: 0.786 cycle_A: 1.391 idt_A: 0.130 D_B: 0.146 G_B: 0.326 cycle_B: 0.423 idt_B: 0.443 \n",
      "(epoch: 80, iters: 300, time: 0.228, data: 0.002) D_A: 0.203 G_A: 0.597 cycle_A: 1.504 idt_A: 0.150 D_B: 0.151 G_B: 0.234 cycle_B: 0.431 idt_B: 0.540 \n",
      "(epoch: 80, iters: 400, time: 0.228, data: 0.002) D_A: 0.042 G_A: 0.736 cycle_A: 0.812 idt_A: 0.235 D_B: 0.187 G_B: 0.345 cycle_B: 0.602 idt_B: 0.382 \n",
      "(epoch: 80, iters: 500, time: 0.538, data: 0.002) D_A: 0.138 G_A: 0.740 cycle_A: 1.420 idt_A: 0.109 D_B: 0.322 G_B: 0.104 cycle_B: 0.411 idt_B: 0.572 \n",
      "saving the latest model (epoch 80, total_iters 40000)\n",
      "saving the model at the end of epoch 80, iters 40000\n",
      "End of epoch 80 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 100, time: 0.228, data: 0.097) D_A: 0.048 G_A: 0.443 cycle_A: 0.945 idt_A: 0.369 D_B: 0.150 G_B: 0.211 cycle_B: 0.866 idt_B: 0.276 \n",
      "(epoch: 81, iters: 200, time: 0.228, data: 0.002) D_A: 0.121 G_A: 0.406 cycle_A: 1.314 idt_A: 0.148 D_B: 0.146 G_B: 0.446 cycle_B: 0.409 idt_B: 0.394 \n",
      "(epoch: 81, iters: 300, time: 0.229, data: 0.001) D_A: 0.198 G_A: 1.264 cycle_A: 1.098 idt_A: 0.096 D_B: 0.075 G_B: 0.522 cycle_B: 0.362 idt_B: 0.406 \n",
      "(epoch: 81, iters: 400, time: 0.539, data: 0.002) D_A: 0.231 G_A: 0.433 cycle_A: 0.908 idt_A: 0.133 D_B: 0.159 G_B: 0.365 cycle_B: 0.409 idt_B: 0.236 \n",
      "(epoch: 81, iters: 500, time: 0.229, data: 0.001) D_A: 0.195 G_A: 0.807 cycle_A: 1.748 idt_A: 0.129 D_B: 0.303 G_B: 0.145 cycle_B: 0.388 idt_B: 0.531 \n",
      "End of epoch 81 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 100, time: 0.231, data: 0.102) D_A: 0.158 G_A: 0.719 cycle_A: 1.165 idt_A: 0.226 D_B: 0.125 G_B: 0.456 cycle_B: 0.594 idt_B: 0.438 \n",
      "(epoch: 82, iters: 200, time: 0.229, data: 0.002) D_A: 0.077 G_A: 0.543 cycle_A: 0.845 idt_A: 0.241 D_B: 0.123 G_B: 0.539 cycle_B: 0.554 idt_B: 0.216 \n",
      "(epoch: 82, iters: 300, time: 0.538, data: 0.002) D_A: 0.149 G_A: 0.303 cycle_A: 1.473 idt_A: 0.107 D_B: 0.175 G_B: 0.276 cycle_B: 0.337 idt_B: 0.296 \n",
      "(epoch: 82, iters: 400, time: 0.230, data: 0.001) D_A: 0.164 G_A: 0.212 cycle_A: 1.138 idt_A: 0.174 D_B: 0.343 G_B: 0.822 cycle_B: 0.510 idt_B: 0.695 \n",
      "(epoch: 82, iters: 500, time: 0.231, data: 0.002) D_A: 0.185 G_A: 0.355 cycle_A: 1.399 idt_A: 0.217 D_B: 0.107 G_B: 0.296 cycle_B: 0.408 idt_B: 0.373 \n",
      "End of epoch 82 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 100, time: 0.230, data: 0.105) D_A: 0.043 G_A: 0.692 cycle_A: 0.684 idt_A: 0.254 D_B: 0.275 G_B: 0.469 cycle_B: 0.743 idt_B: 0.269 \n",
      "(epoch: 83, iters: 200, time: 0.552, data: 0.001) D_A: 0.089 G_A: 0.638 cycle_A: 1.483 idt_A: 0.225 D_B: 0.112 G_B: 0.605 cycle_B: 0.668 idt_B: 0.777 \n",
      "(epoch: 83, iters: 300, time: 0.227, data: 0.001) D_A: 0.110 G_A: 0.590 cycle_A: 1.060 idt_A: 0.257 D_B: 0.226 G_B: 0.378 cycle_B: 0.794 idt_B: 0.582 \n",
      "(epoch: 83, iters: 400, time: 0.229, data: 0.001) D_A: 0.053 G_A: 0.842 cycle_A: 0.989 idt_A: 0.166 D_B: 0.213 G_B: 0.549 cycle_B: 0.460 idt_B: 0.665 \n",
      "(epoch: 83, iters: 500, time: 0.229, data: 0.001) D_A: 0.125 G_A: 1.226 cycle_A: 1.274 idt_A: 0.147 D_B: 0.123 G_B: 0.422 cycle_B: 0.397 idt_B: 0.593 \n",
      "End of epoch 83 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 100, time: 0.540, data: 0.119) D_A: 0.336 G_A: 0.379 cycle_A: 1.052 idt_A: 0.214 D_B: 0.139 G_B: 0.493 cycle_B: 0.603 idt_B: 0.373 \n",
      "(epoch: 84, iters: 200, time: 0.228, data: 0.002) D_A: 0.411 G_A: 0.988 cycle_A: 1.064 idt_A: 0.219 D_B: 0.173 G_B: 0.504 cycle_B: 0.393 idt_B: 0.376 \n",
      "(epoch: 84, iters: 300, time: 0.228, data: 0.002) D_A: 0.086 G_A: 0.237 cycle_A: 1.151 idt_A: 0.153 D_B: 0.236 G_B: 0.431 cycle_B: 0.377 idt_B: 0.603 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 84, iters: 400, time: 0.228, data: 0.002) D_A: 0.163 G_A: 1.185 cycle_A: 1.210 idt_A: 0.215 D_B: 0.150 G_B: 0.353 cycle_B: 0.482 idt_B: 0.452 \n",
      "(epoch: 84, iters: 500, time: 0.538, data: 0.002) D_A: 0.326 G_A: 0.128 cycle_A: 1.516 idt_A: 0.176 D_B: 0.166 G_B: 0.528 cycle_B: 0.600 idt_B: 0.524 \n",
      "End of epoch 84 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 100, time: 0.227, data: 0.105) D_A: 0.137 G_A: 0.843 cycle_A: 0.892 idt_A: 0.164 D_B: 0.233 G_B: 0.191 cycle_B: 0.429 idt_B: 0.376 \n",
      "(epoch: 85, iters: 200, time: 0.228, data: 0.001) D_A: 0.100 G_A: 0.617 cycle_A: 0.761 idt_A: 0.139 D_B: 0.195 G_B: 0.931 cycle_B: 0.384 idt_B: 0.295 \n",
      "(epoch: 85, iters: 300, time: 0.229, data: 0.001) D_A: 0.217 G_A: 0.791 cycle_A: 1.619 idt_A: 0.175 D_B: 0.188 G_B: 0.386 cycle_B: 0.620 idt_B: 0.543 \n",
      "(epoch: 85, iters: 400, time: 0.513, data: 0.001) D_A: 0.096 G_A: 0.485 cycle_A: 1.287 idt_A: 0.085 D_B: 0.050 G_B: 0.661 cycle_B: 0.306 idt_B: 0.379 \n",
      "(epoch: 85, iters: 500, time: 0.229, data: 0.001) D_A: 0.143 G_A: 0.384 cycle_A: 1.136 idt_A: 0.172 D_B: 0.124 G_B: 0.525 cycle_B: 0.508 idt_B: 0.398 \n",
      "saving the model at the end of epoch 85, iters 42500\n",
      "End of epoch 85 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 100, time: 0.229, data: 0.096) D_A: 0.111 G_A: 0.767 cycle_A: 1.335 idt_A: 0.370 D_B: 0.253 G_B: 0.264 cycle_B: 0.799 idt_B: 0.355 \n",
      "(epoch: 86, iters: 200, time: 0.228, data: 0.001) D_A: 0.085 G_A: 0.708 cycle_A: 1.692 idt_A: 0.176 D_B: 0.142 G_B: 0.390 cycle_B: 0.477 idt_B: 0.636 \n",
      "(epoch: 86, iters: 300, time: 0.554, data: 0.002) D_A: 0.077 G_A: 0.525 cycle_A: 1.337 idt_A: 0.172 D_B: 0.211 G_B: 0.354 cycle_B: 0.514 idt_B: 0.320 \n",
      "(epoch: 86, iters: 400, time: 0.230, data: 0.001) D_A: 0.177 G_A: 0.383 cycle_A: 1.214 idt_A: 0.055 D_B: 0.200 G_B: 0.337 cycle_B: 0.231 idt_B: 0.548 \n",
      "(epoch: 86, iters: 500, time: 0.229, data: 0.002) D_A: 0.075 G_A: 0.500 cycle_A: 1.014 idt_A: 0.191 D_B: 0.195 G_B: 0.089 cycle_B: 0.498 idt_B: 0.340 \n",
      "End of epoch 86 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 100, time: 0.231, data: 0.103) D_A: 0.105 G_A: 0.472 cycle_A: 1.400 idt_A: 0.225 D_B: 0.161 G_B: 0.893 cycle_B: 0.643 idt_B: 0.417 \n",
      "(epoch: 87, iters: 200, time: 0.551, data: 0.002) D_A: 0.273 G_A: 0.804 cycle_A: 1.315 idt_A: 0.196 D_B: 0.248 G_B: 1.005 cycle_B: 0.555 idt_B: 0.460 \n",
      "(epoch: 87, iters: 300, time: 0.230, data: 0.001) D_A: 0.093 G_A: 0.427 cycle_A: 1.946 idt_A: 0.139 D_B: 0.277 G_B: 0.277 cycle_B: 0.356 idt_B: 0.723 \n",
      "(epoch: 87, iters: 400, time: 0.227, data: 0.001) D_A: 0.037 G_A: 0.759 cycle_A: 1.269 idt_A: 0.096 D_B: 0.180 G_B: 0.390 cycle_B: 0.255 idt_B: 0.451 \n",
      "(epoch: 87, iters: 500, time: 0.229, data: 0.002) D_A: 0.103 G_A: 0.664 cycle_A: 0.997 idt_A: 0.154 D_B: 0.178 G_B: 0.379 cycle_B: 0.463 idt_B: 0.269 \n",
      "End of epoch 87 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 100, time: 0.539, data: 0.126) D_A: 0.186 G_A: 1.220 cycle_A: 0.732 idt_A: 0.179 D_B: 0.046 G_B: 0.539 cycle_B: 0.488 idt_B: 0.346 \n",
      "(epoch: 88, iters: 200, time: 0.229, data: 0.002) D_A: 0.151 G_A: 0.787 cycle_A: 1.374 idt_A: 0.145 D_B: 0.109 G_B: 0.792 cycle_B: 0.441 idt_B: 0.587 \n",
      "(epoch: 88, iters: 300, time: 0.229, data: 0.002) D_A: 0.190 G_A: 0.224 cycle_A: 1.767 idt_A: 0.236 D_B: 0.186 G_B: 0.241 cycle_B: 0.667 idt_B: 0.590 \n",
      "(epoch: 88, iters: 400, time: 0.230, data: 0.001) D_A: 0.082 G_A: 0.495 cycle_A: 1.174 idt_A: 0.232 D_B: 0.136 G_B: 0.434 cycle_B: 0.695 idt_B: 0.306 \n",
      "(epoch: 88, iters: 500, time: 0.534, data: 0.002) D_A: 0.350 G_A: 0.990 cycle_A: 1.100 idt_A: 0.284 D_B: 0.142 G_B: 0.242 cycle_B: 0.627 idt_B: 0.396 \n",
      "End of epoch 88 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 100, time: 0.230, data: 0.098) D_A: 0.136 G_A: 0.349 cycle_A: 1.750 idt_A: 0.217 D_B: 0.136 G_B: 0.515 cycle_B: 0.566 idt_B: 0.614 \n",
      "(epoch: 89, iters: 200, time: 0.228, data: 0.001) D_A: 0.136 G_A: 0.466 cycle_A: 0.868 idt_A: 0.146 D_B: 0.238 G_B: 0.451 cycle_B: 0.474 idt_B: 0.473 \n",
      "(epoch: 89, iters: 300, time: 0.228, data: 0.001) D_A: 0.084 G_A: 0.557 cycle_A: 1.216 idt_A: 0.170 D_B: 0.183 G_B: 0.271 cycle_B: 0.498 idt_B: 0.352 \n",
      "(epoch: 89, iters: 400, time: 0.543, data: 0.002) D_A: 0.071 G_A: 0.677 cycle_A: 1.174 idt_A: 0.205 D_B: 0.165 G_B: 0.396 cycle_B: 0.549 idt_B: 0.365 \n",
      "(epoch: 89, iters: 500, time: 0.228, data: 0.001) D_A: 0.052 G_A: 0.486 cycle_A: 0.897 idt_A: 0.181 D_B: 0.104 G_B: 0.741 cycle_B: 0.513 idt_B: 0.355 \n",
      "End of epoch 89 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 100, time: 0.230, data: 0.100) D_A: 0.114 G_A: 0.245 cycle_A: 1.134 idt_A: 0.167 D_B: 0.221 G_B: 1.200 cycle_B: 0.442 idt_B: 0.407 \n",
      "(epoch: 90, iters: 200, time: 0.230, data: 0.002) D_A: 0.209 G_A: 0.329 cycle_A: 2.409 idt_A: 0.239 D_B: 0.079 G_B: 0.384 cycle_B: 0.756 idt_B: 0.894 \n",
      "(epoch: 90, iters: 300, time: 0.509, data: 0.002) D_A: 0.070 G_A: 0.322 cycle_A: 1.074 idt_A: 0.149 D_B: 0.135 G_B: 0.371 cycle_B: 0.385 idt_B: 0.296 \n",
      "(epoch: 90, iters: 400, time: 0.231, data: 0.001) D_A: 0.039 G_A: 0.590 cycle_A: 1.270 idt_A: 0.119 D_B: 0.297 G_B: 0.789 cycle_B: 0.363 idt_B: 0.340 \n",
      "(epoch: 90, iters: 500, time: 0.229, data: 0.001) D_A: 0.240 G_A: 0.585 cycle_A: 1.212 idt_A: 0.145 D_B: 0.172 G_B: 0.210 cycle_B: 0.545 idt_B: 0.431 \n",
      "saving the latest model (epoch 90, total_iters 45000)\n",
      "saving the model at the end of epoch 90, iters 45000\n",
      "End of epoch 90 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 100, time: 0.230, data: 0.117) D_A: 0.226 G_A: 0.813 cycle_A: 1.077 idt_A: 0.167 D_B: 0.155 G_B: 0.320 cycle_B: 0.462 idt_B: 0.441 \n",
      "(epoch: 91, iters: 200, time: 0.524, data: 0.002) D_A: 0.190 G_A: 0.514 cycle_A: 1.087 idt_A: 0.131 D_B: 0.263 G_B: 0.620 cycle_B: 0.358 idt_B: 0.299 \n",
      "(epoch: 91, iters: 300, time: 0.231, data: 0.001) D_A: 0.044 G_A: 0.818 cycle_A: 1.234 idt_A: 0.065 D_B: 0.204 G_B: 0.289 cycle_B: 0.210 idt_B: 0.458 \n",
      "(epoch: 91, iters: 400, time: 0.229, data: 0.002) D_A: 0.065 G_A: 0.593 cycle_A: 2.073 idt_A: 0.178 D_B: 0.270 G_B: 0.186 cycle_B: 0.494 idt_B: 1.376 \n",
      "(epoch: 91, iters: 500, time: 0.231, data: 0.002) D_A: 0.231 G_A: 0.868 cycle_A: 1.000 idt_A: 0.300 D_B: 0.110 G_B: 0.329 cycle_B: 0.830 idt_B: 0.251 \n",
      "End of epoch 91 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 100, time: 0.565, data: 0.123) D_A: 0.175 G_A: 0.328 cycle_A: 0.926 idt_A: 0.258 D_B: 0.092 G_B: 0.611 cycle_B: 0.694 idt_B: 0.304 \n",
      "(epoch: 92, iters: 200, time: 0.231, data: 0.001) D_A: 0.117 G_A: 0.692 cycle_A: 1.049 idt_A: 0.140 D_B: 0.105 G_B: 0.257 cycle_B: 0.411 idt_B: 0.327 \n",
      "(epoch: 92, iters: 300, time: 0.230, data: 0.001) D_A: 0.189 G_A: 0.343 cycle_A: 1.307 idt_A: 0.296 D_B: 0.106 G_B: 0.325 cycle_B: 0.745 idt_B: 0.449 \n",
      "(epoch: 92, iters: 400, time: 0.229, data: 0.001) D_A: 0.178 G_A: 0.368 cycle_A: 0.856 idt_A: 0.184 D_B: 0.173 G_B: 0.579 cycle_B: 0.559 idt_B: 0.314 \n",
      "(epoch: 92, iters: 500, time: 0.552, data: 0.001) D_A: 0.093 G_A: 0.618 cycle_A: 1.057 idt_A: 0.122 D_B: 0.083 G_B: 0.278 cycle_B: 0.468 idt_B: 0.351 \n",
      "End of epoch 92 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 100, time: 0.231, data: 0.094) D_A: 0.085 G_A: 0.450 cycle_A: 1.398 idt_A: 0.289 D_B: 0.187 G_B: 0.112 cycle_B: 0.831 idt_B: 0.592 \n",
      "(epoch: 93, iters: 200, time: 0.229, data: 0.002) D_A: 0.244 G_A: 0.824 cycle_A: 1.995 idt_A: 0.133 D_B: 0.189 G_B: 0.543 cycle_B: 0.437 idt_B: 0.650 \n",
      "(epoch: 93, iters: 300, time: 0.229, data: 0.002) D_A: 0.131 G_A: 0.687 cycle_A: 0.968 idt_A: 0.121 D_B: 0.152 G_B: 0.713 cycle_B: 0.344 idt_B: 0.211 \n",
      "(epoch: 93, iters: 400, time: 0.529, data: 0.002) D_A: 0.177 G_A: 0.734 cycle_A: 0.960 idt_A: 0.047 D_B: 0.099 G_B: 0.475 cycle_B: 0.164 idt_B: 0.263 \n",
      "(epoch: 93, iters: 500, time: 0.229, data: 0.001) D_A: 0.092 G_A: 0.579 cycle_A: 1.071 idt_A: 0.166 D_B: 0.142 G_B: 0.517 cycle_B: 0.517 idt_B: 0.392 \n",
      "End of epoch 93 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 100, time: 0.245, data: 0.096) D_A: 0.075 G_A: 0.409 cycle_A: 1.332 idt_A: 0.351 D_B: 0.201 G_B: 0.405 cycle_B: 1.006 idt_B: 0.323 \n",
      "(epoch: 94, iters: 200, time: 0.228, data: 0.001) D_A: 0.214 G_A: 0.532 cycle_A: 1.220 idt_A: 0.083 D_B: 0.114 G_B: 0.760 cycle_B: 0.206 idt_B: 0.348 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 94, iters: 300, time: 0.550, data: 0.001) D_A: 0.069 G_A: 0.690 cycle_A: 1.705 idt_A: 0.177 D_B: 0.120 G_B: 0.266 cycle_B: 0.631 idt_B: 0.633 \n",
      "(epoch: 94, iters: 400, time: 0.229, data: 0.001) D_A: 0.185 G_A: 0.285 cycle_A: 0.824 idt_A: 0.144 D_B: 0.188 G_B: 0.385 cycle_B: 0.480 idt_B: 0.476 \n",
      "(epoch: 94, iters: 500, time: 0.229, data: 0.002) D_A: 0.042 G_A: 0.661 cycle_A: 1.384 idt_A: 0.159 D_B: 0.067 G_B: 0.816 cycle_B: 0.458 idt_B: 0.343 \n",
      "End of epoch 94 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 100, time: 0.230, data: 0.118) D_A: 0.261 G_A: 1.100 cycle_A: 1.536 idt_A: 0.220 D_B: 0.234 G_B: 0.840 cycle_B: 0.575 idt_B: 0.492 \n",
      "(epoch: 95, iters: 200, time: 0.544, data: 0.002) D_A: 0.101 G_A: 0.416 cycle_A: 0.944 idt_A: 0.253 D_B: 0.217 G_B: 0.310 cycle_B: 0.589 idt_B: 0.232 \n",
      "(epoch: 95, iters: 300, time: 0.230, data: 0.001) D_A: 0.202 G_A: 0.322 cycle_A: 1.289 idt_A: 0.093 D_B: 0.194 G_B: 0.388 cycle_B: 0.235 idt_B: 0.514 \n",
      "(epoch: 95, iters: 400, time: 0.230, data: 0.001) D_A: 0.096 G_A: 0.550 cycle_A: 0.639 idt_A: 0.108 D_B: 0.140 G_B: 0.219 cycle_B: 0.304 idt_B: 0.233 \n",
      "(epoch: 95, iters: 500, time: 0.229, data: 0.001) D_A: 0.212 G_A: 0.244 cycle_A: 1.238 idt_A: 0.195 D_B: 0.124 G_B: 0.330 cycle_B: 0.506 idt_B: 0.290 \n",
      "saving the model at the end of epoch 95, iters 47500\n",
      "End of epoch 95 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 100, time: 0.569, data: 0.096) D_A: 0.087 G_A: 0.197 cycle_A: 0.789 idt_A: 0.170 D_B: 0.146 G_B: 0.199 cycle_B: 0.475 idt_B: 0.282 \n",
      "(epoch: 96, iters: 200, time: 0.229, data: 0.001) D_A: 0.127 G_A: 0.525 cycle_A: 1.191 idt_A: 0.191 D_B: 0.129 G_B: 0.447 cycle_B: 0.507 idt_B: 0.525 \n",
      "(epoch: 96, iters: 300, time: 0.228, data: 0.002) D_A: 0.126 G_A: 0.590 cycle_A: 1.123 idt_A: 0.145 D_B: 0.216 G_B: 0.367 cycle_B: 0.446 idt_B: 0.463 \n",
      "(epoch: 96, iters: 400, time: 0.230, data: 0.002) D_A: 0.079 G_A: 0.742 cycle_A: 0.804 idt_A: 0.206 D_B: 0.105 G_B: 0.400 cycle_B: 0.561 idt_B: 0.308 \n",
      "(epoch: 96, iters: 500, time: 0.556, data: 0.002) D_A: 0.073 G_A: 0.649 cycle_A: 0.886 idt_A: 0.160 D_B: 0.107 G_B: 0.428 cycle_B: 0.480 idt_B: 0.297 \n",
      "End of epoch 96 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 100, time: 0.229, data: 0.111) D_A: 0.307 G_A: 0.095 cycle_A: 0.928 idt_A: 0.173 D_B: 0.204 G_B: 1.146 cycle_B: 0.512 idt_B: 0.327 \n",
      "(epoch: 97, iters: 200, time: 0.229, data: 0.001) D_A: 0.195 G_A: 0.181 cycle_A: 0.979 idt_A: 0.170 D_B: 0.215 G_B: 0.427 cycle_B: 0.449 idt_B: 0.313 \n",
      "(epoch: 97, iters: 300, time: 0.229, data: 0.002) D_A: 0.222 G_A: 0.948 cycle_A: 1.047 idt_A: 0.125 D_B: 0.157 G_B: 0.150 cycle_B: 0.440 idt_B: 0.415 \n",
      "(epoch: 97, iters: 400, time: 0.557, data: 0.002) D_A: 0.119 G_A: 0.432 cycle_A: 1.406 idt_A: 0.218 D_B: 0.210 G_B: 0.476 cycle_B: 0.596 idt_B: 0.593 \n",
      "(epoch: 97, iters: 500, time: 0.231, data: 0.002) D_A: 0.226 G_A: 0.888 cycle_A: 1.577 idt_A: 0.142 D_B: 0.155 G_B: 0.384 cycle_B: 0.401 idt_B: 0.625 \n",
      "End of epoch 97 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 100, time: 0.228, data: 0.096) D_A: 0.085 G_A: 0.738 cycle_A: 2.406 idt_A: 0.140 D_B: 0.209 G_B: 0.097 cycle_B: 0.381 idt_B: 0.645 \n",
      "(epoch: 98, iters: 200, time: 0.232, data: 0.002) D_A: 0.141 G_A: 0.321 cycle_A: 1.125 idt_A: 0.446 D_B: 0.246 G_B: 0.689 cycle_B: 1.032 idt_B: 0.379 \n",
      "(epoch: 98, iters: 300, time: 0.567, data: 0.001) D_A: 0.174 G_A: 0.236 cycle_A: 1.763 idt_A: 0.199 D_B: 0.216 G_B: 0.313 cycle_B: 0.499 idt_B: 0.347 \n",
      "(epoch: 98, iters: 400, time: 0.229, data: 0.001) D_A: 0.139 G_A: 0.746 cycle_A: 2.188 idt_A: 0.153 D_B: 0.124 G_B: 0.548 cycle_B: 0.402 idt_B: 1.149 \n",
      "(epoch: 98, iters: 500, time: 0.229, data: 0.002) D_A: 0.099 G_A: 0.338 cycle_A: 0.924 idt_A: 0.124 D_B: 0.387 G_B: 0.358 cycle_B: 0.427 idt_B: 0.367 \n",
      "End of epoch 98 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 100, time: 0.229, data: 0.103) D_A: 0.139 G_A: 0.525 cycle_A: 0.799 idt_A: 0.217 D_B: 0.280 G_B: 0.527 cycle_B: 0.525 idt_B: 0.254 \n",
      "(epoch: 99, iters: 200, time: 0.560, data: 0.002) D_A: 0.033 G_A: 1.071 cycle_A: 1.087 idt_A: 0.165 D_B: 0.115 G_B: 0.579 cycle_B: 0.520 idt_B: 0.272 \n",
      "(epoch: 99, iters: 300, time: 0.228, data: 0.001) D_A: 0.098 G_A: 0.734 cycle_A: 0.723 idt_A: 0.307 D_B: 0.183 G_B: 0.378 cycle_B: 0.816 idt_B: 0.226 \n",
      "(epoch: 99, iters: 400, time: 0.228, data: 0.001) D_A: 0.061 G_A: 0.495 cycle_A: 1.240 idt_A: 0.136 D_B: 0.098 G_B: 0.488 cycle_B: 0.467 idt_B: 0.419 \n",
      "(epoch: 99, iters: 500, time: 0.230, data: 0.001) D_A: 0.130 G_A: 0.362 cycle_A: 1.302 idt_A: 0.220 D_B: 0.143 G_B: 0.424 cycle_B: 0.570 idt_B: 0.752 \n",
      "End of epoch 99 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 100, time: 0.580, data: 0.104) D_A: 0.050 G_A: 0.902 cycle_A: 2.093 idt_A: 0.208 D_B: 0.159 G_B: 0.332 cycle_B: 0.603 idt_B: 1.009 \n",
      "(epoch: 100, iters: 200, time: 0.228, data: 0.001) D_A: 0.152 G_A: 0.523 cycle_A: 2.084 idt_A: 0.171 D_B: 0.279 G_B: 0.706 cycle_B: 0.506 idt_B: 0.994 \n",
      "(epoch: 100, iters: 300, time: 0.242, data: 0.001) D_A: 0.104 G_A: 1.393 cycle_A: 0.950 idt_A: 0.280 D_B: 0.151 G_B: 0.304 cycle_B: 0.709 idt_B: 0.356 \n",
      "(epoch: 100, iters: 400, time: 0.230, data: 0.002) D_A: 0.143 G_A: 0.983 cycle_A: 1.081 idt_A: 0.128 D_B: 0.117 G_B: 0.441 cycle_B: 0.322 idt_B: 0.431 \n",
      "(epoch: 100, iters: 500, time: 0.585, data: 0.002) D_A: 0.167 G_A: 1.029 cycle_A: 2.169 idt_A: 0.230 D_B: 0.125 G_B: 0.470 cycle_B: 0.626 idt_B: 0.732 \n",
      "saving the latest model (epoch 100, total_iters 50000)\n",
      "saving the model at the end of epoch 100, iters 50000\n",
      "End of epoch 100 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.228, data: 0.112) D_A: 0.027 G_A: 0.807 cycle_A: 0.737 idt_A: 0.172 D_B: 0.124 G_B: 0.441 cycle_B: 0.528 idt_B: 0.260 \n",
      "(epoch: 101, iters: 200, time: 0.228, data: 0.001) D_A: 0.091 G_A: 0.448 cycle_A: 1.320 idt_A: 0.091 D_B: 0.248 G_B: 0.241 cycle_B: 0.282 idt_B: 0.301 \n",
      "(epoch: 101, iters: 300, time: 0.229, data: 0.001) D_A: 0.143 G_A: 0.876 cycle_A: 0.759 idt_A: 0.138 D_B: 0.107 G_B: 0.572 cycle_B: 0.437 idt_B: 0.260 \n",
      "(epoch: 101, iters: 400, time: 0.585, data: 0.002) D_A: 0.176 G_A: 0.691 cycle_A: 1.083 idt_A: 0.159 D_B: 0.150 G_B: 0.293 cycle_B: 0.365 idt_B: 0.325 \n",
      "(epoch: 101, iters: 500, time: 0.228, data: 0.002) D_A: 0.131 G_A: 0.610 cycle_A: 1.682 idt_A: 0.182 D_B: 0.179 G_B: 0.268 cycle_B: 0.492 idt_B: 0.492 \n",
      "End of epoch 101 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 100, time: 0.232, data: 0.096) D_A: 0.240 G_A: 1.028 cycle_A: 1.319 idt_A: 0.131 D_B: 0.172 G_B: 0.455 cycle_B: 0.403 idt_B: 0.419 \n",
      "(epoch: 102, iters: 200, time: 0.228, data: 0.002) D_A: 0.107 G_A: 0.324 cycle_A: 1.569 idt_A: 0.193 D_B: 0.072 G_B: 0.407 cycle_B: 0.534 idt_B: 0.670 \n",
      "(epoch: 102, iters: 300, time: 0.583, data: 0.001) D_A: 0.135 G_A: 0.795 cycle_A: 1.189 idt_A: 0.361 D_B: 0.086 G_B: 0.329 cycle_B: 0.849 idt_B: 0.372 \n",
      "(epoch: 102, iters: 400, time: 0.229, data: 0.001) D_A: 0.071 G_A: 0.725 cycle_A: 1.508 idt_A: 0.256 D_B: 0.151 G_B: 0.442 cycle_B: 0.604 idt_B: 0.389 \n",
      "(epoch: 102, iters: 500, time: 0.231, data: 0.001) D_A: 0.107 G_A: 0.370 cycle_A: 1.426 idt_A: 0.152 D_B: 0.128 G_B: 0.268 cycle_B: 0.650 idt_B: 0.449 \n",
      "End of epoch 102 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 100, time: 0.231, data: 0.116) D_A: 0.084 G_A: 0.336 cycle_A: 1.151 idt_A: 0.243 D_B: 0.183 G_B: 0.408 cycle_B: 0.641 idt_B: 0.477 \n",
      "(epoch: 103, iters: 200, time: 0.570, data: 0.002) D_A: 0.151 G_A: 0.269 cycle_A: 1.040 idt_A: 0.245 D_B: 0.231 G_B: 0.276 cycle_B: 0.766 idt_B: 0.189 \n",
      "(epoch: 103, iters: 300, time: 0.229, data: 0.001) D_A: 0.104 G_A: 0.823 cycle_A: 0.673 idt_A: 0.197 D_B: 0.194 G_B: 0.496 cycle_B: 0.534 idt_B: 0.260 \n",
      "(epoch: 103, iters: 400, time: 0.231, data: 0.001) D_A: 0.099 G_A: 0.403 cycle_A: 0.964 idt_A: 0.207 D_B: 0.386 G_B: 0.690 cycle_B: 0.577 idt_B: 0.469 \n",
      "(epoch: 103, iters: 500, time: 0.230, data: 0.002) D_A: 0.069 G_A: 0.736 cycle_A: 0.705 idt_A: 0.192 D_B: 0.057 G_B: 0.513 cycle_B: 0.568 idt_B: 0.150 \n",
      "End of epoch 103 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 100, time: 0.569, data: 0.121) D_A: 0.111 G_A: 0.384 cycle_A: 0.899 idt_A: 0.116 D_B: 0.170 G_B: 0.265 cycle_B: 0.342 idt_B: 0.310 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 104, iters: 200, time: 0.228, data: 0.001) D_A: 0.218 G_A: 0.376 cycle_A: 0.898 idt_A: 0.123 D_B: 0.153 G_B: 0.469 cycle_B: 0.354 idt_B: 0.278 \n",
      "(epoch: 104, iters: 300, time: 0.227, data: 0.001) D_A: 0.153 G_A: 0.178 cycle_A: 1.527 idt_A: 0.174 D_B: 0.141 G_B: 0.302 cycle_B: 0.527 idt_B: 0.350 \n",
      "(epoch: 104, iters: 400, time: 0.228, data: 0.002) D_A: 0.082 G_A: 0.545 cycle_A: 1.040 idt_A: 0.173 D_B: 0.120 G_B: 0.523 cycle_B: 0.380 idt_B: 0.241 \n",
      "(epoch: 104, iters: 500, time: 0.581, data: 0.002) D_A: 0.124 G_A: 1.107 cycle_A: 0.724 idt_A: 0.117 D_B: 0.251 G_B: 0.361 cycle_B: 0.354 idt_B: 0.293 \n",
      "End of epoch 104 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 100, time: 0.229, data: 0.103) D_A: 0.090 G_A: 0.464 cycle_A: 1.474 idt_A: 0.286 D_B: 0.122 G_B: 0.280 cycle_B: 0.693 idt_B: 0.334 \n",
      "(epoch: 105, iters: 200, time: 0.229, data: 0.001) D_A: 0.094 G_A: 0.400 cycle_A: 0.996 idt_A: 0.146 D_B: 0.166 G_B: 0.179 cycle_B: 0.393 idt_B: 0.390 \n",
      "(epoch: 105, iters: 300, time: 0.228, data: 0.002) D_A: 0.188 G_A: 0.252 cycle_A: 1.043 idt_A: 0.127 D_B: 0.155 G_B: 0.990 cycle_B: 0.333 idt_B: 0.335 \n",
      "(epoch: 105, iters: 400, time: 0.556, data: 0.001) D_A: 0.151 G_A: 0.407 cycle_A: 0.891 idt_A: 0.163 D_B: 0.244 G_B: 0.531 cycle_B: 0.395 idt_B: 0.234 \n",
      "(epoch: 105, iters: 500, time: 0.229, data: 0.001) D_A: 0.116 G_A: 0.460 cycle_A: 0.666 idt_A: 0.190 D_B: 0.120 G_B: 0.908 cycle_B: 0.475 idt_B: 0.223 \n",
      "saving the model at the end of epoch 105, iters 52500\n",
      "End of epoch 105 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 100, time: 0.228, data: 0.097) D_A: 0.127 G_A: 0.526 cycle_A: 1.111 idt_A: 0.135 D_B: 0.073 G_B: 0.569 cycle_B: 0.417 idt_B: 0.380 \n",
      "(epoch: 106, iters: 200, time: 0.229, data: 0.002) D_A: 0.198 G_A: 0.286 cycle_A: 1.176 idt_A: 0.134 D_B: 0.092 G_B: 0.229 cycle_B: 0.342 idt_B: 0.485 \n",
      "(epoch: 106, iters: 300, time: 0.576, data: 0.001) D_A: 0.188 G_A: 0.224 cycle_A: 0.746 idt_A: 0.225 D_B: 0.177 G_B: 0.359 cycle_B: 0.607 idt_B: 0.221 \n",
      "(epoch: 106, iters: 400, time: 0.228, data: 0.001) D_A: 0.073 G_A: 0.745 cycle_A: 1.311 idt_A: 0.204 D_B: 0.065 G_B: 0.669 cycle_B: 0.567 idt_B: 0.699 \n",
      "(epoch: 106, iters: 500, time: 0.228, data: 0.002) D_A: 0.058 G_A: 0.651 cycle_A: 1.013 idt_A: 0.345 D_B: 0.142 G_B: 0.372 cycle_B: 0.831 idt_B: 0.299 \n",
      "End of epoch 106 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 100, time: 0.229, data: 0.097) D_A: 0.088 G_A: 0.535 cycle_A: 0.981 idt_A: 0.179 D_B: 0.160 G_B: 0.302 cycle_B: 0.470 idt_B: 0.275 \n",
      "(epoch: 107, iters: 200, time: 0.576, data: 0.002) D_A: 0.332 G_A: 0.639 cycle_A: 1.298 idt_A: 0.065 D_B: 0.183 G_B: 0.451 cycle_B: 0.191 idt_B: 0.316 \n",
      "(epoch: 107, iters: 300, time: 0.229, data: 0.002) D_A: 0.137 G_A: 0.888 cycle_A: 0.850 idt_A: 0.175 D_B: 0.105 G_B: 0.598 cycle_B: 0.530 idt_B: 0.242 \n",
      "(epoch: 107, iters: 400, time: 0.228, data: 0.002) D_A: 0.185 G_A: 0.856 cycle_A: 0.919 idt_A: 0.146 D_B: 0.157 G_B: 0.407 cycle_B: 0.458 idt_B: 0.332 \n",
      "(epoch: 107, iters: 500, time: 0.228, data: 0.002) D_A: 0.128 G_A: 0.641 cycle_A: 1.485 idt_A: 0.098 D_B: 0.238 G_B: 0.397 cycle_B: 0.344 idt_B: 0.631 \n",
      "End of epoch 107 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 100, time: 0.596, data: 0.116) D_A: 0.090 G_A: 0.327 cycle_A: 1.038 idt_A: 0.172 D_B: 0.187 G_B: 0.539 cycle_B: 0.540 idt_B: 0.315 \n",
      "(epoch: 108, iters: 200, time: 0.229, data: 0.001) D_A: 0.150 G_A: 1.072 cycle_A: 0.797 idt_A: 0.195 D_B: 0.120 G_B: 0.461 cycle_B: 0.529 idt_B: 0.248 \n",
      "(epoch: 108, iters: 300, time: 0.228, data: 0.001) D_A: 0.174 G_A: 0.475 cycle_A: 0.904 idt_A: 0.140 D_B: 0.175 G_B: 0.757 cycle_B: 0.471 idt_B: 0.322 \n",
      "(epoch: 108, iters: 400, time: 0.231, data: 0.001) D_A: 0.181 G_A: 0.440 cycle_A: 1.880 idt_A: 0.134 D_B: 0.135 G_B: 0.215 cycle_B: 0.312 idt_B: 0.848 \n",
      "(epoch: 108, iters: 500, time: 0.583, data: 0.002) D_A: 0.136 G_A: 0.329 cycle_A: 1.259 idt_A: 0.164 D_B: 0.070 G_B: 0.738 cycle_B: 0.466 idt_B: 0.473 \n",
      "End of epoch 108 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 100, time: 0.229, data: 0.127) D_A: 0.082 G_A: 0.705 cycle_A: 0.914 idt_A: 0.139 D_B: 0.076 G_B: 0.555 cycle_B: 0.382 idt_B: 0.386 \n",
      "(epoch: 109, iters: 200, time: 0.232, data: 0.001) D_A: 0.085 G_A: 0.689 cycle_A: 1.187 idt_A: 0.163 D_B: 0.177 G_B: 0.449 cycle_B: 0.354 idt_B: 0.680 \n",
      "(epoch: 109, iters: 300, time: 0.230, data: 0.002) D_A: 0.221 G_A: 0.542 cycle_A: 1.332 idt_A: 0.077 D_B: 0.179 G_B: 0.521 cycle_B: 0.213 idt_B: 0.307 \n",
      "(epoch: 109, iters: 400, time: 0.594, data: 0.001) D_A: 0.134 G_A: 0.793 cycle_A: 0.826 idt_A: 0.115 D_B: 0.182 G_B: 0.303 cycle_B: 0.370 idt_B: 0.194 \n",
      "(epoch: 109, iters: 500, time: 0.228, data: 0.002) D_A: 0.167 G_A: 0.453 cycle_A: 0.860 idt_A: 0.167 D_B: 0.203 G_B: 0.708 cycle_B: 0.428 idt_B: 0.276 \n",
      "End of epoch 109 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 100, time: 0.228, data: 0.112) D_A: 0.141 G_A: 0.358 cycle_A: 1.445 idt_A: 0.223 D_B: 0.082 G_B: 0.492 cycle_B: 0.557 idt_B: 0.655 \n",
      "(epoch: 110, iters: 200, time: 0.228, data: 0.002) D_A: 0.112 G_A: 0.700 cycle_A: 0.961 idt_A: 0.149 D_B: 0.173 G_B: 0.441 cycle_B: 0.293 idt_B: 0.302 \n",
      "(epoch: 110, iters: 300, time: 0.585, data: 0.001) D_A: 0.047 G_A: 0.412 cycle_A: 0.794 idt_A: 0.207 D_B: 0.237 G_B: 0.455 cycle_B: 0.445 idt_B: 0.614 \n",
      "(epoch: 110, iters: 400, time: 0.229, data: 0.001) D_A: 0.109 G_A: 0.372 cycle_A: 1.565 idt_A: 0.183 D_B: 0.165 G_B: 0.354 cycle_B: 0.477 idt_B: 0.344 \n",
      "(epoch: 110, iters: 500, time: 0.239, data: 0.001) D_A: 0.127 G_A: 1.282 cycle_A: 0.774 idt_A: 0.133 D_B: 0.110 G_B: 0.350 cycle_B: 0.393 idt_B: 0.186 \n",
      "saving the latest model (epoch 110, total_iters 55000)\n",
      "saving the model at the end of epoch 110, iters 55000\n",
      "End of epoch 110 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 100, time: 0.229, data: 0.095) D_A: 0.090 G_A: 0.239 cycle_A: 1.357 idt_A: 0.101 D_B: 0.231 G_B: 0.196 cycle_B: 0.291 idt_B: 0.670 \n",
      "(epoch: 111, iters: 200, time: 0.573, data: 0.001) D_A: 0.110 G_A: 0.494 cycle_A: 1.179 idt_A: 0.353 D_B: 0.195 G_B: 0.321 cycle_B: 0.798 idt_B: 0.293 \n",
      "(epoch: 111, iters: 300, time: 0.228, data: 0.001) D_A: 0.180 G_A: 0.251 cycle_A: 1.231 idt_A: 0.174 D_B: 0.232 G_B: 0.208 cycle_B: 0.490 idt_B: 0.473 \n",
      "(epoch: 111, iters: 400, time: 0.227, data: 0.001) D_A: 0.050 G_A: 0.456 cycle_A: 0.869 idt_A: 0.348 D_B: 0.155 G_B: 0.188 cycle_B: 0.759 idt_B: 0.328 \n",
      "(epoch: 111, iters: 500, time: 0.230, data: 0.001) D_A: 0.100 G_A: 0.641 cycle_A: 0.750 idt_A: 0.253 D_B: 0.081 G_B: 0.524 cycle_B: 0.525 idt_B: 0.321 \n",
      "End of epoch 111 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 100, time: 0.563, data: 0.095) D_A: 0.181 G_A: 0.707 cycle_A: 0.936 idt_A: 0.271 D_B: 0.151 G_B: 0.412 cycle_B: 0.690 idt_B: 0.372 \n",
      "(epoch: 112, iters: 200, time: 0.230, data: 0.001) D_A: 0.126 G_A: 0.456 cycle_A: 1.091 idt_A: 0.123 D_B: 0.152 G_B: 0.283 cycle_B: 0.406 idt_B: 0.450 \n",
      "(epoch: 112, iters: 300, time: 0.228, data: 0.002) D_A: 0.120 G_A: 0.381 cycle_A: 1.052 idt_A: 0.330 D_B: 0.220 G_B: 0.429 cycle_B: 0.788 idt_B: 0.266 \n",
      "(epoch: 112, iters: 400, time: 0.228, data: 0.002) D_A: 0.126 G_A: 0.363 cycle_A: 1.294 idt_A: 0.150 D_B: 0.162 G_B: 0.285 cycle_B: 0.433 idt_B: 0.259 \n",
      "(epoch: 112, iters: 500, time: 0.590, data: 0.002) D_A: 0.195 G_A: 0.273 cycle_A: 1.105 idt_A: 0.113 D_B: 0.066 G_B: 0.457 cycle_B: 0.337 idt_B: 0.353 \n",
      "End of epoch 112 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 100, time: 0.228, data: 0.100) D_A: 0.189 G_A: 0.734 cycle_A: 0.670 idt_A: 0.237 D_B: 0.127 G_B: 0.558 cycle_B: 0.680 idt_B: 0.276 \n",
      "(epoch: 113, iters: 200, time: 0.230, data: 0.002) D_A: 0.213 G_A: 0.225 cycle_A: 1.025 idt_A: 0.104 D_B: 0.243 G_B: 0.318 cycle_B: 0.320 idt_B: 0.387 \n",
      "(epoch: 113, iters: 300, time: 0.229, data: 0.002) D_A: 0.031 G_A: 0.451 cycle_A: 1.330 idt_A: 0.226 D_B: 0.220 G_B: 0.459 cycle_B: 0.568 idt_B: 0.440 \n",
      "(epoch: 113, iters: 400, time: 0.589, data: 0.001) D_A: 0.097 G_A: 0.352 cycle_A: 0.929 idt_A: 0.222 D_B: 0.120 G_B: 0.386 cycle_B: 0.680 idt_B: 0.269 \n",
      "(epoch: 113, iters: 500, time: 0.229, data: 0.001) D_A: 0.162 G_A: 0.805 cycle_A: 0.924 idt_A: 0.089 D_B: 0.137 G_B: 0.396 cycle_B: 0.306 idt_B: 0.249 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 113 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 100, time: 0.232, data: 0.095) D_A: 0.141 G_A: 1.105 cycle_A: 1.375 idt_A: 0.096 D_B: 0.163 G_B: 0.544 cycle_B: 0.418 idt_B: 0.553 \n",
      "(epoch: 114, iters: 200, time: 0.228, data: 0.002) D_A: 0.164 G_A: 0.643 cycle_A: 2.010 idt_A: 0.142 D_B: 0.215 G_B: 0.381 cycle_B: 0.357 idt_B: 0.879 \n",
      "(epoch: 114, iters: 300, time: 0.604, data: 0.002) D_A: 0.167 G_A: 0.417 cycle_A: 1.366 idt_A: 0.210 D_B: 0.059 G_B: 0.628 cycle_B: 0.463 idt_B: 0.347 \n",
      "(epoch: 114, iters: 400, time: 0.228, data: 0.001) D_A: 0.103 G_A: 0.405 cycle_A: 0.767 idt_A: 0.141 D_B: 0.112 G_B: 0.512 cycle_B: 0.454 idt_B: 0.330 \n",
      "(epoch: 114, iters: 500, time: 0.229, data: 0.002) D_A: 0.403 G_A: 0.805 cycle_A: 1.006 idt_A: 0.100 D_B: 0.125 G_B: 0.443 cycle_B: 0.133 idt_B: 0.283 \n",
      "End of epoch 114 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 100, time: 0.227, data: 0.098) D_A: 0.128 G_A: 0.717 cycle_A: 1.489 idt_A: 0.138 D_B: 0.102 G_B: 0.357 cycle_B: 0.426 idt_B: 0.964 \n",
      "(epoch: 115, iters: 200, time: 0.602, data: 0.002) D_A: 0.129 G_A: 0.858 cycle_A: 1.004 idt_A: 0.156 D_B: 0.236 G_B: 0.340 cycle_B: 0.377 idt_B: 0.331 \n",
      "(epoch: 115, iters: 300, time: 0.228, data: 0.001) D_A: 0.169 G_A: 0.993 cycle_A: 1.078 idt_A: 0.100 D_B: 0.135 G_B: 0.382 cycle_B: 0.271 idt_B: 0.466 \n",
      "(epoch: 115, iters: 400, time: 0.229, data: 0.001) D_A: 0.162 G_A: 0.351 cycle_A: 1.668 idt_A: 0.201 D_B: 0.239 G_B: 0.876 cycle_B: 0.572 idt_B: 0.937 \n",
      "(epoch: 115, iters: 500, time: 0.228, data: 0.002) D_A: 0.167 G_A: 0.572 cycle_A: 1.627 idt_A: 0.133 D_B: 0.163 G_B: 0.340 cycle_B: 0.373 idt_B: 0.435 \n",
      "saving the model at the end of epoch 115, iters 57500\n",
      "End of epoch 115 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 100, time: 0.609, data: 0.120) D_A: 0.158 G_A: 0.396 cycle_A: 1.211 idt_A: 0.126 D_B: 0.148 G_B: 0.523 cycle_B: 0.408 idt_B: 0.282 \n",
      "(epoch: 116, iters: 200, time: 0.228, data: 0.001) D_A: 0.206 G_A: 0.199 cycle_A: 0.637 idt_A: 0.243 D_B: 0.077 G_B: 0.285 cycle_B: 0.773 idt_B: 0.254 \n",
      "(epoch: 116, iters: 300, time: 0.230, data: 0.001) D_A: 0.122 G_A: 0.311 cycle_A: 1.279 idt_A: 0.103 D_B: 0.180 G_B: 0.189 cycle_B: 0.361 idt_B: 0.457 \n",
      "(epoch: 116, iters: 400, time: 0.230, data: 0.002) D_A: 0.226 G_A: 0.822 cycle_A: 1.006 idt_A: 0.101 D_B: 0.077 G_B: 0.395 cycle_B: 0.383 idt_B: 0.319 \n",
      "(epoch: 116, iters: 500, time: 0.570, data: 0.002) D_A: 0.151 G_A: 0.437 cycle_A: 1.302 idt_A: 0.090 D_B: 0.187 G_B: 0.308 cycle_B: 0.250 idt_B: 0.502 \n",
      "End of epoch 116 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 100, time: 0.229, data: 0.121) D_A: 0.142 G_A: 0.665 cycle_A: 0.709 idt_A: 0.143 D_B: 0.108 G_B: 0.318 cycle_B: 0.541 idt_B: 0.230 \n",
      "(epoch: 117, iters: 200, time: 0.231, data: 0.002) D_A: 0.180 G_A: 0.578 cycle_A: 2.581 idt_A: 0.034 D_B: 0.245 G_B: 0.269 cycle_B: 0.133 idt_B: 1.055 \n",
      "(epoch: 117, iters: 300, time: 0.229, data: 0.001) D_A: 0.249 G_A: 0.221 cycle_A: 0.927 idt_A: 0.137 D_B: 0.271 G_B: 0.131 cycle_B: 0.542 idt_B: 0.468 \n",
      "(epoch: 117, iters: 400, time: 0.612, data: 0.001) D_A: 0.187 G_A: 0.365 cycle_A: 2.316 idt_A: 0.160 D_B: 0.064 G_B: 0.815 cycle_B: 0.486 idt_B: 0.576 \n",
      "(epoch: 117, iters: 500, time: 0.229, data: 0.002) D_A: 0.104 G_A: 0.438 cycle_A: 0.966 idt_A: 0.309 D_B: 0.206 G_B: 0.367 cycle_B: 0.811 idt_B: 0.250 \n",
      "End of epoch 117 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 100, time: 0.228, data: 0.097) D_A: 0.292 G_A: 0.276 cycle_A: 1.450 idt_A: 0.087 D_B: 0.170 G_B: 0.578 cycle_B: 0.375 idt_B: 0.369 \n",
      "(epoch: 118, iters: 200, time: 0.244, data: 0.002) D_A: 0.046 G_A: 0.444 cycle_A: 1.246 idt_A: 0.295 D_B: 0.159 G_B: 0.370 cycle_B: 0.769 idt_B: 0.581 \n",
      "(epoch: 118, iters: 300, time: 0.601, data: 0.002) D_A: 0.106 G_A: 0.579 cycle_A: 1.083 idt_A: 0.172 D_B: 0.185 G_B: 0.546 cycle_B: 0.469 idt_B: 0.214 \n",
      "(epoch: 118, iters: 400, time: 0.231, data: 0.002) D_A: 0.230 G_A: 0.684 cycle_A: 1.142 idt_A: 0.059 D_B: 0.082 G_B: 0.356 cycle_B: 0.210 idt_B: 0.241 \n",
      "(epoch: 118, iters: 500, time: 0.229, data: 0.002) D_A: 0.196 G_A: 0.704 cycle_A: 0.770 idt_A: 0.163 D_B: 0.167 G_B: 0.418 cycle_B: 0.474 idt_B: 0.274 \n",
      "End of epoch 118 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 100, time: 0.228, data: 0.098) D_A: 0.259 G_A: 0.133 cycle_A: 1.026 idt_A: 0.088 D_B: 0.070 G_B: 0.398 cycle_B: 0.334 idt_B: 0.302 \n",
      "(epoch: 119, iters: 200, time: 0.614, data: 0.002) D_A: 0.115 G_A: 0.454 cycle_A: 0.992 idt_A: 0.118 D_B: 0.132 G_B: 0.514 cycle_B: 0.311 idt_B: 0.281 \n",
      "(epoch: 119, iters: 300, time: 0.228, data: 0.002) D_A: 0.079 G_A: 0.721 cycle_A: 0.907 idt_A: 0.223 D_B: 0.239 G_B: 0.695 cycle_B: 0.568 idt_B: 0.216 \n",
      "(epoch: 119, iters: 400, time: 0.228, data: 0.002) D_A: 0.125 G_A: 0.695 cycle_A: 0.927 idt_A: 0.193 D_B: 0.100 G_B: 0.564 cycle_B: 0.386 idt_B: 0.214 \n",
      "(epoch: 119, iters: 500, time: 0.228, data: 0.002) D_A: 0.123 G_A: 0.706 cycle_A: 1.072 idt_A: 0.181 D_B: 0.219 G_B: 0.386 cycle_B: 0.626 idt_B: 0.454 \n",
      "End of epoch 119 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 100, time: 0.612, data: 0.098) D_A: 0.076 G_A: 0.710 cycle_A: 3.517 idt_A: 0.189 D_B: 0.087 G_B: 0.549 cycle_B: 0.575 idt_B: 1.529 \n",
      "(epoch: 120, iters: 200, time: 0.229, data: 0.001) D_A: 0.182 G_A: 0.525 cycle_A: 1.189 idt_A: 0.085 D_B: 0.215 G_B: 0.290 cycle_B: 0.218 idt_B: 0.376 \n",
      "(epoch: 120, iters: 300, time: 0.230, data: 0.002) D_A: 0.188 G_A: 0.221 cycle_A: 1.206 idt_A: 0.133 D_B: 0.147 G_B: 0.382 cycle_B: 0.432 idt_B: 0.452 \n",
      "(epoch: 120, iters: 400, time: 0.228, data: 0.001) D_A: 0.164 G_A: 0.787 cycle_A: 1.281 idt_A: 0.168 D_B: 0.134 G_B: 0.317 cycle_B: 0.445 idt_B: 0.589 \n",
      "(epoch: 120, iters: 500, time: 0.599, data: 0.001) D_A: 0.221 G_A: 0.872 cycle_A: 0.836 idt_A: 0.136 D_B: 0.101 G_B: 0.638 cycle_B: 0.441 idt_B: 0.285 \n",
      "saving the latest model (epoch 120, total_iters 60000)\n",
      "saving the model at the end of epoch 120, iters 60000\n",
      "End of epoch 120 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 100, time: 0.228, data: 0.113) D_A: 0.346 G_A: 0.456 cycle_A: 0.855 idt_A: 0.126 D_B: 0.148 G_B: 0.415 cycle_B: 0.331 idt_B: 0.392 \n",
      "(epoch: 121, iters: 200, time: 0.227, data: 0.002) D_A: 0.125 G_A: 0.473 cycle_A: 0.588 idt_A: 0.230 D_B: 0.216 G_B: 0.293 cycle_B: 0.652 idt_B: 0.183 \n",
      "(epoch: 121, iters: 300, time: 0.230, data: 0.002) D_A: 0.178 G_A: 0.867 cycle_A: 0.983 idt_A: 0.109 D_B: 0.172 G_B: 0.618 cycle_B: 0.307 idt_B: 0.521 \n",
      "(epoch: 121, iters: 400, time: 0.584, data: 0.001) D_A: 0.182 G_A: 0.990 cycle_A: 1.230 idt_A: 0.143 D_B: 0.205 G_B: 0.311 cycle_B: 0.290 idt_B: 0.443 \n",
      "(epoch: 121, iters: 500, time: 0.229, data: 0.001) D_A: 0.068 G_A: 0.498 cycle_A: 1.034 idt_A: 0.151 D_B: 0.195 G_B: 0.268 cycle_B: 0.476 idt_B: 0.326 \n",
      "End of epoch 121 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 100, time: 0.229, data: 0.120) D_A: 0.134 G_A: 0.625 cycle_A: 1.150 idt_A: 0.252 D_B: 0.158 G_B: 0.479 cycle_B: 0.620 idt_B: 0.437 \n",
      "(epoch: 122, iters: 200, time: 0.228, data: 0.001) D_A: 0.090 G_A: 0.332 cycle_A: 1.062 idt_A: 0.143 D_B: 0.175 G_B: 0.578 cycle_B: 0.426 idt_B: 0.315 \n",
      "(epoch: 122, iters: 300, time: 0.592, data: 0.002) D_A: 0.279 G_A: 0.484 cycle_A: 1.313 idt_A: 0.139 D_B: 0.058 G_B: 0.617 cycle_B: 0.308 idt_B: 0.409 \n",
      "(epoch: 122, iters: 400, time: 0.228, data: 0.001) D_A: 0.060 G_A: 0.686 cycle_A: 0.723 idt_A: 0.177 D_B: 0.154 G_B: 0.351 cycle_B: 0.516 idt_B: 0.158 \n",
      "(epoch: 122, iters: 500, time: 0.229, data: 0.002) D_A: 0.055 G_A: 0.305 cycle_A: 1.137 idt_A: 0.162 D_B: 0.362 G_B: 0.336 cycle_B: 0.516 idt_B: 0.401 \n",
      "End of epoch 122 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 100, time: 0.229, data: 0.097) D_A: 0.086 G_A: 0.568 cycle_A: 1.479 idt_A: 0.306 D_B: 0.118 G_B: 0.321 cycle_B: 0.755 idt_B: 0.431 \n",
      "(epoch: 123, iters: 200, time: 0.598, data: 0.002) D_A: 0.107 G_A: 0.428 cycle_A: 0.609 idt_A: 0.152 D_B: 0.242 G_B: 0.227 cycle_B: 0.424 idt_B: 0.230 \n",
      "(epoch: 123, iters: 300, time: 0.231, data: 0.002) D_A: 0.097 G_A: 0.772 cycle_A: 0.858 idt_A: 0.121 D_B: 0.184 G_B: 0.288 cycle_B: 0.283 idt_B: 0.354 \n",
      "(epoch: 123, iters: 400, time: 0.229, data: 0.002) D_A: 0.173 G_A: 0.257 cycle_A: 1.724 idt_A: 0.157 D_B: 0.110 G_B: 0.557 cycle_B: 0.411 idt_B: 0.539 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 123, iters: 500, time: 0.229, data: 0.002) D_A: 0.122 G_A: 0.438 cycle_A: 1.321 idt_A: 0.135 D_B: 0.121 G_B: 0.265 cycle_B: 0.425 idt_B: 0.655 \n",
      "End of epoch 123 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 100, time: 0.626, data: 0.115) D_A: 0.217 G_A: 0.190 cycle_A: 0.950 idt_A: 0.265 D_B: 0.220 G_B: 0.636 cycle_B: 0.628 idt_B: 0.363 \n",
      "(epoch: 124, iters: 200, time: 0.244, data: 0.001) D_A: 0.120 G_A: 0.851 cycle_A: 1.115 idt_A: 0.152 D_B: 0.071 G_B: 0.622 cycle_B: 0.326 idt_B: 0.328 \n",
      "(epoch: 124, iters: 300, time: 0.227, data: 0.002) D_A: 0.179 G_A: 0.480 cycle_A: 0.774 idt_A: 0.151 D_B: 0.112 G_B: 0.551 cycle_B: 0.381 idt_B: 0.295 \n",
      "(epoch: 124, iters: 400, time: 0.228, data: 0.002) D_A: 0.098 G_A: 0.412 cycle_A: 0.943 idt_A: 0.177 D_B: 0.164 G_B: 0.370 cycle_B: 0.495 idt_B: 0.358 \n",
      "(epoch: 124, iters: 500, time: 0.602, data: 0.001) D_A: 0.183 G_A: 0.289 cycle_A: 1.179 idt_A: 0.132 D_B: 0.202 G_B: 0.844 cycle_B: 0.345 idt_B: 0.385 \n",
      "End of epoch 124 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 100, time: 0.228, data: 0.117) D_A: 0.112 G_A: 0.456 cycle_A: 1.772 idt_A: 0.195 D_B: 0.130 G_B: 0.255 cycle_B: 0.523 idt_B: 0.798 \n",
      "(epoch: 125, iters: 200, time: 0.228, data: 0.002) D_A: 0.149 G_A: 0.480 cycle_A: 1.922 idt_A: 0.180 D_B: 0.149 G_B: 0.442 cycle_B: 0.445 idt_B: 0.761 \n",
      "(epoch: 125, iters: 300, time: 0.229, data: 0.002) D_A: 0.166 G_A: 1.229 cycle_A: 1.062 idt_A: 0.120 D_B: 0.230 G_B: 0.171 cycle_B: 0.331 idt_B: 0.334 \n",
      "(epoch: 125, iters: 400, time: 0.617, data: 0.002) D_A: 0.055 G_A: 0.523 cycle_A: 0.776 idt_A: 0.125 D_B: 0.194 G_B: 0.265 cycle_B: 0.378 idt_B: 0.295 \n",
      "(epoch: 125, iters: 500, time: 0.229, data: 0.002) D_A: 0.083 G_A: 0.642 cycle_A: 1.939 idt_A: 0.149 D_B: 0.071 G_B: 0.337 cycle_B: 0.372 idt_B: 0.590 \n",
      "saving the model at the end of epoch 125, iters 62500\n",
      "End of epoch 125 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 100, time: 0.228, data: 0.097) D_A: 0.077 G_A: 0.835 cycle_A: 0.642 idt_A: 0.238 D_B: 0.173 G_B: 0.222 cycle_B: 0.647 idt_B: 0.221 \n",
      "(epoch: 126, iters: 200, time: 0.230, data: 0.002) D_A: 0.122 G_A: 0.487 cycle_A: 0.772 idt_A: 0.136 D_B: 0.148 G_B: 0.495 cycle_B: 0.409 idt_B: 0.290 \n",
      "(epoch: 126, iters: 300, time: 0.627, data: 0.002) D_A: 0.105 G_A: 0.591 cycle_A: 1.304 idt_A: 0.220 D_B: 0.136 G_B: 0.380 cycle_B: 0.493 idt_B: 0.542 \n",
      "(epoch: 126, iters: 400, time: 0.228, data: 0.002) D_A: 0.090 G_A: 0.534 cycle_A: 0.969 idt_A: 0.125 D_B: 0.091 G_B: 0.711 cycle_B: 0.396 idt_B: 0.297 \n",
      "(epoch: 126, iters: 500, time: 0.231, data: 0.002) D_A: 0.153 G_A: 0.246 cycle_A: 1.460 idt_A: 0.102 D_B: 0.134 G_B: 0.401 cycle_B: 0.302 idt_B: 0.511 \n",
      "End of epoch 126 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 100, time: 0.229, data: 0.104) D_A: 0.238 G_A: 0.581 cycle_A: 0.645 idt_A: 0.128 D_B: 0.293 G_B: 0.482 cycle_B: 0.343 idt_B: 0.191 \n",
      "(epoch: 127, iters: 200, time: 0.613, data: 0.002) D_A: 0.079 G_A: 0.667 cycle_A: 0.695 idt_A: 0.127 D_B: 0.195 G_B: 0.367 cycle_B: 0.318 idt_B: 0.274 \n",
      "(epoch: 127, iters: 300, time: 0.230, data: 0.002) D_A: 0.154 G_A: 0.460 cycle_A: 0.892 idt_A: 0.210 D_B: 0.192 G_B: 0.200 cycle_B: 0.509 idt_B: 0.524 \n",
      "(epoch: 127, iters: 400, time: 0.228, data: 0.002) D_A: 0.032 G_A: 0.624 cycle_A: 1.437 idt_A: 0.142 D_B: 0.192 G_B: 0.341 cycle_B: 0.451 idt_B: 0.577 \n",
      "(epoch: 127, iters: 500, time: 0.229, data: 0.001) D_A: 0.051 G_A: 0.962 cycle_A: 0.867 idt_A: 0.167 D_B: 0.132 G_B: 0.281 cycle_B: 0.488 idt_B: 0.237 \n",
      "End of epoch 127 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 100, time: 0.593, data: 0.100) D_A: 0.077 G_A: 0.487 cycle_A: 1.451 idt_A: 0.155 D_B: 0.154 G_B: 0.400 cycle_B: 0.398 idt_B: 0.263 \n",
      "(epoch: 128, iters: 200, time: 0.227, data: 0.001) D_A: 0.036 G_A: 0.718 cycle_A: 1.124 idt_A: 0.181 D_B: 0.115 G_B: 0.304 cycle_B: 0.930 idt_B: 0.406 \n",
      "(epoch: 128, iters: 300, time: 0.229, data: 0.001) D_A: 0.084 G_A: 0.753 cycle_A: 0.516 idt_A: 0.134 D_B: 0.256 G_B: 0.328 cycle_B: 0.400 idt_B: 0.273 \n",
      "(epoch: 128, iters: 400, time: 0.231, data: 0.001) D_A: 0.174 G_A: 0.138 cycle_A: 0.847 idt_A: 0.169 D_B: 0.101 G_B: 0.576 cycle_B: 0.464 idt_B: 0.328 \n",
      "(epoch: 128, iters: 500, time: 0.620, data: 0.001) D_A: 0.128 G_A: 0.157 cycle_A: 1.910 idt_A: 0.229 D_B: 0.210 G_B: 0.407 cycle_B: 0.609 idt_B: 0.738 \n",
      "End of epoch 128 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 100, time: 0.227, data: 0.111) D_A: 0.114 G_A: 0.872 cycle_A: 1.727 idt_A: 0.162 D_B: 0.185 G_B: 0.248 cycle_B: 0.442 idt_B: 0.633 \n",
      "(epoch: 129, iters: 200, time: 0.230, data: 0.002) D_A: 0.165 G_A: 0.601 cycle_A: 1.217 idt_A: 0.121 D_B: 0.245 G_B: 0.416 cycle_B: 0.450 idt_B: 0.197 \n",
      "(epoch: 129, iters: 300, time: 0.230, data: 0.001) D_A: 0.191 G_A: 0.505 cycle_A: 0.772 idt_A: 0.186 D_B: 0.201 G_B: 0.246 cycle_B: 0.486 idt_B: 0.246 \n",
      "(epoch: 129, iters: 400, time: 0.631, data: 0.002) D_A: 0.092 G_A: 0.659 cycle_A: 1.711 idt_A: 0.113 D_B: 0.170 G_B: 0.434 cycle_B: 0.383 idt_B: 0.838 \n",
      "(epoch: 129, iters: 500, time: 0.227, data: 0.002) D_A: 0.101 G_A: 0.400 cycle_A: 0.867 idt_A: 0.202 D_B: 0.210 G_B: 0.353 cycle_B: 0.548 idt_B: 0.287 \n",
      "End of epoch 129 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 100, time: 0.231, data: 0.103) D_A: 0.090 G_A: 0.853 cycle_A: 1.233 idt_A: 0.224 D_B: 0.237 G_B: 0.170 cycle_B: 0.573 idt_B: 0.487 \n",
      "(epoch: 130, iters: 200, time: 0.228, data: 0.002) D_A: 0.121 G_A: 0.577 cycle_A: 0.604 idt_A: 0.132 D_B: 0.178 G_B: 0.652 cycle_B: 0.388 idt_B: 0.168 \n",
      "(epoch: 130, iters: 300, time: 0.632, data: 0.002) D_A: 0.241 G_A: 0.407 cycle_A: 1.122 idt_A: 0.118 D_B: 0.193 G_B: 0.300 cycle_B: 0.299 idt_B: 0.310 \n",
      "(epoch: 130, iters: 400, time: 0.228, data: 0.002) D_A: 0.040 G_A: 0.915 cycle_A: 0.625 idt_A: 0.156 D_B: 0.068 G_B: 0.386 cycle_B: 0.467 idt_B: 0.445 \n",
      "(epoch: 130, iters: 500, time: 0.230, data: 0.001) D_A: 0.140 G_A: 0.420 cycle_A: 1.400 idt_A: 0.239 D_B: 0.091 G_B: 0.363 cycle_B: 0.678 idt_B: 0.424 \n",
      "saving the latest model (epoch 130, total_iters 65000)\n",
      "saving the model at the end of epoch 130, iters 65000\n",
      "End of epoch 130 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 100, time: 0.228, data: 0.094) D_A: 0.167 G_A: 0.481 cycle_A: 1.086 idt_A: 0.144 D_B: 0.113 G_B: 0.279 cycle_B: 0.424 idt_B: 0.287 \n",
      "(epoch: 131, iters: 200, time: 0.637, data: 0.002) D_A: 0.243 G_A: 0.661 cycle_A: 0.826 idt_A: 0.221 D_B: 0.168 G_B: 0.480 cycle_B: 0.545 idt_B: 0.364 \n",
      "(epoch: 131, iters: 300, time: 0.229, data: 0.002) D_A: 0.073 G_A: 0.803 cycle_A: 0.741 idt_A: 0.149 D_B: 0.239 G_B: 0.245 cycle_B: 0.400 idt_B: 0.461 \n",
      "(epoch: 131, iters: 400, time: 0.228, data: 0.002) D_A: 0.101 G_A: 1.138 cycle_A: 0.671 idt_A: 0.141 D_B: 0.044 G_B: 0.651 cycle_B: 0.930 idt_B: 0.193 \n",
      "(epoch: 131, iters: 500, time: 0.228, data: 0.002) D_A: 0.138 G_A: 0.540 cycle_A: 0.840 idt_A: 0.119 D_B: 0.159 G_B: 0.273 cycle_B: 0.361 idt_B: 0.667 \n",
      "End of epoch 131 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 100, time: 0.620, data: 0.101) D_A: 0.096 G_A: 0.653 cycle_A: 1.028 idt_A: 0.183 D_B: 0.097 G_B: 0.621 cycle_B: 0.432 idt_B: 0.396 \n",
      "(epoch: 132, iters: 200, time: 0.229, data: 0.001) D_A: 0.179 G_A: 0.628 cycle_A: 1.802 idt_A: 0.147 D_B: 0.190 G_B: 0.266 cycle_B: 0.482 idt_B: 0.649 \n",
      "(epoch: 132, iters: 300, time: 0.230, data: 0.002) D_A: 0.069 G_A: 0.570 cycle_A: 1.642 idt_A: 0.141 D_B: 0.148 G_B: 0.460 cycle_B: 0.445 idt_B: 0.776 \n",
      "(epoch: 132, iters: 400, time: 0.228, data: 0.001) D_A: 0.207 G_A: 0.397 cycle_A: 1.219 idt_A: 0.079 D_B: 0.146 G_B: 0.486 cycle_B: 0.265 idt_B: 0.590 \n",
      "(epoch: 132, iters: 500, time: 0.625, data: 0.002) D_A: 0.227 G_A: 0.531 cycle_A: 1.138 idt_A: 0.166 D_B: 0.182 G_B: 0.618 cycle_B: 0.447 idt_B: 0.471 \n",
      "End of epoch 132 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 100, time: 0.232, data: 0.099) D_A: 0.069 G_A: 0.505 cycle_A: 1.494 idt_A: 0.197 D_B: 0.085 G_B: 0.624 cycle_B: 0.486 idt_B: 0.601 \n",
      "(epoch: 133, iters: 200, time: 0.228, data: 0.002) D_A: 0.075 G_A: 0.504 cycle_A: 0.794 idt_A: 0.174 D_B: 0.209 G_B: 0.293 cycle_B: 0.518 idt_B: 0.192 \n",
      "(epoch: 133, iters: 300, time: 0.232, data: 0.002) D_A: 0.031 G_A: 0.316 cycle_A: 0.833 idt_A: 0.142 D_B: 0.155 G_B: 0.316 cycle_B: 0.413 idt_B: 0.354 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 133, iters: 400, time: 0.623, data: 0.002) D_A: 0.123 G_A: 0.738 cycle_A: 1.080 idt_A: 0.149 D_B: 0.156 G_B: 0.566 cycle_B: 0.432 idt_B: 0.301 \n",
      "(epoch: 133, iters: 500, time: 0.228, data: 0.001) D_A: 0.131 G_A: 0.624 cycle_A: 1.020 idt_A: 0.127 D_B: 0.120 G_B: 0.495 cycle_B: 0.405 idt_B: 0.242 \n",
      "End of epoch 133 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 100, time: 0.229, data: 0.102) D_A: 0.131 G_A: 0.308 cycle_A: 0.997 idt_A: 0.160 D_B: 0.098 G_B: 0.480 cycle_B: 0.408 idt_B: 0.355 \n",
      "(epoch: 134, iters: 200, time: 0.229, data: 0.001) D_A: 0.127 G_A: 0.466 cycle_A: 1.168 idt_A: 0.154 D_B: 0.197 G_B: 0.428 cycle_B: 0.434 idt_B: 0.313 \n",
      "(epoch: 134, iters: 300, time: 0.637, data: 0.001) D_A: 0.144 G_A: 0.689 cycle_A: 1.082 idt_A: 0.164 D_B: 0.182 G_B: 0.284 cycle_B: 0.448 idt_B: 0.205 \n",
      "(epoch: 134, iters: 400, time: 0.229, data: 0.002) D_A: 0.125 G_A: 0.233 cycle_A: 1.824 idt_A: 0.160 D_B: 0.260 G_B: 0.454 cycle_B: 0.453 idt_B: 0.773 \n",
      "(epoch: 134, iters: 500, time: 0.227, data: 0.002) D_A: 0.235 G_A: 0.382 cycle_A: 0.888 idt_A: 0.205 D_B: 0.146 G_B: 0.523 cycle_B: 0.466 idt_B: 0.287 \n",
      "End of epoch 134 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 100, time: 0.229, data: 0.113) D_A: 0.164 G_A: 0.569 cycle_A: 0.561 idt_A: 0.075 D_B: 0.182 G_B: 0.626 cycle_B: 0.202 idt_B: 0.301 \n",
      "(epoch: 135, iters: 200, time: 0.641, data: 0.001) D_A: 0.087 G_A: 0.577 cycle_A: 1.002 idt_A: 0.139 D_B: 0.218 G_B: 0.434 cycle_B: 0.397 idt_B: 0.424 \n",
      "(epoch: 135, iters: 300, time: 0.230, data: 0.001) D_A: 0.106 G_A: 0.733 cycle_A: 0.849 idt_A: 0.125 D_B: 0.306 G_B: 0.195 cycle_B: 0.439 idt_B: 0.371 \n",
      "(epoch: 135, iters: 400, time: 0.228, data: 0.002) D_A: 0.098 G_A: 0.542 cycle_A: 1.371 idt_A: 0.209 D_B: 0.167 G_B: 0.327 cycle_B: 0.556 idt_B: 0.416 \n",
      "(epoch: 135, iters: 500, time: 0.228, data: 0.002) D_A: 0.093 G_A: 0.957 cycle_A: 0.715 idt_A: 0.138 D_B: 0.117 G_B: 0.538 cycle_B: 0.431 idt_B: 0.385 \n",
      "saving the model at the end of epoch 135, iters 67500\n",
      "End of epoch 135 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 100, time: 0.617, data: 0.123) D_A: 0.178 G_A: 0.361 cycle_A: 0.772 idt_A: 0.127 D_B: 0.116 G_B: 0.328 cycle_B: 0.395 idt_B: 0.273 \n",
      "(epoch: 136, iters: 200, time: 0.230, data: 0.001) D_A: 0.089 G_A: 0.302 cycle_A: 1.292 idt_A: 0.142 D_B: 0.199 G_B: 0.206 cycle_B: 0.444 idt_B: 0.607 \n",
      "(epoch: 136, iters: 300, time: 0.228, data: 0.002) D_A: 0.154 G_A: 0.473 cycle_A: 2.046 idt_A: 0.193 D_B: 0.092 G_B: 0.466 cycle_B: 0.423 idt_B: 0.374 \n",
      "(epoch: 136, iters: 400, time: 0.229, data: 0.002) D_A: 0.042 G_A: 0.645 cycle_A: 1.190 idt_A: 0.141 D_B: 0.068 G_B: 0.468 cycle_B: 0.348 idt_B: 0.329 \n",
      "(epoch: 136, iters: 500, time: 0.622, data: 0.002) D_A: 0.064 G_A: 0.580 cycle_A: 1.216 idt_A: 0.207 D_B: 0.381 G_B: 0.816 cycle_B: 0.572 idt_B: 0.691 \n",
      "End of epoch 136 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 100, time: 0.228, data: 0.117) D_A: 0.086 G_A: 0.618 cycle_A: 0.816 idt_A: 0.142 D_B: 0.131 G_B: 0.394 cycle_B: 0.378 idt_B: 0.430 \n",
      "(epoch: 137, iters: 200, time: 0.230, data: 0.001) D_A: 0.041 G_A: 0.306 cycle_A: 1.721 idt_A: 0.197 D_B: 0.166 G_B: 0.290 cycle_B: 0.631 idt_B: 0.410 \n",
      "(epoch: 137, iters: 300, time: 0.229, data: 0.002) D_A: 0.191 G_A: 0.692 cycle_A: 1.018 idt_A: 0.185 D_B: 0.136 G_B: 0.419 cycle_B: 0.533 idt_B: 0.318 \n",
      "(epoch: 137, iters: 400, time: 0.607, data: 0.002) D_A: 0.181 G_A: 0.632 cycle_A: 0.949 idt_A: 0.272 D_B: 0.173 G_B: 0.411 cycle_B: 0.671 idt_B: 0.221 \n",
      "(epoch: 137, iters: 500, time: 0.229, data: 0.001) D_A: 0.140 G_A: 0.835 cycle_A: 0.869 idt_A: 0.097 D_B: 0.037 G_B: 0.442 cycle_B: 0.283 idt_B: 0.285 \n",
      "End of epoch 137 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 100, time: 0.229, data: 0.123) D_A: 0.129 G_A: 0.744 cycle_A: 1.228 idt_A: 0.114 D_B: 0.162 G_B: 0.381 cycle_B: 0.281 idt_B: 0.330 \n",
      "(epoch: 138, iters: 200, time: 0.228, data: 0.002) D_A: 0.126 G_A: 0.232 cycle_A: 1.188 idt_A: 0.156 D_B: 0.232 G_B: 0.277 cycle_B: 0.470 idt_B: 0.285 \n",
      "(epoch: 138, iters: 300, time: 0.664, data: 0.002) D_A: 0.189 G_A: 0.276 cycle_A: 0.836 idt_A: 0.190 D_B: 0.212 G_B: 0.478 cycle_B: 0.461 idt_B: 0.684 \n",
      "(epoch: 138, iters: 400, time: 0.228, data: 0.001) D_A: 0.101 G_A: 0.568 cycle_A: 1.008 idt_A: 0.139 D_B: 0.140 G_B: 0.642 cycle_B: 0.374 idt_B: 0.297 \n",
      "(epoch: 138, iters: 500, time: 0.228, data: 0.002) D_A: 0.082 G_A: 0.459 cycle_A: 1.073 idt_A: 0.149 D_B: 0.120 G_B: 0.397 cycle_B: 0.432 idt_B: 0.358 \n",
      "End of epoch 138 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 100, time: 0.230, data: 0.101) D_A: 0.073 G_A: 0.505 cycle_A: 0.688 idt_A: 0.122 D_B: 0.138 G_B: 0.527 cycle_B: 0.366 idt_B: 0.339 \n",
      "(epoch: 139, iters: 200, time: 0.629, data: 0.002) D_A: 0.112 G_A: 0.699 cycle_A: 1.020 idt_A: 0.157 D_B: 0.218 G_B: 0.257 cycle_B: 0.431 idt_B: 0.236 \n",
      "(epoch: 139, iters: 300, time: 0.229, data: 0.001) D_A: 0.131 G_A: 0.546 cycle_A: 1.079 idt_A: 0.160 D_B: 0.175 G_B: 0.635 cycle_B: 0.450 idt_B: 0.464 \n",
      "(epoch: 139, iters: 400, time: 0.229, data: 0.001) D_A: 0.102 G_A: 0.439 cycle_A: 0.982 idt_A: 0.131 D_B: 0.168 G_B: 0.456 cycle_B: 0.366 idt_B: 0.230 \n",
      "(epoch: 139, iters: 500, time: 0.229, data: 0.002) D_A: 0.119 G_A: 0.627 cycle_A: 1.042 idt_A: 0.180 D_B: 0.142 G_B: 0.269 cycle_B: 0.592 idt_B: 0.452 \n",
      "End of epoch 139 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 100, time: 0.646, data: 0.120) D_A: 0.183 G_A: 0.725 cycle_A: 0.674 idt_A: 0.106 D_B: 0.059 G_B: 0.323 cycle_B: 0.331 idt_B: 0.260 \n",
      "(epoch: 140, iters: 200, time: 0.231, data: 0.002) D_A: 0.193 G_A: 0.281 cycle_A: 0.969 idt_A: 0.086 D_B: 0.252 G_B: 0.265 cycle_B: 0.270 idt_B: 0.249 \n",
      "(epoch: 140, iters: 300, time: 0.228, data: 0.001) D_A: 0.049 G_A: 0.757 cycle_A: 0.640 idt_A: 0.140 D_B: 0.083 G_B: 0.439 cycle_B: 0.421 idt_B: 0.250 \n",
      "(epoch: 140, iters: 400, time: 0.229, data: 0.002) D_A: 0.096 G_A: 0.834 cycle_A: 1.289 idt_A: 0.184 D_B: 0.116 G_B: 0.427 cycle_B: 0.530 idt_B: 0.494 \n",
      "(epoch: 140, iters: 500, time: 0.637, data: 0.002) D_A: 0.224 G_A: 0.257 cycle_A: 1.083 idt_A: 0.195 D_B: 0.207 G_B: 0.392 cycle_B: 0.602 idt_B: 0.354 \n",
      "saving the latest model (epoch 140, total_iters 70000)\n",
      "saving the model at the end of epoch 140, iters 70000\n",
      "End of epoch 140 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 100, time: 0.227, data: 0.122) D_A: 0.115 G_A: 0.182 cycle_A: 0.933 idt_A: 0.150 D_B: 0.047 G_B: 0.303 cycle_B: 0.438 idt_B: 0.258 \n",
      "(epoch: 141, iters: 200, time: 0.229, data: 0.001) D_A: 0.185 G_A: 0.783 cycle_A: 0.581 idt_A: 0.122 D_B: 0.142 G_B: 0.208 cycle_B: 0.362 idt_B: 0.155 \n",
      "(epoch: 141, iters: 300, time: 0.228, data: 0.002) D_A: 0.224 G_A: 0.436 cycle_A: 1.473 idt_A: 0.178 D_B: 0.120 G_B: 0.364 cycle_B: 0.409 idt_B: 0.256 \n",
      "(epoch: 141, iters: 400, time: 0.639, data: 0.002) D_A: 0.029 G_A: 0.727 cycle_A: 0.902 idt_A: 0.160 D_B: 0.079 G_B: 0.203 cycle_B: 0.460 idt_B: 0.329 \n",
      "(epoch: 141, iters: 500, time: 0.228, data: 0.001) D_A: 0.159 G_A: 0.359 cycle_A: 1.328 idt_A: 0.123 D_B: 0.058 G_B: 0.621 cycle_B: 0.377 idt_B: 0.239 \n",
      "End of epoch 141 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 100, time: 0.229, data: 0.110) D_A: 0.135 G_A: 0.396 cycle_A: 1.868 idt_A: 0.105 D_B: 0.272 G_B: 0.480 cycle_B: 0.277 idt_B: 0.886 \n",
      "(epoch: 142, iters: 200, time: 0.230, data: 0.001) D_A: 0.157 G_A: 0.722 cycle_A: 0.930 idt_A: 0.172 D_B: 0.167 G_B: 0.265 cycle_B: 0.431 idt_B: 0.288 \n",
      "(epoch: 142, iters: 300, time: 0.638, data: 0.001) D_A: 0.071 G_A: 0.383 cycle_A: 1.185 idt_A: 0.168 D_B: 0.079 G_B: 0.483 cycle_B: 0.477 idt_B: 0.279 \n",
      "(epoch: 142, iters: 400, time: 0.230, data: 0.002) D_A: 0.091 G_A: 0.400 cycle_A: 0.798 idt_A: 0.131 D_B: 0.254 G_B: 0.406 cycle_B: 0.319 idt_B: 0.354 \n",
      "(epoch: 142, iters: 500, time: 0.231, data: 0.002) D_A: 0.138 G_A: 0.505 cycle_A: 0.781 idt_A: 0.120 D_B: 0.145 G_B: 0.943 cycle_B: 0.382 idt_B: 0.273 \n",
      "End of epoch 142 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 100, time: 0.229, data: 0.098) D_A: 0.192 G_A: 0.973 cycle_A: 1.488 idt_A: 0.175 D_B: 0.183 G_B: 0.301 cycle_B: 0.406 idt_B: 0.794 \n",
      "(epoch: 143, iters: 200, time: 0.623, data: 0.001) D_A: 0.046 G_A: 0.676 cycle_A: 0.996 idt_A: 0.218 D_B: 0.140 G_B: 0.437 cycle_B: 0.654 idt_B: 0.531 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 143, iters: 300, time: 0.229, data: 0.001) D_A: 0.145 G_A: 0.262 cycle_A: 1.152 idt_A: 0.175 D_B: 0.236 G_B: 0.347 cycle_B: 0.443 idt_B: 0.494 \n",
      "(epoch: 143, iters: 400, time: 0.227, data: 0.002) D_A: 0.210 G_A: 0.307 cycle_A: 1.154 idt_A: 0.085 D_B: 0.130 G_B: 0.201 cycle_B: 0.221 idt_B: 0.455 \n",
      "(epoch: 143, iters: 500, time: 0.228, data: 0.001) D_A: 0.069 G_A: 0.511 cycle_A: 1.078 idt_A: 0.169 D_B: 0.204 G_B: 0.554 cycle_B: 0.407 idt_B: 0.653 \n",
      "End of epoch 143 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 100, time: 0.638, data: 0.099) D_A: 0.062 G_A: 0.671 cycle_A: 0.705 idt_A: 0.135 D_B: 0.177 G_B: 0.535 cycle_B: 0.371 idt_B: 0.173 \n",
      "(epoch: 144, iters: 200, time: 0.228, data: 0.001) D_A: 0.114 G_A: 0.577 cycle_A: 1.147 idt_A: 0.140 D_B: 0.347 G_B: 0.521 cycle_B: 0.370 idt_B: 0.255 \n",
      "(epoch: 144, iters: 300, time: 0.229, data: 0.001) D_A: 0.114 G_A: 0.561 cycle_A: 0.899 idt_A: 0.231 D_B: 0.105 G_B: 0.487 cycle_B: 0.558 idt_B: 0.389 \n",
      "(epoch: 144, iters: 400, time: 0.231, data: 0.002) D_A: 0.071 G_A: 0.768 cycle_A: 0.781 idt_A: 0.151 D_B: 0.117 G_B: 0.502 cycle_B: 0.487 idt_B: 0.223 \n",
      "(epoch: 144, iters: 500, time: 0.638, data: 0.002) D_A: 0.113 G_A: 0.697 cycle_A: 0.738 idt_A: 0.188 D_B: 0.131 G_B: 0.428 cycle_B: 0.514 idt_B: 0.392 \n",
      "End of epoch 144 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 100, time: 0.231, data: 0.116) D_A: 0.078 G_A: 0.827 cycle_A: 0.878 idt_A: 0.162 D_B: 0.174 G_B: 0.401 cycle_B: 0.496 idt_B: 0.414 \n",
      "(epoch: 145, iters: 200, time: 0.228, data: 0.002) D_A: 0.159 G_A: 0.542 cycle_A: 0.813 idt_A: 0.174 D_B: 0.193 G_B: 0.444 cycle_B: 0.443 idt_B: 0.291 \n",
      "(epoch: 145, iters: 300, time: 0.228, data: 0.002) D_A: 0.047 G_A: 0.807 cycle_A: 1.123 idt_A: 0.142 D_B: 0.101 G_B: 0.640 cycle_B: 0.442 idt_B: 0.335 \n",
      "(epoch: 145, iters: 400, time: 0.672, data: 0.001) D_A: 0.102 G_A: 0.628 cycle_A: 0.913 idt_A: 0.181 D_B: 0.191 G_B: 0.569 cycle_B: 0.553 idt_B: 0.251 \n",
      "(epoch: 145, iters: 500, time: 0.228, data: 0.002) D_A: 0.262 G_A: 0.637 cycle_A: 1.097 idt_A: 0.113 D_B: 0.158 G_B: 0.367 cycle_B: 0.341 idt_B: 0.259 \n",
      "saving the model at the end of epoch 145, iters 72500\n",
      "End of epoch 145 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 100, time: 0.228, data: 0.102) D_A: 0.345 G_A: 1.004 cycle_A: 0.778 idt_A: 0.101 D_B: 0.143 G_B: 0.392 cycle_B: 0.209 idt_B: 0.212 \n",
      "(epoch: 146, iters: 200, time: 0.230, data: 0.001) D_A: 0.165 G_A: 0.556 cycle_A: 0.781 idt_A: 0.124 D_B: 0.124 G_B: 0.521 cycle_B: 0.432 idt_B: 0.271 \n",
      "(epoch: 146, iters: 300, time: 0.663, data: 0.001) D_A: 0.115 G_A: 0.869 cycle_A: 1.077 idt_A: 0.101 D_B: 0.246 G_B: 0.501 cycle_B: 0.274 idt_B: 0.235 \n",
      "(epoch: 146, iters: 400, time: 0.229, data: 0.002) D_A: 0.157 G_A: 0.748 cycle_A: 0.871 idt_A: 0.141 D_B: 0.208 G_B: 0.284 cycle_B: 0.365 idt_B: 0.274 \n",
      "(epoch: 146, iters: 500, time: 0.229, data: 0.002) D_A: 0.054 G_A: 0.672 cycle_A: 1.160 idt_A: 0.202 D_B: 0.125 G_B: 0.373 cycle_B: 0.405 idt_B: 0.245 \n",
      "End of epoch 146 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 100, time: 0.229, data: 0.098) D_A: 0.110 G_A: 0.589 cycle_A: 1.080 idt_A: 0.130 D_B: 0.191 G_B: 0.337 cycle_B: 0.396 idt_B: 0.494 \n",
      "(epoch: 147, iters: 200, time: 0.660, data: 0.001) D_A: 0.245 G_A: 0.589 cycle_A: 1.302 idt_A: 0.153 D_B: 0.195 G_B: 0.359 cycle_B: 0.457 idt_B: 0.444 \n",
      "(epoch: 147, iters: 300, time: 0.231, data: 0.002) D_A: 0.154 G_A: 0.746 cycle_A: 0.831 idt_A: 0.193 D_B: 0.086 G_B: 0.596 cycle_B: 0.527 idt_B: 0.203 \n",
      "(epoch: 147, iters: 400, time: 0.228, data: 0.002) D_A: 0.206 G_A: 0.507 cycle_A: 1.272 idt_A: 0.101 D_B: 0.098 G_B: 0.377 cycle_B: 0.285 idt_B: 0.679 \n",
      "(epoch: 147, iters: 500, time: 0.230, data: 0.002) D_A: 0.103 G_A: 0.823 cycle_A: 1.000 idt_A: 0.113 D_B: 0.128 G_B: 0.382 cycle_B: 0.365 idt_B: 0.371 \n",
      "End of epoch 147 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 100, time: 0.650, data: 0.097) D_A: 0.156 G_A: 0.842 cycle_A: 0.668 idt_A: 0.053 D_B: 0.243 G_B: 0.251 cycle_B: 0.167 idt_B: 0.399 \n",
      "(epoch: 148, iters: 200, time: 0.229, data: 0.001) D_A: 0.035 G_A: 0.458 cycle_A: 0.987 idt_A: 0.135 D_B: 0.153 G_B: 0.620 cycle_B: 0.373 idt_B: 0.307 \n",
      "(epoch: 148, iters: 300, time: 0.228, data: 0.002) D_A: 0.110 G_A: 0.583 cycle_A: 0.799 idt_A: 0.216 D_B: 0.156 G_B: 0.270 cycle_B: 0.524 idt_B: 0.171 \n",
      "(epoch: 148, iters: 400, time: 0.231, data: 0.002) D_A: 0.112 G_A: 0.818 cycle_A: 0.829 idt_A: 0.103 D_B: 0.108 G_B: 0.622 cycle_B: 0.397 idt_B: 0.453 \n",
      "(epoch: 148, iters: 500, time: 0.624, data: 0.002) D_A: 0.068 G_A: 0.755 cycle_A: 0.500 idt_A: 0.090 D_B: 0.107 G_B: 0.198 cycle_B: 0.274 idt_B: 0.273 \n",
      "End of epoch 148 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 100, time: 0.229, data: 0.100) D_A: 0.241 G_A: 0.215 cycle_A: 0.667 idt_A: 0.151 D_B: 0.130 G_B: 0.366 cycle_B: 0.375 idt_B: 0.217 \n",
      "(epoch: 149, iters: 200, time: 0.230, data: 0.001) D_A: 0.054 G_A: 0.428 cycle_A: 0.836 idt_A: 0.158 D_B: 0.222 G_B: 0.422 cycle_B: 0.438 idt_B: 0.323 \n",
      "(epoch: 149, iters: 300, time: 0.230, data: 0.001) D_A: 0.148 G_A: 0.531 cycle_A: 0.458 idt_A: 0.205 D_B: 0.045 G_B: 0.308 cycle_B: 0.507 idt_B: 0.147 \n",
      "(epoch: 149, iters: 400, time: 0.629, data: 0.002) D_A: 0.158 G_A: 0.454 cycle_A: 0.811 idt_A: 0.095 D_B: 0.142 G_B: 0.307 cycle_B: 0.263 idt_B: 0.326 \n",
      "(epoch: 149, iters: 500, time: 0.228, data: 0.001) D_A: 0.089 G_A: 0.420 cycle_A: 1.027 idt_A: 0.274 D_B: 0.260 G_B: 0.431 cycle_B: 0.686 idt_B: 0.516 \n",
      "End of epoch 149 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 100, time: 0.230, data: 0.115) D_A: 0.230 G_A: 0.792 cycle_A: 0.918 idt_A: 0.073 D_B: 0.105 G_B: 0.401 cycle_B: 0.209 idt_B: 0.272 \n",
      "(epoch: 150, iters: 200, time: 0.232, data: 0.002) D_A: 0.237 G_A: 0.153 cycle_A: 0.848 idt_A: 0.121 D_B: 0.260 G_B: 0.179 cycle_B: 0.324 idt_B: 0.235 \n",
      "(epoch: 150, iters: 300, time: 0.676, data: 0.002) D_A: 0.081 G_A: 0.236 cycle_A: 1.444 idt_A: 0.162 D_B: 0.215 G_B: 0.377 cycle_B: 0.475 idt_B: 0.620 \n",
      "(epoch: 150, iters: 400, time: 0.230, data: 0.001) D_A: 0.162 G_A: 0.318 cycle_A: 1.283 idt_A: 0.195 D_B: 0.152 G_B: 0.435 cycle_B: 0.552 idt_B: 0.405 \n",
      "(epoch: 150, iters: 500, time: 0.229, data: 0.002) D_A: 0.224 G_A: 0.711 cycle_A: 0.711 idt_A: 0.024 D_B: 0.129 G_B: 0.355 cycle_B: 0.104 idt_B: 0.271 \n",
      "saving the latest model (epoch 150, total_iters 75000)\n",
      "saving the model at the end of epoch 150, iters 75000\n",
      "End of epoch 150 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 100, time: 0.230, data: 0.096) D_A: 0.060 G_A: 0.729 cycle_A: 0.833 idt_A: 0.151 D_B: 0.135 G_B: 0.489 cycle_B: 0.433 idt_B: 0.462 \n",
      "(epoch: 151, iters: 200, time: 0.637, data: 0.002) D_A: 0.084 G_A: 0.452 cycle_A: 0.615 idt_A: 0.111 D_B: 0.224 G_B: 0.303 cycle_B: 0.293 idt_B: 0.327 \n",
      "(epoch: 151, iters: 300, time: 0.231, data: 0.001) D_A: 0.051 G_A: 0.797 cycle_A: 0.870 idt_A: 0.135 D_B: 0.077 G_B: 0.443 cycle_B: 0.415 idt_B: 0.250 \n",
      "(epoch: 151, iters: 400, time: 0.231, data: 0.002) D_A: 0.094 G_A: 0.687 cycle_A: 0.926 idt_A: 0.113 D_B: 0.065 G_B: 0.302 cycle_B: 0.352 idt_B: 0.256 \n",
      "(epoch: 151, iters: 500, time: 0.231, data: 0.001) D_A: 0.149 G_A: 0.743 cycle_A: 0.965 idt_A: 0.139 D_B: 0.198 G_B: 0.477 cycle_B: 0.417 idt_B: 0.159 \n",
      "End of epoch 151 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 100, time: 0.692, data: 0.104) D_A: 0.031 G_A: 0.768 cycle_A: 0.773 idt_A: 0.176 D_B: 0.166 G_B: 0.570 cycle_B: 0.420 idt_B: 0.247 \n",
      "(epoch: 152, iters: 200, time: 0.227, data: 0.001) D_A: 0.295 G_A: 0.406 cycle_A: 0.942 idt_A: 0.048 D_B: 0.167 G_B: 0.479 cycle_B: 0.159 idt_B: 0.267 \n",
      "(epoch: 152, iters: 300, time: 0.229, data: 0.001) D_A: 0.089 G_A: 0.571 cycle_A: 0.718 idt_A: 0.224 D_B: 0.128 G_B: 0.600 cycle_B: 0.515 idt_B: 0.493 \n",
      "(epoch: 152, iters: 400, time: 0.230, data: 0.002) D_A: 0.161 G_A: 0.531 cycle_A: 1.105 idt_A: 0.157 D_B: 0.079 G_B: 0.738 cycle_B: 0.380 idt_B: 0.469 \n",
      "(epoch: 152, iters: 500, time: 0.660, data: 0.002) D_A: 0.129 G_A: 0.412 cycle_A: 1.067 idt_A: 0.116 D_B: 0.135 G_B: 0.260 cycle_B: 0.328 idt_B: 0.204 \n",
      "End of epoch 152 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 100, time: 0.231, data: 0.107) D_A: 0.076 G_A: 0.675 cycle_A: 0.593 idt_A: 0.257 D_B: 0.248 G_B: 0.548 cycle_B: 0.636 idt_B: 0.326 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 153, iters: 200, time: 0.228, data: 0.002) D_A: 0.210 G_A: 0.530 cycle_A: 1.254 idt_A: 0.157 D_B: 0.072 G_B: 0.631 cycle_B: 0.396 idt_B: 0.302 \n",
      "(epoch: 153, iters: 300, time: 0.229, data: 0.002) D_A: 0.095 G_A: 0.321 cycle_A: 0.704 idt_A: 0.123 D_B: 0.244 G_B: 0.357 cycle_B: 0.335 idt_B: 0.286 \n",
      "(epoch: 153, iters: 400, time: 0.677, data: 0.002) D_A: 0.208 G_A: 0.199 cycle_A: 0.779 idt_A: 0.126 D_B: 0.086 G_B: 0.590 cycle_B: 0.466 idt_B: 0.238 \n",
      "(epoch: 153, iters: 500, time: 0.228, data: 0.002) D_A: 0.089 G_A: 0.489 cycle_A: 0.942 idt_A: 0.135 D_B: 0.090 G_B: 0.611 cycle_B: 0.342 idt_B: 0.421 \n",
      "End of epoch 153 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 100, time: 0.228, data: 0.115) D_A: 0.165 G_A: 0.293 cycle_A: 1.052 idt_A: 0.185 D_B: 0.194 G_B: 0.483 cycle_B: 0.409 idt_B: 0.291 \n",
      "(epoch: 154, iters: 200, time: 0.230, data: 0.002) D_A: 0.190 G_A: 0.688 cycle_A: 1.126 idt_A: 0.098 D_B: 0.183 G_B: 0.402 cycle_B: 0.331 idt_B: 0.253 \n",
      "(epoch: 154, iters: 300, time: 0.670, data: 0.002) D_A: 0.183 G_A: 0.309 cycle_A: 1.246 idt_A: 0.126 D_B: 0.227 G_B: 0.368 cycle_B: 0.372 idt_B: 0.392 \n",
      "(epoch: 154, iters: 400, time: 0.228, data: 0.002) D_A: 0.041 G_A: 0.334 cycle_A: 0.848 idt_A: 0.140 D_B: 0.148 G_B: 0.433 cycle_B: 0.428 idt_B: 0.232 \n",
      "(epoch: 154, iters: 500, time: 0.228, data: 0.002) D_A: 0.141 G_A: 0.580 cycle_A: 0.854 idt_A: 0.193 D_B: 0.155 G_B: 0.701 cycle_B: 0.541 idt_B: 0.202 \n",
      "End of epoch 154 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 100, time: 0.228, data: 0.119) D_A: 0.257 G_A: 0.865 cycle_A: 1.018 idt_A: 0.258 D_B: 0.164 G_B: 0.571 cycle_B: 0.613 idt_B: 0.227 \n",
      "(epoch: 155, iters: 200, time: 0.679, data: 0.002) D_A: 0.220 G_A: 0.605 cycle_A: 0.575 idt_A: 0.127 D_B: 0.131 G_B: 0.509 cycle_B: 0.330 idt_B: 0.276 \n",
      "(epoch: 155, iters: 300, time: 0.228, data: 0.002) D_A: 0.089 G_A: 0.522 cycle_A: 1.088 idt_A: 0.156 D_B: 0.231 G_B: 0.349 cycle_B: 0.457 idt_B: 0.296 \n",
      "(epoch: 155, iters: 400, time: 0.230, data: 0.002) D_A: 0.287 G_A: 0.588 cycle_A: 0.765 idt_A: 0.048 D_B: 0.172 G_B: 0.538 cycle_B: 0.144 idt_B: 0.188 \n",
      "(epoch: 155, iters: 500, time: 0.228, data: 0.002) D_A: 0.071 G_A: 0.495 cycle_A: 0.855 idt_A: 0.215 D_B: 0.080 G_B: 0.472 cycle_B: 0.481 idt_B: 0.178 \n",
      "saving the model at the end of epoch 155, iters 77500\n",
      "End of epoch 155 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 100, time: 0.649, data: 0.123) D_A: 0.083 G_A: 0.423 cycle_A: 1.100 idt_A: 0.152 D_B: 0.150 G_B: 0.443 cycle_B: 0.419 idt_B: 0.353 \n",
      "(epoch: 156, iters: 200, time: 0.227, data: 0.001) D_A: 0.200 G_A: 0.929 cycle_A: 0.864 idt_A: 0.125 D_B: 0.224 G_B: 0.481 cycle_B: 0.258 idt_B: 0.243 \n",
      "(epoch: 156, iters: 300, time: 0.227, data: 0.002) D_A: 0.251 G_A: 0.878 cycle_A: 1.561 idt_A: 0.102 D_B: 0.157 G_B: 0.644 cycle_B: 0.233 idt_B: 0.546 \n",
      "(epoch: 156, iters: 400, time: 0.230, data: 0.001) D_A: 0.177 G_A: 0.656 cycle_A: 0.642 idt_A: 0.022 D_B: 0.176 G_B: 0.338 cycle_B: 0.083 idt_B: 0.268 \n",
      "(epoch: 156, iters: 500, time: 0.682, data: 0.001) D_A: 0.162 G_A: 0.367 cycle_A: 1.019 idt_A: 0.116 D_B: 0.273 G_B: 0.099 cycle_B: 0.362 idt_B: 0.529 \n",
      "End of epoch 156 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 100, time: 0.229, data: 0.101) D_A: 0.214 G_A: 0.903 cycle_A: 0.815 idt_A: 0.106 D_B: 0.062 G_B: 0.502 cycle_B: 0.270 idt_B: 0.255 \n",
      "(epoch: 157, iters: 200, time: 0.229, data: 0.002) D_A: 0.069 G_A: 0.642 cycle_A: 1.021 idt_A: 0.200 D_B: 0.085 G_B: 0.502 cycle_B: 0.526 idt_B: 0.288 \n",
      "(epoch: 157, iters: 300, time: 0.231, data: 0.002) D_A: 0.038 G_A: 0.564 cycle_A: 0.647 idt_A: 0.129 D_B: 0.177 G_B: 0.442 cycle_B: 0.337 idt_B: 0.275 \n",
      "(epoch: 157, iters: 400, time: 0.650, data: 0.001) D_A: 0.236 G_A: 0.420 cycle_A: 1.206 idt_A: 0.128 D_B: 0.116 G_B: 0.419 cycle_B: 0.308 idt_B: 0.334 \n",
      "(epoch: 157, iters: 500, time: 0.229, data: 0.002) D_A: 0.155 G_A: 0.825 cycle_A: 1.284 idt_A: 0.091 D_B: 0.264 G_B: 0.441 cycle_B: 0.349 idt_B: 0.359 \n",
      "End of epoch 157 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 100, time: 0.230, data: 0.101) D_A: 0.091 G_A: 0.489 cycle_A: 0.602 idt_A: 0.213 D_B: 0.217 G_B: 0.375 cycle_B: 0.487 idt_B: 0.291 \n",
      "(epoch: 158, iters: 200, time: 0.229, data: 0.001) D_A: 0.196 G_A: 0.668 cycle_A: 1.162 idt_A: 0.059 D_B: 0.202 G_B: 0.292 cycle_B: 0.274 idt_B: 0.296 \n",
      "(epoch: 158, iters: 300, time: 0.678, data: 0.002) D_A: 0.129 G_A: 0.362 cycle_A: 0.738 idt_A: 0.146 D_B: 0.258 G_B: 0.366 cycle_B: 0.399 idt_B: 0.336 \n",
      "(epoch: 158, iters: 400, time: 0.228, data: 0.002) D_A: 0.335 G_A: 0.747 cycle_A: 0.827 idt_A: 0.048 D_B: 0.120 G_B: 0.369 cycle_B: 0.133 idt_B: 0.423 \n",
      "(epoch: 158, iters: 500, time: 0.230, data: 0.002) D_A: 0.060 G_A: 0.565 cycle_A: 0.612 idt_A: 0.112 D_B: 0.216 G_B: 0.523 cycle_B: 0.304 idt_B: 0.186 \n",
      "End of epoch 158 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 100, time: 0.230, data: 0.119) D_A: 0.093 G_A: 0.898 cycle_A: 0.922 idt_A: 0.138 D_B: 0.116 G_B: 0.315 cycle_B: 0.370 idt_B: 0.255 \n",
      "(epoch: 159, iters: 200, time: 0.689, data: 0.002) D_A: 0.069 G_A: 0.566 cycle_A: 1.068 idt_A: 0.204 D_B: 0.091 G_B: 0.374 cycle_B: 0.476 idt_B: 0.219 \n",
      "(epoch: 159, iters: 300, time: 0.231, data: 0.001) D_A: 0.223 G_A: 0.725 cycle_A: 0.871 idt_A: 0.151 D_B: 0.193 G_B: 0.329 cycle_B: 0.296 idt_B: 0.608 \n",
      "(epoch: 159, iters: 400, time: 0.232, data: 0.002) D_A: 0.112 G_A: 1.089 cycle_A: 0.602 idt_A: 0.169 D_B: 0.063 G_B: 0.339 cycle_B: 0.440 idt_B: 0.383 \n",
      "(epoch: 159, iters: 500, time: 0.229, data: 0.001) D_A: 0.193 G_A: 0.236 cycle_A: 0.694 idt_A: 0.070 D_B: 0.355 G_B: 0.376 cycle_B: 0.202 idt_B: 0.213 \n",
      "End of epoch 159 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 100, time: 0.694, data: 0.098) D_A: 0.201 G_A: 0.474 cycle_A: 1.032 idt_A: 0.046 D_B: 0.153 G_B: 0.552 cycle_B: 0.141 idt_B: 0.349 \n",
      "(epoch: 160, iters: 200, time: 0.227, data: 0.001) D_A: 0.146 G_A: 0.495 cycle_A: 0.730 idt_A: 0.097 D_B: 0.210 G_B: 0.383 cycle_B: 0.298 idt_B: 0.213 \n",
      "(epoch: 160, iters: 300, time: 0.230, data: 0.001) D_A: 0.360 G_A: 0.805 cycle_A: 0.913 idt_A: 0.064 D_B: 0.173 G_B: 0.365 cycle_B: 0.170 idt_B: 0.225 \n",
      "(epoch: 160, iters: 400, time: 0.231, data: 0.002) D_A: 0.223 G_A: 0.411 cycle_A: 0.773 idt_A: 0.096 D_B: 0.221 G_B: 0.374 cycle_B: 0.303 idt_B: 0.189 \n",
      "(epoch: 160, iters: 500, time: 0.689, data: 0.002) D_A: 0.090 G_A: 0.712 cycle_A: 1.031 idt_A: 0.143 D_B: 0.204 G_B: 0.262 cycle_B: 0.385 idt_B: 0.300 \n",
      "saving the latest model (epoch 160, total_iters 80000)\n",
      "saving the model at the end of epoch 160, iters 80000\n",
      "End of epoch 160 / 200 \t Time Taken: 115 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 100, time: 0.228, data: 0.098) D_A: 0.113 G_A: 0.317 cycle_A: 0.795 idt_A: 0.095 D_B: 0.237 G_B: 0.225 cycle_B: 0.219 idt_B: 0.362 \n",
      "(epoch: 161, iters: 200, time: 0.230, data: 0.001) D_A: 0.086 G_A: 0.460 cycle_A: 0.582 idt_A: 0.156 D_B: 0.140 G_B: 0.272 cycle_B: 0.401 idt_B: 0.204 \n",
      "(epoch: 161, iters: 300, time: 0.229, data: 0.002) D_A: 0.112 G_A: 0.417 cycle_A: 1.071 idt_A: 0.141 D_B: 0.142 G_B: 0.392 cycle_B: 0.366 idt_B: 0.233 \n",
      "(epoch: 161, iters: 400, time: 0.694, data: 0.002) D_A: 0.063 G_A: 0.737 cycle_A: 0.820 idt_A: 0.117 D_B: 0.235 G_B: 0.245 cycle_B: 0.343 idt_B: 0.275 \n",
      "(epoch: 161, iters: 500, time: 0.228, data: 0.002) D_A: 0.056 G_A: 0.846 cycle_A: 0.476 idt_A: 0.165 D_B: 0.108 G_B: 0.459 cycle_B: 0.493 idt_B: 0.171 \n",
      "End of epoch 161 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 100, time: 0.230, data: 0.101) D_A: 0.148 G_A: 0.612 cycle_A: 0.810 idt_A: 0.187 D_B: 0.085 G_B: 0.538 cycle_B: 0.524 idt_B: 0.246 \n",
      "(epoch: 162, iters: 200, time: 0.231, data: 0.002) D_A: 0.081 G_A: 0.815 cycle_A: 0.966 idt_A: 0.129 D_B: 0.267 G_B: 0.273 cycle_B: 0.390 idt_B: 0.220 \n",
      "(epoch: 162, iters: 300, time: 0.701, data: 0.002) D_A: 0.072 G_A: 0.631 cycle_A: 0.810 idt_A: 0.187 D_B: 0.095 G_B: 0.507 cycle_B: 0.648 idt_B: 0.373 \n",
      "(epoch: 162, iters: 400, time: 0.231, data: 0.002) D_A: 0.184 G_A: 0.918 cycle_A: 0.610 idt_A: 0.091 D_B: 0.074 G_B: 0.589 cycle_B: 0.237 idt_B: 0.156 \n",
      "(epoch: 162, iters: 500, time: 0.227, data: 0.001) D_A: 0.028 G_A: 0.727 cycle_A: 0.875 idt_A: 0.114 D_B: 0.119 G_B: 0.592 cycle_B: 0.351 idt_B: 0.416 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 162 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 100, time: 0.228, data: 0.097) D_A: 0.067 G_A: 0.805 cycle_A: 1.377 idt_A: 0.128 D_B: 0.123 G_B: 0.438 cycle_B: 0.384 idt_B: 0.303 \n",
      "(epoch: 163, iters: 200, time: 0.680, data: 0.002) D_A: 0.113 G_A: 0.615 cycle_A: 0.861 idt_A: 0.102 D_B: 0.249 G_B: 0.526 cycle_B: 0.265 idt_B: 0.264 \n",
      "(epoch: 163, iters: 300, time: 0.228, data: 0.002) D_A: 0.072 G_A: 0.702 cycle_A: 0.707 idt_A: 0.138 D_B: 0.105 G_B: 0.488 cycle_B: 0.397 idt_B: 0.229 \n",
      "(epoch: 163, iters: 400, time: 0.228, data: 0.001) D_A: 0.075 G_A: 0.628 cycle_A: 1.024 idt_A: 0.276 D_B: 0.104 G_B: 0.439 cycle_B: 0.536 idt_B: 0.227 \n",
      "(epoch: 163, iters: 500, time: 0.227, data: 0.002) D_A: 0.104 G_A: 0.923 cycle_A: 0.618 idt_A: 0.116 D_B: 0.138 G_B: 0.342 cycle_B: 0.408 idt_B: 0.275 \n",
      "End of epoch 163 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 100, time: 0.693, data: 0.096) D_A: 0.088 G_A: 0.424 cycle_A: 0.975 idt_A: 0.142 D_B: 0.051 G_B: 0.455 cycle_B: 0.466 idt_B: 0.242 \n",
      "(epoch: 164, iters: 200, time: 0.229, data: 0.001) D_A: 0.039 G_A: 0.981 cycle_A: 0.807 idt_A: 0.113 D_B: 0.152 G_B: 0.312 cycle_B: 0.373 idt_B: 0.339 \n",
      "(epoch: 164, iters: 300, time: 0.231, data: 0.002) D_A: 0.155 G_A: 0.163 cycle_A: 0.729 idt_A: 0.291 D_B: 0.199 G_B: 0.491 cycle_B: 0.656 idt_B: 0.167 \n",
      "(epoch: 164, iters: 400, time: 0.229, data: 0.001) D_A: 0.144 G_A: 0.380 cycle_A: 0.810 idt_A: 0.161 D_B: 0.155 G_B: 0.323 cycle_B: 0.453 idt_B: 0.717 \n",
      "(epoch: 164, iters: 500, time: 0.691, data: 0.002) D_A: 0.091 G_A: 0.593 cycle_A: 0.925 idt_A: 0.147 D_B: 0.061 G_B: 0.488 cycle_B: 0.465 idt_B: 0.502 \n",
      "End of epoch 164 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 100, time: 0.230, data: 0.096) D_A: 0.292 G_A: 0.432 cycle_A: 0.786 idt_A: 0.071 D_B: 0.114 G_B: 0.486 cycle_B: 0.222 idt_B: 0.193 \n",
      "(epoch: 165, iters: 200, time: 0.228, data: 0.002) D_A: 0.094 G_A: 0.530 cycle_A: 1.472 idt_A: 0.157 D_B: 0.132 G_B: 0.265 cycle_B: 0.427 idt_B: 0.557 \n",
      "(epoch: 165, iters: 300, time: 0.228, data: 0.002) D_A: 0.106 G_A: 0.411 cycle_A: 0.883 idt_A: 0.274 D_B: 0.157 G_B: 0.454 cycle_B: 0.708 idt_B: 0.298 \n",
      "(epoch: 165, iters: 400, time: 0.676, data: 0.002) D_A: 0.064 G_A: 0.608 cycle_A: 0.683 idt_A: 0.129 D_B: 0.158 G_B: 0.482 cycle_B: 0.418 idt_B: 0.192 \n",
      "(epoch: 165, iters: 500, time: 0.228, data: 0.001) D_A: 0.163 G_A: 0.336 cycle_A: 0.893 idt_A: 0.190 D_B: 0.061 G_B: 0.607 cycle_B: 0.492 idt_B: 0.173 \n",
      "saving the model at the end of epoch 165, iters 82500\n",
      "End of epoch 165 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 100, time: 0.229, data: 0.118) D_A: 0.029 G_A: 0.930 cycle_A: 0.796 idt_A: 0.167 D_B: 0.075 G_B: 0.526 cycle_B: 0.463 idt_B: 0.286 \n",
      "(epoch: 166, iters: 200, time: 0.229, data: 0.001) D_A: 0.104 G_A: 0.427 cycle_A: 0.864 idt_A: 0.237 D_B: 0.114 G_B: 0.642 cycle_B: 0.522 idt_B: 0.193 \n",
      "(epoch: 166, iters: 300, time: 0.692, data: 0.002) D_A: 0.255 G_A: 0.280 cycle_A: 0.754 idt_A: 0.151 D_B: 0.137 G_B: 0.469 cycle_B: 0.428 idt_B: 0.223 \n",
      "(epoch: 166, iters: 400, time: 0.230, data: 0.002) D_A: 0.146 G_A: 0.300 cycle_A: 0.902 idt_A: 0.193 D_B: 0.262 G_B: 0.486 cycle_B: 0.449 idt_B: 0.255 \n",
      "(epoch: 166, iters: 500, time: 0.230, data: 0.002) D_A: 0.109 G_A: 0.609 cycle_A: 0.825 idt_A: 0.097 D_B: 0.109 G_B: 0.272 cycle_B: 0.335 idt_B: 0.315 \n",
      "End of epoch 166 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 100, time: 0.229, data: 0.118) D_A: 0.145 G_A: 0.565 cycle_A: 0.896 idt_A: 0.267 D_B: 0.238 G_B: 0.717 cycle_B: 0.628 idt_B: 0.367 \n",
      "(epoch: 167, iters: 200, time: 0.692, data: 0.002) D_A: 0.139 G_A: 0.495 cycle_A: 0.839 idt_A: 0.130 D_B: 0.132 G_B: 0.438 cycle_B: 0.327 idt_B: 0.279 \n",
      "(epoch: 167, iters: 300, time: 0.230, data: 0.002) D_A: 0.051 G_A: 0.386 cycle_A: 0.773 idt_A: 0.169 D_B: 0.138 G_B: 0.486 cycle_B: 0.524 idt_B: 0.184 \n",
      "(epoch: 167, iters: 400, time: 0.229, data: 0.001) D_A: 0.207 G_A: 0.495 cycle_A: 0.861 idt_A: 0.125 D_B: 0.096 G_B: 0.397 cycle_B: 0.306 idt_B: 0.313 \n",
      "(epoch: 167, iters: 500, time: 0.229, data: 0.002) D_A: 0.113 G_A: 0.292 cycle_A: 0.650 idt_A: 0.118 D_B: 0.325 G_B: 0.370 cycle_B: 0.402 idt_B: 0.241 \n",
      "End of epoch 167 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 100, time: 0.696, data: 0.102) D_A: 0.067 G_A: 0.626 cycle_A: 0.875 idt_A: 0.136 D_B: 0.101 G_B: 0.318 cycle_B: 0.359 idt_B: 0.266 \n",
      "(epoch: 168, iters: 200, time: 0.231, data: 0.002) D_A: 0.147 G_A: 0.268 cycle_A: 1.106 idt_A: 0.160 D_B: 0.077 G_B: 0.559 cycle_B: 0.460 idt_B: 0.218 \n",
      "(epoch: 168, iters: 300, time: 0.227, data: 0.002) D_A: 0.210 G_A: 0.571 cycle_A: 1.232 idt_A: 0.126 D_B: 0.222 G_B: 0.542 cycle_B: 0.276 idt_B: 0.177 \n",
      "(epoch: 168, iters: 400, time: 0.228, data: 0.001) D_A: 0.121 G_A: 0.506 cycle_A: 0.714 idt_A: 0.134 D_B: 0.198 G_B: 0.285 cycle_B: 0.306 idt_B: 0.140 \n",
      "(epoch: 168, iters: 500, time: 0.701, data: 0.001) D_A: 0.107 G_A: 0.992 cycle_A: 0.763 idt_A: 0.272 D_B: 0.115 G_B: 0.350 cycle_B: 0.481 idt_B: 0.403 \n",
      "End of epoch 168 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 100, time: 0.228, data: 0.101) D_A: 0.168 G_A: 0.390 cycle_A: 0.645 idt_A: 0.163 D_B: 0.185 G_B: 0.386 cycle_B: 0.467 idt_B: 0.203 \n",
      "(epoch: 169, iters: 200, time: 0.229, data: 0.002) D_A: 0.059 G_A: 0.595 cycle_A: 0.943 idt_A: 0.138 D_B: 0.124 G_B: 0.376 cycle_B: 0.365 idt_B: 0.243 \n",
      "(epoch: 169, iters: 300, time: 0.229, data: 0.002) D_A: 0.146 G_A: 0.125 cycle_A: 2.683 idt_A: 0.153 D_B: 0.196 G_B: 0.437 cycle_B: 0.465 idt_B: 1.306 \n",
      "(epoch: 169, iters: 400, time: 0.716, data: 0.001) D_A: 0.092 G_A: 0.721 cycle_A: 0.640 idt_A: 0.211 D_B: 0.205 G_B: 0.457 cycle_B: 0.634 idt_B: 0.181 \n",
      "(epoch: 169, iters: 500, time: 0.229, data: 0.002) D_A: 0.085 G_A: 0.662 cycle_A: 0.619 idt_A: 0.092 D_B: 0.143 G_B: 0.373 cycle_B: 0.347 idt_B: 0.185 \n",
      "End of epoch 169 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 100, time: 0.228, data: 0.101) D_A: 0.055 G_A: 0.467 cycle_A: 0.928 idt_A: 0.140 D_B: 0.140 G_B: 0.472 cycle_B: 0.389 idt_B: 0.189 \n",
      "(epoch: 170, iters: 200, time: 0.229, data: 0.001) D_A: 0.065 G_A: 0.720 cycle_A: 0.729 idt_A: 0.108 D_B: 0.047 G_B: 0.569 cycle_B: 0.337 idt_B: 0.237 \n",
      "(epoch: 170, iters: 300, time: 0.703, data: 0.001) D_A: 0.076 G_A: 0.606 cycle_A: 0.608 idt_A: 0.152 D_B: 0.184 G_B: 0.421 cycle_B: 0.425 idt_B: 0.264 \n",
      "(epoch: 170, iters: 400, time: 0.230, data: 0.002) D_A: 0.167 G_A: 0.321 cycle_A: 0.757 idt_A: 0.081 D_B: 0.349 G_B: 0.438 cycle_B: 0.290 idt_B: 0.259 \n",
      "(epoch: 170, iters: 500, time: 0.228, data: 0.001) D_A: 0.178 G_A: 0.416 cycle_A: 1.673 idt_A: 0.136 D_B: 0.228 G_B: 0.166 cycle_B: 0.330 idt_B: 0.731 \n",
      "saving the latest model (epoch 170, total_iters 85000)\n",
      "saving the model at the end of epoch 170, iters 85000\n",
      "End of epoch 170 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 100, time: 0.228, data: 0.099) D_A: 0.136 G_A: 0.648 cycle_A: 0.889 idt_A: 0.166 D_B: 0.315 G_B: 0.312 cycle_B: 0.521 idt_B: 0.254 \n",
      "(epoch: 171, iters: 200, time: 0.721, data: 0.002) D_A: 0.095 G_A: 0.534 cycle_A: 0.615 idt_A: 0.242 D_B: 0.168 G_B: 0.545 cycle_B: 0.680 idt_B: 0.338 \n",
      "(epoch: 171, iters: 300, time: 0.228, data: 0.002) D_A: 0.079 G_A: 0.548 cycle_A: 0.802 idt_A: 0.185 D_B: 0.076 G_B: 0.283 cycle_B: 0.538 idt_B: 0.335 \n",
      "(epoch: 171, iters: 400, time: 0.228, data: 0.001) D_A: 0.122 G_A: 0.276 cycle_A: 0.882 idt_A: 0.125 D_B: 0.203 G_B: 0.467 cycle_B: 0.388 idt_B: 0.348 \n",
      "(epoch: 171, iters: 500, time: 0.229, data: 0.002) D_A: 0.223 G_A: 0.394 cycle_A: 0.891 idt_A: 0.115 D_B: 0.152 G_B: 0.484 cycle_B: 0.314 idt_B: 0.260 \n",
      "End of epoch 171 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 100, time: 0.701, data: 0.104) D_A: 0.051 G_A: 0.680 cycle_A: 0.686 idt_A: 0.133 D_B: 0.146 G_B: 0.562 cycle_B: 0.375 idt_B: 0.391 \n",
      "(epoch: 172, iters: 200, time: 0.228, data: 0.001) D_A: 0.159 G_A: 0.623 cycle_A: 0.935 idt_A: 0.124 D_B: 0.098 G_B: 0.216 cycle_B: 0.345 idt_B: 0.336 \n",
      "(epoch: 172, iters: 300, time: 0.229, data: 0.001) D_A: 0.128 G_A: 0.477 cycle_A: 0.476 idt_A: 0.130 D_B: 0.057 G_B: 0.568 cycle_B: 0.404 idt_B: 0.161 \n",
      "(epoch: 172, iters: 400, time: 0.228, data: 0.002) D_A: 0.131 G_A: 0.466 cycle_A: 1.207 idt_A: 0.172 D_B: 0.134 G_B: 0.369 cycle_B: 0.463 idt_B: 0.208 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 172, iters: 500, time: 0.708, data: 0.002) D_A: 0.124 G_A: 0.214 cycle_A: 0.956 idt_A: 0.140 D_B: 0.101 G_B: 0.486 cycle_B: 0.369 idt_B: 0.212 \n",
      "End of epoch 172 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 100, time: 0.229, data: 0.102) D_A: 0.084 G_A: 0.626 cycle_A: 0.649 idt_A: 0.105 D_B: 0.165 G_B: 0.392 cycle_B: 0.311 idt_B: 0.337 \n",
      "(epoch: 173, iters: 200, time: 0.229, data: 0.002) D_A: 0.103 G_A: 1.007 cycle_A: 0.934 idt_A: 0.109 D_B: 0.103 G_B: 0.292 cycle_B: 0.324 idt_B: 0.205 \n",
      "(epoch: 173, iters: 300, time: 0.232, data: 0.002) D_A: 0.145 G_A: 0.282 cycle_A: 0.893 idt_A: 0.099 D_B: 0.111 G_B: 0.409 cycle_B: 0.321 idt_B: 0.387 \n",
      "(epoch: 173, iters: 400, time: 0.719, data: 0.002) D_A: 0.136 G_A: 0.607 cycle_A: 0.814 idt_A: 0.122 D_B: 0.091 G_B: 0.509 cycle_B: 0.357 idt_B: 0.281 \n",
      "(epoch: 173, iters: 500, time: 0.228, data: 0.001) D_A: 0.111 G_A: 0.291 cycle_A: 1.177 idt_A: 0.111 D_B: 0.249 G_B: 0.266 cycle_B: 0.370 idt_B: 0.458 \n",
      "End of epoch 173 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 100, time: 0.230, data: 0.103) D_A: 0.104 G_A: 0.653 cycle_A: 0.745 idt_A: 0.102 D_B: 0.165 G_B: 0.568 cycle_B: 0.310 idt_B: 0.161 \n",
      "(epoch: 174, iters: 200, time: 0.231, data: 0.002) D_A: 0.135 G_A: 0.683 cycle_A: 0.610 idt_A: 0.115 D_B: 0.096 G_B: 0.461 cycle_B: 0.314 idt_B: 0.227 \n",
      "(epoch: 174, iters: 300, time: 0.696, data: 0.001) D_A: 0.105 G_A: 0.596 cycle_A: 0.661 idt_A: 0.104 D_B: 0.204 G_B: 0.481 cycle_B: 0.276 idt_B: 0.231 \n",
      "(epoch: 174, iters: 400, time: 0.231, data: 0.002) D_A: 0.283 G_A: 0.437 cycle_A: 0.912 idt_A: 0.092 D_B: 0.315 G_B: 0.438 cycle_B: 0.211 idt_B: 0.205 \n",
      "(epoch: 174, iters: 500, time: 0.227, data: 0.001) D_A: 0.104 G_A: 0.610 cycle_A: 0.892 idt_A: 0.131 D_B: 0.137 G_B: 0.614 cycle_B: 0.376 idt_B: 0.272 \n",
      "End of epoch 174 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 100, time: 0.230, data: 0.129) D_A: 0.132 G_A: 0.739 cycle_A: 1.203 idt_A: 0.117 D_B: 0.114 G_B: 0.427 cycle_B: 0.344 idt_B: 0.242 \n",
      "(epoch: 175, iters: 200, time: 0.707, data: 0.002) D_A: 0.150 G_A: 0.328 cycle_A: 1.142 idt_A: 0.141 D_B: 0.144 G_B: 0.422 cycle_B: 0.397 idt_B: 0.311 \n",
      "(epoch: 175, iters: 300, time: 0.228, data: 0.001) D_A: 0.078 G_A: 0.432 cycle_A: 0.871 idt_A: 0.123 D_B: 0.058 G_B: 0.676 cycle_B: 0.359 idt_B: 0.196 \n",
      "(epoch: 175, iters: 400, time: 0.229, data: 0.002) D_A: 0.163 G_A: 0.342 cycle_A: 1.024 idt_A: 0.107 D_B: 0.124 G_B: 0.484 cycle_B: 0.344 idt_B: 0.266 \n",
      "(epoch: 175, iters: 500, time: 0.230, data: 0.001) D_A: 0.185 G_A: 0.870 cycle_A: 0.964 idt_A: 0.143 D_B: 0.206 G_B: 0.451 cycle_B: 0.363 idt_B: 0.409 \n",
      "saving the model at the end of epoch 175, iters 87500\n",
      "End of epoch 175 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 100, time: 0.678, data: 0.102) D_A: 0.247 G_A: 0.458 cycle_A: 0.803 idt_A: 0.073 D_B: 0.177 G_B: 0.484 cycle_B: 0.175 idt_B: 0.188 \n",
      "(epoch: 176, iters: 200, time: 0.229, data: 0.001) D_A: 0.183 G_A: 0.518 cycle_A: 0.541 idt_A: 0.103 D_B: 0.161 G_B: 0.424 cycle_B: 0.351 idt_B: 0.246 \n",
      "(epoch: 176, iters: 300, time: 0.229, data: 0.002) D_A: 0.158 G_A: 0.415 cycle_A: 0.944 idt_A: 0.075 D_B: 0.327 G_B: 0.468 cycle_B: 0.241 idt_B: 0.232 \n",
      "(epoch: 176, iters: 400, time: 0.230, data: 0.001) D_A: 0.100 G_A: 0.475 cycle_A: 0.761 idt_A: 0.101 D_B: 0.150 G_B: 0.617 cycle_B: 0.289 idt_B: 0.188 \n",
      "(epoch: 176, iters: 500, time: 0.668, data: 0.002) D_A: 0.176 G_A: 0.439 cycle_A: 0.809 idt_A: 0.052 D_B: 0.173 G_B: 0.330 cycle_B: 0.147 idt_B: 0.343 \n",
      "End of epoch 176 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 100, time: 0.229, data: 0.119) D_A: 0.079 G_A: 0.423 cycle_A: 0.704 idt_A: 0.128 D_B: 0.125 G_B: 0.370 cycle_B: 0.343 idt_B: 0.217 \n",
      "(epoch: 177, iters: 200, time: 0.228, data: 0.001) D_A: 0.091 G_A: 0.603 cycle_A: 0.576 idt_A: 0.085 D_B: 0.233 G_B: 0.232 cycle_B: 0.262 idt_B: 0.231 \n",
      "(epoch: 177, iters: 300, time: 0.228, data: 0.001) D_A: 0.226 G_A: 0.339 cycle_A: 0.633 idt_A: 0.102 D_B: 0.216 G_B: 0.378 cycle_B: 0.293 idt_B: 0.193 \n",
      "(epoch: 177, iters: 400, time: 0.711, data: 0.001) D_A: 0.092 G_A: 0.787 cycle_A: 0.704 idt_A: 0.134 D_B: 0.194 G_B: 0.254 cycle_B: 0.384 idt_B: 0.174 \n",
      "(epoch: 177, iters: 500, time: 0.229, data: 0.002) D_A: 0.115 G_A: 0.465 cycle_A: 0.688 idt_A: 0.113 D_B: 0.175 G_B: 0.357 cycle_B: 0.299 idt_B: 0.444 \n",
      "End of epoch 177 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 100, time: 0.231, data: 0.099) D_A: 0.118 G_A: 0.891 cycle_A: 0.727 idt_A: 0.095 D_B: 0.198 G_B: 0.523 cycle_B: 0.288 idt_B: 0.273 \n",
      "(epoch: 178, iters: 200, time: 0.228, data: 0.002) D_A: 0.101 G_A: 0.810 cycle_A: 1.192 idt_A: 0.152 D_B: 0.070 G_B: 0.418 cycle_B: 0.503 idt_B: 0.332 \n",
      "(epoch: 178, iters: 300, time: 0.709, data: 0.001) D_A: 0.091 G_A: 0.541 cycle_A: 0.834 idt_A: 0.149 D_B: 0.099 G_B: 0.467 cycle_B: 0.434 idt_B: 0.242 \n",
      "(epoch: 178, iters: 400, time: 0.232, data: 0.001) D_A: 0.306 G_A: 0.427 cycle_A: 0.713 idt_A: 0.071 D_B: 0.276 G_B: 0.375 cycle_B: 0.193 idt_B: 0.341 \n",
      "(epoch: 178, iters: 500, time: 0.228, data: 0.001) D_A: 0.160 G_A: 0.539 cycle_A: 0.674 idt_A: 0.088 D_B: 0.210 G_B: 0.514 cycle_B: 0.248 idt_B: 0.265 \n",
      "End of epoch 178 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 100, time: 0.229, data: 0.102) D_A: 0.076 G_A: 0.549 cycle_A: 0.596 idt_A: 0.131 D_B: 0.154 G_B: 0.447 cycle_B: 0.389 idt_B: 0.167 \n",
      "(epoch: 179, iters: 200, time: 0.728, data: 0.002) D_A: 0.083 G_A: 0.260 cycle_A: 1.188 idt_A: 0.148 D_B: 0.082 G_B: 0.633 cycle_B: 0.447 idt_B: 0.277 \n",
      "(epoch: 179, iters: 300, time: 0.228, data: 0.001) D_A: 0.118 G_A: 0.407 cycle_A: 0.872 idt_A: 0.109 D_B: 0.186 G_B: 0.438 cycle_B: 0.302 idt_B: 0.244 \n",
      "(epoch: 179, iters: 400, time: 0.233, data: 0.002) D_A: 0.087 G_A: 0.629 cycle_A: 0.418 idt_A: 0.172 D_B: 0.108 G_B: 0.371 cycle_B: 0.511 idt_B: 0.139 \n",
      "(epoch: 179, iters: 500, time: 0.228, data: 0.001) D_A: 0.104 G_A: 0.491 cycle_A: 0.656 idt_A: 0.100 D_B: 0.108 G_B: 0.452 cycle_B: 0.317 idt_B: 0.280 \n",
      "End of epoch 179 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000416\n",
      "(epoch: 180, iters: 100, time: 0.737, data: 0.101) D_A: 0.126 G_A: 0.548 cycle_A: 1.237 idt_A: 0.176 D_B: 0.150 G_B: 0.407 cycle_B: 0.546 idt_B: 0.609 \n",
      "(epoch: 180, iters: 200, time: 0.229, data: 0.002) D_A: 0.066 G_A: 0.778 cycle_A: 0.676 idt_A: 0.124 D_B: 0.191 G_B: 0.228 cycle_B: 0.458 idt_B: 0.290 \n",
      "(epoch: 180, iters: 300, time: 0.228, data: 0.001) D_A: 0.121 G_A: 0.443 cycle_A: 0.969 idt_A: 0.120 D_B: 0.078 G_B: 0.375 cycle_B: 0.337 idt_B: 0.288 \n",
      "(epoch: 180, iters: 400, time: 0.227, data: 0.001) D_A: 0.234 G_A: 0.467 cycle_A: 0.585 idt_A: 0.061 D_B: 0.216 G_B: 0.524 cycle_B: 0.148 idt_B: 0.424 \n",
      "(epoch: 180, iters: 500, time: 0.712, data: 0.002) D_A: 0.079 G_A: 0.652 cycle_A: 0.661 idt_A: 0.166 D_B: 0.092 G_B: 0.416 cycle_B: 0.421 idt_B: 0.169 \n",
      "saving the latest model (epoch 180, total_iters 90000)\n",
      "saving the model at the end of epoch 180, iters 90000\n",
      "End of epoch 180 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 100, time: 0.228, data: 0.099) D_A: 0.235 G_A: 0.563 cycle_A: 0.786 idt_A: 0.101 D_B: 0.082 G_B: 0.439 cycle_B: 0.288 idt_B: 0.203 \n",
      "(epoch: 181, iters: 200, time: 0.229, data: 0.002) D_A: 0.080 G_A: 0.663 cycle_A: 1.025 idt_A: 0.103 D_B: 0.210 G_B: 0.493 cycle_B: 0.303 idt_B: 0.237 \n",
      "(epoch: 181, iters: 300, time: 0.233, data: 0.002) D_A: 0.084 G_A: 0.493 cycle_A: 0.808 idt_A: 0.156 D_B: 0.121 G_B: 0.371 cycle_B: 0.477 idt_B: 0.346 \n",
      "(epoch: 181, iters: 400, time: 0.722, data: 0.002) D_A: 0.132 G_A: 0.512 cycle_A: 0.712 idt_A: 0.114 D_B: 0.178 G_B: 0.292 cycle_B: 0.323 idt_B: 0.233 \n",
      "(epoch: 181, iters: 500, time: 0.229, data: 0.001) D_A: 0.209 G_A: 0.135 cycle_A: 0.624 idt_A: 0.204 D_B: 0.238 G_B: 0.544 cycle_B: 0.495 idt_B: 0.237 \n",
      "End of epoch 181 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 100, time: 0.227, data: 0.099) D_A: 0.101 G_A: 0.332 cycle_A: 0.801 idt_A: 0.117 D_B: 0.246 G_B: 0.538 cycle_B: 0.341 idt_B: 0.247 \n",
      "(epoch: 182, iters: 200, time: 0.227, data: 0.002) D_A: 0.369 G_A: 0.344 cycle_A: 0.759 idt_A: 0.050 D_B: 0.165 G_B: 0.668 cycle_B: 0.149 idt_B: 0.205 \n",
      "(epoch: 182, iters: 300, time: 0.704, data: 0.001) D_A: 0.194 G_A: 0.626 cycle_A: 0.704 idt_A: 0.043 D_B: 0.127 G_B: 0.302 cycle_B: 0.139 idt_B: 0.239 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 182, iters: 400, time: 0.228, data: 0.001) D_A: 0.097 G_A: 0.505 cycle_A: 0.815 idt_A: 0.177 D_B: 0.107 G_B: 0.424 cycle_B: 0.449 idt_B: 0.264 \n",
      "(epoch: 182, iters: 500, time: 0.229, data: 0.002) D_A: 0.074 G_A: 0.349 cycle_A: 1.117 idt_A: 0.125 D_B: 0.181 G_B: 0.405 cycle_B: 0.336 idt_B: 0.700 \n",
      "End of epoch 182 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 100, time: 0.231, data: 0.098) D_A: 0.113 G_A: 0.688 cycle_A: 1.134 idt_A: 0.114 D_B: 0.157 G_B: 0.333 cycle_B: 0.344 idt_B: 0.304 \n",
      "(epoch: 183, iters: 200, time: 0.725, data: 0.002) D_A: 0.300 G_A: 0.202 cycle_A: 0.735 idt_A: 0.106 D_B: 0.110 G_B: 0.325 cycle_B: 0.331 idt_B: 0.251 \n",
      "(epoch: 183, iters: 300, time: 0.228, data: 0.002) D_A: 0.068 G_A: 0.509 cycle_A: 0.660 idt_A: 0.113 D_B: 0.163 G_B: 0.466 cycle_B: 0.301 idt_B: 0.181 \n",
      "(epoch: 183, iters: 400, time: 0.230, data: 0.002) D_A: 0.036 G_A: 0.742 cycle_A: 0.698 idt_A: 0.187 D_B: 0.205 G_B: 0.416 cycle_B: 0.489 idt_B: 0.194 \n",
      "(epoch: 183, iters: 500, time: 0.231, data: 0.002) D_A: 0.142 G_A: 0.420 cycle_A: 0.793 idt_A: 0.158 D_B: 0.134 G_B: 0.470 cycle_B: 0.439 idt_B: 0.199 \n",
      "End of epoch 183 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 100, time: 0.740, data: 0.101) D_A: 0.226 G_A: 0.623 cycle_A: 0.878 idt_A: 0.105 D_B: 0.168 G_B: 0.455 cycle_B: 0.241 idt_B: 0.237 \n",
      "(epoch: 184, iters: 200, time: 0.228, data: 0.001) D_A: 0.194 G_A: 0.659 cycle_A: 0.756 idt_A: 0.147 D_B: 0.140 G_B: 0.177 cycle_B: 0.417 idt_B: 0.190 \n",
      "(epoch: 184, iters: 300, time: 0.230, data: 0.002) D_A: 0.217 G_A: 0.577 cycle_A: 0.506 idt_A: 0.114 D_B: 0.193 G_B: 0.438 cycle_B: 0.342 idt_B: 0.145 \n",
      "(epoch: 184, iters: 400, time: 0.229, data: 0.002) D_A: 0.078 G_A: 0.765 cycle_A: 1.325 idt_A: 0.128 D_B: 0.219 G_B: 0.396 cycle_B: 0.377 idt_B: 0.628 \n",
      "(epoch: 184, iters: 500, time: 0.716, data: 0.002) D_A: 0.080 G_A: 0.646 cycle_A: 0.532 idt_A: 0.146 D_B: 0.141 G_B: 0.567 cycle_B: 0.419 idt_B: 0.182 \n",
      "End of epoch 184 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 100, time: 0.228, data: 0.105) D_A: 0.074 G_A: 0.708 cycle_A: 0.431 idt_A: 0.092 D_B: 0.050 G_B: 0.393 cycle_B: 0.266 idt_B: 0.119 \n",
      "(epoch: 185, iters: 200, time: 0.230, data: 0.001) D_A: 0.167 G_A: 0.503 cycle_A: 0.871 idt_A: 0.144 D_B: 0.066 G_B: 0.439 cycle_B: 0.332 idt_B: 0.230 \n",
      "(epoch: 185, iters: 300, time: 0.230, data: 0.001) D_A: 0.081 G_A: 0.625 cycle_A: 0.457 idt_A: 0.127 D_B: 0.079 G_B: 0.491 cycle_B: 0.364 idt_B: 0.123 \n",
      "(epoch: 185, iters: 400, time: 0.740, data: 0.001) D_A: 0.054 G_A: 0.616 cycle_A: 0.528 idt_A: 0.157 D_B: 0.205 G_B: 0.489 cycle_B: 0.451 idt_B: 0.252 \n",
      "(epoch: 185, iters: 500, time: 0.229, data: 0.002) D_A: 0.066 G_A: 0.536 cycle_A: 0.820 idt_A: 0.182 D_B: 0.217 G_B: 0.376 cycle_B: 0.376 idt_B: 0.200 \n",
      "saving the model at the end of epoch 185, iters 92500\n",
      "End of epoch 185 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 100, time: 0.231, data: 0.096) D_A: 0.089 G_A: 0.787 cycle_A: 0.486 idt_A: 0.148 D_B: 0.116 G_B: 0.682 cycle_B: 0.389 idt_B: 0.176 \n",
      "(epoch: 186, iters: 200, time: 0.230, data: 0.001) D_A: 0.115 G_A: 0.647 cycle_A: 0.597 idt_A: 0.172 D_B: 0.089 G_B: 0.410 cycle_B: 0.332 idt_B: 0.356 \n",
      "(epoch: 186, iters: 300, time: 0.715, data: 0.001) D_A: 0.130 G_A: 0.417 cycle_A: 0.574 idt_A: 0.143 D_B: 0.192 G_B: 0.520 cycle_B: 0.431 idt_B: 0.129 \n",
      "(epoch: 186, iters: 400, time: 0.229, data: 0.001) D_A: 0.094 G_A: 0.354 cycle_A: 0.874 idt_A: 0.099 D_B: 0.124 G_B: 0.627 cycle_B: 0.275 idt_B: 0.329 \n",
      "(epoch: 186, iters: 500, time: 0.228, data: 0.001) D_A: 0.161 G_A: 0.827 cycle_A: 0.696 idt_A: 0.111 D_B: 0.134 G_B: 0.154 cycle_B: 0.369 idt_B: 0.230 \n",
      "End of epoch 186 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 100, time: 0.228, data: 0.095) D_A: 0.093 G_A: 0.645 cycle_A: 0.595 idt_A: 0.192 D_B: 0.078 G_B: 0.513 cycle_B: 0.481 idt_B: 0.151 \n",
      "(epoch: 187, iters: 200, time: 0.722, data: 0.002) D_A: 0.124 G_A: 0.977 cycle_A: 0.613 idt_A: 0.140 D_B: 0.035 G_B: 0.298 cycle_B: 0.399 idt_B: 0.123 \n",
      "(epoch: 187, iters: 300, time: 0.229, data: 0.002) D_A: 0.345 G_A: 0.292 cycle_A: 0.566 idt_A: 0.078 D_B: 0.239 G_B: 0.361 cycle_B: 0.199 idt_B: 0.267 \n",
      "(epoch: 187, iters: 400, time: 0.230, data: 0.002) D_A: 0.104 G_A: 0.624 cycle_A: 1.070 idt_A: 0.181 D_B: 0.133 G_B: 0.587 cycle_B: 0.397 idt_B: 0.252 \n",
      "(epoch: 187, iters: 500, time: 0.229, data: 0.002) D_A: 0.073 G_A: 0.577 cycle_A: 0.672 idt_A: 0.141 D_B: 0.232 G_B: 0.358 cycle_B: 0.413 idt_B: 0.210 \n",
      "End of epoch 187 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 100, time: 0.749, data: 0.099) D_A: 0.092 G_A: 0.589 cycle_A: 1.091 idt_A: 0.105 D_B: 0.069 G_B: 0.451 cycle_B: 0.302 idt_B: 0.258 \n",
      "(epoch: 188, iters: 200, time: 0.230, data: 0.002) D_A: 0.164 G_A: 0.551 cycle_A: 1.291 idt_A: 0.152 D_B: 0.211 G_B: 0.470 cycle_B: 0.423 idt_B: 0.285 \n",
      "(epoch: 188, iters: 300, time: 0.230, data: 0.002) D_A: 0.128 G_A: 0.667 cycle_A: 0.693 idt_A: 0.085 D_B: 0.158 G_B: 0.404 cycle_B: 0.291 idt_B: 0.279 \n",
      "(epoch: 188, iters: 400, time: 0.229, data: 0.002) D_A: 0.241 G_A: 0.283 cycle_A: 0.822 idt_A: 0.136 D_B: 0.194 G_B: 0.471 cycle_B: 0.348 idt_B: 0.207 \n",
      "(epoch: 188, iters: 500, time: 0.743, data: 0.002) D_A: 0.147 G_A: 0.422 cycle_A: 0.728 idt_A: 0.109 D_B: 0.277 G_B: 0.318 cycle_B: 0.348 idt_B: 0.206 \n",
      "End of epoch 188 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 100, time: 0.230, data: 0.099) D_A: 0.101 G_A: 0.560 cycle_A: 1.059 idt_A: 0.084 D_B: 0.299 G_B: 0.324 cycle_B: 0.277 idt_B: 0.303 \n",
      "(epoch: 189, iters: 200, time: 0.228, data: 0.002) D_A: 0.118 G_A: 0.676 cycle_A: 0.594 idt_A: 0.170 D_B: 0.164 G_B: 0.465 cycle_B: 0.396 idt_B: 0.186 \n",
      "(epoch: 189, iters: 300, time: 0.230, data: 0.002) D_A: 0.151 G_A: 0.519 cycle_A: 0.984 idt_A: 0.143 D_B: 0.316 G_B: 0.640 cycle_B: 0.381 idt_B: 0.299 \n",
      "(epoch: 189, iters: 400, time: 0.742, data: 0.002) D_A: 0.132 G_A: 0.574 cycle_A: 0.743 idt_A: 0.095 D_B: 0.055 G_B: 0.485 cycle_B: 0.294 idt_B: 0.185 \n",
      "(epoch: 189, iters: 500, time: 0.228, data: 0.002) D_A: 0.180 G_A: 0.534 cycle_A: 1.175 idt_A: 0.207 D_B: 0.075 G_B: 0.509 cycle_B: 0.458 idt_B: 0.283 \n",
      "End of epoch 189 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 100, time: 0.229, data: 0.122) D_A: 0.118 G_A: 0.478 cycle_A: 1.101 idt_A: 0.151 D_B: 0.044 G_B: 0.416 cycle_B: 0.385 idt_B: 0.273 \n",
      "(epoch: 190, iters: 200, time: 0.230, data: 0.002) D_A: 0.220 G_A: 0.386 cycle_A: 0.515 idt_A: 0.100 D_B: 0.351 G_B: 0.400 cycle_B: 0.227 idt_B: 0.176 \n",
      "(epoch: 190, iters: 300, time: 0.755, data: 0.002) D_A: 0.098 G_A: 0.747 cycle_A: 1.045 idt_A: 0.169 D_B: 0.172 G_B: 0.418 cycle_B: 0.481 idt_B: 0.245 \n",
      "(epoch: 190, iters: 400, time: 0.230, data: 0.002) D_A: 0.150 G_A: 0.396 cycle_A: 0.717 idt_A: 0.175 D_B: 0.260 G_B: 0.462 cycle_B: 0.422 idt_B: 0.193 \n",
      "(epoch: 190, iters: 500, time: 0.232, data: 0.001) D_A: 0.168 G_A: 0.354 cycle_A: 0.715 idt_A: 0.097 D_B: 0.135 G_B: 0.372 cycle_B: 0.296 idt_B: 0.218 \n",
      "saving the latest model (epoch 190, total_iters 95000)\n",
      "saving the model at the end of epoch 190, iters 95000\n",
      "End of epoch 190 / 200 \t Time Taken: 114 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 100, time: 0.228, data: 0.114) D_A: 0.095 G_A: 0.591 cycle_A: 1.896 idt_A: 0.224 D_B: 0.197 G_B: 0.285 cycle_B: 0.568 idt_B: 1.074 \n",
      "(epoch: 191, iters: 200, time: 0.709, data: 0.001) D_A: 0.242 G_A: 0.634 cycle_A: 0.997 idt_A: 0.111 D_B: 0.088 G_B: 0.443 cycle_B: 0.204 idt_B: 0.763 \n",
      "(epoch: 191, iters: 300, time: 0.231, data: 0.002) D_A: 0.166 G_A: 0.349 cycle_A: 0.668 idt_A: 0.109 D_B: 0.106 G_B: 0.462 cycle_B: 0.332 idt_B: 0.191 \n",
      "(epoch: 191, iters: 400, time: 0.229, data: 0.002) D_A: 0.086 G_A: 0.620 cycle_A: 0.781 idt_A: 0.137 D_B: 0.196 G_B: 0.417 cycle_B: 0.387 idt_B: 0.201 \n",
      "(epoch: 191, iters: 500, time: 0.229, data: 0.002) D_A: 0.056 G_A: 0.445 cycle_A: 0.939 idt_A: 0.113 D_B: 0.143 G_B: 0.601 cycle_B: 0.350 idt_B: 0.438 \n",
      "End of epoch 191 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 100, time: 0.760, data: 0.103) D_A: 0.062 G_A: 0.378 cycle_A: 0.857 idt_A: 0.187 D_B: 0.166 G_B: 0.464 cycle_B: 0.482 idt_B: 0.207 \n",
      "(epoch: 192, iters: 200, time: 0.227, data: 0.002) D_A: 0.047 G_A: 0.666 cycle_A: 0.806 idt_A: 0.135 D_B: 0.158 G_B: 0.630 cycle_B: 0.436 idt_B: 0.297 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 192, iters: 300, time: 0.229, data: 0.001) D_A: 0.142 G_A: 0.533 cycle_A: 1.057 idt_A: 0.155 D_B: 0.159 G_B: 0.396 cycle_B: 0.497 idt_B: 0.435 \n",
      "(epoch: 192, iters: 400, time: 0.230, data: 0.002) D_A: 0.116 G_A: 0.419 cycle_A: 0.897 idt_A: 0.101 D_B: 0.143 G_B: 0.416 cycle_B: 0.304 idt_B: 0.256 \n",
      "(epoch: 192, iters: 500, time: 0.702, data: 0.002) D_A: 0.055 G_A: 0.664 cycle_A: 1.810 idt_A: 0.138 D_B: 0.208 G_B: 0.328 cycle_B: 0.480 idt_B: 0.958 \n",
      "End of epoch 192 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 100, time: 0.228, data: 0.098) D_A: 0.091 G_A: 0.664 cycle_A: 0.729 idt_A: 0.117 D_B: 0.296 G_B: 0.429 cycle_B: 0.358 idt_B: 0.140 \n",
      "(epoch: 193, iters: 200, time: 0.227, data: 0.001) D_A: 0.281 G_A: 0.624 cycle_A: 0.777 idt_A: 0.083 D_B: 0.081 G_B: 0.324 cycle_B: 0.230 idt_B: 0.195 \n",
      "(epoch: 193, iters: 300, time: 0.231, data: 0.001) D_A: 0.077 G_A: 0.559 cycle_A: 0.580 idt_A: 0.101 D_B: 0.136 G_B: 0.432 cycle_B: 0.263 idt_B: 0.174 \n",
      "(epoch: 193, iters: 400, time: 0.752, data: 0.002) D_A: 0.173 G_A: 0.422 cycle_A: 0.748 idt_A: 0.109 D_B: 0.101 G_B: 0.420 cycle_B: 0.302 idt_B: 0.171 \n",
      "(epoch: 193, iters: 500, time: 0.231, data: 0.001) D_A: 0.230 G_A: 0.272 cycle_A: 0.677 idt_A: 0.092 D_B: 0.114 G_B: 0.488 cycle_B: 0.253 idt_B: 0.136 \n",
      "End of epoch 193 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 100, time: 0.229, data: 0.100) D_A: 0.082 G_A: 0.592 cycle_A: 0.716 idt_A: 0.174 D_B: 0.156 G_B: 0.526 cycle_B: 0.381 idt_B: 0.209 \n",
      "(epoch: 194, iters: 200, time: 0.228, data: 0.002) D_A: 0.140 G_A: 0.418 cycle_A: 0.499 idt_A: 0.102 D_B: 0.205 G_B: 0.358 cycle_B: 0.320 idt_B: 0.187 \n",
      "(epoch: 194, iters: 300, time: 0.735, data: 0.002) D_A: 0.231 G_A: 0.767 cycle_A: 0.460 idt_A: 0.058 D_B: 0.058 G_B: 0.436 cycle_B: 0.179 idt_B: 0.150 \n",
      "(epoch: 194, iters: 400, time: 0.229, data: 0.002) D_A: 0.104 G_A: 0.423 cycle_A: 0.651 idt_A: 0.154 D_B: 0.166 G_B: 0.525 cycle_B: 0.447 idt_B: 0.230 \n",
      "(epoch: 194, iters: 500, time: 0.229, data: 0.002) D_A: 0.146 G_A: 0.563 cycle_A: 1.065 idt_A: 0.091 D_B: 0.071 G_B: 0.536 cycle_B: 0.332 idt_B: 0.278 \n",
      "End of epoch 194 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 100, time: 0.229, data: 0.100) D_A: 0.072 G_A: 0.616 cycle_A: 0.570 idt_A: 0.159 D_B: 0.174 G_B: 0.458 cycle_B: 0.385 idt_B: 0.180 \n",
      "(epoch: 195, iters: 200, time: 0.758, data: 0.002) D_A: 0.121 G_A: 0.799 cycle_A: 0.459 idt_A: 0.145 D_B: 0.109 G_B: 0.405 cycle_B: 0.368 idt_B: 0.104 \n",
      "(epoch: 195, iters: 300, time: 0.230, data: 0.002) D_A: 0.253 G_A: 0.439 cycle_A: 1.106 idt_A: 0.096 D_B: 0.228 G_B: 0.523 cycle_B: 0.239 idt_B: 0.300 \n",
      "(epoch: 195, iters: 400, time: 0.230, data: 0.002) D_A: 0.170 G_A: 0.528 cycle_A: 0.757 idt_A: 0.152 D_B: 0.125 G_B: 0.495 cycle_B: 0.378 idt_B: 0.232 \n",
      "(epoch: 195, iters: 500, time: 0.229, data: 0.002) D_A: 0.093 G_A: 0.585 cycle_A: 0.837 idt_A: 0.082 D_B: 0.122 G_B: 0.377 cycle_B: 0.241 idt_B: 0.226 \n",
      "saving the model at the end of epoch 195, iters 97500\n",
      "End of epoch 195 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 100, time: 0.757, data: 0.097) D_A: 0.087 G_A: 0.621 cycle_A: 0.651 idt_A: 0.139 D_B: 0.149 G_B: 0.364 cycle_B: 0.311 idt_B: 0.220 \n",
      "(epoch: 196, iters: 200, time: 0.228, data: 0.002) D_A: 0.075 G_A: 0.578 cycle_A: 0.711 idt_A: 0.150 D_B: 0.111 G_B: 0.393 cycle_B: 0.381 idt_B: 0.170 \n",
      "(epoch: 196, iters: 300, time: 0.229, data: 0.002) D_A: 0.091 G_A: 0.553 cycle_A: 0.630 idt_A: 0.153 D_B: 0.116 G_B: 0.482 cycle_B: 0.380 idt_B: 0.165 \n",
      "(epoch: 196, iters: 400, time: 0.230, data: 0.002) D_A: 0.107 G_A: 0.509 cycle_A: 0.626 idt_A: 0.117 D_B: 0.198 G_B: 0.557 cycle_B: 0.354 idt_B: 0.331 \n",
      "(epoch: 196, iters: 500, time: 0.741, data: 0.001) D_A: 0.081 G_A: 0.781 cycle_A: 0.483 idt_A: 0.119 D_B: 0.107 G_B: 0.404 cycle_B: 0.346 idt_B: 0.157 \n",
      "End of epoch 196 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 100, time: 0.231, data: 0.097) D_A: 0.100 G_A: 0.513 cycle_A: 0.434 idt_A: 0.110 D_B: 0.316 G_B: 0.393 cycle_B: 0.349 idt_B: 0.207 \n",
      "(epoch: 197, iters: 200, time: 0.228, data: 0.001) D_A: 0.122 G_A: 0.348 cycle_A: 0.738 idt_A: 0.129 D_B: 0.174 G_B: 0.398 cycle_B: 0.405 idt_B: 0.192 \n",
      "(epoch: 197, iters: 300, time: 0.232, data: 0.001) D_A: 0.130 G_A: 0.451 cycle_A: 0.505 idt_A: 0.177 D_B: 0.297 G_B: 0.349 cycle_B: 0.446 idt_B: 0.157 \n",
      "(epoch: 197, iters: 400, time: 0.758, data: 0.001) D_A: 0.089 G_A: 0.644 cycle_A: 0.606 idt_A: 0.182 D_B: 0.283 G_B: 0.362 cycle_B: 0.466 idt_B: 0.239 \n",
      "(epoch: 197, iters: 500, time: 0.228, data: 0.002) D_A: 0.104 G_A: 0.817 cycle_A: 1.049 idt_A: 0.147 D_B: 0.082 G_B: 0.524 cycle_B: 0.452 idt_B: 0.298 \n",
      "End of epoch 197 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 100, time: 0.228, data: 0.119) D_A: 0.280 G_A: 0.373 cycle_A: 0.500 idt_A: 0.076 D_B: 0.263 G_B: 0.392 cycle_B: 0.252 idt_B: 0.201 \n",
      "(epoch: 198, iters: 200, time: 0.229, data: 0.002) D_A: 0.076 G_A: 0.476 cycle_A: 0.798 idt_A: 0.115 D_B: 0.113 G_B: 0.431 cycle_B: 0.314 idt_B: 0.194 \n",
      "(epoch: 198, iters: 300, time: 0.764, data: 0.002) D_A: 0.085 G_A: 0.631 cycle_A: 0.621 idt_A: 0.140 D_B: 0.300 G_B: 0.361 cycle_B: 0.395 idt_B: 0.173 \n",
      "(epoch: 198, iters: 400, time: 0.228, data: 0.002) D_A: 0.111 G_A: 0.627 cycle_A: 0.893 idt_A: 0.107 D_B: 0.151 G_B: 0.413 cycle_B: 0.332 idt_B: 0.357 \n",
      "(epoch: 198, iters: 500, time: 0.230, data: 0.002) D_A: 0.058 G_A: 0.531 cycle_A: 1.197 idt_A: 0.136 D_B: 0.180 G_B: 0.353 cycle_B: 0.386 idt_B: 0.696 \n",
      "End of epoch 198 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 100, time: 0.232, data: 0.118) D_A: 0.137 G_A: 0.433 cycle_A: 0.515 idt_A: 0.160 D_B: 0.139 G_B: 0.472 cycle_B: 0.370 idt_B: 0.116 \n",
      "(epoch: 199, iters: 200, time: 0.751, data: 0.002) D_A: 0.170 G_A: 0.414 cycle_A: 0.560 idt_A: 0.114 D_B: 0.156 G_B: 0.392 cycle_B: 0.353 idt_B: 0.174 \n",
      "(epoch: 199, iters: 300, time: 0.228, data: 0.002) D_A: 0.163 G_A: 0.519 cycle_A: 0.602 idt_A: 0.099 D_B: 0.085 G_B: 0.549 cycle_B: 0.274 idt_B: 0.166 \n",
      "(epoch: 199, iters: 400, time: 0.229, data: 0.002) D_A: 0.092 G_A: 0.344 cycle_A: 0.852 idt_A: 0.201 D_B: 0.155 G_B: 0.445 cycle_B: 0.449 idt_B: 0.257 \n",
      "(epoch: 199, iters: 500, time: 0.229, data: 0.002) D_A: 0.087 G_A: 0.632 cycle_A: 0.849 idt_A: 0.159 D_B: 0.070 G_B: 0.507 cycle_B: 0.338 idt_B: 0.222 \n",
      "End of epoch 199 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 100, time: 0.768, data: 0.103) D_A: 0.072 G_A: 0.625 cycle_A: 0.601 idt_A: 0.128 D_B: 0.137 G_B: 0.500 cycle_B: 0.339 idt_B: 0.282 \n",
      "(epoch: 200, iters: 200, time: 0.232, data: 0.002) D_A: 0.105 G_A: 0.777 cycle_A: 0.732 idt_A: 0.150 D_B: 0.053 G_B: 0.552 cycle_B: 0.296 idt_B: 0.197 \n",
      "(epoch: 200, iters: 300, time: 0.230, data: 0.002) D_A: 0.118 G_A: 0.733 cycle_A: 0.592 idt_A: 0.171 D_B: 0.103 G_B: 0.494 cycle_B: 0.447 idt_B: 0.156 \n",
      "(epoch: 200, iters: 400, time: 0.228, data: 0.002) D_A: 0.132 G_A: 0.498 cycle_A: 0.850 idt_A: 0.072 D_B: 0.163 G_B: 0.553 cycle_B: 0.221 idt_B: 0.266 \n",
      "(epoch: 200, iters: 500, time: 0.730, data: 0.002) D_A: 0.045 G_A: 0.811 cycle_A: 1.293 idt_A: 0.106 D_B: 0.110 G_B: 0.474 cycle_B: 0.299 idt_B: 0.271 \n",
      "saving the latest model (epoch 200, total_iters 100000)\n",
      "saving the model at the end of epoch 200, iters 100000\n",
      "End of epoch 200 / 200 \t Time Taken: 115 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot cycleGANrealsyn --model cycle_gan --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 2  --netG resnet_9blocks --preprocess resize_and_crop --load_size 400 --crop_size 300 --name cyclerealsyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 2                             \t[default: 1]\n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: pix2pixtest                   \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: cycle756real                  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_Apr29                 \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from Apr17/cycle756real/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.366 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['pix2pixtest/test_A/002.jpg']\n",
      "processing (0005)-th image... ['pix2pixtest/test_A/012.jpg']\n",
      "processing (0010)-th image... ['pix2pixtest/test_A/024.jpg']\n",
      "processing (0015)-th image... ['pix2pixtest/test_A/043.jpg']\n",
      "The image size needs to be a multiple of 4. The loaded image size was (679, 960), so it was adjusted to (680, 960). This adjustment will be done to all images whose sizes are not multiples of 4\n",
      "processing (0020)-th image... ['pix2pixtest/test_A/2.jpg']\n",
      "processing (0025)-th image... ['pix2pixtest/test_A/6.jpeg']\n",
      "processing (0030)-th image... ['pix2pixtest/test_A/t01.jpg']\n",
      "processing (0035)-th image... ['pix2pixtest/test_A/t11.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot pix2pixtest --model test --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 2 --netG resnet_9blocks --preprocess none --name cycle756real --results_dir results_Apr29 --dataset_mode single --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 2                             \t[default: 1]\n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: testimages                    \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: cyclerealsyn                  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_cycle_e_realsyn       \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from Apr17/cyclerealsyn/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.366 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['testimages/0054-160-m3h--5-h-ksb-etanorm-g-100-200-g11.jpg']\n",
      "The image size needs to be a multiple of 4. The loaded image size was (1801, 1169), so it was adjusted to (1800, 1168). This adjustment will be done to all images whose sizes are not multiples of 4\n",
      "processing (0005)-th image... ['testimages/17J-SG02_17J-SG02 nameplate.jpeg']\n",
      "processing (0010)-th image... ['testimages/2968_3.jpeg']\n",
      "processing (0015)-th image... ['testimages/4.jpg']\n",
      "processing (0020)-th image... ['testimages/7506_3.jpeg']\n",
      "processing (0025)-th image... ['testimages/NamePlate110.jpeg']\n",
      "processing (0030)-th image... ['testimages/image_185.jpg']\n",
      "processing (0035)-th image... ['testimages/image_765.jpg']\n",
      "processing (0040)-th image... ['testimages/s-l640.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot testimages --model test --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 2 --netG resnet_9blocks --preprocess none --name cyclerealsyn --results_dir results_cycle_e_realsyn  --dataset_mode single --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 2                             \t[default: 1]\n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: testimg                       \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: cycle756real                  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_cycle_t_real          \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from Apr17/cycle756real/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.366 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['testimg/001.jpg']\n",
      "processing (0005)-th image... ['testimg/006.jpg']\n",
      "processing (0010)-th image... ['testimg/011.jpg']\n",
      "processing (0015)-th image... ['testimg/016.jpg']\n",
      "processing (0020)-th image... ['testimg/021.jpg']\n",
      "processing (0025)-th image... ['testimg/026.jpg']\n",
      "processing (0030)-th image... ['testimg/031.jpg']\n",
      "processing (0035)-th image... ['testimg/036.jpg']\n",
      "processing (0040)-th image... ['testimg/041.jpg']\n",
      "processing (0045)-th image... ['testimg/046.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot testimg --model test --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 2 --netG resnet_9blocks --preprocess none --name cycle756real --results_dir results_cycle_t_real  --dataset_mode single --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 2                             \t[default: 1]\n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: testimages                    \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: cycle756real                  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_cycle_e_real          \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from Apr17/cycle756real/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.366 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['testimages/0054-160-m3h--5-h-ksb-etanorm-g-100-200-g11.jpg']\n",
      "The image size needs to be a multiple of 4. The loaded image size was (1801, 1169), so it was adjusted to (1800, 1168). This adjustment will be done to all images whose sizes are not multiples of 4\n",
      "processing (0005)-th image... ['testimages/17J-SG02_17J-SG02 nameplate.jpeg']\n",
      "processing (0010)-th image... ['testimages/2968_3.jpeg']\n",
      "processing (0015)-th image... ['testimages/4.jpg']\n",
      "processing (0020)-th image... ['testimages/7506_3.jpeg']\n",
      "processing (0025)-th image... ['testimages/NamePlate110.jpeg']\n",
      "processing (0030)-th image... ['testimages/image_185.jpg']\n",
      "processing (0035)-th image... ['testimages/image_765.jpg']\n",
      "processing (0040)-th image... ['testimages/s-l640.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot testimages --model test --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 2 --netG resnet_9blocks --preprocess none --name cycle756real --results_dir results_cycle_e_real  --dataset_mode single --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 4                             \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: extracolor/AB                 \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: 417real                       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \t[default: batch]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 417\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.366 M\n",
      "[Network D] Total number of parameters : 2.764 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory Apr17/417real/web...\n",
      "(epoch: 1, iters: 100, time: 0.148, data: 0.138) G_GAN: 1.043 G_L1: 8.010 D_real: 0.937 D_fake: 0.664 \n",
      "(epoch: 1, iters: 200, time: 0.148, data: 0.002) G_GAN: 1.477 G_L1: 11.400 D_real: 0.342 D_fake: 0.468 \n",
      "(epoch: 1, iters: 300, time: 0.148, data: 0.002) G_GAN: 1.303 G_L1: 12.373 D_real: 0.318 D_fake: 0.450 \n",
      "(epoch: 1, iters: 400, time: 0.196, data: 0.002) G_GAN: 1.901 G_L1: 8.772 D_real: 0.955 D_fake: 0.185 \n",
      "End of epoch 1 / 200 \t Time Taken: 43 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 80, time: 0.149, data: 0.002) G_GAN: 1.714 G_L1: 12.050 D_real: 0.105 D_fake: 0.756 \n",
      "(epoch: 2, iters: 180, time: 0.150, data: 0.003) G_GAN: 1.306 G_L1: 6.828 D_real: 0.849 D_fake: 0.374 \n",
      "(epoch: 2, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.005 G_L1: 9.677 D_real: 0.758 D_fake: 0.226 \n",
      "(epoch: 2, iters: 380, time: 0.218, data: 0.002) G_GAN: 1.058 G_L1: 8.110 D_real: 0.828 D_fake: 0.370 \n",
      "End of epoch 2 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 60, time: 0.150, data: 0.002) G_GAN: 1.380 G_L1: 9.169 D_real: 0.899 D_fake: 0.424 \n",
      "(epoch: 3, iters: 160, time: 0.150, data: 0.003) G_GAN: 0.845 G_L1: 9.782 D_real: 0.549 D_fake: 0.375 \n",
      "(epoch: 3, iters: 260, time: 0.149, data: 0.003) G_GAN: 1.284 G_L1: 9.935 D_real: 0.221 D_fake: 0.351 \n",
      "(epoch: 3, iters: 360, time: 0.203, data: 0.002) G_GAN: 1.187 G_L1: 5.524 D_real: 0.946 D_fake: 0.425 \n",
      "End of epoch 3 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.284 G_L1: 9.490 D_real: 0.310 D_fake: 0.527 \n",
      "(epoch: 4, iters: 140, time: 0.150, data: 0.003) G_GAN: 1.337 G_L1: 7.262 D_real: 1.068 D_fake: 0.230 \n",
      "(epoch: 4, iters: 240, time: 0.151, data: 0.002) G_GAN: 0.991 G_L1: 7.185 D_real: 0.232 D_fake: 1.116 \n",
      "(epoch: 4, iters: 340, time: 0.214, data: 0.003) G_GAN: 1.115 G_L1: 9.363 D_real: 0.676 D_fake: 0.217 \n",
      "End of epoch 4 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.583 G_L1: 9.627 D_real: 0.696 D_fake: 0.296 \n",
      "(epoch: 5, iters: 120, time: 0.150, data: 0.003) G_GAN: 1.365 G_L1: 6.991 D_real: 1.102 D_fake: 0.178 \n",
      "(epoch: 5, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.338 G_L1: 10.680 D_real: 0.371 D_fake: 0.308 \n",
      "(epoch: 5, iters: 320, time: 0.211, data: 0.003) G_GAN: 0.952 G_L1: 9.020 D_real: 0.891 D_fake: 0.509 \n",
      "(epoch: 5, iters: 420, time: 0.104, data: 0.002) G_GAN: 1.022 G_L1: 10.311 D_real: 0.293 D_fake: 0.669 \n",
      "saving the model at the end of epoch 5, iters 2100\n",
      "End of epoch 5 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.149, data: 0.142) G_GAN: 1.093 G_L1: 7.937 D_real: 0.191 D_fake: 0.823 \n",
      "(epoch: 6, iters: 200, time: 0.150, data: 0.002) G_GAN: 0.943 G_L1: 8.853 D_real: 0.625 D_fake: 0.643 \n",
      "(epoch: 6, iters: 300, time: 0.220, data: 0.002) G_GAN: 1.160 G_L1: 7.774 D_real: 0.398 D_fake: 1.198 \n",
      "(epoch: 6, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.204 G_L1: 12.047 D_real: 0.123 D_fake: 0.482 \n",
      "End of epoch 6 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.471 G_L1: 10.895 D_real: 0.114 D_fake: 1.598 \n",
      "(epoch: 7, iters: 180, time: 0.151, data: 0.002) G_GAN: 1.294 G_L1: 8.680 D_real: 0.505 D_fake: 0.216 \n",
      "(epoch: 7, iters: 280, time: 0.211, data: 0.002) G_GAN: 0.903 G_L1: 6.567 D_real: 0.533 D_fake: 0.946 \n",
      "(epoch: 7, iters: 380, time: 0.149, data: 0.002) G_GAN: 1.102 G_L1: 7.213 D_real: 0.789 D_fake: 0.397 \n",
      "End of epoch 7 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 60, time: 0.151, data: 0.002) G_GAN: 1.428 G_L1: 8.570 D_real: 0.108 D_fake: 0.908 \n",
      "(epoch: 8, iters: 160, time: 0.150, data: 0.003) G_GAN: 1.075 G_L1: 9.041 D_real: 0.340 D_fake: 0.481 \n",
      "(epoch: 8, iters: 260, time: 0.220, data: 0.002) G_GAN: 0.467 G_L1: 6.860 D_real: 0.954 D_fake: 0.351 \n",
      "(epoch: 8, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.598 G_L1: 11.893 D_real: 0.100 D_fake: 0.729 \n",
      "End of epoch 8 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 40, time: 0.149, data: 0.003) G_GAN: 0.957 G_L1: 7.213 D_real: 0.498 D_fake: 0.672 \n",
      "(epoch: 9, iters: 140, time: 0.150, data: 0.002) G_GAN: 1.440 G_L1: 9.349 D_real: 0.624 D_fake: 0.590 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 9, iters: 240, time: 0.204, data: 0.002) G_GAN: 0.955 G_L1: 6.916 D_real: 0.334 D_fake: 0.681 \n",
      "(epoch: 9, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.253 G_L1: 8.324 D_real: 0.412 D_fake: 0.293 \n",
      "End of epoch 9 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.366 G_L1: 8.874 D_real: 0.369 D_fake: 0.832 \n",
      "(epoch: 10, iters: 120, time: 0.149, data: 0.003) G_GAN: 1.512 G_L1: 11.630 D_real: 0.215 D_fake: 0.535 \n",
      "(epoch: 10, iters: 220, time: 0.224, data: 0.002) G_GAN: 1.240 G_L1: 7.376 D_real: 0.387 D_fake: 0.665 \n",
      "(epoch: 10, iters: 320, time: 0.150, data: 0.002) G_GAN: 0.862 G_L1: 5.581 D_real: 0.441 D_fake: 0.777 \n",
      "(epoch: 10, iters: 420, time: 0.103, data: 0.002) G_GAN: 1.325 G_L1: 5.682 D_real: 1.171 D_fake: 0.143 \n",
      "saving the model at the end of epoch 10, iters 4200\n",
      "End of epoch 10 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.150, data: 0.157) G_GAN: 0.771 G_L1: 6.566 D_real: 0.692 D_fake: 0.378 \n",
      "(epoch: 11, iters: 200, time: 0.214, data: 0.002) G_GAN: 0.740 G_L1: 6.966 D_real: 0.629 D_fake: 0.663 \n",
      "(epoch: 11, iters: 300, time: 0.150, data: 0.002) G_GAN: 0.967 G_L1: 8.555 D_real: 0.737 D_fake: 0.536 \n",
      "(epoch: 11, iters: 400, time: 0.150, data: 0.002) G_GAN: 0.511 G_L1: 6.087 D_real: 0.782 D_fake: 0.372 \n",
      "End of epoch 11 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 80, time: 0.149, data: 0.002) G_GAN: 1.529 G_L1: 8.896 D_real: 0.399 D_fake: 0.890 \n",
      "(epoch: 12, iters: 180, time: 0.226, data: 0.002) G_GAN: 0.444 G_L1: 7.758 D_real: 0.759 D_fake: 0.468 \n",
      "(epoch: 12, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.776 G_L1: 11.579 D_real: 0.134 D_fake: 0.868 \n",
      "(epoch: 12, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.123 G_L1: 7.373 D_real: 0.686 D_fake: 0.395 \n",
      "saving the latest model (epoch 12, total_iters 5000)\n",
      "End of epoch 12 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 60, time: 0.150, data: 0.002) G_GAN: 1.224 G_L1: 8.476 D_real: 0.531 D_fake: 0.561 \n",
      "(epoch: 13, iters: 160, time: 0.226, data: 0.002) G_GAN: 0.988 G_L1: 7.531 D_real: 0.806 D_fake: 0.314 \n",
      "(epoch: 13, iters: 260, time: 0.150, data: 0.002) G_GAN: 1.122 G_L1: 8.361 D_real: 1.145 D_fake: 0.367 \n",
      "(epoch: 13, iters: 360, time: 0.149, data: 0.003) G_GAN: 0.942 G_L1: 7.103 D_real: 0.734 D_fake: 0.358 \n",
      "End of epoch 13 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.317 G_L1: 9.905 D_real: 0.630 D_fake: 0.313 \n",
      "(epoch: 14, iters: 140, time: 0.209, data: 0.002) G_GAN: 0.837 G_L1: 4.770 D_real: 0.728 D_fake: 0.633 \n",
      "(epoch: 14, iters: 240, time: 0.150, data: 0.002) G_GAN: 0.750 G_L1: 3.271 D_real: 0.970 D_fake: 0.458 \n",
      "(epoch: 14, iters: 340, time: 0.151, data: 0.002) G_GAN: 0.790 G_L1: 5.877 D_real: 0.900 D_fake: 0.315 \n",
      "End of epoch 14 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 20, time: 0.149, data: 0.002) G_GAN: 0.888 G_L1: 5.751 D_real: 0.572 D_fake: 0.607 \n",
      "(epoch: 15, iters: 120, time: 0.230, data: 0.001) G_GAN: 1.349 G_L1: 7.608 D_real: 0.368 D_fake: 0.558 \n",
      "(epoch: 15, iters: 220, time: 0.150, data: 0.003) G_GAN: 1.714 G_L1: 9.810 D_real: 0.203 D_fake: 1.039 \n",
      "(epoch: 15, iters: 320, time: 0.150, data: 0.002) G_GAN: 0.745 G_L1: 8.129 D_real: 0.798 D_fake: 0.369 \n",
      "(epoch: 15, iters: 420, time: 0.103, data: 0.002) G_GAN: 0.692 G_L1: 5.837 D_real: 0.399 D_fake: 1.012 \n",
      "saving the model at the end of epoch 15, iters 6300\n",
      "End of epoch 15 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 100, time: 0.216, data: 0.155) G_GAN: 1.379 G_L1: 7.316 D_real: 0.401 D_fake: 0.353 \n",
      "(epoch: 16, iters: 200, time: 0.149, data: 0.002) G_GAN: 1.084 G_L1: 6.247 D_real: 0.767 D_fake: 0.539 \n",
      "(epoch: 16, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.401 G_L1: 9.373 D_real: 0.760 D_fake: 0.416 \n",
      "(epoch: 16, iters: 400, time: 0.150, data: 0.002) G_GAN: 0.965 G_L1: 8.349 D_real: 0.696 D_fake: 0.404 \n",
      "End of epoch 16 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 80, time: 0.233, data: 0.002) G_GAN: 1.036 G_L1: 8.736 D_real: 0.552 D_fake: 0.295 \n",
      "(epoch: 17, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.396 G_L1: 8.896 D_real: 0.119 D_fake: 0.864 \n",
      "(epoch: 17, iters: 280, time: 0.150, data: 0.003) G_GAN: 0.884 G_L1: 7.375 D_real: 0.340 D_fake: 0.479 \n",
      "(epoch: 17, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.027 G_L1: 5.563 D_real: 0.373 D_fake: 0.697 \n",
      "End of epoch 17 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 60, time: 0.234, data: 0.003) G_GAN: 1.015 G_L1: 6.094 D_real: 0.317 D_fake: 0.767 \n",
      "(epoch: 18, iters: 160, time: 0.150, data: 0.002) G_GAN: 0.888 G_L1: 4.400 D_real: 0.726 D_fake: 0.558 \n",
      "(epoch: 18, iters: 260, time: 0.150, data: 0.002) G_GAN: 0.824 G_L1: 4.512 D_real: 0.664 D_fake: 0.461 \n",
      "(epoch: 18, iters: 360, time: 0.150, data: 0.003) G_GAN: 1.414 G_L1: 10.417 D_real: 0.237 D_fake: 0.510 \n",
      "End of epoch 18 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 40, time: 0.233, data: 0.003) G_GAN: 0.886 G_L1: 6.737 D_real: 0.628 D_fake: 0.496 \n",
      "(epoch: 19, iters: 140, time: 0.149, data: 0.002) G_GAN: 1.054 G_L1: 6.755 D_real: 0.436 D_fake: 0.935 \n",
      "(epoch: 19, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.293 G_L1: 6.119 D_real: 0.796 D_fake: 0.492 \n",
      "(epoch: 19, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.242 G_L1: 9.418 D_real: 0.388 D_fake: 0.312 \n",
      "End of epoch 19 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 20, time: 0.222, data: 0.003) G_GAN: 0.756 G_L1: 7.144 D_real: 1.347 D_fake: 0.450 \n",
      "(epoch: 20, iters: 120, time: 0.150, data: 0.002) G_GAN: 1.128 G_L1: 8.784 D_real: 0.530 D_fake: 0.394 \n",
      "(epoch: 20, iters: 220, time: 0.150, data: 0.002) G_GAN: 0.844 G_L1: 4.409 D_real: 1.055 D_fake: 0.358 \n",
      "(epoch: 20, iters: 320, time: 0.150, data: 0.002) G_GAN: 1.292 G_L1: 8.286 D_real: 0.248 D_fake: 0.375 \n",
      "(epoch: 20, iters: 420, time: 0.196, data: 0.002) G_GAN: 0.417 G_L1: 9.231 D_real: 1.007 D_fake: 0.242 \n",
      "saving the model at the end of epoch 20, iters 8400\n",
      "End of epoch 20 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 100, time: 0.149, data: 0.162) G_GAN: 1.061 G_L1: 7.336 D_real: 0.503 D_fake: 0.398 \n",
      "(epoch: 21, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.283 G_L1: 7.267 D_real: 0.366 D_fake: 0.525 \n",
      "(epoch: 21, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.426 G_L1: 7.641 D_real: 0.670 D_fake: 0.408 \n",
      "(epoch: 21, iters: 400, time: 0.243, data: 0.002) G_GAN: 1.453 G_L1: 7.520 D_real: 0.343 D_fake: 1.039 \n",
      "End of epoch 21 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 80, time: 0.150, data: 0.003) G_GAN: 1.069 G_L1: 5.010 D_real: 0.477 D_fake: 0.663 \n",
      "(epoch: 22, iters: 180, time: 0.150, data: 0.003) G_GAN: 1.064 G_L1: 7.260 D_real: 0.522 D_fake: 0.650 \n",
      "(epoch: 22, iters: 280, time: 0.150, data: 0.002) G_GAN: 0.958 G_L1: 5.965 D_real: 1.000 D_fake: 0.390 \n",
      "(epoch: 22, iters: 380, time: 0.239, data: 0.002) G_GAN: 1.351 G_L1: 7.869 D_real: 0.309 D_fake: 0.446 \n",
      "End of epoch 22 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 60, time: 0.150, data: 0.002) G_GAN: 1.727 G_L1: 9.675 D_real: 0.165 D_fake: 0.566 \n",
      "(epoch: 23, iters: 160, time: 0.150, data: 0.002) G_GAN: 1.460 G_L1: 7.565 D_real: 0.672 D_fake: 0.548 \n",
      "(epoch: 23, iters: 260, time: 0.150, data: 0.002) G_GAN: 1.533 G_L1: 9.326 D_real: 0.572 D_fake: 0.789 \n",
      "(epoch: 23, iters: 360, time: 0.231, data: 0.002) G_GAN: 1.362 G_L1: 9.975 D_real: 0.359 D_fake: 0.360 \n",
      "End of epoch 23 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 40, time: 0.149, data: 0.002) G_GAN: 0.775 G_L1: 5.078 D_real: 0.689 D_fake: 0.456 \n",
      "(epoch: 24, iters: 140, time: 0.150, data: 0.003) G_GAN: 0.813 G_L1: 5.567 D_real: 1.068 D_fake: 0.338 \n",
      "(epoch: 24, iters: 240, time: 0.151, data: 0.002) G_GAN: 1.429 G_L1: 7.810 D_real: 0.337 D_fake: 0.365 \n",
      "(epoch: 24, iters: 340, time: 0.230, data: 0.002) G_GAN: 0.833 G_L1: 4.520 D_real: 0.748 D_fake: 0.533 \n",
      "saving the latest model (epoch 24, total_iters 10000)\n",
      "End of epoch 24 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.304 G_L1: 6.891 D_real: 0.931 D_fake: 0.396 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 25, iters: 120, time: 0.150, data: 0.001) G_GAN: 1.254 G_L1: 5.626 D_real: 0.533 D_fake: 0.379 \n",
      "(epoch: 25, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.600 G_L1: 8.342 D_real: 0.219 D_fake: 0.750 \n",
      "(epoch: 25, iters: 320, time: 0.238, data: 0.002) G_GAN: 1.123 G_L1: 7.328 D_real: 1.010 D_fake: 0.227 \n",
      "(epoch: 25, iters: 420, time: 0.103, data: 0.002) G_GAN: 1.492 G_L1: 11.154 D_real: 0.198 D_fake: 0.247 \n",
      "saving the model at the end of epoch 25, iters 10500\n",
      "End of epoch 25 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.149, data: 0.141) G_GAN: 1.952 G_L1: 7.158 D_real: 0.949 D_fake: 1.088 \n",
      "(epoch: 26, iters: 200, time: 0.151, data: 0.002) G_GAN: 1.120 G_L1: 7.180 D_real: 0.543 D_fake: 0.423 \n",
      "(epoch: 26, iters: 300, time: 0.241, data: 0.002) G_GAN: 1.958 G_L1: 8.706 D_real: 0.407 D_fake: 0.284 \n",
      "(epoch: 26, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.442 G_L1: 7.515 D_real: 0.471 D_fake: 0.286 \n",
      "End of epoch 26 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.077 G_L1: 7.868 D_real: 0.414 D_fake: 0.401 \n",
      "(epoch: 27, iters: 180, time: 0.149, data: 0.003) G_GAN: 0.868 G_L1: 8.181 D_real: 0.892 D_fake: 0.294 \n",
      "(epoch: 27, iters: 280, time: 0.247, data: 0.002) G_GAN: 1.670 G_L1: 7.569 D_real: 0.199 D_fake: 0.517 \n",
      "(epoch: 27, iters: 380, time: 0.150, data: 0.002) G_GAN: 0.912 G_L1: 5.979 D_real: 0.919 D_fake: 0.390 \n",
      "End of epoch 27 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 60, time: 0.150, data: 0.002) G_GAN: 0.785 G_L1: 4.855 D_real: 0.808 D_fake: 0.500 \n",
      "(epoch: 28, iters: 160, time: 0.150, data: 0.002) G_GAN: 1.474 G_L1: 7.812 D_real: 0.340 D_fake: 0.446 \n",
      "(epoch: 28, iters: 260, time: 0.238, data: 0.002) G_GAN: 1.103 G_L1: 4.663 D_real: 0.879 D_fake: 0.217 \n",
      "(epoch: 28, iters: 360, time: 0.149, data: 0.002) G_GAN: 1.350 G_L1: 5.649 D_real: 0.466 D_fake: 0.382 \n",
      "End of epoch 28 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.660 G_L1: 7.255 D_real: 0.261 D_fake: 0.492 \n",
      "(epoch: 29, iters: 140, time: 0.150, data: 0.002) G_GAN: 1.279 G_L1: 5.619 D_real: 0.425 D_fake: 0.405 \n",
      "(epoch: 29, iters: 240, time: 0.219, data: 0.002) G_GAN: 1.331 G_L1: 5.250 D_real: 0.554 D_fake: 0.343 \n",
      "(epoch: 29, iters: 340, time: 0.151, data: 0.003) G_GAN: 1.258 G_L1: 5.792 D_real: 0.582 D_fake: 0.465 \n",
      "End of epoch 29 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.890 G_L1: 5.897 D_real: 0.641 D_fake: 0.680 \n",
      "(epoch: 30, iters: 120, time: 0.149, data: 0.002) G_GAN: 1.292 G_L1: 7.585 D_real: 0.512 D_fake: 0.379 \n",
      "(epoch: 30, iters: 220, time: 0.238, data: 0.003) G_GAN: 1.390 G_L1: 8.373 D_real: 0.262 D_fake: 0.503 \n",
      "(epoch: 30, iters: 320, time: 0.150, data: 0.003) G_GAN: 1.437 G_L1: 6.913 D_real: 0.280 D_fake: 0.247 \n",
      "(epoch: 30, iters: 420, time: 0.104, data: 0.003) G_GAN: 0.742 G_L1: 7.164 D_real: 0.719 D_fake: 0.207 \n",
      "saving the model at the end of epoch 30, iters 12600\n",
      "End of epoch 30 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 100, time: 0.149, data: 0.163) G_GAN: 1.148 G_L1: 5.475 D_real: 0.488 D_fake: 0.558 \n",
      "(epoch: 31, iters: 200, time: 0.240, data: 0.002) G_GAN: 1.577 G_L1: 7.178 D_real: 0.517 D_fake: 0.260 \n",
      "(epoch: 31, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.568 G_L1: 6.735 D_real: 0.356 D_fake: 0.486 \n",
      "(epoch: 31, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.068 G_L1: 4.526 D_real: 0.732 D_fake: 0.340 \n",
      "End of epoch 31 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.136 G_L1: 5.907 D_real: 0.621 D_fake: 0.249 \n",
      "(epoch: 32, iters: 180, time: 0.256, data: 0.002) G_GAN: 1.975 G_L1: 8.340 D_real: 0.203 D_fake: 0.300 \n",
      "(epoch: 32, iters: 280, time: 0.149, data: 0.002) G_GAN: 1.281 G_L1: 6.571 D_real: 0.804 D_fake: 0.623 \n",
      "(epoch: 32, iters: 380, time: 0.150, data: 0.002) G_GAN: 0.858 G_L1: 7.040 D_real: 0.909 D_fake: 0.249 \n",
      "End of epoch 32 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 60, time: 0.150, data: 0.003) G_GAN: 1.434 G_L1: 7.271 D_real: 0.389 D_fake: 0.600 \n",
      "(epoch: 33, iters: 160, time: 0.251, data: 0.002) G_GAN: 1.185 G_L1: 6.117 D_real: 1.205 D_fake: 0.153 \n",
      "(epoch: 33, iters: 260, time: 0.150, data: 0.002) G_GAN: 0.962 G_L1: 6.120 D_real: 0.581 D_fake: 0.394 \n",
      "(epoch: 33, iters: 360, time: 0.149, data: 0.002) G_GAN: 1.443 G_L1: 5.732 D_real: 0.196 D_fake: 0.670 \n",
      "End of epoch 33 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 40, time: 0.150, data: 0.002) G_GAN: 2.527 G_L1: 6.734 D_real: 0.161 D_fake: 1.012 \n",
      "(epoch: 34, iters: 140, time: 0.237, data: 0.002) G_GAN: 1.196 G_L1: 4.071 D_real: 0.490 D_fake: 0.501 \n",
      "(epoch: 34, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.642 G_L1: 9.168 D_real: 0.269 D_fake: 0.391 \n",
      "(epoch: 34, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.354 G_L1: 8.804 D_real: 0.336 D_fake: 0.379 \n",
      "End of epoch 34 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.028 G_L1: 6.786 D_real: 0.573 D_fake: 0.377 \n",
      "(epoch: 35, iters: 120, time: 0.237, data: 0.002) G_GAN: 1.570 G_L1: 6.362 D_real: 0.177 D_fake: 0.509 \n",
      "(epoch: 35, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.624 G_L1: 5.971 D_real: 0.379 D_fake: 0.639 \n",
      "(epoch: 35, iters: 320, time: 0.150, data: 0.002) G_GAN: 1.083 G_L1: 2.883 D_real: 0.531 D_fake: 0.650 \n",
      "(epoch: 35, iters: 420, time: 0.103, data: 0.003) G_GAN: 1.111 G_L1: 6.924 D_real: 0.533 D_fake: 0.470 \n",
      "saving the model at the end of epoch 35, iters 14700\n",
      "End of epoch 35 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 100, time: 0.250, data: 0.144) G_GAN: 1.223 G_L1: 5.559 D_real: 0.434 D_fake: 0.373 \n",
      "(epoch: 36, iters: 200, time: 0.150, data: 0.002) G_GAN: 2.059 G_L1: 7.262 D_real: 0.241 D_fake: 0.710 \n",
      "(epoch: 36, iters: 300, time: 0.151, data: 0.002) G_GAN: 1.203 G_L1: 7.405 D_real: 0.517 D_fake: 0.326 \n",
      "saving the latest model (epoch 36, total_iters 15000)\n",
      "(epoch: 36, iters: 400, time: 0.150, data: 0.002) G_GAN: 0.705 G_L1: 7.729 D_real: 0.597 D_fake: 0.325 \n",
      "End of epoch 36 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 80, time: 0.253, data: 0.003) G_GAN: 1.421 G_L1: 5.338 D_real: 0.359 D_fake: 0.461 \n",
      "(epoch: 37, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.712 G_L1: 7.072 D_real: 0.350 D_fake: 0.516 \n",
      "(epoch: 37, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.135 G_L1: 7.323 D_real: 0.598 D_fake: 0.183 \n",
      "(epoch: 37, iters: 380, time: 0.149, data: 0.002) G_GAN: 2.004 G_L1: 6.912 D_real: 0.463 D_fake: 0.781 \n",
      "End of epoch 37 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 60, time: 0.254, data: 0.002) G_GAN: 0.685 G_L1: 4.697 D_real: 0.891 D_fake: 0.366 \n",
      "(epoch: 38, iters: 160, time: 0.149, data: 0.002) G_GAN: 1.679 G_L1: 7.699 D_real: 0.385 D_fake: 0.494 \n",
      "(epoch: 38, iters: 260, time: 0.149, data: 0.002) G_GAN: 1.154 G_L1: 5.320 D_real: 0.357 D_fake: 0.515 \n",
      "(epoch: 38, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.256 G_L1: 10.903 D_real: 0.360 D_fake: 0.296 \n",
      "End of epoch 38 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 40, time: 0.247, data: 0.002) G_GAN: 0.766 G_L1: 5.580 D_real: 0.946 D_fake: 0.479 \n",
      "(epoch: 39, iters: 140, time: 0.150, data: 0.002) G_GAN: 1.270 G_L1: 7.844 D_real: 0.593 D_fake: 0.476 \n",
      "(epoch: 39, iters: 240, time: 0.150, data: 0.002) G_GAN: 0.860 G_L1: 5.568 D_real: 1.192 D_fake: 0.352 \n",
      "(epoch: 39, iters: 340, time: 0.149, data: 0.002) G_GAN: 1.081 G_L1: 6.188 D_real: 0.475 D_fake: 0.755 \n",
      "End of epoch 39 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 20, time: 0.266, data: 0.002) G_GAN: 1.128 G_L1: 5.712 D_real: 0.669 D_fake: 0.738 \n",
      "(epoch: 40, iters: 120, time: 0.150, data: 0.001) G_GAN: 0.715 G_L1: 5.593 D_real: 1.240 D_fake: 0.194 \n",
      "(epoch: 40, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.654 G_L1: 8.262 D_real: 0.364 D_fake: 0.687 \n",
      "(epoch: 40, iters: 320, time: 0.150, data: 0.003) G_GAN: 1.752 G_L1: 8.215 D_real: 0.238 D_fake: 0.932 \n",
      "(epoch: 40, iters: 420, time: 0.214, data: 0.002) G_GAN: 1.965 G_L1: 11.169 D_real: 0.397 D_fake: 0.661 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model at the end of epoch 40, iters 16800\n",
      "End of epoch 40 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 100, time: 0.150, data: 0.165) G_GAN: 1.188 G_L1: 5.756 D_real: 0.553 D_fake: 0.653 \n",
      "(epoch: 41, iters: 200, time: 0.150, data: 0.002) G_GAN: 2.030 G_L1: 7.855 D_real: 0.102 D_fake: 1.599 \n",
      "(epoch: 41, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.407 G_L1: 6.492 D_real: 0.636 D_fake: 0.643 \n",
      "(epoch: 41, iters: 400, time: 0.258, data: 0.002) G_GAN: 0.675 G_L1: 6.872 D_real: 0.843 D_fake: 0.338 \n",
      "End of epoch 41 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.255 G_L1: 8.262 D_real: 0.651 D_fake: 0.343 \n",
      "(epoch: 42, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.132 G_L1: 5.985 D_real: 0.614 D_fake: 0.617 \n",
      "(epoch: 42, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.198 G_L1: 5.645 D_real: 0.270 D_fake: 0.669 \n",
      "(epoch: 42, iters: 380, time: 0.263, data: 0.003) G_GAN: 1.162 G_L1: 5.559 D_real: 0.644 D_fake: 0.971 \n",
      "End of epoch 42 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 60, time: 0.150, data: 0.002) G_GAN: 1.049 G_L1: 4.570 D_real: 0.886 D_fake: 0.383 \n",
      "(epoch: 43, iters: 160, time: 0.150, data: 0.002) G_GAN: 0.864 G_L1: 5.806 D_real: 0.671 D_fake: 0.373 \n",
      "(epoch: 43, iters: 260, time: 0.150, data: 0.002) G_GAN: 0.914 G_L1: 5.402 D_real: 0.647 D_fake: 0.422 \n",
      "(epoch: 43, iters: 360, time: 0.238, data: 0.003) G_GAN: 0.987 G_L1: 2.332 D_real: 0.643 D_fake: 0.565 \n",
      "End of epoch 43 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 40, time: 0.151, data: 0.002) G_GAN: 1.179 G_L1: 7.347 D_real: 0.629 D_fake: 0.634 \n",
      "(epoch: 44, iters: 140, time: 0.150, data: 0.003) G_GAN: 0.984 G_L1: 6.876 D_real: 0.633 D_fake: 0.793 \n",
      "(epoch: 44, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.103 G_L1: 3.598 D_real: 1.164 D_fake: 0.370 \n",
      "(epoch: 44, iters: 340, time: 0.255, data: 0.002) G_GAN: 0.646 G_L1: 4.993 D_real: 0.887 D_fake: 0.321 \n",
      "End of epoch 44 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.327 G_L1: 7.067 D_real: 0.298 D_fake: 0.786 \n",
      "(epoch: 45, iters: 120, time: 0.150, data: 0.002) G_GAN: 1.291 G_L1: 6.400 D_real: 1.009 D_fake: 0.193 \n",
      "(epoch: 45, iters: 220, time: 0.150, data: 0.003) G_GAN: 1.344 G_L1: 8.333 D_real: 0.528 D_fake: 0.834 \n",
      "(epoch: 45, iters: 320, time: 0.262, data: 0.002) G_GAN: 0.527 G_L1: 5.630 D_real: 1.136 D_fake: 0.334 \n",
      "(epoch: 45, iters: 420, time: 0.103, data: 0.002) G_GAN: 0.750 G_L1: 5.721 D_real: 0.492 D_fake: 0.378 \n",
      "saving the model at the end of epoch 45, iters 18900\n",
      "End of epoch 45 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 100, time: 0.150, data: 0.137) G_GAN: 0.997 G_L1: 6.679 D_real: 0.769 D_fake: 0.553 \n",
      "(epoch: 46, iters: 200, time: 0.150, data: 0.002) G_GAN: 0.967 G_L1: 9.062 D_real: 0.352 D_fake: 0.667 \n",
      "(epoch: 46, iters: 300, time: 0.265, data: 0.002) G_GAN: 1.416 G_L1: 8.008 D_real: 0.262 D_fake: 0.754 \n",
      "(epoch: 46, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.298 G_L1: 7.053 D_real: 0.561 D_fake: 0.730 \n",
      "End of epoch 46 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 80, time: 0.150, data: 0.003) G_GAN: 1.136 G_L1: 8.829 D_real: 0.513 D_fake: 0.367 \n",
      "(epoch: 47, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.455 G_L1: 9.531 D_real: 0.705 D_fake: 0.522 \n",
      "(epoch: 47, iters: 280, time: 0.262, data: 0.002) G_GAN: 1.261 G_L1: 6.093 D_real: 0.407 D_fake: 0.580 \n",
      "(epoch: 47, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.183 G_L1: 6.438 D_real: 0.849 D_fake: 0.273 \n",
      "End of epoch 47 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 60, time: 0.150, data: 0.003) G_GAN: 1.155 G_L1: 6.246 D_real: 0.482 D_fake: 0.380 \n",
      "(epoch: 48, iters: 160, time: 0.149, data: 0.002) G_GAN: 0.991 G_L1: 4.771 D_real: 0.405 D_fake: 0.860 \n",
      "(epoch: 48, iters: 260, time: 0.269, data: 0.002) G_GAN: 0.911 G_L1: 5.310 D_real: 0.761 D_fake: 0.420 \n",
      "saving the latest model (epoch 48, total_iters 20000)\n",
      "(epoch: 48, iters: 360, time: 0.150, data: 0.002) G_GAN: 0.690 G_L1: 6.407 D_real: 1.360 D_fake: 0.216 \n",
      "End of epoch 48 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.191 G_L1: 9.540 D_real: 0.823 D_fake: 0.194 \n",
      "(epoch: 49, iters: 140, time: 0.149, data: 0.003) G_GAN: 0.989 G_L1: 5.985 D_real: 0.571 D_fake: 0.555 \n",
      "(epoch: 49, iters: 240, time: 0.278, data: 0.002) G_GAN: 0.947 G_L1: 6.338 D_real: 0.579 D_fake: 0.730 \n",
      "(epoch: 49, iters: 340, time: 0.150, data: 0.002) G_GAN: 0.902 G_L1: 8.743 D_real: 0.656 D_fake: 0.400 \n",
      "End of epoch 49 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 20, time: 0.149, data: 0.003) G_GAN: 1.486 G_L1: 6.919 D_real: 0.466 D_fake: 0.772 \n",
      "(epoch: 50, iters: 120, time: 0.150, data: 0.001) G_GAN: 1.522 G_L1: 10.682 D_real: 0.290 D_fake: 0.917 \n",
      "(epoch: 50, iters: 220, time: 0.269, data: 0.003) G_GAN: 1.290 G_L1: 8.478 D_real: 0.675 D_fake: 0.353 \n",
      "(epoch: 50, iters: 320, time: 0.150, data: 0.002) G_GAN: 0.992 G_L1: 6.190 D_real: 0.628 D_fake: 0.443 \n",
      "(epoch: 50, iters: 420, time: 0.103, data: 0.002) G_GAN: 1.497 G_L1: 0.307 D_real: 0.533 D_fake: 0.855 \n",
      "saving the model at the end of epoch 50, iters 21000\n",
      "End of epoch 50 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.149, data: 0.179) G_GAN: 1.101 G_L1: 5.988 D_real: 0.320 D_fake: 0.885 \n",
      "(epoch: 51, iters: 200, time: 0.275, data: 0.002) G_GAN: 1.767 G_L1: 9.412 D_real: 0.461 D_fake: 0.155 \n",
      "(epoch: 51, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.099 G_L1: 7.253 D_real: 0.553 D_fake: 0.544 \n",
      "(epoch: 51, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.174 G_L1: 8.279 D_real: 0.409 D_fake: 0.407 \n",
      "End of epoch 51 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.196 G_L1: 4.889 D_real: 0.525 D_fake: 0.842 \n",
      "(epoch: 52, iters: 180, time: 0.274, data: 0.003) G_GAN: 1.248 G_L1: 6.029 D_real: 0.481 D_fake: 0.866 \n",
      "(epoch: 52, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.050 G_L1: 5.022 D_real: 0.248 D_fake: 0.868 \n",
      "(epoch: 52, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.061 G_L1: 7.183 D_real: 0.323 D_fake: 0.724 \n",
      "End of epoch 52 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 60, time: 0.150, data: 0.002) G_GAN: 1.326 G_L1: 6.503 D_real: 0.227 D_fake: 0.887 \n",
      "(epoch: 53, iters: 160, time: 0.269, data: 0.002) G_GAN: 0.699 G_L1: 6.809 D_real: 0.585 D_fake: 0.460 \n",
      "(epoch: 53, iters: 260, time: 0.150, data: 0.002) G_GAN: 1.446 G_L1: 6.529 D_real: 0.239 D_fake: 0.903 \n",
      "(epoch: 53, iters: 360, time: 0.150, data: 0.002) G_GAN: 0.980 G_L1: 1.822 D_real: 0.826 D_fake: 0.511 \n",
      "End of epoch 53 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 40, time: 0.151, data: 0.002) G_GAN: 1.863 G_L1: 8.816 D_real: 0.420 D_fake: 0.396 \n",
      "(epoch: 54, iters: 140, time: 0.270, data: 0.003) G_GAN: 1.451 G_L1: 6.336 D_real: 0.323 D_fake: 1.277 \n",
      "(epoch: 54, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.268 G_L1: 4.918 D_real: 0.550 D_fake: 0.516 \n",
      "(epoch: 54, iters: 340, time: 0.150, data: 0.003) G_GAN: 1.588 G_L1: 5.828 D_real: 0.174 D_fake: 0.767 \n",
      "End of epoch 54 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 20, time: 0.149, data: 0.003) G_GAN: 1.164 G_L1: 3.836 D_real: 0.482 D_fake: 0.815 \n",
      "(epoch: 55, iters: 120, time: 0.264, data: 0.003) G_GAN: 0.737 G_L1: 6.557 D_real: 0.801 D_fake: 0.343 \n",
      "(epoch: 55, iters: 220, time: 0.150, data: 0.002) G_GAN: 0.801 G_L1: 6.310 D_real: 1.227 D_fake: 0.445 \n",
      "(epoch: 55, iters: 320, time: 0.158, data: 0.002) G_GAN: 0.942 G_L1: 4.412 D_real: 0.600 D_fake: 0.595 \n",
      "(epoch: 55, iters: 420, time: 0.103, data: 0.002) G_GAN: 0.238 G_L1: 5.952 D_real: 0.598 D_fake: 0.233 \n",
      "saving the model at the end of epoch 55, iters 23100\n",
      "End of epoch 55 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 100, time: 0.270, data: 0.140) G_GAN: 1.262 G_L1: 6.655 D_real: 0.461 D_fake: 0.642 \n",
      "(epoch: 56, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.180 G_L1: 8.227 D_real: 0.671 D_fake: 0.256 \n",
      "(epoch: 56, iters: 300, time: 0.150, data: 0.002) G_GAN: 0.909 G_L1: 5.667 D_real: 0.693 D_fake: 0.585 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 56, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.232 G_L1: 6.734 D_real: 0.500 D_fake: 0.595 \n",
      "End of epoch 56 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 80, time: 0.279, data: 0.002) G_GAN: 1.737 G_L1: 6.162 D_real: 0.520 D_fake: 0.737 \n",
      "(epoch: 57, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.227 G_L1: 4.959 D_real: 0.832 D_fake: 0.337 \n",
      "(epoch: 57, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.196 G_L1: 6.416 D_real: 0.553 D_fake: 0.499 \n",
      "(epoch: 57, iters: 380, time: 0.150, data: 0.002) G_GAN: 0.849 G_L1: 4.699 D_real: 0.935 D_fake: 0.456 \n",
      "End of epoch 57 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 60, time: 0.278, data: 0.003) G_GAN: 1.399 G_L1: 7.185 D_real: 0.548 D_fake: 0.435 \n",
      "(epoch: 58, iters: 160, time: 0.150, data: 0.002) G_GAN: 0.894 G_L1: 9.772 D_real: 0.358 D_fake: 0.723 \n",
      "(epoch: 58, iters: 260, time: 0.150, data: 0.003) G_GAN: 1.218 G_L1: 6.715 D_real: 0.457 D_fake: 0.711 \n",
      "(epoch: 58, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.630 G_L1: 6.829 D_real: 0.264 D_fake: 0.940 \n",
      "End of epoch 58 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 40, time: 0.276, data: 0.002) G_GAN: 1.603 G_L1: 7.172 D_real: 0.383 D_fake: 0.273 \n",
      "(epoch: 59, iters: 140, time: 0.150, data: 0.002) G_GAN: 0.865 G_L1: 6.873 D_real: 0.404 D_fake: 0.684 \n",
      "(epoch: 59, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.924 G_L1: 6.649 D_real: 0.087 D_fake: 1.046 \n",
      "(epoch: 59, iters: 340, time: 0.150, data: 0.002) G_GAN: 0.627 G_L1: 7.360 D_real: 1.026 D_fake: 0.473 \n",
      "End of epoch 59 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 20, time: 0.276, data: 0.002) G_GAN: 1.315 G_L1: 7.322 D_real: 0.351 D_fake: 0.494 \n",
      "(epoch: 60, iters: 120, time: 0.150, data: 0.001) G_GAN: 0.960 G_L1: 5.679 D_real: 0.943 D_fake: 0.369 \n",
      "(epoch: 60, iters: 220, time: 0.149, data: 0.003) G_GAN: 1.416 G_L1: 8.394 D_real: 0.587 D_fake: 0.527 \n",
      "saving the latest model (epoch 60, total_iters 25000)\n",
      "(epoch: 60, iters: 320, time: 0.150, data: 0.003) G_GAN: 1.011 G_L1: 7.114 D_real: 0.965 D_fake: 0.337 \n",
      "(epoch: 60, iters: 420, time: 0.236, data: 0.002) G_GAN: 0.434 G_L1: 7.020 D_real: 1.039 D_fake: 0.343 \n",
      "saving the model at the end of epoch 60, iters 25200\n",
      "End of epoch 60 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 100, time: 0.149, data: 0.163) G_GAN: 1.308 G_L1: 7.862 D_real: 0.379 D_fake: 0.726 \n",
      "(epoch: 61, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.283 G_L1: 7.037 D_real: 0.468 D_fake: 0.502 \n",
      "(epoch: 61, iters: 300, time: 0.150, data: 0.002) G_GAN: 0.949 G_L1: 4.972 D_real: 0.929 D_fake: 0.472 \n",
      "(epoch: 61, iters: 400, time: 0.278, data: 0.002) G_GAN: 0.913 G_L1: 6.220 D_real: 0.703 D_fake: 0.519 \n",
      "End of epoch 61 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 80, time: 0.149, data: 0.002) G_GAN: 1.139 G_L1: 6.933 D_real: 0.767 D_fake: 0.321 \n",
      "(epoch: 62, iters: 180, time: 0.150, data: 0.003) G_GAN: 1.319 G_L1: 7.098 D_real: 0.541 D_fake: 0.503 \n",
      "(epoch: 62, iters: 280, time: 0.150, data: 0.002) G_GAN: 0.896 G_L1: 7.956 D_real: 0.661 D_fake: 0.237 \n",
      "(epoch: 62, iters: 380, time: 0.283, data: 0.002) G_GAN: 0.581 G_L1: 7.686 D_real: 0.799 D_fake: 0.579 \n",
      "End of epoch 62 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 60, time: 0.150, data: 0.002) G_GAN: 0.838 G_L1: 6.961 D_real: 0.664 D_fake: 0.382 \n",
      "(epoch: 63, iters: 160, time: 0.150, data: 0.002) G_GAN: 0.811 G_L1: 7.685 D_real: 1.107 D_fake: 0.551 \n",
      "(epoch: 63, iters: 260, time: 0.149, data: 0.003) G_GAN: 1.175 G_L1: 6.838 D_real: 0.403 D_fake: 0.521 \n",
      "(epoch: 63, iters: 360, time: 0.279, data: 0.002) G_GAN: 1.084 G_L1: 6.077 D_real: 0.855 D_fake: 0.490 \n",
      "End of epoch 63 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.912 G_L1: 7.467 D_real: 0.300 D_fake: 0.471 \n",
      "(epoch: 64, iters: 140, time: 0.150, data: 0.002) G_GAN: 1.820 G_L1: 8.692 D_real: 0.111 D_fake: 0.750 \n",
      "(epoch: 64, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.378 G_L1: 6.371 D_real: 0.475 D_fake: 0.356 \n",
      "(epoch: 64, iters: 340, time: 0.287, data: 0.002) G_GAN: 1.201 G_L1: 4.164 D_real: 0.532 D_fake: 0.576 \n",
      "End of epoch 64 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 20, time: 0.150, data: 0.002) G_GAN: 2.165 G_L1: 8.253 D_real: 0.156 D_fake: 0.884 \n",
      "(epoch: 65, iters: 120, time: 0.149, data: 0.002) G_GAN: 1.346 G_L1: 8.975 D_real: 0.322 D_fake: 0.606 \n",
      "(epoch: 65, iters: 220, time: 0.149, data: 0.003) G_GAN: 0.810 G_L1: 6.922 D_real: 0.662 D_fake: 0.317 \n",
      "(epoch: 65, iters: 320, time: 0.285, data: 0.002) G_GAN: 0.850 G_L1: 6.406 D_real: 0.822 D_fake: 0.286 \n",
      "(epoch: 65, iters: 420, time: 0.103, data: 0.002) G_GAN: 0.581 G_L1: 6.721 D_real: 0.637 D_fake: 0.170 \n",
      "saving the model at the end of epoch 65, iters 27300\n",
      "End of epoch 65 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 100, time: 0.149, data: 0.143) G_GAN: 1.866 G_L1: 6.778 D_real: 0.201 D_fake: 0.624 \n",
      "(epoch: 66, iters: 200, time: 0.150, data: 0.002) G_GAN: 0.665 G_L1: 6.481 D_real: 1.009 D_fake: 0.269 \n",
      "(epoch: 66, iters: 300, time: 0.290, data: 0.002) G_GAN: 0.782 G_L1: 4.915 D_real: 0.587 D_fake: 0.500 \n",
      "(epoch: 66, iters: 400, time: 0.150, data: 0.001) G_GAN: 0.789 G_L1: 6.233 D_real: 0.555 D_fake: 0.608 \n",
      "End of epoch 66 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 80, time: 0.150, data: 0.002) G_GAN: 0.584 G_L1: 4.809 D_real: 0.831 D_fake: 0.155 \n",
      "(epoch: 67, iters: 180, time: 0.150, data: 0.003) G_GAN: 1.660 G_L1: 7.052 D_real: 0.389 D_fake: 0.490 \n",
      "(epoch: 67, iters: 280, time: 0.284, data: 0.002) G_GAN: 1.526 G_L1: 7.659 D_real: 0.155 D_fake: 1.037 \n",
      "(epoch: 67, iters: 380, time: 0.149, data: 0.002) G_GAN: 1.217 G_L1: 7.994 D_real: 0.338 D_fake: 0.421 \n",
      "End of epoch 67 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 60, time: 0.150, data: 0.002) G_GAN: 0.970 G_L1: 4.262 D_real: 0.656 D_fake: 0.345 \n",
      "(epoch: 68, iters: 160, time: 0.150, data: 0.003) G_GAN: 1.103 G_L1: 5.739 D_real: 0.724 D_fake: 0.259 \n",
      "(epoch: 68, iters: 260, time: 0.290, data: 0.002) G_GAN: 1.287 G_L1: 7.136 D_real: 0.379 D_fake: 0.375 \n",
      "(epoch: 68, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.576 G_L1: 6.385 D_real: 0.346 D_fake: 0.542 \n",
      "End of epoch 68 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.918 G_L1: 8.470 D_real: 0.359 D_fake: 0.501 \n",
      "(epoch: 69, iters: 140, time: 0.150, data: 0.002) G_GAN: 0.971 G_L1: 6.950 D_real: 0.479 D_fake: 0.352 \n",
      "(epoch: 69, iters: 240, time: 0.272, data: 0.003) G_GAN: 1.120 G_L1: 6.042 D_real: 0.424 D_fake: 0.817 \n",
      "(epoch: 69, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.351 G_L1: 5.980 D_real: 0.433 D_fake: 0.330 \n",
      "End of epoch 69 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 20, time: 0.150, data: 0.002) G_GAN: 1.004 G_L1: 3.961 D_real: 0.605 D_fake: 0.573 \n",
      "(epoch: 70, iters: 120, time: 0.150, data: 0.003) G_GAN: 1.673 G_L1: 7.090 D_real: 0.387 D_fake: 0.483 \n",
      "(epoch: 70, iters: 220, time: 0.292, data: 0.003) G_GAN: 1.214 G_L1: 4.840 D_real: 0.754 D_fake: 0.280 \n",
      "(epoch: 70, iters: 320, time: 0.150, data: 0.002) G_GAN: 1.006 G_L1: 7.999 D_real: 0.541 D_fake: 0.461 \n",
      "(epoch: 70, iters: 420, time: 0.103, data: 0.002) G_GAN: 0.335 G_L1: 5.344 D_real: 1.684 D_fake: 0.159 \n",
      "saving the model at the end of epoch 70, iters 29400\n",
      "End of epoch 70 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 100, time: 0.150, data: 0.143) G_GAN: 1.174 G_L1: 6.122 D_real: 0.556 D_fake: 0.444 \n",
      "(epoch: 71, iters: 200, time: 0.294, data: 0.003) G_GAN: 1.135 G_L1: 6.541 D_real: 0.374 D_fake: 0.655 \n",
      "(epoch: 71, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.097 G_L1: 7.790 D_real: 0.649 D_fake: 0.563 \n",
      "(epoch: 71, iters: 400, time: 0.150, data: 0.003) G_GAN: 1.853 G_L1: 4.831 D_real: 0.287 D_fake: 1.536 \n",
      "End of epoch 71 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 80, time: 0.149, data: 0.002) G_GAN: 0.901 G_L1: 1.600 D_real: 0.681 D_fake: 0.557 \n",
      "(epoch: 72, iters: 180, time: 0.298, data: 0.002) G_GAN: 1.135 G_L1: 7.397 D_real: 0.893 D_fake: 0.260 \n",
      "saving the latest model (epoch 72, total_iters 30000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 72, iters: 280, time: 0.149, data: 0.003) G_GAN: 1.311 G_L1: 8.341 D_real: 0.378 D_fake: 0.430 \n",
      "(epoch: 72, iters: 380, time: 0.150, data: 0.003) G_GAN: 1.269 G_L1: 6.545 D_real: 0.403 D_fake: 0.715 \n",
      "End of epoch 72 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 60, time: 0.150, data: 0.002) G_GAN: 0.998 G_L1: 7.909 D_real: 1.062 D_fake: 0.284 \n",
      "(epoch: 73, iters: 160, time: 0.291, data: 0.002) G_GAN: 1.448 G_L1: 5.848 D_real: 0.489 D_fake: 0.460 \n",
      "(epoch: 73, iters: 260, time: 0.150, data: 0.002) G_GAN: 0.866 G_L1: 6.169 D_real: 0.996 D_fake: 0.220 \n",
      "(epoch: 73, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.219 G_L1: 3.766 D_real: 0.346 D_fake: 0.522 \n",
      "End of epoch 73 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 40, time: 0.149, data: 0.002) G_GAN: 0.808 G_L1: 4.329 D_real: 0.595 D_fake: 0.403 \n",
      "(epoch: 74, iters: 140, time: 0.301, data: 0.003) G_GAN: 1.974 G_L1: 10.139 D_real: 0.168 D_fake: 0.544 \n",
      "(epoch: 74, iters: 240, time: 0.150, data: 0.002) G_GAN: 0.914 G_L1: 5.195 D_real: 1.331 D_fake: 0.357 \n",
      "(epoch: 74, iters: 340, time: 0.149, data: 0.003) G_GAN: 1.122 G_L1: 7.033 D_real: 0.654 D_fake: 0.423 \n",
      "End of epoch 74 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 20, time: 0.150, data: 0.003) G_GAN: 0.956 G_L1: 5.057 D_real: 1.014 D_fake: 0.262 \n",
      "(epoch: 75, iters: 120, time: 0.295, data: 0.003) G_GAN: 1.960 G_L1: 8.418 D_real: 0.171 D_fake: 0.923 \n",
      "(epoch: 75, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.696 G_L1: 7.608 D_real: 0.259 D_fake: 0.369 \n",
      "(epoch: 75, iters: 320, time: 0.149, data: 0.002) G_GAN: 1.089 G_L1: 7.639 D_real: 0.428 D_fake: 0.432 \n",
      "(epoch: 75, iters: 420, time: 0.103, data: 0.002) G_GAN: 0.792 G_L1: 6.210 D_real: 0.547 D_fake: 0.157 \n",
      "saving the model at the end of epoch 75, iters 31500\n",
      "End of epoch 75 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 100, time: 0.285, data: 0.167) G_GAN: 1.439 G_L1: 4.504 D_real: 0.557 D_fake: 0.306 \n",
      "(epoch: 76, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.436 G_L1: 7.932 D_real: 0.667 D_fake: 0.285 \n",
      "(epoch: 76, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.793 G_L1: 7.087 D_real: 0.297 D_fake: 0.618 \n",
      "(epoch: 76, iters: 400, time: 0.150, data: 0.002) G_GAN: 2.169 G_L1: 5.670 D_real: 0.305 D_fake: 0.900 \n",
      "End of epoch 76 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 80, time: 0.271, data: 0.002) G_GAN: 1.089 G_L1: 3.880 D_real: 0.569 D_fake: 0.824 \n",
      "(epoch: 77, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.379 G_L1: 7.390 D_real: 0.407 D_fake: 0.262 \n",
      "(epoch: 77, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.661 G_L1: 9.703 D_real: 0.196 D_fake: 0.777 \n",
      "(epoch: 77, iters: 380, time: 0.150, data: 0.003) G_GAN: 1.339 G_L1: 5.960 D_real: 0.432 D_fake: 0.334 \n",
      "End of epoch 77 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 60, time: 0.297, data: 0.002) G_GAN: 0.964 G_L1: 4.357 D_real: 0.739 D_fake: 0.472 \n",
      "(epoch: 78, iters: 160, time: 0.150, data: 0.002) G_GAN: 2.032 G_L1: 7.531 D_real: 0.204 D_fake: 0.609 \n",
      "(epoch: 78, iters: 260, time: 0.150, data: 0.002) G_GAN: 1.338 G_L1: 5.059 D_real: 0.409 D_fake: 0.663 \n",
      "(epoch: 78, iters: 360, time: 0.150, data: 0.002) G_GAN: 0.662 G_L1: 5.105 D_real: 0.818 D_fake: 0.453 \n",
      "End of epoch 78 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 40, time: 0.291, data: 0.002) G_GAN: 1.072 G_L1: 5.818 D_real: 0.323 D_fake: 0.456 \n",
      "(epoch: 79, iters: 140, time: 0.149, data: 0.002) G_GAN: 1.356 G_L1: 4.930 D_real: 0.264 D_fake: 0.866 \n",
      "(epoch: 79, iters: 240, time: 0.150, data: 0.003) G_GAN: 1.378 G_L1: 5.326 D_real: 0.520 D_fake: 0.413 \n",
      "(epoch: 79, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.067 G_L1: 4.966 D_real: 0.519 D_fake: 0.377 \n",
      "End of epoch 79 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 20, time: 0.306, data: 0.003) G_GAN: 1.418 G_L1: 6.783 D_real: 0.463 D_fake: 0.392 \n",
      "(epoch: 80, iters: 120, time: 0.149, data: 0.001) G_GAN: 1.445 G_L1: 4.991 D_real: 0.403 D_fake: 0.583 \n",
      "(epoch: 80, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.151 G_L1: 4.517 D_real: 0.892 D_fake: 0.340 \n",
      "(epoch: 80, iters: 320, time: 0.151, data: 0.002) G_GAN: 1.620 G_L1: 8.066 D_real: 0.268 D_fake: 0.376 \n",
      "(epoch: 80, iters: 420, time: 0.253, data: 0.003) G_GAN: 0.608 G_L1: 6.495 D_real: 0.660 D_fake: 0.120 \n",
      "saving the model at the end of epoch 80, iters 33600\n",
      "End of epoch 80 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 100, time: 0.149, data: 0.138) G_GAN: 0.732 G_L1: 5.647 D_real: 0.729 D_fake: 0.335 \n",
      "(epoch: 81, iters: 200, time: 0.150, data: 0.002) G_GAN: 2.345 G_L1: 8.689 D_real: 0.190 D_fake: 0.847 \n",
      "(epoch: 81, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.613 G_L1: 7.234 D_real: 0.208 D_fake: 0.854 \n",
      "(epoch: 81, iters: 400, time: 0.282, data: 0.003) G_GAN: 1.009 G_L1: 4.717 D_real: 0.737 D_fake: 0.394 \n",
      "End of epoch 81 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.260 G_L1: 7.361 D_real: 0.459 D_fake: 0.746 \n",
      "(epoch: 82, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.370 G_L1: 6.811 D_real: 0.411 D_fake: 0.627 \n",
      "(epoch: 82, iters: 280, time: 0.149, data: 0.002) G_GAN: 1.780 G_L1: 7.445 D_real: 0.304 D_fake: 0.258 \n",
      "(epoch: 82, iters: 380, time: 0.300, data: 0.002) G_GAN: 1.557 G_L1: 6.360 D_real: 0.416 D_fake: 0.745 \n",
      "End of epoch 82 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 60, time: 0.150, data: 0.002) G_GAN: 0.923 G_L1: 7.311 D_real: 0.902 D_fake: 0.390 \n",
      "(epoch: 83, iters: 160, time: 0.150, data: 0.003) G_GAN: 1.302 G_L1: 6.588 D_real: 0.598 D_fake: 0.506 \n",
      "(epoch: 83, iters: 260, time: 0.150, data: 0.003) G_GAN: 0.899 G_L1: 5.410 D_real: 0.803 D_fake: 0.374 \n",
      "(epoch: 83, iters: 360, time: 0.295, data: 0.002) G_GAN: 1.010 G_L1: 6.374 D_real: 0.588 D_fake: 0.477 \n",
      "End of epoch 83 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.029 G_L1: 5.920 D_real: 0.741 D_fake: 0.745 \n",
      "(epoch: 84, iters: 140, time: 0.150, data: 0.002) G_GAN: 1.203 G_L1: 5.332 D_real: 0.215 D_fake: 0.853 \n",
      "saving the latest model (epoch 84, total_iters 35000)\n",
      "(epoch: 84, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.694 G_L1: 5.866 D_real: 0.395 D_fake: 0.583 \n",
      "(epoch: 84, iters: 340, time: 0.314, data: 0.002) G_GAN: 1.160 G_L1: 6.503 D_real: 0.409 D_fake: 0.687 \n",
      "End of epoch 84 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 20, time: 0.150, data: 0.002) G_GAN: 2.011 G_L1: 7.282 D_real: 0.507 D_fake: 0.759 \n",
      "(epoch: 85, iters: 120, time: 0.150, data: 0.003) G_GAN: 1.572 G_L1: 6.609 D_real: 0.258 D_fake: 0.670 \n",
      "(epoch: 85, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.687 G_L1: 6.571 D_real: 0.159 D_fake: 0.739 \n",
      "(epoch: 85, iters: 320, time: 0.302, data: 0.002) G_GAN: 0.891 G_L1: 5.723 D_real: 0.573 D_fake: 0.381 \n",
      "(epoch: 85, iters: 420, time: 0.103, data: 0.002) G_GAN: 1.143 G_L1: 6.979 D_real: 0.422 D_fake: 0.226 \n",
      "saving the model at the end of epoch 85, iters 35700\n",
      "End of epoch 85 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 100, time: 0.150, data: 0.164) G_GAN: 1.395 G_L1: 5.037 D_real: 0.247 D_fake: 0.492 \n",
      "(epoch: 86, iters: 200, time: 0.151, data: 0.002) G_GAN: 0.729 G_L1: 4.731 D_real: 0.837 D_fake: 0.443 \n",
      "(epoch: 86, iters: 300, time: 0.308, data: 0.002) G_GAN: 1.750 G_L1: 6.714 D_real: 0.642 D_fake: 0.120 \n",
      "(epoch: 86, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.039 G_L1: 7.067 D_real: 1.193 D_fake: 0.262 \n",
      "End of epoch 86 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.600 G_L1: 6.559 D_real: 0.387 D_fake: 0.336 \n",
      "(epoch: 87, iters: 180, time: 0.150, data: 0.003) G_GAN: 1.007 G_L1: 5.083 D_real: 0.947 D_fake: 0.320 \n",
      "(epoch: 87, iters: 280, time: 0.293, data: 0.002) G_GAN: 1.977 G_L1: 5.306 D_real: 0.208 D_fake: 0.549 \n",
      "(epoch: 87, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.705 G_L1: 7.084 D_real: 0.385 D_fake: 0.262 \n",
      "End of epoch 87 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 60, time: 0.150, data: 0.002) G_GAN: 1.124 G_L1: 5.598 D_real: 0.390 D_fake: 0.760 \n",
      "(epoch: 88, iters: 160, time: 0.150, data: 0.002) G_GAN: 1.775 G_L1: 5.954 D_real: 0.169 D_fake: 1.140 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 88, iters: 260, time: 0.309, data: 0.002) G_GAN: 0.814 G_L1: 7.621 D_real: 0.621 D_fake: 0.229 \n",
      "(epoch: 88, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.462 G_L1: 6.611 D_real: 0.492 D_fake: 0.774 \n",
      "End of epoch 88 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 40, time: 0.149, data: 0.002) G_GAN: 1.153 G_L1: 5.821 D_real: 0.687 D_fake: 0.431 \n",
      "(epoch: 89, iters: 140, time: 0.150, data: 0.003) G_GAN: 0.504 G_L1: 4.656 D_real: 1.301 D_fake: 0.442 \n",
      "(epoch: 89, iters: 240, time: 0.309, data: 0.002) G_GAN: 1.222 G_L1: 7.524 D_real: 0.450 D_fake: 0.464 \n",
      "(epoch: 89, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.913 G_L1: 6.882 D_real: 0.621 D_fake: 0.377 \n",
      "End of epoch 89 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 20, time: 0.150, data: 0.002) G_GAN: 0.997 G_L1: 4.081 D_real: 0.912 D_fake: 0.324 \n",
      "(epoch: 90, iters: 120, time: 0.150, data: 0.002) G_GAN: 1.353 G_L1: 7.676 D_real: 0.329 D_fake: 0.360 \n",
      "(epoch: 90, iters: 220, time: 0.313, data: 0.002) G_GAN: 1.277 G_L1: 4.256 D_real: 0.558 D_fake: 0.380 \n",
      "(epoch: 90, iters: 320, time: 0.150, data: 0.002) G_GAN: 2.186 G_L1: 6.814 D_real: 0.096 D_fake: 0.650 \n",
      "(epoch: 90, iters: 420, time: 0.103, data: 0.003) G_GAN: 0.338 G_L1: 3.809 D_real: 0.891 D_fake: 0.219 \n",
      "saving the model at the end of epoch 90, iters 37800\n",
      "End of epoch 90 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 100, time: 0.150, data: 0.137) G_GAN: 1.156 G_L1: 7.149 D_real: 0.895 D_fake: 0.274 \n",
      "(epoch: 91, iters: 200, time: 0.310, data: 0.002) G_GAN: 1.767 G_L1: 5.497 D_real: 0.276 D_fake: 0.859 \n",
      "(epoch: 91, iters: 300, time: 0.149, data: 0.002) G_GAN: 1.098 G_L1: 5.586 D_real: 0.512 D_fake: 0.393 \n",
      "(epoch: 91, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.247 G_L1: 6.078 D_real: 0.302 D_fake: 0.520 \n",
      "End of epoch 91 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.088 G_L1: 5.679 D_real: 0.599 D_fake: 0.260 \n",
      "(epoch: 92, iters: 180, time: 0.317, data: 0.002) G_GAN: 1.081 G_L1: 5.920 D_real: 1.031 D_fake: 0.333 \n",
      "(epoch: 92, iters: 280, time: 0.150, data: 0.002) G_GAN: 2.569 G_L1: 9.270 D_real: 0.046 D_fake: 0.193 \n",
      "(epoch: 92, iters: 380, time: 0.150, data: 0.002) G_GAN: 0.961 G_L1: 4.386 D_real: 0.808 D_fake: 0.410 \n",
      "End of epoch 92 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 60, time: 0.150, data: 0.003) G_GAN: 1.917 G_L1: 8.383 D_real: 0.401 D_fake: 0.226 \n",
      "(epoch: 93, iters: 160, time: 0.285, data: 0.003) G_GAN: 0.863 G_L1: 4.478 D_real: 0.960 D_fake: 0.184 \n",
      "(epoch: 93, iters: 260, time: 0.149, data: 0.002) G_GAN: 0.826 G_L1: 5.663 D_real: 1.010 D_fake: 0.216 \n",
      "(epoch: 93, iters: 360, time: 0.151, data: 0.002) G_GAN: 0.991 G_L1: 7.485 D_real: 1.234 D_fake: 0.170 \n",
      "End of epoch 93 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.933 G_L1: 7.070 D_real: 0.217 D_fake: 1.108 \n",
      "(epoch: 94, iters: 140, time: 0.314, data: 0.002) G_GAN: 1.561 G_L1: 6.363 D_real: 0.963 D_fake: 1.054 \n",
      "(epoch: 94, iters: 240, time: 0.149, data: 0.002) G_GAN: 1.076 G_L1: 4.728 D_real: 0.596 D_fake: 0.347 \n",
      "(epoch: 94, iters: 340, time: 0.149, data: 0.002) G_GAN: 1.181 G_L1: 5.663 D_real: 0.447 D_fake: 0.370 \n",
      "End of epoch 94 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.427 G_L1: 7.745 D_real: 0.635 D_fake: 0.505 \n",
      "(epoch: 95, iters: 120, time: 0.294, data: 0.001) G_GAN: 1.861 G_L1: 6.027 D_real: 0.838 D_fake: 0.124 \n",
      "(epoch: 95, iters: 220, time: 0.149, data: 0.002) G_GAN: 0.827 G_L1: 6.554 D_real: 1.228 D_fake: 0.235 \n",
      "(epoch: 95, iters: 320, time: 0.150, data: 0.002) G_GAN: 1.101 G_L1: 3.469 D_real: 0.500 D_fake: 0.486 \n",
      "(epoch: 95, iters: 420, time: 0.104, data: 0.002) G_GAN: 0.847 G_L1: 7.570 D_real: 0.729 D_fake: 0.254 \n",
      "saving the model at the end of epoch 95, iters 39900\n",
      "End of epoch 95 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 100, time: 0.312, data: 0.143) G_GAN: 1.072 G_L1: 7.335 D_real: 0.569 D_fake: 0.299 \n",
      "saving the latest model (epoch 96, total_iters 40000)\n",
      "(epoch: 96, iters: 200, time: 0.149, data: 0.002) G_GAN: 1.334 G_L1: 4.859 D_real: 0.718 D_fake: 0.198 \n",
      "(epoch: 96, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.497 G_L1: 8.346 D_real: 0.444 D_fake: 0.207 \n",
      "(epoch: 96, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.619 G_L1: 6.799 D_real: 0.183 D_fake: 0.356 \n",
      "End of epoch 96 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 80, time: 0.305, data: 0.002) G_GAN: 2.090 G_L1: 6.257 D_real: 0.357 D_fake: 0.488 \n",
      "(epoch: 97, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.082 G_L1: 3.388 D_real: 0.581 D_fake: 0.436 \n",
      "(epoch: 97, iters: 280, time: 0.150, data: 0.002) G_GAN: 2.169 G_L1: 7.398 D_real: 0.161 D_fake: 0.799 \n",
      "(epoch: 97, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.624 G_L1: 4.965 D_real: 0.400 D_fake: 0.425 \n",
      "End of epoch 97 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 60, time: 0.312, data: 0.002) G_GAN: 1.817 G_L1: 4.508 D_real: 0.431 D_fake: 0.405 \n",
      "(epoch: 98, iters: 160, time: 0.149, data: 0.002) G_GAN: 1.341 G_L1: 5.413 D_real: 0.573 D_fake: 0.301 \n",
      "(epoch: 98, iters: 260, time: 0.149, data: 0.003) G_GAN: 1.210 G_L1: 6.081 D_real: 0.565 D_fake: 0.459 \n",
      "(epoch: 98, iters: 360, time: 0.149, data: 0.002) G_GAN: 1.312 G_L1: 6.347 D_real: 0.733 D_fake: 0.434 \n",
      "End of epoch 98 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 40, time: 0.320, data: 0.003) G_GAN: 0.465 G_L1: 7.325 D_real: 0.804 D_fake: 0.250 \n",
      "(epoch: 99, iters: 140, time: 0.150, data: 0.002) G_GAN: 1.105 G_L1: 5.397 D_real: 0.678 D_fake: 0.348 \n",
      "(epoch: 99, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.078 G_L1: 3.803 D_real: 0.424 D_fake: 0.464 \n",
      "(epoch: 99, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.440 G_L1: 4.243 D_real: 0.547 D_fake: 0.511 \n",
      "End of epoch 99 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 20, time: 0.315, data: 0.003) G_GAN: 2.248 G_L1: 7.429 D_real: 0.096 D_fake: 1.353 \n",
      "(epoch: 100, iters: 120, time: 0.149, data: 0.001) G_GAN: 1.110 G_L1: 6.535 D_real: 0.452 D_fake: 0.387 \n",
      "(epoch: 100, iters: 220, time: 0.150, data: 0.003) G_GAN: 1.874 G_L1: 6.161 D_real: 0.173 D_fake: 0.823 \n",
      "(epoch: 100, iters: 320, time: 0.149, data: 0.002) G_GAN: 2.107 G_L1: 8.907 D_real: 0.296 D_fake: 0.609 \n",
      "(epoch: 100, iters: 420, time: 0.281, data: 0.002) G_GAN: 1.303 G_L1: 6.335 D_real: 0.938 D_fake: 0.581 \n",
      "saving the model at the end of epoch 100, iters 42000\n",
      "End of epoch 100 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.150, data: 0.166) G_GAN: 1.945 G_L1: 8.563 D_real: 0.108 D_fake: 0.562 \n",
      "(epoch: 101, iters: 200, time: 0.150, data: 0.003) G_GAN: 1.784 G_L1: 6.634 D_real: 0.168 D_fake: 0.536 \n",
      "(epoch: 101, iters: 300, time: 0.150, data: 0.002) G_GAN: 0.549 G_L1: 6.338 D_real: 1.030 D_fake: 0.578 \n",
      "(epoch: 101, iters: 400, time: 0.309, data: 0.002) G_GAN: 1.072 G_L1: 5.358 D_real: 0.360 D_fake: 0.479 \n",
      "End of epoch 101 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 80, time: 0.150, data: 0.002) G_GAN: 2.050 G_L1: 7.359 D_real: 0.121 D_fake: 0.479 \n",
      "(epoch: 102, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.450 G_L1: 5.690 D_real: 0.391 D_fake: 0.602 \n",
      "(epoch: 102, iters: 280, time: 0.149, data: 0.002) G_GAN: 0.852 G_L1: 5.788 D_real: 0.772 D_fake: 0.271 \n",
      "(epoch: 102, iters: 380, time: 0.318, data: 0.002) G_GAN: 1.984 G_L1: 5.265 D_real: 0.333 D_fake: 0.245 \n",
      "End of epoch 102 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 60, time: 0.149, data: 0.002) G_GAN: 1.546 G_L1: 6.327 D_real: 0.238 D_fake: 0.678 \n",
      "(epoch: 103, iters: 160, time: 0.150, data: 0.003) G_GAN: 1.362 G_L1: 7.807 D_real: 0.580 D_fake: 0.444 \n",
      "(epoch: 103, iters: 260, time: 0.150, data: 0.002) G_GAN: 1.400 G_L1: 6.632 D_real: 0.665 D_fake: 0.488 \n",
      "(epoch: 103, iters: 360, time: 0.328, data: 0.003) G_GAN: 2.474 G_L1: 7.597 D_real: 0.109 D_fake: 1.062 \n",
      "End of epoch 103 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.677 G_L1: 7.797 D_real: 0.102 D_fake: 0.528 \n",
      "(epoch: 104, iters: 140, time: 0.150, data: 0.002) G_GAN: 1.664 G_L1: 5.413 D_real: 0.259 D_fake: 0.556 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 104, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.927 G_L1: 5.766 D_real: 0.274 D_fake: 0.516 \n",
      "(epoch: 104, iters: 340, time: 0.324, data: 0.003) G_GAN: 2.074 G_L1: 7.331 D_real: 0.312 D_fake: 0.235 \n",
      "End of epoch 104 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.053 G_L1: 7.029 D_real: 0.921 D_fake: 1.086 \n",
      "(epoch: 105, iters: 120, time: 0.149, data: 0.001) G_GAN: 2.162 G_L1: 6.137 D_real: 0.287 D_fake: 0.695 \n",
      "(epoch: 105, iters: 220, time: 0.150, data: 0.003) G_GAN: 1.410 G_L1: 5.100 D_real: 0.735 D_fake: 0.832 \n",
      "(epoch: 105, iters: 320, time: 0.323, data: 0.002) G_GAN: 2.387 G_L1: 8.486 D_real: 0.279 D_fake: 0.722 \n",
      "(epoch: 105, iters: 420, time: 0.103, data: 0.002) G_GAN: 2.918 G_L1: 3.198 D_real: 0.851 D_fake: 0.832 \n",
      "saving the model at the end of epoch 105, iters 44100\n",
      "End of epoch 105 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 100, time: 0.149, data: 0.137) G_GAN: 1.034 G_L1: 6.560 D_real: 0.471 D_fake: 0.393 \n",
      "(epoch: 106, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.231 G_L1: 3.963 D_real: 0.687 D_fake: 0.371 \n",
      "(epoch: 106, iters: 300, time: 0.332, data: 0.002) G_GAN: 2.567 G_L1: 6.268 D_real: 0.273 D_fake: 0.733 \n",
      "(epoch: 106, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.944 G_L1: 6.689 D_real: 0.318 D_fake: 0.450 \n",
      "End of epoch 106 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.524 G_L1: 4.794 D_real: 0.417 D_fake: 0.359 \n",
      "(epoch: 107, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.098 G_L1: 4.574 D_real: 0.580 D_fake: 0.573 \n",
      "(epoch: 107, iters: 280, time: 0.344, data: 0.002) G_GAN: 0.754 G_L1: 5.807 D_real: 0.735 D_fake: 0.242 \n",
      "(epoch: 107, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.498 G_L1: 6.645 D_real: 0.268 D_fake: 0.484 \n",
      "End of epoch 107 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 60, time: 0.149, data: 0.002) G_GAN: 1.794 G_L1: 7.647 D_real: 0.268 D_fake: 0.335 \n",
      "saving the latest model (epoch 108, total_iters 45000)\n",
      "(epoch: 108, iters: 160, time: 0.150, data: 0.002) G_GAN: 1.559 G_L1: 7.598 D_real: 0.322 D_fake: 0.725 \n",
      "(epoch: 108, iters: 260, time: 0.331, data: 0.002) G_GAN: 0.875 G_L1: 6.965 D_real: 0.728 D_fake: 0.293 \n",
      "(epoch: 108, iters: 360, time: 0.150, data: 0.002) G_GAN: 0.848 G_L1: 5.811 D_real: 0.605 D_fake: 0.382 \n",
      "End of epoch 108 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 40, time: 0.151, data: 0.002) G_GAN: 1.495 G_L1: 6.779 D_real: 0.625 D_fake: 0.400 \n",
      "(epoch: 109, iters: 140, time: 0.149, data: 0.003) G_GAN: 1.630 G_L1: 6.502 D_real: 0.769 D_fake: 0.668 \n",
      "(epoch: 109, iters: 240, time: 0.319, data: 0.002) G_GAN: 0.781 G_L1: 4.812 D_real: 0.838 D_fake: 0.286 \n",
      "(epoch: 109, iters: 340, time: 0.149, data: 0.002) G_GAN: 1.389 G_L1: 6.741 D_real: 0.736 D_fake: 0.249 \n",
      "End of epoch 109 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.588 G_L1: 7.029 D_real: 0.508 D_fake: 0.163 \n",
      "(epoch: 110, iters: 120, time: 0.150, data: 0.002) G_GAN: 1.516 G_L1: 4.618 D_real: 1.022 D_fake: 0.190 \n",
      "(epoch: 110, iters: 220, time: 0.334, data: 0.003) G_GAN: 1.297 G_L1: 6.744 D_real: 0.429 D_fake: 0.297 \n",
      "(epoch: 110, iters: 320, time: 0.150, data: 0.002) G_GAN: 1.751 G_L1: 6.975 D_real: 0.352 D_fake: 0.233 \n",
      "(epoch: 110, iters: 420, time: 0.104, data: 0.002) G_GAN: 2.702 G_L1: 6.900 D_real: 0.118 D_fake: 0.426 \n",
      "saving the model at the end of epoch 110, iters 46200\n",
      "End of epoch 110 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 100, time: 0.150, data: 0.138) G_GAN: 1.591 G_L1: 6.333 D_real: 0.381 D_fake: 0.556 \n",
      "(epoch: 111, iters: 200, time: 0.343, data: 0.003) G_GAN: 1.141 G_L1: 6.504 D_real: 0.803 D_fake: 0.202 \n",
      "(epoch: 111, iters: 300, time: 0.149, data: 0.002) G_GAN: 2.198 G_L1: 5.538 D_real: 0.186 D_fake: 0.397 \n",
      "(epoch: 111, iters: 400, time: 0.149, data: 0.002) G_GAN: 1.560 G_L1: 8.463 D_real: 0.304 D_fake: 0.869 \n",
      "End of epoch 111 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 80, time: 0.149, data: 0.002) G_GAN: 1.338 G_L1: 6.838 D_real: 0.286 D_fake: 0.452 \n",
      "(epoch: 112, iters: 180, time: 0.319, data: 0.003) G_GAN: 2.453 G_L1: 6.000 D_real: 0.150 D_fake: 0.646 \n",
      "(epoch: 112, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.982 G_L1: 6.183 D_real: 0.174 D_fake: 0.637 \n",
      "(epoch: 112, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.459 G_L1: 5.032 D_real: 0.419 D_fake: 0.453 \n",
      "End of epoch 112 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 60, time: 0.150, data: 0.002) G_GAN: 2.090 G_L1: 5.296 D_real: 0.763 D_fake: 0.266 \n",
      "(epoch: 113, iters: 160, time: 0.341, data: 0.002) G_GAN: 2.201 G_L1: 8.355 D_real: 0.431 D_fake: 0.084 \n",
      "(epoch: 113, iters: 260, time: 0.150, data: 0.002) G_GAN: 1.784 G_L1: 5.507 D_real: 0.209 D_fake: 0.824 \n",
      "(epoch: 113, iters: 360, time: 0.149, data: 0.002) G_GAN: 1.562 G_L1: 7.174 D_real: 0.356 D_fake: 0.598 \n",
      "End of epoch 113 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 40, time: 0.150, data: 0.002) G_GAN: 2.146 G_L1: 4.537 D_real: 0.671 D_fake: 0.254 \n",
      "(epoch: 114, iters: 140, time: 0.333, data: 0.003) G_GAN: 1.893 G_L1: 5.779 D_real: 0.199 D_fake: 0.684 \n",
      "(epoch: 114, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.300 G_L1: 6.003 D_real: 0.342 D_fake: 0.364 \n",
      "(epoch: 114, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.434 G_L1: 5.947 D_real: 0.372 D_fake: 0.695 \n",
      "End of epoch 114 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 20, time: 0.149, data: 0.003) G_GAN: 2.062 G_L1: 7.254 D_real: 0.845 D_fake: 0.880 \n",
      "(epoch: 115, iters: 120, time: 0.339, data: 0.001) G_GAN: 1.124 G_L1: 5.756 D_real: 0.614 D_fake: 0.597 \n",
      "(epoch: 115, iters: 220, time: 0.149, data: 0.002) G_GAN: 2.228 G_L1: 5.706 D_real: 0.553 D_fake: 0.105 \n",
      "(epoch: 115, iters: 320, time: 0.150, data: 0.002) G_GAN: 1.172 G_L1: 4.638 D_real: 0.467 D_fake: 0.464 \n",
      "(epoch: 115, iters: 420, time: 0.104, data: 0.003) G_GAN: 1.070 G_L1: 6.772 D_real: 0.600 D_fake: 0.307 \n",
      "saving the model at the end of epoch 115, iters 48300\n",
      "End of epoch 115 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 100, time: 0.340, data: 0.160) G_GAN: 1.415 G_L1: 7.824 D_real: 0.688 D_fake: 0.321 \n",
      "(epoch: 116, iters: 200, time: 0.149, data: 0.002) G_GAN: 1.117 G_L1: 7.808 D_real: 0.836 D_fake: 0.286 \n",
      "(epoch: 116, iters: 300, time: 0.149, data: 0.003) G_GAN: 1.296 G_L1: 6.706 D_real: 0.310 D_fake: 0.450 \n",
      "(epoch: 116, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.792 G_L1: 7.838 D_real: 0.355 D_fake: 0.330 \n",
      "End of epoch 116 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 80, time: 0.356, data: 0.002) G_GAN: 1.700 G_L1: 7.418 D_real: 0.532 D_fake: 0.464 \n",
      "(epoch: 117, iters: 180, time: 0.150, data: 0.002) G_GAN: 0.743 G_L1: 4.490 D_real: 0.617 D_fake: 0.425 \n",
      "(epoch: 117, iters: 280, time: 0.150, data: 0.003) G_GAN: 1.282 G_L1: 5.995 D_real: 0.624 D_fake: 0.419 \n",
      "(epoch: 117, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.197 G_L1: 5.131 D_real: 0.518 D_fake: 0.522 \n",
      "End of epoch 117 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 60, time: 0.352, data: 0.002) G_GAN: 1.944 G_L1: 4.439 D_real: 0.278 D_fake: 0.452 \n",
      "(epoch: 118, iters: 160, time: 0.150, data: 0.002) G_GAN: 1.627 G_L1: 6.457 D_real: 0.743 D_fake: 0.162 \n",
      "(epoch: 118, iters: 260, time: 0.150, data: 0.003) G_GAN: 1.870 G_L1: 6.654 D_real: 0.368 D_fake: 0.385 \n",
      "(epoch: 118, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.717 G_L1: 6.046 D_real: 0.316 D_fake: 0.375 \n",
      "End of epoch 118 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 40, time: 0.355, data: 0.002) G_GAN: 1.744 G_L1: 6.456 D_real: 0.537 D_fake: 0.209 \n",
      "(epoch: 119, iters: 140, time: 0.150, data: 0.002) G_GAN: 1.612 G_L1: 6.689 D_real: 0.391 D_fake: 0.297 \n",
      "(epoch: 119, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.928 G_L1: 6.360 D_real: 0.498 D_fake: 0.292 \n",
      "(epoch: 119, iters: 340, time: 0.150, data: 0.002) G_GAN: 2.349 G_L1: 7.472 D_real: 0.117 D_fake: 0.648 \n",
      "End of epoch 119 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 20, time: 0.341, data: 0.003) G_GAN: 1.350 G_L1: 5.171 D_real: 0.262 D_fake: 0.959 \n",
      "saving the latest model (epoch 120, total_iters 50000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 120, iters: 120, time: 0.150, data: 0.001) G_GAN: 1.819 G_L1: 6.726 D_real: 0.241 D_fake: 0.886 \n",
      "(epoch: 120, iters: 220, time: 0.150, data: 0.003) G_GAN: 1.860 G_L1: 6.354 D_real: 0.480 D_fake: 0.302 \n",
      "(epoch: 120, iters: 320, time: 0.150, data: 0.002) G_GAN: 1.853 G_L1: 6.309 D_real: 0.958 D_fake: 0.039 \n",
      "(epoch: 120, iters: 420, time: 0.298, data: 0.002) G_GAN: 4.103 G_L1: 1.805 D_real: 0.195 D_fake: 1.060 \n",
      "saving the model at the end of epoch 120, iters 50400\n",
      "End of epoch 120 / 200 \t Time Taken: 43 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 100, time: 0.149, data: 0.161) G_GAN: 1.893 G_L1: 6.672 D_real: 0.340 D_fake: 0.359 \n",
      "(epoch: 121, iters: 200, time: 0.149, data: 0.002) G_GAN: 1.225 G_L1: 5.555 D_real: 0.601 D_fake: 0.326 \n",
      "(epoch: 121, iters: 300, time: 0.149, data: 0.002) G_GAN: 1.453 G_L1: 6.899 D_real: 0.495 D_fake: 0.186 \n",
      "(epoch: 121, iters: 400, time: 0.350, data: 0.002) G_GAN: 1.372 G_L1: 7.952 D_real: 0.296 D_fake: 0.515 \n",
      "End of epoch 121 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 80, time: 0.149, data: 0.002) G_GAN: 1.550 G_L1: 6.437 D_real: 0.183 D_fake: 0.402 \n",
      "(epoch: 122, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.614 G_L1: 4.802 D_real: 0.431 D_fake: 0.398 \n",
      "(epoch: 122, iters: 280, time: 0.150, data: 0.003) G_GAN: 2.188 G_L1: 6.157 D_real: 0.201 D_fake: 0.277 \n",
      "(epoch: 122, iters: 380, time: 0.330, data: 0.002) G_GAN: 1.809 G_L1: 3.906 D_real: 0.671 D_fake: 0.229 \n",
      "End of epoch 122 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 60, time: 0.149, data: 0.003) G_GAN: 2.400 G_L1: 6.786 D_real: 0.109 D_fake: 1.048 \n",
      "(epoch: 123, iters: 160, time: 0.150, data: 0.002) G_GAN: 2.285 G_L1: 5.707 D_real: 0.510 D_fake: 1.088 \n",
      "(epoch: 123, iters: 260, time: 0.149, data: 0.003) G_GAN: 1.250 G_L1: 5.465 D_real: 0.606 D_fake: 0.469 \n",
      "(epoch: 123, iters: 360, time: 0.351, data: 0.002) G_GAN: 1.528 G_L1: 5.800 D_real: 0.531 D_fake: 0.373 \n",
      "End of epoch 123 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.517 G_L1: 6.370 D_real: 0.338 D_fake: 0.622 \n",
      "(epoch: 124, iters: 140, time: 0.150, data: 0.002) G_GAN: 2.409 G_L1: 10.192 D_real: 0.089 D_fake: 0.448 \n",
      "(epoch: 124, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.532 G_L1: 8.124 D_real: 0.421 D_fake: 1.481 \n",
      "(epoch: 124, iters: 340, time: 0.345, data: 0.003) G_GAN: 1.959 G_L1: 4.562 D_real: 0.247 D_fake: 0.234 \n",
      "End of epoch 124 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 20, time: 0.150, data: 0.002) G_GAN: 0.703 G_L1: 4.967 D_real: 1.063 D_fake: 0.146 \n",
      "(epoch: 125, iters: 120, time: 0.150, data: 0.003) G_GAN: 1.872 G_L1: 7.081 D_real: 0.175 D_fake: 0.546 \n",
      "(epoch: 125, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.909 G_L1: 6.078 D_real: 0.294 D_fake: 0.688 \n",
      "(epoch: 125, iters: 320, time: 0.348, data: 0.002) G_GAN: 1.939 G_L1: 7.983 D_real: 0.300 D_fake: 0.207 \n",
      "(epoch: 125, iters: 420, time: 0.103, data: 0.002) G_GAN: 0.797 G_L1: 3.614 D_real: 0.605 D_fake: 0.345 \n",
      "saving the model at the end of epoch 125, iters 52500\n",
      "End of epoch 125 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 100, time: 0.149, data: 0.143) G_GAN: 2.232 G_L1: 6.903 D_real: 0.352 D_fake: 0.774 \n",
      "(epoch: 126, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.658 G_L1: 6.569 D_real: 0.192 D_fake: 0.489 \n",
      "(epoch: 126, iters: 300, time: 0.352, data: 0.002) G_GAN: 2.060 G_L1: 5.520 D_real: 0.487 D_fake: 0.554 \n",
      "(epoch: 126, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.246 G_L1: 6.377 D_real: 0.433 D_fake: 0.646 \n",
      "End of epoch 126 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 80, time: 0.150, data: 0.003) G_GAN: 1.992 G_L1: 7.500 D_real: 0.213 D_fake: 0.500 \n",
      "(epoch: 127, iters: 180, time: 0.149, data: 0.003) G_GAN: 1.064 G_L1: 5.003 D_real: 0.837 D_fake: 0.463 \n",
      "(epoch: 127, iters: 280, time: 0.358, data: 0.003) G_GAN: 1.880 G_L1: 6.301 D_real: 0.436 D_fake: 0.587 \n",
      "(epoch: 127, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.254 G_L1: 5.937 D_real: 0.450 D_fake: 0.479 \n",
      "End of epoch 127 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 60, time: 0.150, data: 0.003) G_GAN: 1.060 G_L1: 5.102 D_real: 0.633 D_fake: 0.204 \n",
      "(epoch: 128, iters: 160, time: 0.150, data: 0.002) G_GAN: 1.146 G_L1: 6.338 D_real: 0.655 D_fake: 0.170 \n",
      "(epoch: 128, iters: 260, time: 0.365, data: 0.002) G_GAN: 1.586 G_L1: 4.959 D_real: 0.305 D_fake: 0.443 \n",
      "(epoch: 128, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.843 G_L1: 3.767 D_real: 0.270 D_fake: 0.575 \n",
      "End of epoch 128 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.833 G_L1: 6.149 D_real: 0.295 D_fake: 0.940 \n",
      "(epoch: 129, iters: 140, time: 0.150, data: 0.002) G_GAN: 1.393 G_L1: 5.822 D_real: 0.471 D_fake: 0.380 \n",
      "(epoch: 129, iters: 240, time: 0.362, data: 0.003) G_GAN: 1.780 G_L1: 7.137 D_real: 0.254 D_fake: 0.318 \n",
      "(epoch: 129, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.629 G_L1: 8.112 D_real: 0.192 D_fake: 0.292 \n",
      "End of epoch 129 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 20, time: 0.149, data: 0.003) G_GAN: 1.706 G_L1: 4.402 D_real: 0.457 D_fake: 0.489 \n",
      "(epoch: 130, iters: 120, time: 0.150, data: 0.001) G_GAN: 1.897 G_L1: 8.177 D_real: 0.885 D_fake: 0.449 \n",
      "(epoch: 130, iters: 220, time: 0.356, data: 0.002) G_GAN: 2.066 G_L1: 6.334 D_real: 0.366 D_fake: 0.352 \n",
      "(epoch: 130, iters: 320, time: 0.149, data: 0.002) G_GAN: 1.158 G_L1: 5.153 D_real: 0.604 D_fake: 0.555 \n",
      "(epoch: 130, iters: 420, time: 0.103, data: 0.002) G_GAN: 0.542 G_L1: 7.312 D_real: 0.977 D_fake: 0.395 \n",
      "saving the model at the end of epoch 130, iters 54600\n",
      "End of epoch 130 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 100, time: 0.149, data: 0.140) G_GAN: 1.192 G_L1: 6.043 D_real: 0.631 D_fake: 0.338 \n",
      "(epoch: 131, iters: 200, time: 0.366, data: 0.002) G_GAN: 1.927 G_L1: 5.694 D_real: 0.206 D_fake: 0.288 \n",
      "(epoch: 131, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.704 G_L1: 5.799 D_real: 0.382 D_fake: 0.320 \n",
      "(epoch: 131, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.706 G_L1: 5.478 D_real: 0.369 D_fake: 0.247 \n",
      "saving the latest model (epoch 131, total_iters 55000)\n",
      "End of epoch 131 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 80, time: 0.150, data: 0.002) G_GAN: 2.092 G_L1: 6.196 D_real: 0.427 D_fake: 0.175 \n",
      "(epoch: 132, iters: 180, time: 0.367, data: 0.002) G_GAN: 0.966 G_L1: 7.183 D_real: 0.800 D_fake: 0.247 \n",
      "(epoch: 132, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.006 G_L1: 4.587 D_real: 0.663 D_fake: 0.343 \n",
      "(epoch: 132, iters: 380, time: 0.149, data: 0.003) G_GAN: 2.052 G_L1: 6.559 D_real: 0.107 D_fake: 0.552 \n",
      "End of epoch 132 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 60, time: 0.151, data: 0.002) G_GAN: 1.476 G_L1: 5.494 D_real: 0.219 D_fake: 0.695 \n",
      "(epoch: 133, iters: 160, time: 0.374, data: 0.003) G_GAN: 2.153 G_L1: 7.384 D_real: 0.214 D_fake: 0.411 \n",
      "(epoch: 133, iters: 260, time: 0.150, data: 0.002) G_GAN: 1.880 G_L1: 6.973 D_real: 0.590 D_fake: 0.130 \n",
      "(epoch: 133, iters: 360, time: 0.150, data: 0.003) G_GAN: 1.949 G_L1: 7.371 D_real: 0.155 D_fake: 0.701 \n",
      "End of epoch 133 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 40, time: 0.149, data: 0.002) G_GAN: 1.827 G_L1: 6.686 D_real: 0.425 D_fake: 0.207 \n",
      "(epoch: 134, iters: 140, time: 0.334, data: 0.003) G_GAN: 1.935 G_L1: 5.018 D_real: 0.454 D_fake: 0.382 \n",
      "(epoch: 134, iters: 240, time: 0.150, data: 0.002) G_GAN: 2.023 G_L1: 7.183 D_real: 0.260 D_fake: 0.414 \n",
      "(epoch: 134, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.457 G_L1: 5.578 D_real: 0.519 D_fake: 0.114 \n",
      "End of epoch 134 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.675 G_L1: 4.072 D_real: 1.025 D_fake: 1.065 \n",
      "(epoch: 135, iters: 120, time: 0.366, data: 0.003) G_GAN: 1.839 G_L1: 8.249 D_real: 0.237 D_fake: 0.539 \n",
      "(epoch: 135, iters: 220, time: 0.149, data: 0.002) G_GAN: 2.148 G_L1: 8.017 D_real: 0.116 D_fake: 0.513 \n",
      "(epoch: 135, iters: 320, time: 0.150, data: 0.002) G_GAN: 1.137 G_L1: 4.340 D_real: 0.762 D_fake: 0.377 \n",
      "(epoch: 135, iters: 420, time: 0.104, data: 0.003) G_GAN: 1.866 G_L1: 5.668 D_real: 0.247 D_fake: 0.545 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model at the end of epoch 135, iters 56700\n",
      "End of epoch 135 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 100, time: 0.353, data: 0.144) G_GAN: 1.144 G_L1: 5.602 D_real: 0.556 D_fake: 0.351 \n",
      "(epoch: 136, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.812 G_L1: 5.635 D_real: 0.233 D_fake: 0.453 \n",
      "(epoch: 136, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.528 G_L1: 7.268 D_real: 0.294 D_fake: 0.290 \n",
      "(epoch: 136, iters: 400, time: 0.150, data: 0.002) G_GAN: 0.717 G_L1: 6.126 D_real: 0.959 D_fake: 0.201 \n",
      "End of epoch 136 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 80, time: 0.350, data: 0.002) G_GAN: 1.576 G_L1: 4.124 D_real: 0.463 D_fake: 0.542 \n",
      "(epoch: 137, iters: 180, time: 0.150, data: 0.003) G_GAN: 1.855 G_L1: 7.376 D_real: 0.252 D_fake: 0.571 \n",
      "(epoch: 137, iters: 280, time: 0.149, data: 0.002) G_GAN: 2.000 G_L1: 7.047 D_real: 0.247 D_fake: 0.209 \n",
      "(epoch: 137, iters: 380, time: 0.150, data: 0.003) G_GAN: 1.103 G_L1: 4.526 D_real: 0.830 D_fake: 0.615 \n",
      "End of epoch 137 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 60, time: 0.374, data: 0.003) G_GAN: 1.799 G_L1: 7.632 D_real: 0.302 D_fake: 0.606 \n",
      "(epoch: 138, iters: 160, time: 0.149, data: 0.002) G_GAN: 1.936 G_L1: 7.901 D_real: 0.186 D_fake: 0.300 \n",
      "(epoch: 138, iters: 260, time: 0.150, data: 0.003) G_GAN: 1.561 G_L1: 5.673 D_real: 0.333 D_fake: 0.240 \n",
      "(epoch: 138, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.526 G_L1: 6.116 D_real: 0.328 D_fake: 0.312 \n",
      "End of epoch 138 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 40, time: 0.371, data: 0.002) G_GAN: 2.122 G_L1: 8.792 D_real: 0.150 D_fake: 0.264 \n",
      "(epoch: 139, iters: 140, time: 0.150, data: 0.002) G_GAN: 1.583 G_L1: 6.907 D_real: 1.139 D_fake: 0.597 \n",
      "(epoch: 139, iters: 240, time: 0.149, data: 0.002) G_GAN: 1.177 G_L1: 6.404 D_real: 0.810 D_fake: 0.110 \n",
      "(epoch: 139, iters: 340, time: 0.150, data: 0.003) G_GAN: 1.424 G_L1: 5.809 D_real: 0.512 D_fake: 0.362 \n",
      "End of epoch 139 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 20, time: 0.366, data: 0.002) G_GAN: 1.856 G_L1: 5.927 D_real: 0.133 D_fake: 0.853 \n",
      "(epoch: 140, iters: 120, time: 0.150, data: 0.003) G_GAN: 1.609 G_L1: 6.492 D_real: 0.377 D_fake: 0.317 \n",
      "(epoch: 140, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.979 G_L1: 6.391 D_real: 0.204 D_fake: 0.691 \n",
      "(epoch: 140, iters: 320, time: 0.150, data: 0.002) G_GAN: 2.366 G_L1: 7.393 D_real: 0.193 D_fake: 0.230 \n",
      "(epoch: 140, iters: 420, time: 0.303, data: 0.002) G_GAN: 2.762 G_L1: 3.841 D_real: 0.294 D_fake: 0.701 \n",
      "saving the model at the end of epoch 140, iters 58800\n",
      "End of epoch 140 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 100, time: 0.149, data: 0.139) G_GAN: 1.338 G_L1: 6.938 D_real: 0.201 D_fake: 0.544 \n",
      "(epoch: 141, iters: 200, time: 0.150, data: 0.002) G_GAN: 0.977 G_L1: 5.707 D_real: 0.788 D_fake: 0.227 \n",
      "(epoch: 141, iters: 300, time: 0.150, data: 0.002) G_GAN: 2.058 G_L1: 5.751 D_real: 0.270 D_fake: 0.522 \n",
      "(epoch: 141, iters: 400, time: 0.351, data: 0.002) G_GAN: 1.732 G_L1: 7.188 D_real: 0.307 D_fake: 0.417 \n",
      "End of epoch 141 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 80, time: 0.149, data: 0.002) G_GAN: 1.485 G_L1: 7.097 D_real: 0.398 D_fake: 0.401 \n",
      "(epoch: 142, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.832 G_L1: 7.263 D_real: 0.359 D_fake: 0.177 \n",
      "(epoch: 142, iters: 280, time: 0.149, data: 0.002) G_GAN: 0.633 G_L1: 6.501 D_real: 0.988 D_fake: 0.232 \n",
      "(epoch: 142, iters: 380, time: 0.386, data: 0.003) G_GAN: 1.528 G_L1: 8.063 D_real: 0.303 D_fake: 0.246 \n",
      "End of epoch 142 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 60, time: 0.149, data: 0.002) G_GAN: 1.403 G_L1: 4.875 D_real: 0.325 D_fake: 0.293 \n",
      "(epoch: 143, iters: 160, time: 0.150, data: 0.002) G_GAN: 2.131 G_L1: 7.216 D_real: 0.315 D_fake: 0.344 \n",
      "(epoch: 143, iters: 260, time: 0.151, data: 0.003) G_GAN: 1.514 G_L1: 4.821 D_real: 0.384 D_fake: 0.634 \n",
      "(epoch: 143, iters: 360, time: 0.379, data: 0.003) G_GAN: 0.839 G_L1: 5.732 D_real: 0.871 D_fake: 0.303 \n",
      "saving the latest model (epoch 143, total_iters 60000)\n",
      "End of epoch 143 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 40, time: 0.150, data: 0.002) G_GAN: 2.736 G_L1: 8.973 D_real: 0.102 D_fake: 1.113 \n",
      "(epoch: 144, iters: 140, time: 0.149, data: 0.002) G_GAN: 0.985 G_L1: 6.833 D_real: 0.659 D_fake: 0.295 \n",
      "(epoch: 144, iters: 240, time: 0.151, data: 0.003) G_GAN: 1.605 G_L1: 6.299 D_real: 0.455 D_fake: 0.411 \n",
      "(epoch: 144, iters: 340, time: 0.381, data: 0.002) G_GAN: 2.126 G_L1: 7.854 D_real: 0.333 D_fake: 0.260 \n",
      "End of epoch 144 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.472 G_L1: 6.362 D_real: 0.430 D_fake: 0.515 \n",
      "(epoch: 145, iters: 120, time: 0.150, data: 0.001) G_GAN: 1.133 G_L1: 6.764 D_real: 0.818 D_fake: 0.227 \n",
      "(epoch: 145, iters: 220, time: 0.150, data: 0.003) G_GAN: 1.474 G_L1: 7.868 D_real: 0.318 D_fake: 0.266 \n",
      "(epoch: 145, iters: 320, time: 0.354, data: 0.002) G_GAN: 0.962 G_L1: 5.553 D_real: 0.739 D_fake: 0.436 \n",
      "(epoch: 145, iters: 420, time: 0.103, data: 0.002) G_GAN: 4.065 G_L1: 8.834 D_real: 0.015 D_fake: 0.730 \n",
      "saving the model at the end of epoch 145, iters 60900\n",
      "End of epoch 145 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 100, time: 0.149, data: 0.145) G_GAN: 1.641 G_L1: 6.132 D_real: 0.500 D_fake: 0.151 \n",
      "(epoch: 146, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.147 G_L1: 5.621 D_real: 0.657 D_fake: 0.275 \n",
      "(epoch: 146, iters: 300, time: 0.355, data: 0.002) G_GAN: 2.750 G_L1: 5.086 D_real: 0.227 D_fake: 0.170 \n",
      "(epoch: 146, iters: 400, time: 0.149, data: 0.003) G_GAN: 1.606 G_L1: 5.482 D_real: 0.584 D_fake: 0.731 \n",
      "End of epoch 146 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 80, time: 0.150, data: 0.003) G_GAN: 1.034 G_L1: 4.642 D_real: 0.924 D_fake: 0.292 \n",
      "(epoch: 147, iters: 180, time: 0.150, data: 0.002) G_GAN: 2.142 G_L1: 7.188 D_real: 0.090 D_fake: 0.471 \n",
      "(epoch: 147, iters: 280, time: 0.373, data: 0.002) G_GAN: 0.883 G_L1: 3.728 D_real: 0.615 D_fake: 0.456 \n",
      "(epoch: 147, iters: 380, time: 0.149, data: 0.002) G_GAN: 1.977 G_L1: 6.031 D_real: 0.632 D_fake: 0.204 \n",
      "End of epoch 147 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 60, time: 0.151, data: 0.002) G_GAN: 1.825 G_L1: 7.139 D_real: 0.170 D_fake: 0.268 \n",
      "(epoch: 148, iters: 160, time: 0.150, data: 0.002) G_GAN: 1.966 G_L1: 6.294 D_real: 0.304 D_fake: 0.394 \n",
      "(epoch: 148, iters: 260, time: 0.373, data: 0.003) G_GAN: 1.201 G_L1: 7.016 D_real: 0.371 D_fake: 0.377 \n",
      "(epoch: 148, iters: 360, time: 0.149, data: 0.002) G_GAN: 1.241 G_L1: 6.410 D_real: 0.687 D_fake: 0.235 \n",
      "End of epoch 148 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 40, time: 0.151, data: 0.002) G_GAN: 1.316 G_L1: 4.946 D_real: 0.762 D_fake: 0.231 \n",
      "(epoch: 149, iters: 140, time: 0.151, data: 0.002) G_GAN: 1.609 G_L1: 5.331 D_real: 0.676 D_fake: 0.159 \n",
      "(epoch: 149, iters: 240, time: 0.368, data: 0.002) G_GAN: 1.728 G_L1: 4.987 D_real: 0.480 D_fake: 0.249 \n",
      "(epoch: 149, iters: 340, time: 0.150, data: 0.002) G_GAN: 0.720 G_L1: 5.278 D_real: 0.942 D_fake: 0.242 \n",
      "End of epoch 149 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 20, time: 0.150, data: 0.002) G_GAN: 2.673 G_L1: 7.805 D_real: 0.513 D_fake: 0.105 \n",
      "(epoch: 150, iters: 120, time: 0.150, data: 0.002) G_GAN: 1.319 G_L1: 5.807 D_real: 0.407 D_fake: 1.000 \n",
      "(epoch: 150, iters: 220, time: 0.382, data: 0.002) G_GAN: 1.709 G_L1: 5.258 D_real: 0.357 D_fake: 0.458 \n",
      "(epoch: 150, iters: 320, time: 0.150, data: 0.002) G_GAN: 2.076 G_L1: 6.892 D_real: 0.293 D_fake: 0.493 \n",
      "(epoch: 150, iters: 420, time: 0.103, data: 0.003) G_GAN: 3.057 G_L1: 5.382 D_real: 0.299 D_fake: 1.565 \n",
      "saving the model at the end of epoch 150, iters 63000\n",
      "End of epoch 150 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 100, time: 0.149, data: 0.165) G_GAN: 2.098 G_L1: 6.585 D_real: 0.220 D_fake: 0.174 \n",
      "(epoch: 151, iters: 200, time: 0.377, data: 0.002) G_GAN: 1.365 G_L1: 7.357 D_real: 0.326 D_fake: 0.431 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 151, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.273 G_L1: 7.219 D_real: 0.180 D_fake: 0.749 \n",
      "(epoch: 151, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.750 G_L1: 6.641 D_real: 0.205 D_fake: 0.289 \n",
      "End of epoch 151 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 80, time: 0.150, data: 0.003) G_GAN: 2.206 G_L1: 6.956 D_real: 0.069 D_fake: 0.317 \n",
      "(epoch: 152, iters: 180, time: 0.384, data: 0.003) G_GAN: 1.557 G_L1: 5.994 D_real: 0.612 D_fake: 0.270 \n",
      "(epoch: 152, iters: 280, time: 0.150, data: 0.002) G_GAN: 2.042 G_L1: 5.897 D_real: 0.497 D_fake: 0.192 \n",
      "(epoch: 152, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.013 G_L1: 5.129 D_real: 0.938 D_fake: 0.297 \n",
      "End of epoch 152 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 60, time: 0.150, data: 0.003) G_GAN: 1.013 G_L1: 6.777 D_real: 0.654 D_fake: 0.761 \n",
      "(epoch: 153, iters: 160, time: 0.377, data: 0.003) G_GAN: 2.019 G_L1: 6.454 D_real: 0.245 D_fake: 0.607 \n",
      "(epoch: 153, iters: 260, time: 0.149, data: 0.003) G_GAN: 1.499 G_L1: 5.819 D_real: 0.236 D_fake: 0.769 \n",
      "(epoch: 153, iters: 360, time: 0.150, data: 0.002) G_GAN: 2.043 G_L1: 5.284 D_real: 0.262 D_fake: 0.558 \n",
      "End of epoch 153 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 40, time: 0.149, data: 0.002) G_GAN: 2.251 G_L1: 7.386 D_real: 0.245 D_fake: 0.267 \n",
      "(epoch: 154, iters: 140, time: 0.375, data: 0.003) G_GAN: 1.524 G_L1: 6.722 D_real: 0.162 D_fake: 0.491 \n",
      "(epoch: 154, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.560 G_L1: 5.422 D_real: 1.066 D_fake: 0.205 \n",
      "(epoch: 154, iters: 340, time: 0.151, data: 0.002) G_GAN: 1.410 G_L1: 6.087 D_real: 0.316 D_fake: 0.541 \n",
      "End of epoch 154 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 20, time: 0.149, data: 0.002) G_GAN: 1.472 G_L1: 6.557 D_real: 0.422 D_fake: 0.804 \n",
      "(epoch: 155, iters: 120, time: 0.380, data: 0.004) G_GAN: 1.366 G_L1: 7.364 D_real: 0.522 D_fake: 0.397 \n",
      "(epoch: 155, iters: 220, time: 0.150, data: 0.003) G_GAN: 1.206 G_L1: 4.870 D_real: 0.487 D_fake: 0.410 \n",
      "(epoch: 155, iters: 320, time: 0.150, data: 0.002) G_GAN: 1.963 G_L1: 6.830 D_real: 0.274 D_fake: 0.328 \n",
      "saving the latest model (epoch 155, total_iters 65000)\n",
      "(epoch: 155, iters: 420, time: 0.103, data: 0.002) G_GAN: 0.792 G_L1: 5.787 D_real: 0.721 D_fake: 0.118 \n",
      "saving the model at the end of epoch 155, iters 65100\n",
      "End of epoch 155 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 100, time: 0.360, data: 0.142) G_GAN: 1.535 G_L1: 5.086 D_real: 0.431 D_fake: 0.160 \n",
      "(epoch: 156, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.380 G_L1: 5.480 D_real: 0.650 D_fake: 0.274 \n",
      "(epoch: 156, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.271 G_L1: 6.698 D_real: 0.564 D_fake: 0.268 \n",
      "(epoch: 156, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.661 G_L1: 6.434 D_real: 0.371 D_fake: 0.366 \n",
      "End of epoch 156 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 80, time: 0.389, data: 0.002) G_GAN: 2.157 G_L1: 8.633 D_real: 0.318 D_fake: 0.271 \n",
      "(epoch: 157, iters: 180, time: 0.149, data: 0.003) G_GAN: 1.985 G_L1: 7.404 D_real: 0.302 D_fake: 0.359 \n",
      "(epoch: 157, iters: 280, time: 0.151, data: 0.002) G_GAN: 1.631 G_L1: 4.673 D_real: 0.250 D_fake: 0.517 \n",
      "(epoch: 157, iters: 380, time: 0.150, data: 0.003) G_GAN: 1.784 G_L1: 6.959 D_real: 0.291 D_fake: 0.561 \n",
      "End of epoch 157 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 60, time: 0.375, data: 0.003) G_GAN: 2.096 G_L1: 4.953 D_real: 0.256 D_fake: 0.466 \n",
      "(epoch: 158, iters: 160, time: 0.149, data: 0.002) G_GAN: 1.737 G_L1: 6.620 D_real: 0.238 D_fake: 0.265 \n",
      "(epoch: 158, iters: 260, time: 0.150, data: 0.003) G_GAN: 0.813 G_L1: 5.544 D_real: 0.712 D_fake: 0.218 \n",
      "(epoch: 158, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.805 G_L1: 5.447 D_real: 0.216 D_fake: 0.406 \n",
      "End of epoch 158 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 40, time: 0.390, data: 0.003) G_GAN: 1.296 G_L1: 6.129 D_real: 0.291 D_fake: 0.387 \n",
      "(epoch: 159, iters: 140, time: 0.150, data: 0.002) G_GAN: 2.004 G_L1: 6.687 D_real: 0.224 D_fake: 0.648 \n",
      "(epoch: 159, iters: 240, time: 0.150, data: 0.002) G_GAN: 2.968 G_L1: 8.397 D_real: 0.115 D_fake: 0.078 \n",
      "(epoch: 159, iters: 340, time: 0.150, data: 0.003) G_GAN: 1.422 G_L1: 5.720 D_real: 0.427 D_fake: 0.404 \n",
      "End of epoch 159 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 20, time: 0.385, data: 0.002) G_GAN: 1.859 G_L1: 6.377 D_real: 0.063 D_fake: 0.565 \n",
      "(epoch: 160, iters: 120, time: 0.149, data: 0.002) G_GAN: 2.126 G_L1: 6.209 D_real: 0.359 D_fake: 0.205 \n",
      "(epoch: 160, iters: 220, time: 0.150, data: 0.003) G_GAN: 0.599 G_L1: 5.272 D_real: 1.330 D_fake: 0.497 \n",
      "(epoch: 160, iters: 320, time: 0.150, data: 0.002) G_GAN: 1.770 G_L1: 4.236 D_real: 0.437 D_fake: 0.458 \n",
      "(epoch: 160, iters: 420, time: 0.350, data: 0.002) G_GAN: 2.414 G_L1: 9.855 D_real: 0.141 D_fake: 0.146 \n",
      "saving the model at the end of epoch 160, iters 67200\n",
      "End of epoch 160 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 100, time: 0.150, data: 0.160) G_GAN: 1.456 G_L1: 5.750 D_real: 0.476 D_fake: 0.408 \n",
      "(epoch: 161, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.317 G_L1: 5.503 D_real: 0.385 D_fake: 0.549 \n",
      "(epoch: 161, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.587 G_L1: 3.064 D_real: 0.519 D_fake: 0.254 \n",
      "(epoch: 161, iters: 400, time: 0.351, data: 0.003) G_GAN: 1.643 G_L1: 4.532 D_real: 0.594 D_fake: 0.162 \n",
      "End of epoch 161 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.976 G_L1: 6.257 D_real: 0.509 D_fake: 0.133 \n",
      "(epoch: 162, iters: 180, time: 0.149, data: 0.003) G_GAN: 1.364 G_L1: 6.049 D_real: 0.441 D_fake: 0.319 \n",
      "(epoch: 162, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.476 G_L1: 6.960 D_real: 0.412 D_fake: 0.280 \n",
      "(epoch: 162, iters: 380, time: 0.390, data: 0.003) G_GAN: 1.609 G_L1: 5.509 D_real: 0.563 D_fake: 0.214 \n",
      "End of epoch 162 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 60, time: 0.150, data: 0.002) G_GAN: 2.080 G_L1: 8.034 D_real: 0.241 D_fake: 0.305 \n",
      "(epoch: 163, iters: 160, time: 0.150, data: 0.002) G_GAN: 1.570 G_L1: 5.343 D_real: 1.061 D_fake: 0.583 \n",
      "(epoch: 163, iters: 260, time: 0.150, data: 0.003) G_GAN: 1.108 G_L1: 6.503 D_real: 0.412 D_fake: 0.224 \n",
      "(epoch: 163, iters: 360, time: 0.363, data: 0.002) G_GAN: 1.754 G_L1: 6.014 D_real: 0.256 D_fake: 0.429 \n",
      "End of epoch 163 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 40, time: 0.149, data: 0.002) G_GAN: 1.591 G_L1: 6.563 D_real: 0.348 D_fake: 0.283 \n",
      "(epoch: 164, iters: 140, time: 0.150, data: 0.003) G_GAN: 2.295 G_L1: 6.227 D_real: 0.153 D_fake: 0.136 \n",
      "(epoch: 164, iters: 240, time: 0.149, data: 0.002) G_GAN: 1.759 G_L1: 7.116 D_real: 0.351 D_fake: 0.529 \n",
      "(epoch: 164, iters: 340, time: 0.374, data: 0.002) G_GAN: 2.185 G_L1: 5.035 D_real: 0.146 D_fake: 0.590 \n",
      "End of epoch 164 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 20, time: 0.150, data: 0.002) G_GAN: 1.448 G_L1: 5.266 D_real: 0.290 D_fake: 0.569 \n",
      "(epoch: 165, iters: 120, time: 0.150, data: 0.001) G_GAN: 1.926 G_L1: 6.499 D_real: 0.249 D_fake: 0.380 \n",
      "(epoch: 165, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.955 G_L1: 6.575 D_real: 0.326 D_fake: 0.269 \n",
      "(epoch: 165, iters: 320, time: 0.411, data: 0.003) G_GAN: 1.301 G_L1: 4.086 D_real: 0.533 D_fake: 0.406 \n",
      "(epoch: 165, iters: 420, time: 0.104, data: 0.002) G_GAN: 2.783 G_L1: 6.485 D_real: 0.340 D_fake: 0.054 \n",
      "saving the model at the end of epoch 165, iters 69300\n",
      "End of epoch 165 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 100, time: 0.150, data: 0.169) G_GAN: 3.345 G_L1: 8.813 D_real: 0.363 D_fake: 0.052 \n",
      "(epoch: 166, iters: 200, time: 0.151, data: 0.002) G_GAN: 1.270 G_L1: 5.979 D_real: 0.352 D_fake: 0.473 \n",
      "(epoch: 166, iters: 300, time: 0.394, data: 0.002) G_GAN: 2.120 G_L1: 7.050 D_real: 0.050 D_fake: 0.496 \n",
      "(epoch: 166, iters: 400, time: 0.149, data: 0.002) G_GAN: 2.205 G_L1: 5.470 D_real: 0.175 D_fake: 0.258 \n",
      "End of epoch 166 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.353 G_L1: 6.995 D_real: 0.486 D_fake: 0.551 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 167, iters: 180, time: 0.150, data: 0.002) G_GAN: 2.475 G_L1: 6.250 D_real: 0.156 D_fake: 0.141 \n",
      "(epoch: 167, iters: 280, time: 0.397, data: 0.003) G_GAN: 1.897 G_L1: 8.205 D_real: 0.240 D_fake: 0.610 \n",
      "saving the latest model (epoch 167, total_iters 70000)\n",
      "(epoch: 167, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.500 G_L1: 5.984 D_real: 0.471 D_fake: 0.305 \n",
      "End of epoch 167 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 60, time: 0.150, data: 0.002) G_GAN: 1.249 G_L1: 2.361 D_real: 0.516 D_fake: 0.372 \n",
      "(epoch: 168, iters: 160, time: 0.150, data: 0.002) G_GAN: 1.398 G_L1: 8.301 D_real: 0.451 D_fake: 0.443 \n",
      "(epoch: 168, iters: 260, time: 0.390, data: 0.003) G_GAN: 1.860 G_L1: 4.117 D_real: 0.383 D_fake: 0.351 \n",
      "(epoch: 168, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.786 G_L1: 5.818 D_real: 0.410 D_fake: 0.281 \n",
      "End of epoch 168 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.375 G_L1: 6.978 D_real: 1.031 D_fake: 0.463 \n",
      "(epoch: 169, iters: 140, time: 0.150, data: 0.002) G_GAN: 1.647 G_L1: 6.222 D_real: 0.216 D_fake: 0.299 \n",
      "(epoch: 169, iters: 240, time: 0.398, data: 0.003) G_GAN: 1.263 G_L1: 5.845 D_real: 0.444 D_fake: 0.470 \n",
      "(epoch: 169, iters: 340, time: 0.149, data: 0.003) G_GAN: 1.663 G_L1: 5.160 D_real: 0.542 D_fake: 0.264 \n",
      "End of epoch 169 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 20, time: 0.150, data: 0.002) G_GAN: 1.084 G_L1: 6.265 D_real: 0.902 D_fake: 0.209 \n",
      "(epoch: 170, iters: 120, time: 0.150, data: 0.002) G_GAN: 1.525 G_L1: 6.654 D_real: 0.438 D_fake: 0.425 \n",
      "(epoch: 170, iters: 220, time: 0.394, data: 0.003) G_GAN: 1.128 G_L1: 5.424 D_real: 0.397 D_fake: 0.696 \n",
      "(epoch: 170, iters: 320, time: 0.150, data: 0.003) G_GAN: 2.071 G_L1: 5.974 D_real: 0.391 D_fake: 0.412 \n",
      "(epoch: 170, iters: 420, time: 0.103, data: 0.002) G_GAN: 1.145 G_L1: 5.136 D_real: 0.671 D_fake: 0.168 \n",
      "saving the model at the end of epoch 170, iters 71400\n",
      "End of epoch 170 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 100, time: 0.150, data: 0.144) G_GAN: 1.134 G_L1: 5.731 D_real: 0.379 D_fake: 0.575 \n",
      "(epoch: 171, iters: 200, time: 0.399, data: 0.002) G_GAN: 1.264 G_L1: 5.844 D_real: 0.461 D_fake: 0.345 \n",
      "(epoch: 171, iters: 300, time: 0.149, data: 0.002) G_GAN: 1.714 G_L1: 5.422 D_real: 0.292 D_fake: 0.327 \n",
      "(epoch: 171, iters: 400, time: 0.149, data: 0.003) G_GAN: 1.324 G_L1: 4.514 D_real: 0.597 D_fake: 0.357 \n",
      "End of epoch 171 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 80, time: 0.150, data: 0.002) G_GAN: 1.621 G_L1: 4.808 D_real: 0.463 D_fake: 0.219 \n",
      "(epoch: 172, iters: 180, time: 0.406, data: 0.002) G_GAN: 1.488 G_L1: 6.736 D_real: 0.214 D_fake: 0.441 \n",
      "(epoch: 172, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.495 G_L1: 6.226 D_real: 0.280 D_fake: 0.818 \n",
      "(epoch: 172, iters: 380, time: 0.150, data: 0.003) G_GAN: 1.463 G_L1: 4.680 D_real: 0.482 D_fake: 0.373 \n",
      "End of epoch 172 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 60, time: 0.150, data: 0.003) G_GAN: 1.596 G_L1: 7.704 D_real: 0.800 D_fake: 0.244 \n",
      "(epoch: 173, iters: 160, time: 0.397, data: 0.002) G_GAN: 1.100 G_L1: 3.582 D_real: 0.549 D_fake: 0.626 \n",
      "(epoch: 173, iters: 260, time: 0.150, data: 0.002) G_GAN: 2.142 G_L1: 7.346 D_real: 0.088 D_fake: 0.238 \n",
      "(epoch: 173, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.703 G_L1: 5.017 D_real: 0.379 D_fake: 0.270 \n",
      "End of epoch 173 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.639 G_L1: 7.526 D_real: 0.353 D_fake: 0.284 \n",
      "(epoch: 174, iters: 140, time: 0.398, data: 0.003) G_GAN: 1.721 G_L1: 6.805 D_real: 0.565 D_fake: 0.176 \n",
      "(epoch: 174, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.752 G_L1: 6.418 D_real: 0.247 D_fake: 0.306 \n",
      "(epoch: 174, iters: 340, time: 0.151, data: 0.002) G_GAN: 1.292 G_L1: 6.188 D_real: 0.505 D_fake: 0.261 \n",
      "End of epoch 174 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 20, time: 0.150, data: 0.003) G_GAN: 1.887 G_L1: 7.164 D_real: 0.316 D_fake: 0.279 \n",
      "(epoch: 175, iters: 120, time: 0.401, data: 0.001) G_GAN: 1.694 G_L1: 7.222 D_real: 0.211 D_fake: 0.536 \n",
      "(epoch: 175, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.032 G_L1: 6.409 D_real: 0.416 D_fake: 1.055 \n",
      "(epoch: 175, iters: 320, time: 0.150, data: 0.003) G_GAN: 1.011 G_L1: 4.779 D_real: 0.579 D_fake: 0.359 \n",
      "(epoch: 175, iters: 420, time: 0.104, data: 0.003) G_GAN: 0.980 G_L1: 5.826 D_real: 0.526 D_fake: 0.427 \n",
      "saving the model at the end of epoch 175, iters 73500\n",
      "End of epoch 175 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 100, time: 0.371, data: 0.147) G_GAN: 1.645 G_L1: 4.994 D_real: 0.266 D_fake: 0.514 \n",
      "(epoch: 176, iters: 200, time: 0.149, data: 0.002) G_GAN: 1.423 G_L1: 6.946 D_real: 0.410 D_fake: 0.408 \n",
      "(epoch: 176, iters: 300, time: 0.151, data: 0.002) G_GAN: 1.688 G_L1: 3.525 D_real: 0.316 D_fake: 0.278 \n",
      "(epoch: 176, iters: 400, time: 0.151, data: 0.002) G_GAN: 1.514 G_L1: 5.540 D_real: 0.449 D_fake: 0.347 \n",
      "End of epoch 176 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 80, time: 0.407, data: 0.002) G_GAN: 1.824 G_L1: 7.775 D_real: 0.362 D_fake: 0.171 \n",
      "(epoch: 177, iters: 180, time: 0.149, data: 0.002) G_GAN: 1.582 G_L1: 6.462 D_real: 0.338 D_fake: 0.451 \n",
      "(epoch: 177, iters: 280, time: 0.150, data: 0.002) G_GAN: 1.668 G_L1: 5.205 D_real: 0.585 D_fake: 0.288 \n",
      "(epoch: 177, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.635 G_L1: 5.284 D_real: 0.216 D_fake: 0.549 \n",
      "End of epoch 177 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 60, time: 0.413, data: 0.003) G_GAN: 1.646 G_L1: 8.059 D_real: 0.199 D_fake: 0.433 \n",
      "(epoch: 178, iters: 160, time: 0.150, data: 0.003) G_GAN: 1.772 G_L1: 6.377 D_real: 0.321 D_fake: 0.457 \n",
      "(epoch: 178, iters: 260, time: 0.151, data: 0.002) G_GAN: 1.724 G_L1: 6.397 D_real: 0.295 D_fake: 0.504 \n",
      "(epoch: 178, iters: 360, time: 0.150, data: 0.002) G_GAN: 1.677 G_L1: 8.378 D_real: 0.505 D_fake: 0.222 \n",
      "End of epoch 178 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 40, time: 0.413, data: 0.002) G_GAN: 1.922 G_L1: 6.023 D_real: 0.263 D_fake: 0.340 \n",
      "(epoch: 179, iters: 140, time: 0.149, data: 0.002) G_GAN: 1.386 G_L1: 6.125 D_real: 0.452 D_fake: 0.270 \n",
      "(epoch: 179, iters: 240, time: 0.150, data: 0.003) G_GAN: 1.550 G_L1: 6.449 D_real: 0.358 D_fake: 0.458 \n",
      "saving the latest model (epoch 179, total_iters 75000)\n",
      "(epoch: 179, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.236 G_L1: 6.238 D_real: 0.335 D_fake: 0.553 \n",
      "End of epoch 179 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000416\n",
      "(epoch: 180, iters: 20, time: 0.414, data: 0.002) G_GAN: 1.220 G_L1: 5.413 D_real: 0.574 D_fake: 0.386 \n",
      "(epoch: 180, iters: 120, time: 0.150, data: 0.003) G_GAN: 1.988 G_L1: 6.555 D_real: 0.248 D_fake: 0.155 \n",
      "(epoch: 180, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.571 G_L1: 7.164 D_real: 0.308 D_fake: 0.469 \n",
      "(epoch: 180, iters: 320, time: 0.150, data: 0.002) G_GAN: 1.655 G_L1: 7.225 D_real: 0.413 D_fake: 0.234 \n",
      "(epoch: 180, iters: 420, time: 0.358, data: 0.002) G_GAN: 1.713 G_L1: 7.242 D_real: 0.293 D_fake: 0.332 \n",
      "saving the model at the end of epoch 180, iters 75600\n",
      "End of epoch 180 / 200 \t Time Taken: 43 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 100, time: 0.149, data: 0.143) G_GAN: 1.450 G_L1: 3.656 D_real: 0.431 D_fake: 0.288 \n",
      "(epoch: 181, iters: 200, time: 0.149, data: 0.002) G_GAN: 1.985 G_L1: 6.703 D_real: 0.529 D_fake: 0.214 \n",
      "(epoch: 181, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.695 G_L1: 5.278 D_real: 0.511 D_fake: 0.261 \n",
      "(epoch: 181, iters: 400, time: 0.396, data: 0.002) G_GAN: 2.077 G_L1: 5.026 D_real: 0.407 D_fake: 0.171 \n",
      "End of epoch 181 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 80, time: 0.149, data: 0.002) G_GAN: 1.789 G_L1: 4.370 D_real: 0.547 D_fake: 0.219 \n",
      "(epoch: 182, iters: 180, time: 0.150, data: 0.002) G_GAN: 1.633 G_L1: 9.814 D_real: 0.145 D_fake: 0.411 \n",
      "(epoch: 182, iters: 280, time: 0.149, data: 0.002) G_GAN: 1.814 G_L1: 5.122 D_real: 0.294 D_fake: 0.383 \n",
      "(epoch: 182, iters: 380, time: 0.404, data: 0.002) G_GAN: 1.890 G_L1: 7.746 D_real: 0.434 D_fake: 0.291 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 182 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 60, time: 0.150, data: 0.003) G_GAN: 2.328 G_L1: 8.228 D_real: 0.169 D_fake: 0.155 \n",
      "(epoch: 183, iters: 160, time: 0.149, data: 0.003) G_GAN: 1.857 G_L1: 10.652 D_real: 0.211 D_fake: 0.279 \n",
      "(epoch: 183, iters: 260, time: 0.150, data: 0.002) G_GAN: 1.967 G_L1: 7.414 D_real: 0.452 D_fake: 0.183 \n",
      "(epoch: 183, iters: 360, time: 0.403, data: 0.002) G_GAN: 1.489 G_L1: 6.500 D_real: 0.367 D_fake: 0.320 \n",
      "End of epoch 183 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 40, time: 0.149, data: 0.002) G_GAN: 1.549 G_L1: 5.513 D_real: 0.408 D_fake: 0.294 \n",
      "(epoch: 184, iters: 140, time: 0.150, data: 0.003) G_GAN: 1.645 G_L1: 5.695 D_real: 0.456 D_fake: 0.255 \n",
      "(epoch: 184, iters: 240, time: 0.150, data: 0.002) G_GAN: 1.193 G_L1: 4.999 D_real: 0.624 D_fake: 0.445 \n",
      "(epoch: 184, iters: 340, time: 0.397, data: 0.003) G_GAN: 1.344 G_L1: 5.441 D_real: 0.275 D_fake: 0.879 \n",
      "End of epoch 184 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 20, time: 0.150, data: 0.002) G_GAN: 1.923 G_L1: 7.702 D_real: 0.202 D_fake: 0.334 \n",
      "(epoch: 185, iters: 120, time: 0.149, data: 0.003) G_GAN: 0.796 G_L1: 3.664 D_real: 1.424 D_fake: 0.490 \n",
      "(epoch: 185, iters: 220, time: 0.151, data: 0.002) G_GAN: 1.655 G_L1: 6.523 D_real: 0.206 D_fake: 0.455 \n",
      "(epoch: 185, iters: 320, time: 0.401, data: 0.002) G_GAN: 1.172 G_L1: 5.036 D_real: 0.451 D_fake: 0.604 \n",
      "(epoch: 185, iters: 420, time: 0.103, data: 0.002) G_GAN: 2.185 G_L1: 1.584 D_real: 0.221 D_fake: 0.155 \n",
      "saving the model at the end of epoch 185, iters 77700\n",
      "End of epoch 185 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 100, time: 0.150, data: 0.143) G_GAN: 1.496 G_L1: 5.769 D_real: 0.209 D_fake: 0.358 \n",
      "(epoch: 186, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.594 G_L1: 6.243 D_real: 0.372 D_fake: 0.298 \n",
      "(epoch: 186, iters: 300, time: 0.412, data: 0.002) G_GAN: 1.482 G_L1: 4.664 D_real: 0.284 D_fake: 0.474 \n",
      "(epoch: 186, iters: 400, time: 0.150, data: 0.003) G_GAN: 1.220 G_L1: 3.643 D_real: 0.500 D_fake: 0.343 \n",
      "End of epoch 186 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 80, time: 0.149, data: 0.002) G_GAN: 1.842 G_L1: 7.584 D_real: 0.350 D_fake: 0.208 \n",
      "(epoch: 187, iters: 180, time: 0.151, data: 0.002) G_GAN: 1.453 G_L1: 5.883 D_real: 0.470 D_fake: 0.385 \n",
      "(epoch: 187, iters: 280, time: 0.423, data: 0.003) G_GAN: 1.520 G_L1: 6.775 D_real: 0.309 D_fake: 0.317 \n",
      "(epoch: 187, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.443 G_L1: 5.734 D_real: 0.316 D_fake: 0.463 \n",
      "End of epoch 187 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 60, time: 0.150, data: 0.002) G_GAN: 1.566 G_L1: 5.562 D_real: 0.411 D_fake: 0.308 \n",
      "(epoch: 188, iters: 160, time: 0.150, data: 0.002) G_GAN: 1.485 G_L1: 7.334 D_real: 0.169 D_fake: 0.495 \n",
      "(epoch: 188, iters: 260, time: 0.417, data: 0.003) G_GAN: 1.531 G_L1: 7.049 D_real: 0.198 D_fake: 0.569 \n",
      "(epoch: 188, iters: 360, time: 0.150, data: 0.003) G_GAN: 1.304 G_L1: 6.174 D_real: 0.325 D_fake: 0.437 \n",
      "End of epoch 188 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 40, time: 0.150, data: 0.003) G_GAN: 2.041 G_L1: 5.883 D_real: 0.306 D_fake: 0.171 \n",
      "(epoch: 189, iters: 140, time: 0.150, data: 0.003) G_GAN: 1.652 G_L1: 6.396 D_real: 0.275 D_fake: 0.302 \n",
      "(epoch: 189, iters: 240, time: 0.418, data: 0.002) G_GAN: 1.446 G_L1: 6.577 D_real: 0.362 D_fake: 0.431 \n",
      "(epoch: 189, iters: 340, time: 0.149, data: 0.002) G_GAN: 1.379 G_L1: 5.603 D_real: 0.445 D_fake: 0.307 \n",
      "End of epoch 189 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 20, time: 0.150, data: 0.002) G_GAN: 1.623 G_L1: 6.824 D_real: 0.243 D_fake: 0.338 \n",
      "(epoch: 190, iters: 120, time: 0.149, data: 0.004) G_GAN: 1.330 G_L1: 8.502 D_real: 0.619 D_fake: 0.519 \n",
      "(epoch: 190, iters: 220, time: 0.422, data: 0.002) G_GAN: 1.432 G_L1: 5.453 D_real: 0.787 D_fake: 0.251 \n",
      "(epoch: 190, iters: 320, time: 0.150, data: 0.003) G_GAN: 1.561 G_L1: 6.094 D_real: 0.252 D_fake: 0.387 \n",
      "(epoch: 190, iters: 420, time: 0.103, data: 0.002) G_GAN: 2.735 G_L1: 6.630 D_real: 0.343 D_fake: 0.059 \n",
      "saving the model at the end of epoch 190, iters 79800\n",
      "End of epoch 190 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 100, time: 0.149, data: 0.137) G_GAN: 1.506 G_L1: 4.685 D_real: 0.295 D_fake: 0.372 \n",
      "(epoch: 191, iters: 200, time: 0.419, data: 0.002) G_GAN: 1.876 G_L1: 7.549 D_real: 0.288 D_fake: 0.220 \n",
      "saving the latest model (epoch 191, total_iters 80000)\n",
      "(epoch: 191, iters: 300, time: 0.149, data: 0.002) G_GAN: 1.492 G_L1: 5.561 D_real: 0.519 D_fake: 0.396 \n",
      "(epoch: 191, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.686 G_L1: 7.781 D_real: 0.219 D_fake: 0.306 \n",
      "End of epoch 191 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 80, time: 0.151, data: 0.002) G_GAN: 1.459 G_L1: 6.454 D_real: 0.484 D_fake: 0.369 \n",
      "(epoch: 192, iters: 180, time: 0.420, data: 0.002) G_GAN: 1.486 G_L1: 5.204 D_real: 0.560 D_fake: 0.365 \n",
      "(epoch: 192, iters: 280, time: 0.150, data: 0.003) G_GAN: 1.556 G_L1: 4.739 D_real: 0.320 D_fake: 0.355 \n",
      "(epoch: 192, iters: 380, time: 0.151, data: 0.002) G_GAN: 1.473 G_L1: 5.272 D_real: 0.249 D_fake: 0.401 \n",
      "End of epoch 192 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 60, time: 0.150, data: 0.002) G_GAN: 1.156 G_L1: 5.615 D_real: 0.195 D_fake: 0.683 \n",
      "(epoch: 193, iters: 160, time: 0.422, data: 0.002) G_GAN: 1.541 G_L1: 6.871 D_real: 0.434 D_fake: 0.257 \n",
      "(epoch: 193, iters: 260, time: 0.150, data: 0.003) G_GAN: 1.447 G_L1: 5.855 D_real: 0.258 D_fake: 0.403 \n",
      "(epoch: 193, iters: 360, time: 0.149, data: 0.003) G_GAN: 1.853 G_L1: 6.981 D_real: 0.445 D_fake: 0.374 \n",
      "End of epoch 193 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 40, time: 0.150, data: 0.002) G_GAN: 1.736 G_L1: 5.239 D_real: 0.332 D_fake: 0.309 \n",
      "(epoch: 194, iters: 140, time: 0.416, data: 0.003) G_GAN: 1.449 G_L1: 4.746 D_real: 0.499 D_fake: 0.267 \n",
      "(epoch: 194, iters: 240, time: 0.150, data: 0.003) G_GAN: 1.458 G_L1: 7.360 D_real: 0.429 D_fake: 0.310 \n",
      "(epoch: 194, iters: 340, time: 0.150, data: 0.002) G_GAN: 1.146 G_L1: 3.754 D_real: 0.491 D_fake: 0.467 \n",
      "End of epoch 194 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 20, time: 0.150, data: 0.003) G_GAN: 1.780 G_L1: 7.127 D_real: 0.239 D_fake: 0.242 \n",
      "(epoch: 195, iters: 120, time: 0.430, data: 0.004) G_GAN: 1.519 G_L1: 5.327 D_real: 0.274 D_fake: 0.368 \n",
      "(epoch: 195, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.549 G_L1: 5.475 D_real: 0.546 D_fake: 0.286 \n",
      "(epoch: 195, iters: 320, time: 0.149, data: 0.002) G_GAN: 1.529 G_L1: 6.773 D_real: 0.316 D_fake: 0.297 \n",
      "(epoch: 195, iters: 420, time: 0.104, data: 0.003) G_GAN: 1.720 G_L1: 6.519 D_real: 0.114 D_fake: 0.368 \n",
      "saving the model at the end of epoch 195, iters 81900\n",
      "End of epoch 195 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 100, time: 0.423, data: 0.132) G_GAN: 1.839 G_L1: 5.430 D_real: 0.337 D_fake: 0.323 \n",
      "(epoch: 196, iters: 200, time: 0.150, data: 0.002) G_GAN: 1.094 G_L1: 2.926 D_real: 0.670 D_fake: 0.472 \n",
      "(epoch: 196, iters: 300, time: 0.150, data: 0.002) G_GAN: 1.423 G_L1: 7.281 D_real: 0.389 D_fake: 0.350 \n",
      "(epoch: 196, iters: 400, time: 0.150, data: 0.002) G_GAN: 1.199 G_L1: 4.257 D_real: 0.540 D_fake: 0.424 \n",
      "End of epoch 196 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 80, time: 0.425, data: 0.002) G_GAN: 2.092 G_L1: 6.114 D_real: 0.366 D_fake: 0.163 \n",
      "(epoch: 197, iters: 180, time: 0.149, data: 0.003) G_GAN: 1.617 G_L1: 6.828 D_real: 0.204 D_fake: 0.316 \n",
      "(epoch: 197, iters: 280, time: 0.149, data: 0.003) G_GAN: 1.860 G_L1: 5.231 D_real: 0.257 D_fake: 0.239 \n",
      "(epoch: 197, iters: 380, time: 0.150, data: 0.002) G_GAN: 1.131 G_L1: 4.906 D_real: 0.434 D_fake: 0.560 \n",
      "End of epoch 197 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 60, time: 0.429, data: 0.002) G_GAN: 1.753 G_L1: 5.430 D_real: 0.327 D_fake: 0.278 \n",
      "(epoch: 198, iters: 160, time: 0.149, data: 0.002) G_GAN: 1.477 G_L1: 4.287 D_real: 0.558 D_fake: 0.297 \n",
      "(epoch: 198, iters: 260, time: 0.149, data: 0.002) G_GAN: 1.471 G_L1: 5.350 D_real: 0.361 D_fake: 0.414 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 198, iters: 360, time: 0.150, data: 0.003) G_GAN: 1.590 G_L1: 5.513 D_real: 0.404 D_fake: 0.310 \n",
      "End of epoch 198 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 40, time: 0.433, data: 0.003) G_GAN: 1.439 G_L1: 4.980 D_real: 0.342 D_fake: 0.396 \n",
      "(epoch: 199, iters: 140, time: 0.150, data: 0.002) G_GAN: 2.474 G_L1: 4.339 D_real: 0.337 D_fake: 0.123 \n",
      "(epoch: 199, iters: 240, time: 0.160, data: 0.003) G_GAN: 1.462 G_L1: 4.732 D_real: 0.484 D_fake: 0.343 \n",
      "(epoch: 199, iters: 340, time: 0.151, data: 0.002) G_GAN: 1.494 G_L1: 6.597 D_real: 0.348 D_fake: 0.315 \n",
      "End of epoch 199 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 20, time: 0.433, data: 0.002) G_GAN: 1.378 G_L1: 6.343 D_real: 0.267 D_fake: 0.516 \n",
      "(epoch: 200, iters: 120, time: 0.151, data: 0.001) G_GAN: 2.217 G_L1: 5.820 D_real: 0.292 D_fake: 0.193 \n",
      "(epoch: 200, iters: 220, time: 0.150, data: 0.002) G_GAN: 1.339 G_L1: 7.041 D_real: 0.264 D_fake: 0.527 \n",
      "(epoch: 200, iters: 320, time: 0.150, data: 0.003) G_GAN: 1.965 G_L1: 5.496 D_real: 0.328 D_fake: 0.231 \n",
      "(epoch: 200, iters: 420, time: 0.370, data: 0.003) G_GAN: 2.272 G_L1: 4.677 D_real: 0.173 D_fake: 0.134 \n",
      "saving the model at the end of epoch 200, iters 84000\n",
      "End of epoch 200 / 200 \t Time Taken: 43 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot extracolor/AB --model pix2pix --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 4  --netG resnet_9blocks --preprocess none --name 417real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 4                             \t[default: 1]\n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: testimg                       \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: 417real                       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_apr17_t_real          \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from Apr17/417real/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.366 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['testimg/001.jpg']\n",
      "processing (0005)-th image... ['testimg/006.jpg']\n",
      "processing (0010)-th image... ['testimg/011.jpg']\n",
      "processing (0015)-th image... ['testimg/016.jpg']\n",
      "processing (0020)-th image... ['testimg/021.jpg']\n",
      "processing (0025)-th image... ['testimg/026.jpg']\n",
      "processing (0030)-th image... ['testimg/031.jpg']\n",
      "processing (0035)-th image... ['testimg/036.jpg']\n",
      "processing (0040)-th image... ['testimg/041.jpg']\n",
      "processing (0045)-th image... ['testimg/046.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot testimg --model test --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 4 --netG resnet_9blocks --preprocess none --name 417real --results_dir results_apr17_t_real  --dataset_mode single "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 4                             \t[default: 1]\n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: testimages                    \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: 417real                       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_apr17_e_real          \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from Apr17/417real/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.366 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['testimages/0054-160-m3h--5-h-ksb-etanorm-g-100-200-g11.jpg']\n",
      "The image size needs to be a multiple of 4. The loaded image size was (1801, 1169), so it was adjusted to (1800, 1168). This adjustment will be done to all images whose sizes are not multiples of 4\n",
      "processing (0005)-th image... ['testimages/17J-SG02_17J-SG02 nameplate.jpeg']\n",
      "processing (0010)-th image... ['testimages/2968_3.jpeg']\n",
      "processing (0015)-th image... ['testimages/4.jpg']\n",
      "processing (0020)-th image... ['testimages/7506_3.jpeg']\n",
      "processing (0025)-th image... ['testimages/NamePlate110.jpeg']\n",
      "processing (0030)-th image... ['testimages/image_185.jpg']\n",
      "processing (0035)-th image... ['testimages/image_765.jpg']\n",
      "processing (0040)-th image... ['testimages/s-l640.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot testimages --model test --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 4 --netG resnet_9blocks --preprocess none --name 417real --results_dir results_apr17_e_real  --dataset_mode single "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 4                             \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: extrarealsyncolor/AB          \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: realsyn                       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \t[default: batch]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 500\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.366 M\n",
      "[Network D] Total number of parameters : 2.764 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory Apr17/realsyn/web...\n",
      "(epoch: 1, iters: 100, time: 0.161, data: 0.134) G_GAN: 1.429 G_L1: 12.786 D_real: 0.465 D_fake: 0.365 \n",
      "(epoch: 1, iters: 200, time: 0.162, data: 0.002) G_GAN: 1.607 G_L1: 9.994 D_real: 0.736 D_fake: 0.363 \n",
      "(epoch: 1, iters: 300, time: 0.162, data: 0.002) G_GAN: 1.936 G_L1: 9.746 D_real: 0.795 D_fake: 0.123 \n",
      "(epoch: 1, iters: 400, time: 0.223, data: 0.002) G_GAN: 1.438 G_L1: 13.597 D_real: 0.533 D_fake: 0.209 \n",
      "(epoch: 1, iters: 500, time: 0.163, data: 0.002) G_GAN: 2.402 G_L1: 10.822 D_real: 0.692 D_fake: 0.071 \n",
      "End of epoch 1 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 100, time: 0.162, data: 0.173) G_GAN: 1.431 G_L1: 12.371 D_real: 0.053 D_fake: 1.428 \n",
      "(epoch: 2, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.728 G_L1: 10.684 D_real: 0.717 D_fake: 0.199 \n",
      "(epoch: 2, iters: 300, time: 0.216, data: 0.002) G_GAN: 1.634 G_L1: 8.788 D_real: 0.959 D_fake: 0.185 \n",
      "(epoch: 2, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.236 G_L1: 10.570 D_real: 0.341 D_fake: 0.308 \n",
      "(epoch: 2, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.290 G_L1: 8.773 D_real: 0.839 D_fake: 0.442 \n",
      "End of epoch 2 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 100, time: 0.163, data: 0.172) G_GAN: 1.149 G_L1: 9.502 D_real: 0.400 D_fake: 0.702 \n",
      "(epoch: 3, iters: 200, time: 0.232, data: 0.002) G_GAN: 1.149 G_L1: 11.360 D_real: 0.126 D_fake: 0.695 \n",
      "(epoch: 3, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.358 G_L1: 9.416 D_real: 0.710 D_fake: 0.495 \n",
      "(epoch: 3, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.245 G_L1: 7.905 D_real: 0.471 D_fake: 0.477 \n",
      "(epoch: 3, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.227 G_L1: 8.904 D_real: 1.549 D_fake: 0.277 \n",
      "End of epoch 3 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 100, time: 0.236, data: 0.170) G_GAN: 1.050 G_L1: 9.649 D_real: 0.451 D_fake: 0.917 \n",
      "(epoch: 4, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.170 G_L1: 8.774 D_real: 0.265 D_fake: 0.573 \n",
      "(epoch: 4, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.280 G_L1: 8.602 D_real: 0.497 D_fake: 0.622 \n",
      "(epoch: 4, iters: 400, time: 0.164, data: 0.003) G_GAN: 1.096 G_L1: 8.356 D_real: 0.590 D_fake: 0.335 \n",
      "(epoch: 4, iters: 500, time: 0.235, data: 0.002) G_GAN: 0.944 G_L1: 9.832 D_real: 0.281 D_fake: 0.589 \n",
      "End of epoch 4 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 100, time: 0.164, data: 0.150) G_GAN: 1.308 G_L1: 7.147 D_real: 0.830 D_fake: 0.585 \n",
      "(epoch: 5, iters: 200, time: 0.163, data: 0.002) G_GAN: 0.972 G_L1: 6.320 D_real: 0.689 D_fake: 0.414 \n",
      "(epoch: 5, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.193 G_L1: 9.262 D_real: 0.443 D_fake: 0.344 \n",
      "(epoch: 5, iters: 400, time: 0.241, data: 0.002) G_GAN: 1.227 G_L1: 9.873 D_real: 0.711 D_fake: 0.583 \n",
      "(epoch: 5, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.145 G_L1: 7.503 D_real: 1.423 D_fake: 0.296 \n",
      "saving the model at the end of epoch 5, iters 2500\n",
      "End of epoch 5 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.163, data: 0.147) G_GAN: 1.018 G_L1: 6.303 D_real: 0.362 D_fake: 0.751 \n",
      "(epoch: 6, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.002 G_L1: 7.959 D_real: 0.762 D_fake: 0.352 \n",
      "(epoch: 6, iters: 300, time: 0.231, data: 0.002) G_GAN: 0.957 G_L1: 10.146 D_real: 0.784 D_fake: 0.287 \n",
      "(epoch: 6, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.112 G_L1: 6.457 D_real: 0.868 D_fake: 0.203 \n",
      "(epoch: 6, iters: 500, time: 0.164, data: 0.003) G_GAN: 1.278 G_L1: 8.505 D_real: 0.308 D_fake: 0.776 \n",
      "End of epoch 6 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 100, time: 0.164, data: 0.153) G_GAN: 1.501 G_L1: 8.635 D_real: 0.055 D_fake: 1.989 \n",
      "(epoch: 7, iters: 200, time: 0.224, data: 0.002) G_GAN: 1.194 G_L1: 9.184 D_real: 0.453 D_fake: 0.596 \n",
      "(epoch: 7, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.195 G_L1: 7.964 D_real: 0.457 D_fake: 0.533 \n",
      "(epoch: 7, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.184 G_L1: 7.900 D_real: 0.954 D_fake: 0.288 \n",
      "(epoch: 7, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.153 G_L1: 7.532 D_real: 0.904 D_fake: 0.280 \n",
      "End of epoch 7 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 100, time: 0.235, data: 0.149) G_GAN: 0.839 G_L1: 6.143 D_real: 0.593 D_fake: 0.450 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 8, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.605 G_L1: 10.045 D_real: 0.309 D_fake: 0.425 \n",
      "(epoch: 8, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.160 G_L1: 7.691 D_real: 0.855 D_fake: 0.488 \n",
      "(epoch: 8, iters: 400, time: 0.164, data: 0.003) G_GAN: 1.670 G_L1: 9.880 D_real: 0.143 D_fake: 0.762 \n",
      "(epoch: 8, iters: 500, time: 0.233, data: 0.002) G_GAN: 0.551 G_L1: 7.338 D_real: 0.931 D_fake: 0.310 \n",
      "End of epoch 8 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 100, time: 0.163, data: 0.179) G_GAN: 0.862 G_L1: 5.970 D_real: 0.405 D_fake: 0.844 \n",
      "(epoch: 9, iters: 200, time: 0.163, data: 0.003) G_GAN: 1.400 G_L1: 6.624 D_real: 0.702 D_fake: 0.385 \n",
      "(epoch: 9, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.243 G_L1: 8.356 D_real: 0.340 D_fake: 0.478 \n",
      "(epoch: 9, iters: 400, time: 0.232, data: 0.002) G_GAN: 0.879 G_L1: 8.230 D_real: 0.473 D_fake: 0.547 \n",
      "(epoch: 9, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.217 G_L1: 7.414 D_real: 0.394 D_fake: 0.798 \n",
      "End of epoch 9 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 100, time: 0.163, data: 0.167) G_GAN: 0.911 G_L1: 6.614 D_real: 0.825 D_fake: 0.387 \n",
      "(epoch: 10, iters: 200, time: 0.163, data: 0.002) G_GAN: 0.835 G_L1: 7.714 D_real: 0.808 D_fake: 0.314 \n",
      "(epoch: 10, iters: 300, time: 0.235, data: 0.002) G_GAN: 1.016 G_L1: 9.356 D_real: 0.362 D_fake: 0.340 \n",
      "(epoch: 10, iters: 400, time: 0.164, data: 0.002) G_GAN: 0.892 G_L1: 8.956 D_real: 0.825 D_fake: 0.292 \n",
      "(epoch: 10, iters: 500, time: 0.163, data: 0.002) G_GAN: 0.787 G_L1: 5.695 D_real: 1.156 D_fake: 0.318 \n",
      "saving the latest model (epoch 10, total_iters 5000)\n",
      "saving the model at the end of epoch 10, iters 5000\n",
      "End of epoch 10 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.163, data: 0.145) G_GAN: 1.383 G_L1: 8.971 D_real: 0.447 D_fake: 0.516 \n",
      "(epoch: 11, iters: 200, time: 0.245, data: 0.003) G_GAN: 1.160 G_L1: 8.873 D_real: 0.414 D_fake: 0.583 \n",
      "(epoch: 11, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.584 G_L1: 8.626 D_real: 0.325 D_fake: 0.718 \n",
      "(epoch: 11, iters: 400, time: 0.163, data: 0.003) G_GAN: 1.106 G_L1: 8.665 D_real: 0.345 D_fake: 0.548 \n",
      "(epoch: 11, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.058 G_L1: 5.737 D_real: 0.591 D_fake: 0.673 \n",
      "End of epoch 11 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 100, time: 0.244, data: 0.162) G_GAN: 1.076 G_L1: 7.756 D_real: 0.248 D_fake: 0.987 \n",
      "(epoch: 12, iters: 200, time: 0.163, data: 0.002) G_GAN: 0.666 G_L1: 6.781 D_real: 0.729 D_fake: 0.361 \n",
      "(epoch: 12, iters: 300, time: 0.163, data: 0.003) G_GAN: 1.461 G_L1: 9.352 D_real: 0.802 D_fake: 0.357 \n",
      "(epoch: 12, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.319 G_L1: 9.399 D_real: 0.456 D_fake: 0.537 \n",
      "(epoch: 12, iters: 500, time: 0.241, data: 0.002) G_GAN: 1.506 G_L1: 9.841 D_real: 0.352 D_fake: 0.518 \n",
      "End of epoch 12 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 100, time: 0.163, data: 0.148) G_GAN: 0.965 G_L1: 6.798 D_real: 0.605 D_fake: 0.501 \n",
      "(epoch: 13, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.039 G_L1: 9.186 D_real: 1.234 D_fake: 0.249 \n",
      "(epoch: 13, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.180 G_L1: 7.485 D_real: 0.667 D_fake: 0.602 \n",
      "(epoch: 13, iters: 400, time: 0.242, data: 0.002) G_GAN: 1.381 G_L1: 9.983 D_real: 0.312 D_fake: 0.626 \n",
      "(epoch: 13, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.075 G_L1: 7.853 D_real: 0.153 D_fake: 0.731 \n",
      "End of epoch 13 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 100, time: 0.163, data: 0.151) G_GAN: 1.135 G_L1: 8.344 D_real: 0.292 D_fake: 0.723 \n",
      "(epoch: 14, iters: 200, time: 0.164, data: 0.003) G_GAN: 1.089 G_L1: 7.514 D_real: 0.303 D_fake: 0.842 \n",
      "(epoch: 14, iters: 300, time: 0.239, data: 0.002) G_GAN: 0.811 G_L1: 7.577 D_real: 1.057 D_fake: 0.352 \n",
      "(epoch: 14, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.116 G_L1: 8.530 D_real: 0.230 D_fake: 0.767 \n",
      "(epoch: 14, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.452 G_L1: 10.811 D_real: 0.347 D_fake: 0.371 \n",
      "End of epoch 14 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 100, time: 0.163, data: 0.173) G_GAN: 0.857 G_L1: 6.148 D_real: 0.689 D_fake: 0.689 \n",
      "(epoch: 15, iters: 200, time: 0.250, data: 0.002) G_GAN: 1.367 G_L1: 9.608 D_real: 0.350 D_fake: 0.443 \n",
      "(epoch: 15, iters: 300, time: 0.163, data: 0.002) G_GAN: 0.877 G_L1: 3.666 D_real: 0.802 D_fake: 0.727 \n",
      "(epoch: 15, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.494 G_L1: 9.214 D_real: 0.481 D_fake: 0.518 \n",
      "(epoch: 15, iters: 500, time: 0.164, data: 0.002) G_GAN: 0.950 G_L1: 8.099 D_real: 0.251 D_fake: 0.864 \n",
      "saving the model at the end of epoch 15, iters 7500\n",
      "End of epoch 15 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 100, time: 0.243, data: 0.137) G_GAN: 1.357 G_L1: 6.835 D_real: 0.213 D_fake: 1.032 \n",
      "(epoch: 16, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.255 G_L1: 7.898 D_real: 1.616 D_fake: 0.125 \n",
      "(epoch: 16, iters: 300, time: 0.163, data: 0.003) G_GAN: 0.801 G_L1: 5.260 D_real: 0.611 D_fake: 0.599 \n",
      "(epoch: 16, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.309 G_L1: 7.908 D_real: 0.293 D_fake: 1.170 \n",
      "(epoch: 16, iters: 500, time: 0.235, data: 0.002) G_GAN: 1.092 G_L1: 5.821 D_real: 1.365 D_fake: 0.193 \n",
      "End of epoch 16 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 100, time: 0.163, data: 0.159) G_GAN: 0.794 G_L1: 7.703 D_real: 0.472 D_fake: 0.507 \n",
      "(epoch: 17, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.145 G_L1: 6.286 D_real: 0.609 D_fake: 0.779 \n",
      "(epoch: 17, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.391 G_L1: 8.021 D_real: 0.206 D_fake: 0.654 \n",
      "(epoch: 17, iters: 400, time: 0.243, data: 0.003) G_GAN: 1.013 G_L1: 7.875 D_real: 0.405 D_fake: 0.356 \n",
      "(epoch: 17, iters: 500, time: 0.164, data: 0.002) G_GAN: 0.889 G_L1: 6.061 D_real: 0.879 D_fake: 0.289 \n",
      "End of epoch 17 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 100, time: 0.163, data: 0.152) G_GAN: 0.918 G_L1: 7.409 D_real: 0.615 D_fake: 0.998 \n",
      "(epoch: 18, iters: 200, time: 0.163, data: 0.002) G_GAN: 0.469 G_L1: 6.599 D_real: 1.160 D_fake: 0.298 \n",
      "(epoch: 18, iters: 300, time: 0.247, data: 0.002) G_GAN: 1.213 G_L1: 8.021 D_real: 0.392 D_fake: 0.468 \n",
      "(epoch: 18, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.446 G_L1: 7.338 D_real: 0.515 D_fake: 0.284 \n",
      "(epoch: 18, iters: 500, time: 0.163, data: 0.002) G_GAN: 0.860 G_L1: 5.690 D_real: 0.769 D_fake: 0.425 \n",
      "End of epoch 18 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 100, time: 0.163, data: 0.151) G_GAN: 0.878 G_L1: 5.468 D_real: 0.683 D_fake: 0.444 \n",
      "(epoch: 19, iters: 200, time: 0.225, data: 0.003) G_GAN: 0.818 G_L1: 2.441 D_real: 0.991 D_fake: 0.408 \n",
      "(epoch: 19, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.363 G_L1: 7.084 D_real: 0.465 D_fake: 0.564 \n",
      "(epoch: 19, iters: 400, time: 0.164, data: 0.003) G_GAN: 1.029 G_L1: 10.152 D_real: 0.987 D_fake: 0.318 \n",
      "(epoch: 19, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.071 G_L1: 6.616 D_real: 0.531 D_fake: 0.592 \n",
      "End of epoch 19 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 100, time: 0.248, data: 0.155) G_GAN: 1.532 G_L1: 8.694 D_real: 0.258 D_fake: 0.811 \n",
      "(epoch: 20, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.435 G_L1: 7.024 D_real: 0.424 D_fake: 0.946 \n",
      "(epoch: 20, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.221 G_L1: 8.525 D_real: 0.506 D_fake: 0.674 \n",
      "(epoch: 20, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.300 G_L1: 5.487 D_real: 0.578 D_fake: 0.474 \n",
      "(epoch: 20, iters: 500, time: 0.252, data: 0.002) G_GAN: 1.046 G_L1: 8.280 D_real: 0.409 D_fake: 0.439 \n",
      "saving the latest model (epoch 20, total_iters 10000)\n",
      "saving the model at the end of epoch 20, iters 10000\n",
      "End of epoch 20 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 100, time: 0.163, data: 0.174) G_GAN: 0.846 G_L1: 6.036 D_real: 0.730 D_fake: 0.416 \n",
      "(epoch: 21, iters: 200, time: 0.163, data: 0.002) G_GAN: 0.689 G_L1: 6.559 D_real: 0.757 D_fake: 0.416 \n",
      "(epoch: 21, iters: 300, time: 0.163, data: 0.002) G_GAN: 0.954 G_L1: 5.300 D_real: 0.372 D_fake: 0.803 \n",
      "(epoch: 21, iters: 400, time: 0.253, data: 0.002) G_GAN: 1.215 G_L1: 8.026 D_real: 0.773 D_fake: 0.603 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 21, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.003 G_L1: 7.037 D_real: 0.528 D_fake: 0.367 \n",
      "End of epoch 21 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 100, time: 0.163, data: 0.173) G_GAN: 1.358 G_L1: 7.039 D_real: 0.423 D_fake: 0.553 \n",
      "(epoch: 22, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.493 G_L1: 8.302 D_real: 1.513 D_fake: 0.170 \n",
      "(epoch: 22, iters: 300, time: 0.252, data: 0.002) G_GAN: 1.269 G_L1: 6.628 D_real: 0.385 D_fake: 0.609 \n",
      "(epoch: 22, iters: 400, time: 0.163, data: 0.002) G_GAN: 0.983 G_L1: 7.194 D_real: 0.994 D_fake: 0.227 \n",
      "(epoch: 22, iters: 500, time: 0.172, data: 0.002) G_GAN: 0.966 G_L1: 6.968 D_real: 0.468 D_fake: 0.357 \n",
      "End of epoch 22 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 100, time: 0.163, data: 0.163) G_GAN: 1.104 G_L1: 4.005 D_real: 0.820 D_fake: 0.419 \n",
      "(epoch: 23, iters: 200, time: 0.256, data: 0.002) G_GAN: 1.209 G_L1: 6.770 D_real: 0.874 D_fake: 0.307 \n",
      "(epoch: 23, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.175 G_L1: 8.304 D_real: 0.364 D_fake: 0.575 \n",
      "(epoch: 23, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.231 G_L1: 9.158 D_real: 0.507 D_fake: 0.669 \n",
      "(epoch: 23, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.513 G_L1: 6.613 D_real: 0.440 D_fake: 0.796 \n",
      "End of epoch 23 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 100, time: 0.254, data: 0.152) G_GAN: 1.324 G_L1: 5.844 D_real: 0.467 D_fake: 0.692 \n",
      "(epoch: 24, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.198 G_L1: 7.001 D_real: 0.705 D_fake: 0.320 \n",
      "(epoch: 24, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.235 G_L1: 8.449 D_real: 0.648 D_fake: 0.357 \n",
      "(epoch: 24, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.083 G_L1: 8.713 D_real: 0.181 D_fake: 0.881 \n",
      "(epoch: 24, iters: 500, time: 0.232, data: 0.002) G_GAN: 0.846 G_L1: 3.667 D_real: 1.190 D_fake: 0.567 \n",
      "End of epoch 24 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 100, time: 0.164, data: 0.154) G_GAN: 1.212 G_L1: 6.919 D_real: 0.269 D_fake: 0.840 \n",
      "(epoch: 25, iters: 200, time: 0.163, data: 0.002) G_GAN: 0.821 G_L1: 5.184 D_real: 0.353 D_fake: 0.797 \n",
      "(epoch: 25, iters: 300, time: 0.163, data: 0.002) G_GAN: 0.942 G_L1: 6.796 D_real: 0.762 D_fake: 0.255 \n",
      "(epoch: 25, iters: 400, time: 0.251, data: 0.002) G_GAN: 1.260 G_L1: 5.969 D_real: 0.254 D_fake: 0.874 \n",
      "(epoch: 25, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.199 G_L1: 5.183 D_real: 0.575 D_fake: 0.690 \n",
      "saving the model at the end of epoch 25, iters 12500\n",
      "End of epoch 25 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.163, data: 0.148) G_GAN: 0.962 G_L1: 4.762 D_real: 0.512 D_fake: 0.535 \n",
      "(epoch: 26, iters: 200, time: 0.164, data: 0.003) G_GAN: 0.501 G_L1: 7.543 D_real: 0.709 D_fake: 0.522 \n",
      "(epoch: 26, iters: 300, time: 0.256, data: 0.003) G_GAN: 0.894 G_L1: 3.564 D_real: 0.533 D_fake: 0.829 \n",
      "(epoch: 26, iters: 400, time: 0.163, data: 0.003) G_GAN: 0.817 G_L1: 5.373 D_real: 0.769 D_fake: 0.416 \n",
      "(epoch: 26, iters: 500, time: 0.164, data: 0.002) G_GAN: 0.698 G_L1: 5.406 D_real: 0.946 D_fake: 0.340 \n",
      "End of epoch 26 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 100, time: 0.163, data: 0.154) G_GAN: 1.275 G_L1: 7.460 D_real: 0.655 D_fake: 0.455 \n",
      "(epoch: 27, iters: 200, time: 0.257, data: 0.002) G_GAN: 1.856 G_L1: 8.832 D_real: 0.129 D_fake: 0.505 \n",
      "(epoch: 27, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.128 G_L1: 7.568 D_real: 0.268 D_fake: 0.509 \n",
      "(epoch: 27, iters: 400, time: 0.163, data: 0.003) G_GAN: 0.973 G_L1: 5.456 D_real: 0.347 D_fake: 0.811 \n",
      "(epoch: 27, iters: 500, time: 0.164, data: 0.003) G_GAN: 1.426 G_L1: 4.986 D_real: 0.372 D_fake: 1.022 \n",
      "End of epoch 27 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 100, time: 0.268, data: 0.146) G_GAN: 1.682 G_L1: 8.536 D_real: 0.220 D_fake: 1.145 \n",
      "(epoch: 28, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.836 G_L1: 8.410 D_real: 0.271 D_fake: 0.809 \n",
      "(epoch: 28, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.787 G_L1: 9.263 D_real: 0.211 D_fake: 0.828 \n",
      "(epoch: 28, iters: 400, time: 0.163, data: 0.003) G_GAN: 1.072 G_L1: 5.081 D_real: 0.501 D_fake: 0.512 \n",
      "(epoch: 28, iters: 500, time: 0.257, data: 0.002) G_GAN: 0.615 G_L1: 7.138 D_real: 1.068 D_fake: 0.411 \n",
      "End of epoch 28 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 100, time: 0.163, data: 0.174) G_GAN: 1.378 G_L1: 6.829 D_real: 0.538 D_fake: 0.652 \n",
      "(epoch: 29, iters: 200, time: 0.164, data: 0.002) G_GAN: 0.879 G_L1: 8.316 D_real: 0.646 D_fake: 0.380 \n",
      "(epoch: 29, iters: 300, time: 0.163, data: 0.002) G_GAN: 0.780 G_L1: 6.143 D_real: 0.855 D_fake: 0.349 \n",
      "(epoch: 29, iters: 400, time: 0.262, data: 0.002) G_GAN: 1.054 G_L1: 5.960 D_real: 0.696 D_fake: 0.559 \n",
      "(epoch: 29, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.665 G_L1: 10.082 D_real: 0.350 D_fake: 0.338 \n",
      "End of epoch 29 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 100, time: 0.164, data: 0.177) G_GAN: 1.808 G_L1: 7.556 D_real: 0.362 D_fake: 0.546 \n",
      "(epoch: 30, iters: 200, time: 0.163, data: 0.002) G_GAN: 2.210 G_L1: 8.439 D_real: 0.206 D_fake: 0.886 \n",
      "(epoch: 30, iters: 300, time: 0.253, data: 0.002) G_GAN: 1.317 G_L1: 4.217 D_real: 0.341 D_fake: 0.910 \n",
      "(epoch: 30, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.705 G_L1: 7.273 D_real: 0.445 D_fake: 0.549 \n",
      "(epoch: 30, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.243 G_L1: 6.639 D_real: 0.501 D_fake: 0.466 \n",
      "saving the latest model (epoch 30, total_iters 15000)\n",
      "saving the model at the end of epoch 30, iters 15000\n",
      "End of epoch 30 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 100, time: 0.163, data: 0.148) G_GAN: 1.295 G_L1: 6.359 D_real: 0.529 D_fake: 0.419 \n",
      "(epoch: 31, iters: 200, time: 0.259, data: 0.002) G_GAN: 1.686 G_L1: 8.193 D_real: 0.087 D_fake: 1.055 \n",
      "(epoch: 31, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.172 G_L1: 5.324 D_real: 0.504 D_fake: 0.391 \n",
      "(epoch: 31, iters: 400, time: 0.163, data: 0.002) G_GAN: 0.968 G_L1: 7.520 D_real: 0.647 D_fake: 0.251 \n",
      "(epoch: 31, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.132 G_L1: 6.456 D_real: 0.413 D_fake: 0.594 \n",
      "End of epoch 31 / 200 \t Time Taken: 51 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 100, time: 0.264, data: 0.145) G_GAN: 0.967 G_L1: 6.831 D_real: 0.438 D_fake: 0.360 \n",
      "(epoch: 32, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.646 G_L1: 7.997 D_real: 0.209 D_fake: 0.454 \n",
      "(epoch: 32, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.178 G_L1: 4.234 D_real: 0.466 D_fake: 0.597 \n",
      "(epoch: 32, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.483 G_L1: 7.317 D_real: 0.381 D_fake: 0.858 \n",
      "(epoch: 32, iters: 500, time: 0.265, data: 0.002) G_GAN: 1.201 G_L1: 6.879 D_real: 1.013 D_fake: 0.200 \n",
      "End of epoch 32 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 100, time: 0.164, data: 0.149) G_GAN: 1.224 G_L1: 6.027 D_real: 0.731 D_fake: 0.253 \n",
      "(epoch: 33, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.010 G_L1: 6.538 D_real: 0.483 D_fake: 0.498 \n",
      "(epoch: 33, iters: 300, time: 0.163, data: 0.003) G_GAN: 1.708 G_L1: 5.151 D_real: 0.450 D_fake: 0.312 \n",
      "(epoch: 33, iters: 400, time: 0.266, data: 0.002) G_GAN: 0.689 G_L1: 6.319 D_real: 0.913 D_fake: 0.282 \n",
      "(epoch: 33, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.347 G_L1: 6.067 D_real: 0.663 D_fake: 0.614 \n",
      "End of epoch 33 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 100, time: 0.164, data: 0.178) G_GAN: 1.713 G_L1: 8.895 D_real: 0.300 D_fake: 0.558 \n",
      "(epoch: 34, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.125 G_L1: 3.630 D_real: 0.614 D_fake: 0.701 \n",
      "(epoch: 34, iters: 300, time: 0.269, data: 0.003) G_GAN: 1.570 G_L1: 7.159 D_real: 0.184 D_fake: 0.939 \n",
      "(epoch: 34, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.205 G_L1: 6.716 D_real: 0.364 D_fake: 0.399 \n",
      "(epoch: 34, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.862 G_L1: 6.597 D_real: 0.278 D_fake: 0.445 \n",
      "End of epoch 34 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 100, time: 0.163, data: 0.142) G_GAN: 1.451 G_L1: 5.689 D_real: 1.118 D_fake: 0.115 \n",
      "(epoch: 35, iters: 200, time: 0.268, data: 0.003) G_GAN: 0.808 G_L1: 4.792 D_real: 0.631 D_fake: 0.366 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 35, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.870 G_L1: 7.558 D_real: 0.239 D_fake: 0.480 \n",
      "(epoch: 35, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.216 G_L1: 4.862 D_real: 0.812 D_fake: 0.267 \n",
      "(epoch: 35, iters: 500, time: 0.163, data: 0.003) G_GAN: 1.211 G_L1: 3.984 D_real: 0.375 D_fake: 0.766 \n",
      "saving the model at the end of epoch 35, iters 17500\n",
      "End of epoch 35 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 100, time: 0.267, data: 0.174) G_GAN: 0.812 G_L1: 5.294 D_real: 0.748 D_fake: 0.280 \n",
      "(epoch: 36, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.063 G_L1: 6.501 D_real: 0.616 D_fake: 0.114 \n",
      "(epoch: 36, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.232 G_L1: 7.047 D_real: 0.463 D_fake: 0.320 \n",
      "(epoch: 36, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.283 G_L1: 4.567 D_real: 0.522 D_fake: 0.324 \n",
      "(epoch: 36, iters: 500, time: 0.273, data: 0.002) G_GAN: 0.891 G_L1: 6.907 D_real: 0.525 D_fake: 0.377 \n",
      "End of epoch 36 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 100, time: 0.163, data: 0.155) G_GAN: 2.907 G_L1: 7.659 D_real: 0.144 D_fake: 1.517 \n",
      "(epoch: 37, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.334 G_L1: 6.553 D_real: 0.351 D_fake: 0.472 \n",
      "(epoch: 37, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.331 G_L1: 5.048 D_real: 0.344 D_fake: 0.600 \n",
      "(epoch: 37, iters: 400, time: 0.275, data: 0.002) G_GAN: 2.369 G_L1: 7.317 D_real: 0.070 D_fake: 1.161 \n",
      "(epoch: 37, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.735 G_L1: 7.304 D_real: 0.299 D_fake: 0.488 \n",
      "End of epoch 37 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 100, time: 0.163, data: 0.152) G_GAN: 0.903 G_L1: 6.548 D_real: 0.608 D_fake: 0.449 \n",
      "(epoch: 38, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.361 G_L1: 6.436 D_real: 0.368 D_fake: 0.846 \n",
      "(epoch: 38, iters: 300, time: 0.276, data: 0.002) G_GAN: 2.559 G_L1: 9.267 D_real: 0.291 D_fake: 0.893 \n",
      "(epoch: 38, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.630 G_L1: 6.148 D_real: 0.271 D_fake: 0.351 \n",
      "(epoch: 38, iters: 500, time: 0.163, data: 0.003) G_GAN: 1.629 G_L1: 7.210 D_real: 0.243 D_fake: 0.643 \n",
      "End of epoch 38 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 100, time: 0.163, data: 0.152) G_GAN: 0.746 G_L1: 6.875 D_real: 0.637 D_fake: 0.516 \n",
      "(epoch: 39, iters: 200, time: 0.269, data: 0.002) G_GAN: 2.274 G_L1: 7.403 D_real: 0.097 D_fake: 0.501 \n",
      "(epoch: 39, iters: 300, time: 0.163, data: 0.002) G_GAN: 2.000 G_L1: 6.151 D_real: 0.236 D_fake: 0.440 \n",
      "(epoch: 39, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.985 G_L1: 7.748 D_real: 0.304 D_fake: 0.219 \n",
      "(epoch: 39, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.367 G_L1: 7.865 D_real: 0.457 D_fake: 0.573 \n",
      "End of epoch 39 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 100, time: 0.268, data: 0.153) G_GAN: 0.807 G_L1: 8.380 D_real: 0.674 D_fake: 0.360 \n",
      "(epoch: 40, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.840 G_L1: 7.743 D_real: 0.126 D_fake: 0.619 \n",
      "(epoch: 40, iters: 300, time: 0.164, data: 0.002) G_GAN: 2.045 G_L1: 6.504 D_real: 0.186 D_fake: 0.956 \n",
      "(epoch: 40, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.482 G_L1: 9.893 D_real: 0.473 D_fake: 0.449 \n",
      "(epoch: 40, iters: 500, time: 0.247, data: 0.002) G_GAN: 1.322 G_L1: 5.872 D_real: 0.671 D_fake: 0.322 \n",
      "saving the latest model (epoch 40, total_iters 20000)\n",
      "saving the model at the end of epoch 40, iters 20000\n",
      "End of epoch 40 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 100, time: 0.163, data: 0.148) G_GAN: 2.203 G_L1: 6.378 D_real: 0.273 D_fake: 0.823 \n",
      "(epoch: 41, iters: 200, time: 0.165, data: 0.001) G_GAN: 0.811 G_L1: 6.482 D_real: 0.492 D_fake: 0.327 \n",
      "(epoch: 41, iters: 300, time: 0.168, data: 0.002) G_GAN: 1.876 G_L1: 6.618 D_real: 0.221 D_fake: 0.346 \n",
      "(epoch: 41, iters: 400, time: 0.273, data: 0.002) G_GAN: 2.188 G_L1: 7.561 D_real: 0.226 D_fake: 0.625 \n",
      "(epoch: 41, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.314 G_L1: 6.450 D_real: 0.447 D_fake: 0.652 \n",
      "End of epoch 41 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 100, time: 0.163, data: 0.146) G_GAN: 1.240 G_L1: 9.536 D_real: 0.586 D_fake: 0.534 \n",
      "(epoch: 42, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.071 G_L1: 5.390 D_real: 0.892 D_fake: 0.406 \n",
      "(epoch: 42, iters: 300, time: 0.268, data: 0.003) G_GAN: 1.521 G_L1: 7.292 D_real: 0.336 D_fake: 0.337 \n",
      "(epoch: 42, iters: 400, time: 0.165, data: 0.002) G_GAN: 0.788 G_L1: 5.459 D_real: 0.965 D_fake: 0.274 \n",
      "(epoch: 42, iters: 500, time: 0.167, data: 0.002) G_GAN: 1.460 G_L1: 5.576 D_real: 0.428 D_fake: 0.422 \n",
      "End of epoch 42 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 100, time: 0.169, data: 0.172) G_GAN: 1.474 G_L1: 5.902 D_real: 0.495 D_fake: 0.502 \n",
      "(epoch: 43, iters: 200, time: 0.299, data: 0.003) G_GAN: 1.259 G_L1: 7.271 D_real: 0.389 D_fake: 0.704 \n",
      "(epoch: 43, iters: 300, time: 0.164, data: 0.003) G_GAN: 1.538 G_L1: 8.109 D_real: 0.697 D_fake: 0.325 \n",
      "(epoch: 43, iters: 400, time: 0.166, data: 0.002) G_GAN: 0.533 G_L1: 6.548 D_real: 1.205 D_fake: 0.360 \n",
      "(epoch: 43, iters: 500, time: 0.170, data: 0.002) G_GAN: 1.442 G_L1: 8.543 D_real: 0.375 D_fake: 0.482 \n",
      "End of epoch 43 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 100, time: 0.282, data: 0.164) G_GAN: 1.488 G_L1: 6.948 D_real: 0.398 D_fake: 0.438 \n",
      "(epoch: 44, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.663 G_L1: 5.732 D_real: 0.473 D_fake: 0.438 \n",
      "(epoch: 44, iters: 300, time: 0.166, data: 0.002) G_GAN: 1.714 G_L1: 5.621 D_real: 0.150 D_fake: 1.119 \n",
      "(epoch: 44, iters: 400, time: 0.168, data: 0.002) G_GAN: 3.081 G_L1: 7.713 D_real: 0.137 D_fake: 0.961 \n",
      "(epoch: 44, iters: 500, time: 0.276, data: 0.003) G_GAN: 1.460 G_L1: 8.106 D_real: 0.285 D_fake: 0.506 \n",
      "End of epoch 44 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 100, time: 0.164, data: 0.154) G_GAN: 2.204 G_L1: 6.901 D_real: 0.328 D_fake: 0.941 \n",
      "(epoch: 45, iters: 200, time: 0.164, data: 0.002) G_GAN: 0.950 G_L1: 6.430 D_real: 0.680 D_fake: 0.473 \n",
      "(epoch: 45, iters: 300, time: 0.164, data: 0.003) G_GAN: 1.210 G_L1: 5.460 D_real: 0.512 D_fake: 0.483 \n",
      "(epoch: 45, iters: 400, time: 0.280, data: 0.002) G_GAN: 1.583 G_L1: 6.763 D_real: 0.142 D_fake: 1.130 \n",
      "(epoch: 45, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.473 G_L1: 6.770 D_real: 0.384 D_fake: 0.459 \n",
      "saving the model at the end of epoch 45, iters 22500\n",
      "End of epoch 45 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 100, time: 0.163, data: 0.152) G_GAN: 1.188 G_L1: 7.637 D_real: 0.935 D_fake: 0.140 \n",
      "(epoch: 46, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.788 G_L1: 12.138 D_real: 0.310 D_fake: 1.240 \n",
      "(epoch: 46, iters: 300, time: 0.269, data: 0.002) G_GAN: 1.065 G_L1: 5.769 D_real: 0.777 D_fake: 0.498 \n",
      "(epoch: 46, iters: 400, time: 0.164, data: 0.002) G_GAN: 0.553 G_L1: 6.532 D_real: 0.944 D_fake: 0.376 \n",
      "(epoch: 46, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.988 G_L1: 8.470 D_real: 0.310 D_fake: 0.700 \n",
      "End of epoch 46 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 100, time: 0.168, data: 0.160) G_GAN: 1.153 G_L1: 7.166 D_real: 0.381 D_fake: 0.560 \n",
      "(epoch: 47, iters: 200, time: 0.294, data: 0.001) G_GAN: 1.496 G_L1: 5.712 D_real: 0.536 D_fake: 0.802 \n",
      "(epoch: 47, iters: 300, time: 0.168, data: 0.002) G_GAN: 1.013 G_L1: 7.674 D_real: 0.462 D_fake: 0.528 \n",
      "(epoch: 47, iters: 400, time: 0.166, data: 0.004) G_GAN: 1.566 G_L1: 7.814 D_real: 0.516 D_fake: 0.611 \n",
      "(epoch: 47, iters: 500, time: 0.168, data: 0.002) G_GAN: 0.562 G_L1: 5.552 D_real: 0.819 D_fake: 0.234 \n",
      "End of epoch 47 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 100, time: 0.340, data: 0.209) G_GAN: 1.404 G_L1: 5.967 D_real: 0.481 D_fake: 0.538 \n",
      "(epoch: 48, iters: 200, time: 0.168, data: 0.005) G_GAN: 1.109 G_L1: 5.788 D_real: 0.741 D_fake: 0.540 \n",
      "(epoch: 48, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.193 G_L1: 5.589 D_real: 0.437 D_fake: 0.400 \n",
      "(epoch: 48, iters: 400, time: 0.165, data: 0.003) G_GAN: 1.283 G_L1: 6.949 D_real: 0.347 D_fake: 0.526 \n",
      "(epoch: 48, iters: 500, time: 0.302, data: 0.002) G_GAN: 1.317 G_L1: 5.259 D_real: 0.466 D_fake: 0.485 \n",
      "End of epoch 48 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 49, iters: 100, time: 0.167, data: 0.222) G_GAN: 1.489 G_L1: 6.918 D_real: 0.414 D_fake: 0.729 \n",
      "(epoch: 49, iters: 200, time: 0.165, data: 0.003) G_GAN: 1.018 G_L1: 8.131 D_real: 0.626 D_fake: 0.367 \n",
      "(epoch: 49, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.676 G_L1: 6.792 D_real: 0.337 D_fake: 1.068 \n",
      "(epoch: 49, iters: 400, time: 0.294, data: 0.002) G_GAN: 1.703 G_L1: 8.233 D_real: 0.346 D_fake: 0.576 \n",
      "(epoch: 49, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.207 G_L1: 6.553 D_real: 0.481 D_fake: 0.403 \n",
      "End of epoch 49 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 100, time: 0.165, data: 0.154) G_GAN: 0.954 G_L1: 5.667 D_real: 0.599 D_fake: 0.392 \n",
      "(epoch: 50, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.066 G_L1: 6.392 D_real: 0.784 D_fake: 0.308 \n",
      "(epoch: 50, iters: 300, time: 0.286, data: 0.002) G_GAN: 1.702 G_L1: 8.302 D_real: 0.338 D_fake: 0.571 \n",
      "(epoch: 50, iters: 400, time: 0.169, data: 0.002) G_GAN: 1.538 G_L1: 8.058 D_real: 0.288 D_fake: 0.640 \n",
      "(epoch: 50, iters: 500, time: 0.166, data: 0.002) G_GAN: 1.062 G_L1: 5.415 D_real: 0.714 D_fake: 0.287 \n",
      "saving the latest model (epoch 50, total_iters 25000)\n",
      "saving the model at the end of epoch 50, iters 25000\n",
      "End of epoch 50 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.165, data: 0.161) G_GAN: 1.183 G_L1: 5.169 D_real: 0.597 D_fake: 1.117 \n",
      "(epoch: 51, iters: 200, time: 0.285, data: 0.002) G_GAN: 0.697 G_L1: 6.209 D_real: 0.912 D_fake: 0.509 \n",
      "(epoch: 51, iters: 300, time: 0.167, data: 0.002) G_GAN: 1.768 G_L1: 7.180 D_real: 0.215 D_fake: 0.722 \n",
      "(epoch: 51, iters: 400, time: 0.167, data: 0.002) G_GAN: 1.616 G_L1: 6.662 D_real: 0.478 D_fake: 0.795 \n",
      "(epoch: 51, iters: 500, time: 0.167, data: 0.002) G_GAN: 1.609 G_L1: 7.703 D_real: 0.292 D_fake: 0.673 \n",
      "End of epoch 51 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 100, time: 0.300, data: 0.156) G_GAN: 1.350 G_L1: 7.742 D_real: 0.342 D_fake: 0.543 \n",
      "(epoch: 52, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.619 G_L1: 6.618 D_real: 0.264 D_fake: 0.508 \n",
      "(epoch: 52, iters: 300, time: 0.166, data: 0.002) G_GAN: 1.018 G_L1: 7.042 D_real: 0.821 D_fake: 0.435 \n",
      "(epoch: 52, iters: 400, time: 0.166, data: 0.002) G_GAN: 1.414 G_L1: 5.879 D_real: 0.274 D_fake: 1.119 \n",
      "(epoch: 52, iters: 500, time: 0.314, data: 0.001) G_GAN: 1.036 G_L1: 5.157 D_real: 0.748 D_fake: 0.362 \n",
      "End of epoch 52 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 100, time: 0.165, data: 0.162) G_GAN: 0.899 G_L1: 5.891 D_real: 0.926 D_fake: 0.231 \n",
      "(epoch: 53, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.681 G_L1: 9.076 D_real: 0.149 D_fake: 0.603 \n",
      "(epoch: 53, iters: 300, time: 0.166, data: 0.002) G_GAN: 1.860 G_L1: 6.942 D_real: 0.240 D_fake: 0.472 \n",
      "(epoch: 53, iters: 400, time: 0.316, data: 0.002) G_GAN: 0.493 G_L1: 4.671 D_real: 1.159 D_fake: 0.268 \n",
      "(epoch: 53, iters: 500, time: 0.165, data: 0.001) G_GAN: 0.838 G_L1: 5.389 D_real: 0.871 D_fake: 0.414 \n",
      "End of epoch 53 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 100, time: 0.165, data: 0.168) G_GAN: 1.536 G_L1: 6.182 D_real: 0.202 D_fake: 0.807 \n",
      "(epoch: 54, iters: 200, time: 0.166, data: 0.002) G_GAN: 0.983 G_L1: 7.798 D_real: 0.845 D_fake: 0.386 \n",
      "(epoch: 54, iters: 300, time: 0.294, data: 0.002) G_GAN: 1.434 G_L1: 7.844 D_real: 0.989 D_fake: 0.493 \n",
      "(epoch: 54, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.469 G_L1: 8.669 D_real: 0.523 D_fake: 0.160 \n",
      "(epoch: 54, iters: 500, time: 0.165, data: 0.002) G_GAN: 0.860 G_L1: 5.481 D_real: 0.387 D_fake: 0.466 \n",
      "End of epoch 54 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 100, time: 0.165, data: 0.160) G_GAN: 1.365 G_L1: 7.065 D_real: 0.448 D_fake: 0.728 \n",
      "(epoch: 55, iters: 200, time: 0.288, data: 0.002) G_GAN: 1.736 G_L1: 4.760 D_real: 0.374 D_fake: 0.840 \n",
      "(epoch: 55, iters: 300, time: 0.164, data: 0.002) G_GAN: 0.998 G_L1: 5.000 D_real: 0.628 D_fake: 0.531 \n",
      "(epoch: 55, iters: 400, time: 0.165, data: 0.002) G_GAN: 0.847 G_L1: 4.426 D_real: 0.967 D_fake: 0.434 \n",
      "(epoch: 55, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.405 G_L1: 6.188 D_real: 0.332 D_fake: 0.710 \n",
      "saving the model at the end of epoch 55, iters 27500\n",
      "End of epoch 55 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 100, time: 0.297, data: 0.146) G_GAN: 0.837 G_L1: 6.301 D_real: 0.636 D_fake: 0.509 \n",
      "(epoch: 56, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.170 G_L1: 7.121 D_real: 0.546 D_fake: 0.207 \n",
      "(epoch: 56, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.714 G_L1: 7.997 D_real: 0.888 D_fake: 0.169 \n",
      "(epoch: 56, iters: 400, time: 0.164, data: 0.002) G_GAN: 0.900 G_L1: 6.380 D_real: 2.160 D_fake: 0.127 \n",
      "(epoch: 56, iters: 500, time: 0.292, data: 0.002) G_GAN: 2.151 G_L1: 10.561 D_real: 0.170 D_fake: 0.687 \n",
      "End of epoch 56 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 100, time: 0.165, data: 0.154) G_GAN: 0.972 G_L1: 4.972 D_real: 0.628 D_fake: 0.577 \n",
      "(epoch: 57, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.006 G_L1: 5.422 D_real: 0.525 D_fake: 0.744 \n",
      "(epoch: 57, iters: 300, time: 0.166, data: 0.002) G_GAN: 1.841 G_L1: 7.460 D_real: 0.261 D_fake: 0.530 \n",
      "(epoch: 57, iters: 400, time: 0.289, data: 0.002) G_GAN: 1.697 G_L1: 5.722 D_real: 0.514 D_fake: 0.449 \n",
      "(epoch: 57, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.360 G_L1: 4.826 D_real: 0.366 D_fake: 0.407 \n",
      "End of epoch 57 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 100, time: 0.165, data: 0.179) G_GAN: 0.845 G_L1: 6.393 D_real: 0.985 D_fake: 0.286 \n",
      "(epoch: 58, iters: 200, time: 0.165, data: 0.002) G_GAN: 0.876 G_L1: 6.229 D_real: 0.472 D_fake: 0.672 \n",
      "(epoch: 58, iters: 300, time: 0.298, data: 0.003) G_GAN: 1.055 G_L1: 5.301 D_real: 0.986 D_fake: 0.246 \n",
      "(epoch: 58, iters: 400, time: 0.170, data: 0.002) G_GAN: 1.235 G_L1: 6.909 D_real: 0.617 D_fake: 0.272 \n",
      "(epoch: 58, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.491 G_L1: 7.619 D_real: 0.492 D_fake: 0.421 \n",
      "End of epoch 58 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 100, time: 0.166, data: 0.164) G_GAN: 1.296 G_L1: 6.719 D_real: 0.301 D_fake: 0.723 \n",
      "(epoch: 59, iters: 200, time: 0.292, data: 0.002) G_GAN: 1.792 G_L1: 8.905 D_real: 0.291 D_fake: 0.198 \n",
      "(epoch: 59, iters: 300, time: 0.164, data: 0.002) G_GAN: 0.962 G_L1: 7.583 D_real: 1.037 D_fake: 0.145 \n",
      "(epoch: 59, iters: 400, time: 0.164, data: 0.002) G_GAN: 0.793 G_L1: 4.870 D_real: 0.913 D_fake: 0.282 \n",
      "(epoch: 59, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.030 G_L1: 4.562 D_real: 0.468 D_fake: 0.485 \n",
      "End of epoch 59 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 100, time: 0.301, data: 0.172) G_GAN: 2.250 G_L1: 7.260 D_real: 0.341 D_fake: 0.732 \n",
      "(epoch: 60, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.029 G_L1: 6.785 D_real: 0.494 D_fake: 0.551 \n",
      "(epoch: 60, iters: 300, time: 0.168, data: 0.002) G_GAN: 2.007 G_L1: 6.712 D_real: 0.267 D_fake: 0.653 \n",
      "(epoch: 60, iters: 400, time: 0.166, data: 0.002) G_GAN: 0.724 G_L1: 5.702 D_real: 0.964 D_fake: 0.279 \n",
      "(epoch: 60, iters: 500, time: 0.298, data: 0.002) G_GAN: 0.690 G_L1: 8.238 D_real: 0.779 D_fake: 0.230 \n",
      "saving the latest model (epoch 60, total_iters 30000)\n",
      "saving the model at the end of epoch 60, iters 30000\n",
      "End of epoch 60 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 100, time: 0.163, data: 0.153) G_GAN: 1.235 G_L1: 6.886 D_real: 0.719 D_fake: 0.260 \n",
      "(epoch: 61, iters: 200, time: 0.164, data: 0.003) G_GAN: 1.776 G_L1: 7.236 D_real: 0.445 D_fake: 0.787 \n",
      "(epoch: 61, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.247 G_L1: 7.487 D_real: 0.550 D_fake: 0.504 \n",
      "(epoch: 61, iters: 400, time: 0.300, data: 0.003) G_GAN: 1.513 G_L1: 7.847 D_real: 0.554 D_fake: 1.048 \n",
      "(epoch: 61, iters: 500, time: 0.166, data: 0.002) G_GAN: 1.304 G_L1: 7.157 D_real: 0.365 D_fake: 0.502 \n",
      "End of epoch 61 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 100, time: 0.166, data: 0.154) G_GAN: 1.432 G_L1: 6.979 D_real: 0.475 D_fake: 0.536 \n",
      "(epoch: 62, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.192 G_L1: 6.705 D_real: 0.268 D_fake: 0.613 \n",
      "(epoch: 62, iters: 300, time: 0.291, data: 0.002) G_GAN: 1.385 G_L1: 6.209 D_real: 0.436 D_fake: 0.616 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 62, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.337 G_L1: 8.720 D_real: 0.674 D_fake: 0.227 \n",
      "(epoch: 62, iters: 500, time: 0.164, data: 0.003) G_GAN: 1.078 G_L1: 6.349 D_real: 0.965 D_fake: 0.288 \n",
      "End of epoch 62 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 100, time: 0.164, data: 0.161) G_GAN: 0.817 G_L1: 5.543 D_real: 0.982 D_fake: 0.337 \n",
      "(epoch: 63, iters: 200, time: 0.329, data: 0.002) G_GAN: 0.933 G_L1: 5.908 D_real: 0.505 D_fake: 0.362 \n",
      "(epoch: 63, iters: 300, time: 0.165, data: 0.002) G_GAN: 0.690 G_L1: 5.884 D_real: 0.550 D_fake: 0.615 \n",
      "(epoch: 63, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.672 G_L1: 7.935 D_real: 0.652 D_fake: 0.267 \n",
      "(epoch: 63, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.793 G_L1: 5.746 D_real: 0.256 D_fake: 1.146 \n",
      "End of epoch 63 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 100, time: 0.306, data: 0.159) G_GAN: 0.420 G_L1: 5.141 D_real: 1.641 D_fake: 0.385 \n",
      "(epoch: 64, iters: 200, time: 0.166, data: 0.002) G_GAN: 1.315 G_L1: 6.540 D_real: 0.314 D_fake: 0.581 \n",
      "(epoch: 64, iters: 300, time: 0.165, data: 0.003) G_GAN: 1.169 G_L1: 5.706 D_real: 0.886 D_fake: 0.222 \n",
      "(epoch: 64, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.743 G_L1: 7.505 D_real: 0.169 D_fake: 1.435 \n",
      "(epoch: 64, iters: 500, time: 0.272, data: 0.002) G_GAN: 1.696 G_L1: 4.866 D_real: 0.368 D_fake: 0.735 \n",
      "End of epoch 64 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 100, time: 0.165, data: 0.147) G_GAN: 2.258 G_L1: 7.673 D_real: 0.245 D_fake: 0.521 \n",
      "(epoch: 65, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.899 G_L1: 6.692 D_real: 0.186 D_fake: 1.338 \n",
      "(epoch: 65, iters: 300, time: 0.165, data: 0.003) G_GAN: 1.201 G_L1: 8.395 D_real: 0.652 D_fake: 0.163 \n",
      "(epoch: 65, iters: 400, time: 0.312, data: 0.002) G_GAN: 1.457 G_L1: 6.289 D_real: 0.217 D_fake: 1.446 \n",
      "(epoch: 65, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.848 G_L1: 9.470 D_real: 0.237 D_fake: 0.765 \n",
      "saving the model at the end of epoch 65, iters 32500\n",
      "End of epoch 65 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 100, time: 0.164, data: 0.148) G_GAN: 0.977 G_L1: 7.169 D_real: 0.579 D_fake: 0.331 \n",
      "(epoch: 66, iters: 200, time: 0.167, data: 0.002) G_GAN: 0.736 G_L1: 6.423 D_real: 0.744 D_fake: 0.633 \n",
      "(epoch: 66, iters: 300, time: 0.304, data: 0.002) G_GAN: 0.844 G_L1: 7.633 D_real: 0.715 D_fake: 0.277 \n",
      "(epoch: 66, iters: 400, time: 0.166, data: 0.002) G_GAN: 1.387 G_L1: 6.946 D_real: 0.252 D_fake: 0.929 \n",
      "(epoch: 66, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.161 G_L1: 6.233 D_real: 0.575 D_fake: 0.313 \n",
      "End of epoch 66 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 100, time: 0.164, data: 0.155) G_GAN: 1.448 G_L1: 6.792 D_real: 0.384 D_fake: 0.557 \n",
      "(epoch: 67, iters: 200, time: 0.312, data: 0.002) G_GAN: 0.691 G_L1: 5.072 D_real: 1.729 D_fake: 0.161 \n",
      "(epoch: 67, iters: 300, time: 0.166, data: 0.002) G_GAN: 0.987 G_L1: 5.153 D_real: 0.762 D_fake: 0.284 \n",
      "(epoch: 67, iters: 400, time: 0.168, data: 0.004) G_GAN: 0.832 G_L1: 5.815 D_real: 0.925 D_fake: 0.332 \n",
      "(epoch: 67, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.623 G_L1: 5.074 D_real: 0.724 D_fake: 0.256 \n",
      "End of epoch 67 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 100, time: 0.323, data: 0.169) G_GAN: 1.272 G_L1: 5.085 D_real: 0.462 D_fake: 0.676 \n",
      "(epoch: 68, iters: 200, time: 0.169, data: 0.002) G_GAN: 1.927 G_L1: 7.022 D_real: 0.081 D_fake: 1.177 \n",
      "(epoch: 68, iters: 300, time: 0.169, data: 0.003) G_GAN: 1.228 G_L1: 4.860 D_real: 0.849 D_fake: 0.261 \n",
      "(epoch: 68, iters: 400, time: 0.165, data: 0.003) G_GAN: 1.322 G_L1: 8.684 D_real: 0.627 D_fake: 0.295 \n",
      "(epoch: 68, iters: 500, time: 0.298, data: 0.003) G_GAN: 1.288 G_L1: 6.066 D_real: 0.472 D_fake: 0.406 \n",
      "End of epoch 68 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 100, time: 0.165, data: 0.191) G_GAN: 0.789 G_L1: 6.585 D_real: 1.288 D_fake: 0.248 \n",
      "(epoch: 69, iters: 200, time: 0.166, data: 0.002) G_GAN: 1.168 G_L1: 6.408 D_real: 0.429 D_fake: 0.383 \n",
      "(epoch: 69, iters: 300, time: 0.164, data: 0.003) G_GAN: 1.554 G_L1: 8.145 D_real: 0.348 D_fake: 0.381 \n",
      "(epoch: 69, iters: 400, time: 0.306, data: 0.003) G_GAN: 2.082 G_L1: 6.046 D_real: 0.203 D_fake: 0.891 \n",
      "(epoch: 69, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.370 G_L1: 2.887 D_real: 0.562 D_fake: 0.913 \n",
      "End of epoch 69 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 100, time: 0.163, data: 0.150) G_GAN: 1.106 G_L1: 5.918 D_real: 0.662 D_fake: 0.389 \n",
      "(epoch: 70, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.385 G_L1: 7.249 D_real: 0.283 D_fake: 0.954 \n",
      "(epoch: 70, iters: 300, time: 0.339, data: 0.003) G_GAN: 2.053 G_L1: 7.796 D_real: 0.195 D_fake: 0.758 \n",
      "(epoch: 70, iters: 400, time: 0.164, data: 0.002) G_GAN: 0.641 G_L1: 6.378 D_real: 0.875 D_fake: 0.186 \n",
      "(epoch: 70, iters: 500, time: 0.163, data: 0.003) G_GAN: 1.008 G_L1: 5.723 D_real: 0.405 D_fake: 0.513 \n",
      "saving the latest model (epoch 70, total_iters 35000)\n",
      "saving the model at the end of epoch 70, iters 35000\n",
      "End of epoch 70 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 100, time: 0.165, data: 0.178) G_GAN: 1.128 G_L1: 6.326 D_real: 0.917 D_fake: 0.191 \n",
      "(epoch: 71, iters: 200, time: 0.303, data: 0.003) G_GAN: 1.728 G_L1: 8.539 D_real: 0.206 D_fake: 0.356 \n",
      "(epoch: 71, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.651 G_L1: 4.835 D_real: 0.356 D_fake: 0.773 \n",
      "(epoch: 71, iters: 400, time: 0.168, data: 0.002) G_GAN: 0.907 G_L1: 5.056 D_real: 0.669 D_fake: 0.344 \n",
      "(epoch: 71, iters: 500, time: 0.167, data: 0.002) G_GAN: 1.616 G_L1: 5.188 D_real: 0.546 D_fake: 0.588 \n",
      "End of epoch 71 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 100, time: 0.302, data: 0.150) G_GAN: 0.776 G_L1: 6.332 D_real: 0.634 D_fake: 0.264 \n",
      "(epoch: 72, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.199 G_L1: 7.135 D_real: 0.517 D_fake: 0.697 \n",
      "(epoch: 72, iters: 300, time: 0.164, data: 0.002) G_GAN: 0.778 G_L1: 6.741 D_real: 0.710 D_fake: 0.367 \n",
      "(epoch: 72, iters: 400, time: 0.168, data: 0.002) G_GAN: 2.044 G_L1: 6.937 D_real: 0.121 D_fake: 0.721 \n",
      "(epoch: 72, iters: 500, time: 0.313, data: 0.003) G_GAN: 0.959 G_L1: 5.727 D_real: 0.578 D_fake: 0.382 \n",
      "End of epoch 72 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 100, time: 0.167, data: 0.173) G_GAN: 1.756 G_L1: 6.309 D_real: 0.234 D_fake: 0.567 \n",
      "(epoch: 73, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.075 G_L1: 6.251 D_real: 0.236 D_fake: 0.526 \n",
      "(epoch: 73, iters: 300, time: 0.163, data: 0.003) G_GAN: 0.675 G_L1: 6.262 D_real: 0.621 D_fake: 0.578 \n",
      "(epoch: 73, iters: 400, time: 0.302, data: 0.003) G_GAN: 0.933 G_L1: 5.567 D_real: 0.654 D_fake: 0.219 \n",
      "(epoch: 73, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.986 G_L1: 7.612 D_real: 0.176 D_fake: 0.369 \n",
      "End of epoch 73 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 100, time: 0.164, data: 0.165) G_GAN: 1.175 G_L1: 5.735 D_real: 0.873 D_fake: 0.663 \n",
      "(epoch: 74, iters: 200, time: 0.164, data: 0.003) G_GAN: 1.043 G_L1: 6.582 D_real: 0.755 D_fake: 0.245 \n",
      "(epoch: 74, iters: 300, time: 0.319, data: 0.003) G_GAN: 1.240 G_L1: 6.558 D_real: 0.798 D_fake: 0.350 \n",
      "(epoch: 74, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.550 G_L1: 8.179 D_real: 0.311 D_fake: 0.579 \n",
      "(epoch: 74, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.267 G_L1: 6.472 D_real: 0.668 D_fake: 0.659 \n",
      "End of epoch 74 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 100, time: 0.164, data: 0.166) G_GAN: 1.057 G_L1: 7.350 D_real: 0.389 D_fake: 0.559 \n",
      "(epoch: 75, iters: 200, time: 0.288, data: 0.003) G_GAN: 1.866 G_L1: 4.673 D_real: 0.219 D_fake: 0.641 \n",
      "(epoch: 75, iters: 300, time: 0.165, data: 0.002) G_GAN: 0.939 G_L1: 6.434 D_real: 0.354 D_fake: 0.628 \n",
      "(epoch: 75, iters: 400, time: 0.167, data: 0.002) G_GAN: 1.104 G_L1: 7.013 D_real: 0.956 D_fake: 0.172 \n",
      "(epoch: 75, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.155 G_L1: 6.142 D_real: 0.722 D_fake: 0.412 \n",
      "saving the model at the end of epoch 75, iters 37500\n",
      "End of epoch 75 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 100, time: 0.324, data: 0.153) G_GAN: 1.660 G_L1: 7.657 D_real: 0.177 D_fake: 0.474 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 76, iters: 200, time: 0.164, data: 0.003) G_GAN: 2.346 G_L1: 6.748 D_real: 0.136 D_fake: 0.747 \n",
      "(epoch: 76, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.403 G_L1: 5.897 D_real: 0.392 D_fake: 0.402 \n",
      "(epoch: 76, iters: 400, time: 0.164, data: 0.002) G_GAN: 0.451 G_L1: 6.193 D_real: 0.981 D_fake: 0.170 \n",
      "(epoch: 76, iters: 500, time: 0.303, data: 0.003) G_GAN: 1.925 G_L1: 5.116 D_real: 0.147 D_fake: 1.302 \n",
      "End of epoch 76 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 100, time: 0.163, data: 0.173) G_GAN: 1.121 G_L1: 5.532 D_real: 0.656 D_fake: 0.360 \n",
      "(epoch: 77, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.320 G_L1: 8.022 D_real: 0.473 D_fake: 0.928 \n",
      "(epoch: 77, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.017 G_L1: 4.204 D_real: 0.932 D_fake: 0.128 \n",
      "(epoch: 77, iters: 400, time: 0.314, data: 0.002) G_GAN: 1.472 G_L1: 6.276 D_real: 0.292 D_fake: 0.419 \n",
      "(epoch: 77, iters: 500, time: 0.164, data: 0.002) G_GAN: 0.795 G_L1: 7.099 D_real: 0.601 D_fake: 0.390 \n",
      "End of epoch 77 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 100, time: 0.164, data: 0.159) G_GAN: 0.955 G_L1: 6.077 D_real: 0.578 D_fake: 0.859 \n",
      "(epoch: 78, iters: 200, time: 0.163, data: 0.003) G_GAN: 0.979 G_L1: 5.095 D_real: 0.698 D_fake: 0.603 \n",
      "(epoch: 78, iters: 300, time: 0.310, data: 0.002) G_GAN: 1.537 G_L1: 6.805 D_real: 0.441 D_fake: 0.358 \n",
      "(epoch: 78, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.160 G_L1: 3.480 D_real: 0.442 D_fake: 0.427 \n",
      "(epoch: 78, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.400 G_L1: 7.439 D_real: 0.321 D_fake: 0.528 \n",
      "End of epoch 78 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 100, time: 0.164, data: 0.152) G_GAN: 1.581 G_L1: 5.896 D_real: 0.221 D_fake: 0.783 \n",
      "(epoch: 79, iters: 200, time: 0.306, data: 0.003) G_GAN: 1.549 G_L1: 8.016 D_real: 0.392 D_fake: 0.418 \n",
      "(epoch: 79, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.109 G_L1: 4.527 D_real: 0.781 D_fake: 0.619 \n",
      "(epoch: 79, iters: 400, time: 0.164, data: 0.003) G_GAN: 2.040 G_L1: 8.196 D_real: 0.157 D_fake: 0.884 \n",
      "(epoch: 79, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.594 G_L1: 7.204 D_real: 0.411 D_fake: 0.524 \n",
      "End of epoch 79 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 100, time: 0.330, data: 0.157) G_GAN: 1.422 G_L1: 7.322 D_real: 0.280 D_fake: 0.496 \n",
      "(epoch: 80, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.545 G_L1: 6.027 D_real: 0.485 D_fake: 0.417 \n",
      "(epoch: 80, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.201 G_L1: 3.820 D_real: 0.311 D_fake: 0.775 \n",
      "(epoch: 80, iters: 400, time: 0.165, data: 0.003) G_GAN: 1.953 G_L1: 7.849 D_real: 0.344 D_fake: 0.850 \n",
      "(epoch: 80, iters: 500, time: 0.313, data: 0.003) G_GAN: 1.304 G_L1: 5.966 D_real: 0.403 D_fake: 1.047 \n",
      "saving the latest model (epoch 80, total_iters 40000)\n",
      "saving the model at the end of epoch 80, iters 40000\n",
      "End of epoch 80 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 100, time: 0.164, data: 0.155) G_GAN: 1.129 G_L1: 5.727 D_real: 0.495 D_fake: 0.703 \n",
      "(epoch: 81, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.746 G_L1: 5.753 D_real: 0.278 D_fake: 0.483 \n",
      "(epoch: 81, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.350 G_L1: 5.635 D_real: 0.555 D_fake: 0.781 \n",
      "(epoch: 81, iters: 400, time: 0.324, data: 0.002) G_GAN: 0.912 G_L1: 7.995 D_real: 0.515 D_fake: 0.315 \n",
      "(epoch: 81, iters: 500, time: 0.165, data: 0.002) G_GAN: 2.565 G_L1: 7.354 D_real: 0.245 D_fake: 1.393 \n",
      "End of epoch 81 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 100, time: 0.164, data: 0.151) G_GAN: 1.764 G_L1: 8.163 D_real: 0.259 D_fake: 0.667 \n",
      "(epoch: 82, iters: 200, time: 0.165, data: 0.003) G_GAN: 1.334 G_L1: 6.592 D_real: 0.703 D_fake: 0.180 \n",
      "(epoch: 82, iters: 300, time: 0.328, data: 0.003) G_GAN: 1.890 G_L1: 6.494 D_real: 0.508 D_fake: 0.552 \n",
      "(epoch: 82, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.351 G_L1: 6.060 D_real: 0.753 D_fake: 0.241 \n",
      "(epoch: 82, iters: 500, time: 0.167, data: 0.002) G_GAN: 1.065 G_L1: 6.184 D_real: 0.815 D_fake: 0.225 \n",
      "End of epoch 82 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 100, time: 0.168, data: 0.167) G_GAN: 2.126 G_L1: 7.403 D_real: 0.221 D_fake: 0.285 \n",
      "(epoch: 83, iters: 200, time: 0.323, data: 0.003) G_GAN: 1.645 G_L1: 6.778 D_real: 0.460 D_fake: 0.435 \n",
      "(epoch: 83, iters: 300, time: 0.166, data: 0.002) G_GAN: 1.771 G_L1: 5.716 D_real: 1.297 D_fake: 2.056 \n",
      "(epoch: 83, iters: 400, time: 0.165, data: 0.003) G_GAN: 0.861 G_L1: 5.596 D_real: 0.810 D_fake: 0.390 \n",
      "(epoch: 83, iters: 500, time: 0.163, data: 0.003) G_GAN: 1.272 G_L1: 7.350 D_real: 0.846 D_fake: 0.289 \n",
      "End of epoch 83 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 100, time: 0.322, data: 0.168) G_GAN: 1.196 G_L1: 7.238 D_real: 0.314 D_fake: 0.386 \n",
      "(epoch: 84, iters: 200, time: 0.164, data: 0.002) G_GAN: 0.911 G_L1: 5.071 D_real: 0.394 D_fake: 0.409 \n",
      "(epoch: 84, iters: 300, time: 0.163, data: 0.003) G_GAN: 1.287 G_L1: 6.372 D_real: 0.279 D_fake: 0.475 \n",
      "(epoch: 84, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.348 G_L1: 7.810 D_real: 0.167 D_fake: 1.193 \n",
      "(epoch: 84, iters: 500, time: 0.332, data: 0.002) G_GAN: 1.467 G_L1: 5.495 D_real: 0.180 D_fake: 0.580 \n",
      "End of epoch 84 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 100, time: 0.165, data: 0.174) G_GAN: 1.746 G_L1: 6.610 D_real: 0.233 D_fake: 0.994 \n",
      "(epoch: 85, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.989 G_L1: 6.523 D_real: 0.269 D_fake: 0.342 \n",
      "(epoch: 85, iters: 300, time: 0.163, data: 0.003) G_GAN: 0.622 G_L1: 5.837 D_real: 1.466 D_fake: 0.145 \n",
      "(epoch: 85, iters: 400, time: 0.325, data: 0.003) G_GAN: 1.665 G_L1: 6.110 D_real: 0.241 D_fake: 0.658 \n",
      "(epoch: 85, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.596 G_L1: 5.823 D_real: 0.410 D_fake: 0.582 \n",
      "saving the model at the end of epoch 85, iters 42500\n",
      "End of epoch 85 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 100, time: 0.164, data: 0.154) G_GAN: 1.325 G_L1: 4.939 D_real: 0.365 D_fake: 0.383 \n",
      "(epoch: 86, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.247 G_L1: 5.600 D_real: 0.228 D_fake: 1.248 \n",
      "(epoch: 86, iters: 300, time: 0.321, data: 0.002) G_GAN: 1.114 G_L1: 6.200 D_real: 0.587 D_fake: 0.408 \n",
      "(epoch: 86, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.297 G_L1: 4.863 D_real: 0.999 D_fake: 0.251 \n",
      "(epoch: 86, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.966 G_L1: 6.794 D_real: 0.187 D_fake: 0.415 \n",
      "End of epoch 86 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 100, time: 0.164, data: 0.173) G_GAN: 0.653 G_L1: 5.864 D_real: 0.844 D_fake: 0.424 \n",
      "(epoch: 87, iters: 200, time: 0.332, data: 0.002) G_GAN: 1.147 G_L1: 6.051 D_real: 0.611 D_fake: 0.398 \n",
      "(epoch: 87, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.321 G_L1: 5.636 D_real: 0.307 D_fake: 0.939 \n",
      "(epoch: 87, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.545 G_L1: 7.062 D_real: 0.508 D_fake: 0.235 \n",
      "(epoch: 87, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.485 G_L1: 5.366 D_real: 0.500 D_fake: 0.426 \n",
      "End of epoch 87 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 100, time: 0.321, data: 0.149) G_GAN: 1.521 G_L1: 7.767 D_real: 0.249 D_fake: 0.488 \n",
      "(epoch: 88, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.305 G_L1: 7.072 D_real: 0.464 D_fake: 0.344 \n",
      "(epoch: 88, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.198 G_L1: 5.027 D_real: 0.608 D_fake: 0.508 \n",
      "(epoch: 88, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.284 G_L1: 4.423 D_real: 0.292 D_fake: 0.839 \n",
      "(epoch: 88, iters: 500, time: 0.319, data: 0.002) G_GAN: 1.647 G_L1: 6.956 D_real: 0.380 D_fake: 0.488 \n",
      "End of epoch 88 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 100, time: 0.163, data: 0.174) G_GAN: 1.833 G_L1: 7.683 D_real: 0.250 D_fake: 0.675 \n",
      "(epoch: 89, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.086 G_L1: 5.076 D_real: 0.371 D_fake: 0.459 \n",
      "(epoch: 89, iters: 300, time: 0.164, data: 0.002) G_GAN: 0.563 G_L1: 5.503 D_real: 1.102 D_fake: 0.132 \n",
      "(epoch: 89, iters: 400, time: 0.332, data: 0.002) G_GAN: 1.941 G_L1: 7.221 D_real: 0.240 D_fake: 0.307 \n",
      "(epoch: 89, iters: 500, time: 0.163, data: 0.002) G_GAN: 0.830 G_L1: 4.549 D_real: 1.519 D_fake: 0.201 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 89 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 100, time: 0.164, data: 0.157) G_GAN: 1.223 G_L1: 5.675 D_real: 0.730 D_fake: 0.250 \n",
      "(epoch: 90, iters: 200, time: 0.165, data: 0.003) G_GAN: 0.911 G_L1: 6.103 D_real: 1.059 D_fake: 0.219 \n",
      "(epoch: 90, iters: 300, time: 0.320, data: 0.002) G_GAN: 0.728 G_L1: 4.952 D_real: 0.875 D_fake: 0.268 \n",
      "(epoch: 90, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.212 G_L1: 6.453 D_real: 0.759 D_fake: 0.346 \n",
      "(epoch: 90, iters: 500, time: 0.164, data: 0.002) G_GAN: 0.842 G_L1: 5.825 D_real: 0.517 D_fake: 0.757 \n",
      "saving the latest model (epoch 90, total_iters 45000)\n",
      "saving the model at the end of epoch 90, iters 45000\n",
      "End of epoch 90 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 100, time: 0.164, data: 0.169) G_GAN: 1.103 G_L1: 7.304 D_real: 0.572 D_fake: 0.392 \n",
      "(epoch: 91, iters: 200, time: 0.340, data: 0.002) G_GAN: 0.617 G_L1: 5.921 D_real: 1.137 D_fake: 0.382 \n",
      "(epoch: 91, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.428 G_L1: 6.307 D_real: 0.501 D_fake: 0.519 \n",
      "(epoch: 91, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.535 G_L1: 6.607 D_real: 1.412 D_fake: 0.068 \n",
      "(epoch: 91, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.524 G_L1: 7.839 D_real: 0.372 D_fake: 0.934 \n",
      "End of epoch 91 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 100, time: 0.325, data: 0.145) G_GAN: 0.658 G_L1: 6.438 D_real: 0.618 D_fake: 0.222 \n",
      "(epoch: 92, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.501 G_L1: 5.439 D_real: 0.473 D_fake: 0.488 \n",
      "(epoch: 92, iters: 300, time: 0.164, data: 0.003) G_GAN: 2.120 G_L1: 8.074 D_real: 0.157 D_fake: 0.192 \n",
      "(epoch: 92, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.350 G_L1: 7.286 D_real: 0.383 D_fake: 0.310 \n",
      "(epoch: 92, iters: 500, time: 0.325, data: 0.002) G_GAN: 1.117 G_L1: 5.098 D_real: 0.532 D_fake: 0.541 \n",
      "End of epoch 92 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 100, time: 0.163, data: 0.156) G_GAN: 1.895 G_L1: 6.999 D_real: 0.096 D_fake: 0.588 \n",
      "(epoch: 93, iters: 200, time: 0.165, data: 0.003) G_GAN: 1.724 G_L1: 5.280 D_real: 0.250 D_fake: 0.558 \n",
      "(epoch: 93, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.512 G_L1: 6.230 D_real: 0.338 D_fake: 0.376 \n",
      "(epoch: 93, iters: 400, time: 0.314, data: 0.002) G_GAN: 1.153 G_L1: 4.450 D_real: 0.401 D_fake: 0.541 \n",
      "(epoch: 93, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.125 G_L1: 5.816 D_real: 0.734 D_fake: 0.276 \n",
      "End of epoch 93 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 100, time: 0.164, data: 0.149) G_GAN: 1.563 G_L1: 7.478 D_real: 0.142 D_fake: 0.478 \n",
      "(epoch: 94, iters: 200, time: 0.163, data: 0.003) G_GAN: 1.732 G_L1: 7.206 D_real: 0.377 D_fake: 0.466 \n",
      "(epoch: 94, iters: 300, time: 0.322, data: 0.002) G_GAN: 1.806 G_L1: 6.543 D_real: 0.522 D_fake: 0.388 \n",
      "(epoch: 94, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.168 G_L1: 4.242 D_real: 0.714 D_fake: 0.358 \n",
      "(epoch: 94, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.344 G_L1: 5.383 D_real: 0.594 D_fake: 0.532 \n",
      "End of epoch 94 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 100, time: 0.164, data: 0.163) G_GAN: 0.529 G_L1: 6.566 D_real: 1.494 D_fake: 0.123 \n",
      "(epoch: 95, iters: 200, time: 0.335, data: 0.002) G_GAN: 1.032 G_L1: 7.500 D_real: 0.441 D_fake: 0.414 \n",
      "(epoch: 95, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.192 G_L1: 7.603 D_real: 0.439 D_fake: 0.422 \n",
      "(epoch: 95, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.585 G_L1: 8.307 D_real: 0.432 D_fake: 0.282 \n",
      "(epoch: 95, iters: 500, time: 0.163, data: 0.002) G_GAN: 0.800 G_L1: 5.916 D_real: 0.631 D_fake: 0.421 \n",
      "saving the model at the end of epoch 95, iters 47500\n",
      "End of epoch 95 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 100, time: 0.344, data: 0.142) G_GAN: 1.612 G_L1: 5.382 D_real: 0.188 D_fake: 1.074 \n",
      "(epoch: 96, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.717 G_L1: 7.319 D_real: 0.218 D_fake: 0.886 \n",
      "(epoch: 96, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.408 G_L1: 5.747 D_real: 0.545 D_fake: 0.614 \n",
      "(epoch: 96, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.347 G_L1: 6.722 D_real: 0.481 D_fake: 0.400 \n",
      "(epoch: 96, iters: 500, time: 0.330, data: 0.002) G_GAN: 1.210 G_L1: 6.156 D_real: 0.465 D_fake: 0.401 \n",
      "End of epoch 96 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 100, time: 0.163, data: 0.154) G_GAN: 2.587 G_L1: 6.192 D_real: 0.143 D_fake: 0.912 \n",
      "(epoch: 97, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.351 G_L1: 6.708 D_real: 1.431 D_fake: 0.155 \n",
      "(epoch: 97, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.554 G_L1: 4.640 D_real: 0.343 D_fake: 0.604 \n",
      "(epoch: 97, iters: 400, time: 0.335, data: 0.002) G_GAN: 1.332 G_L1: 5.880 D_real: 0.631 D_fake: 0.301 \n",
      "(epoch: 97, iters: 500, time: 0.165, data: 0.002) G_GAN: 0.761 G_L1: 5.556 D_real: 1.046 D_fake: 0.372 \n",
      "End of epoch 97 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 100, time: 0.164, data: 0.177) G_GAN: 1.171 G_L1: 5.979 D_real: 0.461 D_fake: 0.583 \n",
      "(epoch: 98, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.246 G_L1: 6.767 D_real: 0.394 D_fake: 0.794 \n",
      "(epoch: 98, iters: 300, time: 0.304, data: 0.002) G_GAN: 1.306 G_L1: 6.739 D_real: 0.237 D_fake: 0.486 \n",
      "(epoch: 98, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.028 G_L1: 5.697 D_real: 0.897 D_fake: 0.494 \n",
      "(epoch: 98, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.128 G_L1: 6.494 D_real: 0.885 D_fake: 0.473 \n",
      "End of epoch 98 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 100, time: 0.164, data: 0.152) G_GAN: 0.760 G_L1: 7.115 D_real: 0.671 D_fake: 0.582 \n",
      "(epoch: 99, iters: 200, time: 0.348, data: 0.002) G_GAN: 2.452 G_L1: 6.894 D_real: 0.114 D_fake: 0.898 \n",
      "(epoch: 99, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.668 G_L1: 5.793 D_real: 0.501 D_fake: 0.296 \n",
      "(epoch: 99, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.058 G_L1: 5.729 D_real: 0.609 D_fake: 0.466 \n",
      "(epoch: 99, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.670 G_L1: 6.129 D_real: 0.563 D_fake: 0.283 \n",
      "End of epoch 99 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 100, time: 0.333, data: 0.151) G_GAN: 2.021 G_L1: 8.177 D_real: 0.226 D_fake: 0.112 \n",
      "(epoch: 100, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.255 G_L1: 6.617 D_real: 0.356 D_fake: 0.687 \n",
      "(epoch: 100, iters: 300, time: 0.163, data: 0.003) G_GAN: 1.914 G_L1: 5.921 D_real: 1.326 D_fake: 0.148 \n",
      "(epoch: 100, iters: 400, time: 0.164, data: 0.002) G_GAN: 2.473 G_L1: 4.776 D_real: 0.191 D_fake: 0.598 \n",
      "(epoch: 100, iters: 500, time: 0.311, data: 0.002) G_GAN: 0.920 G_L1: 4.791 D_real: 0.614 D_fake: 0.536 \n",
      "saving the latest model (epoch 100, total_iters 50000)\n",
      "saving the model at the end of epoch 100, iters 50000\n",
      "End of epoch 100 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.164, data: 0.147) G_GAN: 1.881 G_L1: 6.427 D_real: 0.192 D_fake: 0.766 \n",
      "(epoch: 101, iters: 200, time: 0.164, data: 0.002) G_GAN: 0.809 G_L1: 6.522 D_real: 0.735 D_fake: 0.264 \n",
      "(epoch: 101, iters: 300, time: 0.164, data: 0.002) G_GAN: 0.923 G_L1: 7.264 D_real: 0.375 D_fake: 0.528 \n",
      "(epoch: 101, iters: 400, time: 0.332, data: 0.002) G_GAN: 1.396 G_L1: 5.262 D_real: 0.463 D_fake: 0.338 \n",
      "(epoch: 101, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.332 G_L1: 6.152 D_real: 0.710 D_fake: 0.330 \n",
      "End of epoch 101 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 100, time: 0.164, data: 0.141) G_GAN: 0.845 G_L1: 4.640 D_real: 0.821 D_fake: 0.375 \n",
      "(epoch: 102, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.463 G_L1: 7.145 D_real: 0.290 D_fake: 0.562 \n",
      "(epoch: 102, iters: 300, time: 0.347, data: 0.002) G_GAN: 1.027 G_L1: 7.190 D_real: 1.061 D_fake: 0.163 \n",
      "(epoch: 102, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.763 G_L1: 6.619 D_real: 0.332 D_fake: 0.263 \n",
      "(epoch: 102, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.511 G_L1: 5.783 D_real: 0.495 D_fake: 0.401 \n",
      "End of epoch 102 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 100, time: 0.163, data: 0.149) G_GAN: 1.589 G_L1: 6.053 D_real: 0.165 D_fake: 0.631 \n",
      "(epoch: 103, iters: 200, time: 0.342, data: 0.002) G_GAN: 1.430 G_L1: 6.464 D_real: 0.473 D_fake: 0.369 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 103, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.738 G_L1: 6.656 D_real: 0.432 D_fake: 0.658 \n",
      "(epoch: 103, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.242 G_L1: 5.899 D_real: 0.625 D_fake: 0.275 \n",
      "(epoch: 103, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.584 G_L1: 6.740 D_real: 0.489 D_fake: 0.336 \n",
      "End of epoch 103 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 100, time: 0.350, data: 0.146) G_GAN: 1.501 G_L1: 6.783 D_real: 0.465 D_fake: 0.516 \n",
      "(epoch: 104, iters: 200, time: 0.163, data: 0.002) G_GAN: 0.431 G_L1: 5.688 D_real: 0.886 D_fake: 0.301 \n",
      "(epoch: 104, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.592 G_L1: 5.893 D_real: 0.356 D_fake: 0.498 \n",
      "(epoch: 104, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.035 G_L1: 5.840 D_real: 0.993 D_fake: 0.400 \n",
      "(epoch: 104, iters: 500, time: 0.342, data: 0.002) G_GAN: 1.614 G_L1: 6.500 D_real: 0.381 D_fake: 0.347 \n",
      "End of epoch 104 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 100, time: 0.163, data: 0.150) G_GAN: 2.034 G_L1: 6.737 D_real: 0.122 D_fake: 0.810 \n",
      "(epoch: 105, iters: 200, time: 0.164, data: 0.002) G_GAN: 2.029 G_L1: 8.498 D_real: 0.129 D_fake: 0.626 \n",
      "(epoch: 105, iters: 300, time: 0.163, data: 0.002) G_GAN: 2.141 G_L1: 7.112 D_real: 0.173 D_fake: 0.300 \n",
      "(epoch: 105, iters: 400, time: 0.338, data: 0.002) G_GAN: 1.328 G_L1: 5.881 D_real: 0.380 D_fake: 0.657 \n",
      "(epoch: 105, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.060 G_L1: 5.831 D_real: 1.085 D_fake: 0.327 \n",
      "saving the model at the end of epoch 105, iters 52500\n",
      "End of epoch 105 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 100, time: 0.164, data: 0.172) G_GAN: 1.050 G_L1: 4.742 D_real: 1.132 D_fake: 0.461 \n",
      "(epoch: 106, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.270 G_L1: 5.671 D_real: 0.468 D_fake: 0.643 \n",
      "(epoch: 106, iters: 300, time: 0.351, data: 0.002) G_GAN: 1.436 G_L1: 6.445 D_real: 0.361 D_fake: 0.733 \n",
      "(epoch: 106, iters: 400, time: 0.163, data: 0.002) G_GAN: 0.793 G_L1: 5.826 D_real: 0.915 D_fake: 0.128 \n",
      "(epoch: 106, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.183 G_L1: 4.483 D_real: 0.491 D_fake: 0.442 \n",
      "End of epoch 106 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 100, time: 0.164, data: 0.152) G_GAN: 1.143 G_L1: 6.116 D_real: 0.659 D_fake: 0.249 \n",
      "(epoch: 107, iters: 200, time: 0.341, data: 0.002) G_GAN: 1.202 G_L1: 6.274 D_real: 0.462 D_fake: 0.394 \n",
      "(epoch: 107, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.056 G_L1: 4.022 D_real: 0.788 D_fake: 0.591 \n",
      "(epoch: 107, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.623 G_L1: 5.274 D_real: 0.268 D_fake: 0.802 \n",
      "(epoch: 107, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.261 G_L1: 7.323 D_real: 0.898 D_fake: 0.417 \n",
      "End of epoch 107 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 100, time: 0.358, data: 0.144) G_GAN: 1.484 G_L1: 7.049 D_real: 0.943 D_fake: 0.114 \n",
      "(epoch: 108, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.356 G_L1: 5.492 D_real: 0.697 D_fake: 0.410 \n",
      "(epoch: 108, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.612 G_L1: 6.900 D_real: 0.215 D_fake: 0.624 \n",
      "(epoch: 108, iters: 400, time: 0.164, data: 0.003) G_GAN: 1.056 G_L1: 4.377 D_real: 0.460 D_fake: 0.515 \n",
      "(epoch: 108, iters: 500, time: 0.326, data: 0.002) G_GAN: 1.738 G_L1: 4.648 D_real: 0.052 D_fake: 1.104 \n",
      "End of epoch 108 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 100, time: 0.163, data: 0.154) G_GAN: 1.167 G_L1: 4.035 D_real: 0.471 D_fake: 0.511 \n",
      "(epoch: 109, iters: 200, time: 0.164, data: 0.003) G_GAN: 1.345 G_L1: 6.737 D_real: 0.237 D_fake: 0.572 \n",
      "(epoch: 109, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.891 G_L1: 5.753 D_real: 0.309 D_fake: 0.322 \n",
      "(epoch: 109, iters: 400, time: 0.354, data: 0.002) G_GAN: 0.850 G_L1: 5.983 D_real: 1.681 D_fake: 0.192 \n",
      "(epoch: 109, iters: 500, time: 0.163, data: 0.002) G_GAN: 0.911 G_L1: 6.709 D_real: 1.346 D_fake: 0.165 \n",
      "End of epoch 109 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 100, time: 0.164, data: 0.180) G_GAN: 2.053 G_L1: 6.282 D_real: 0.332 D_fake: 0.318 \n",
      "(epoch: 110, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.223 G_L1: 6.853 D_real: 0.662 D_fake: 0.581 \n",
      "(epoch: 110, iters: 300, time: 0.353, data: 0.002) G_GAN: 1.042 G_L1: 6.509 D_real: 0.847 D_fake: 0.361 \n",
      "(epoch: 110, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.994 G_L1: 8.333 D_real: 0.736 D_fake: 0.169 \n",
      "(epoch: 110, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.135 G_L1: 7.058 D_real: 0.594 D_fake: 0.711 \n",
      "saving the latest model (epoch 110, total_iters 55000)\n",
      "saving the model at the end of epoch 110, iters 55000\n",
      "End of epoch 110 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 100, time: 0.163, data: 0.178) G_GAN: 1.992 G_L1: 7.048 D_real: 0.175 D_fake: 0.456 \n",
      "(epoch: 111, iters: 200, time: 0.364, data: 0.002) G_GAN: 0.890 G_L1: 7.198 D_real: 0.803 D_fake: 0.209 \n",
      "(epoch: 111, iters: 300, time: 0.164, data: 0.002) G_GAN: 0.846 G_L1: 5.717 D_real: 1.164 D_fake: 0.296 \n",
      "(epoch: 111, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.741 G_L1: 6.990 D_real: 0.634 D_fake: 0.297 \n",
      "(epoch: 111, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.562 G_L1: 6.151 D_real: 0.353 D_fake: 0.463 \n",
      "End of epoch 111 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 100, time: 0.349, data: 0.154) G_GAN: 1.481 G_L1: 6.608 D_real: 0.446 D_fake: 0.806 \n",
      "(epoch: 112, iters: 200, time: 0.164, data: 0.003) G_GAN: 1.375 G_L1: 5.539 D_real: 0.477 D_fake: 0.335 \n",
      "(epoch: 112, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.771 G_L1: 6.948 D_real: 0.345 D_fake: 0.551 \n",
      "(epoch: 112, iters: 400, time: 0.164, data: 0.003) G_GAN: 1.662 G_L1: 6.167 D_real: 0.261 D_fake: 0.527 \n",
      "(epoch: 112, iters: 500, time: 0.349, data: 0.002) G_GAN: 1.336 G_L1: 7.071 D_real: 0.547 D_fake: 0.749 \n",
      "End of epoch 112 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 100, time: 0.164, data: 0.139) G_GAN: 1.439 G_L1: 6.197 D_real: 0.324 D_fake: 0.455 \n",
      "(epoch: 113, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.732 G_L1: 6.755 D_real: 0.091 D_fake: 1.225 \n",
      "(epoch: 113, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.475 G_L1: 6.452 D_real: 0.562 D_fake: 0.328 \n",
      "(epoch: 113, iters: 400, time: 0.351, data: 0.002) G_GAN: 2.759 G_L1: 8.981 D_real: 0.099 D_fake: 0.236 \n",
      "(epoch: 113, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.767 G_L1: 6.824 D_real: 0.336 D_fake: 1.063 \n",
      "End of epoch 113 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 100, time: 0.163, data: 0.151) G_GAN: 1.160 G_L1: 4.592 D_real: 0.643 D_fake: 0.282 \n",
      "(epoch: 114, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.532 G_L1: 5.939 D_real: 0.779 D_fake: 0.164 \n",
      "(epoch: 114, iters: 300, time: 0.362, data: 0.002) G_GAN: 1.536 G_L1: 6.737 D_real: 0.269 D_fake: 0.329 \n",
      "(epoch: 114, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.607 G_L1: 5.044 D_real: 0.412 D_fake: 0.537 \n",
      "(epoch: 114, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.111 G_L1: 3.974 D_real: 0.478 D_fake: 0.483 \n",
      "End of epoch 114 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 100, time: 0.165, data: 0.175) G_GAN: 1.816 G_L1: 7.504 D_real: 0.368 D_fake: 0.520 \n",
      "(epoch: 115, iters: 200, time: 0.356, data: 0.002) G_GAN: 1.684 G_L1: 7.203 D_real: 0.311 D_fake: 0.365 \n",
      "(epoch: 115, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.467 G_L1: 6.358 D_real: 0.340 D_fake: 0.418 \n",
      "(epoch: 115, iters: 400, time: 0.163, data: 0.002) G_GAN: 2.249 G_L1: 6.835 D_real: 0.117 D_fake: 1.078 \n",
      "(epoch: 115, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.708 G_L1: 6.306 D_real: 0.773 D_fake: 0.467 \n",
      "saving the model at the end of epoch 115, iters 57500\n",
      "End of epoch 115 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 100, time: 0.333, data: 0.145) G_GAN: 1.740 G_L1: 4.523 D_real: 0.173 D_fake: 0.557 \n",
      "(epoch: 116, iters: 200, time: 0.163, data: 0.002) G_GAN: 2.015 G_L1: 4.744 D_real: 0.303 D_fake: 0.600 \n",
      "(epoch: 116, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.429 G_L1: 7.512 D_real: 0.619 D_fake: 0.200 \n",
      "(epoch: 116, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.103 G_L1: 3.313 D_real: 0.997 D_fake: 0.275 \n",
      "(epoch: 116, iters: 500, time: 0.345, data: 0.003) G_GAN: 1.208 G_L1: 4.854 D_real: 1.052 D_fake: 0.124 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 116 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 100, time: 0.163, data: 0.155) G_GAN: 0.996 G_L1: 4.324 D_real: 0.528 D_fake: 0.762 \n",
      "(epoch: 117, iters: 200, time: 0.163, data: 0.003) G_GAN: 1.239 G_L1: 5.788 D_real: 0.293 D_fake: 0.712 \n",
      "(epoch: 117, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.932 G_L1: 7.438 D_real: 0.158 D_fake: 0.630 \n",
      "(epoch: 117, iters: 400, time: 0.368, data: 0.002) G_GAN: 1.272 G_L1: 7.075 D_real: 0.687 D_fake: 0.422 \n",
      "(epoch: 117, iters: 500, time: 0.163, data: 0.002) G_GAN: 2.381 G_L1: 8.617 D_real: 0.027 D_fake: 0.532 \n",
      "End of epoch 117 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 100, time: 0.163, data: 0.157) G_GAN: 1.158 G_L1: 6.784 D_real: 0.383 D_fake: 0.281 \n",
      "(epoch: 118, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.290 G_L1: 5.908 D_real: 0.303 D_fake: 0.899 \n",
      "(epoch: 118, iters: 300, time: 0.341, data: 0.002) G_GAN: 1.785 G_L1: 4.289 D_real: 0.281 D_fake: 0.489 \n",
      "(epoch: 118, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.869 G_L1: 6.572 D_real: 0.446 D_fake: 0.542 \n",
      "(epoch: 118, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.476 G_L1: 4.826 D_real: 0.701 D_fake: 0.784 \n",
      "End of epoch 118 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 100, time: 0.164, data: 0.150) G_GAN: 1.613 G_L1: 6.309 D_real: 0.291 D_fake: 0.472 \n",
      "(epoch: 119, iters: 200, time: 0.353, data: 0.003) G_GAN: 2.481 G_L1: 7.603 D_real: 0.104 D_fake: 0.200 \n",
      "(epoch: 119, iters: 300, time: 0.164, data: 0.002) G_GAN: 0.929 G_L1: 6.149 D_real: 0.745 D_fake: 0.372 \n",
      "(epoch: 119, iters: 400, time: 0.163, data: 0.002) G_GAN: 2.663 G_L1: 6.671 D_real: 0.065 D_fake: 1.509 \n",
      "(epoch: 119, iters: 500, time: 0.163, data: 0.002) G_GAN: 0.754 G_L1: 5.373 D_real: 1.344 D_fake: 0.308 \n",
      "End of epoch 119 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 100, time: 0.357, data: 0.152) G_GAN: 1.129 G_L1: 4.721 D_real: 0.650 D_fake: 0.426 \n",
      "(epoch: 120, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.458 G_L1: 8.977 D_real: 0.414 D_fake: 0.342 \n",
      "(epoch: 120, iters: 300, time: 0.164, data: 0.003) G_GAN: 1.671 G_L1: 6.777 D_real: 0.328 D_fake: 0.296 \n",
      "(epoch: 120, iters: 400, time: 0.163, data: 0.002) G_GAN: 0.841 G_L1: 5.055 D_real: 0.787 D_fake: 0.162 \n",
      "(epoch: 120, iters: 500, time: 0.371, data: 0.002) G_GAN: 2.435 G_L1: 8.004 D_real: 0.268 D_fake: 0.249 \n",
      "saving the latest model (epoch 120, total_iters 60000)\n",
      "saving the model at the end of epoch 120, iters 60000\n",
      "End of epoch 120 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 100, time: 0.163, data: 0.147) G_GAN: 1.344 G_L1: 7.438 D_real: 0.622 D_fake: 0.287 \n",
      "(epoch: 121, iters: 200, time: 0.164, data: 0.002) G_GAN: 0.745 G_L1: 5.295 D_real: 0.922 D_fake: 0.320 \n",
      "(epoch: 121, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.314 G_L1: 5.914 D_real: 0.563 D_fake: 0.349 \n",
      "(epoch: 121, iters: 400, time: 0.351, data: 0.002) G_GAN: 1.366 G_L1: 4.986 D_real: 0.400 D_fake: 0.396 \n",
      "(epoch: 121, iters: 500, time: 0.164, data: 0.003) G_GAN: 2.050 G_L1: 6.642 D_real: 0.273 D_fake: 0.809 \n",
      "End of epoch 121 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 100, time: 0.163, data: 0.181) G_GAN: 1.426 G_L1: 5.445 D_real: 0.291 D_fake: 0.577 \n",
      "(epoch: 122, iters: 200, time: 0.163, data: 0.003) G_GAN: 1.092 G_L1: 4.025 D_real: 0.867 D_fake: 0.371 \n",
      "(epoch: 122, iters: 300, time: 0.357, data: 0.002) G_GAN: 3.268 G_L1: 6.297 D_real: 0.300 D_fake: 1.921 \n",
      "(epoch: 122, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.080 G_L1: 4.733 D_real: 0.773 D_fake: 0.148 \n",
      "(epoch: 122, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.665 G_L1: 5.015 D_real: 0.796 D_fake: 0.248 \n",
      "End of epoch 122 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 100, time: 0.164, data: 0.147) G_GAN: 1.559 G_L1: 6.466 D_real: 0.772 D_fake: 0.447 \n",
      "(epoch: 123, iters: 200, time: 0.365, data: 0.002) G_GAN: 1.368 G_L1: 6.496 D_real: 0.616 D_fake: 0.445 \n",
      "(epoch: 123, iters: 300, time: 0.163, data: 0.003) G_GAN: 1.760 G_L1: 7.697 D_real: 0.825 D_fake: 0.260 \n",
      "(epoch: 123, iters: 400, time: 0.163, data: 0.002) G_GAN: 0.837 G_L1: 7.274 D_real: 0.730 D_fake: 0.325 \n",
      "(epoch: 123, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.292 G_L1: 3.694 D_real: 0.463 D_fake: 0.459 \n",
      "End of epoch 123 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 100, time: 0.380, data: 0.178) G_GAN: 1.083 G_L1: 6.108 D_real: 0.494 D_fake: 0.500 \n",
      "(epoch: 124, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.690 G_L1: 7.254 D_real: 0.170 D_fake: 0.578 \n",
      "(epoch: 124, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.714 G_L1: 5.908 D_real: 0.208 D_fake: 0.765 \n",
      "(epoch: 124, iters: 400, time: 0.163, data: 0.003) G_GAN: 1.376 G_L1: 7.144 D_real: 0.617 D_fake: 0.311 \n",
      "(epoch: 124, iters: 500, time: 0.368, data: 0.002) G_GAN: 1.920 G_L1: 6.797 D_real: 0.687 D_fake: 0.463 \n",
      "End of epoch 124 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 100, time: 0.163, data: 0.156) G_GAN: 1.575 G_L1: 6.051 D_real: 0.420 D_fake: 0.651 \n",
      "(epoch: 125, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.765 G_L1: 7.654 D_real: 0.430 D_fake: 0.388 \n",
      "(epoch: 125, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.114 G_L1: 6.661 D_real: 0.900 D_fake: 0.398 \n",
      "(epoch: 125, iters: 400, time: 0.372, data: 0.003) G_GAN: 1.325 G_L1: 6.678 D_real: 0.594 D_fake: 0.273 \n",
      "(epoch: 125, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.338 G_L1: 6.079 D_real: 0.425 D_fake: 0.734 \n",
      "saving the model at the end of epoch 125, iters 62500\n",
      "End of epoch 125 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 100, time: 0.164, data: 0.147) G_GAN: 2.433 G_L1: 8.612 D_real: 0.406 D_fake: 0.141 \n",
      "(epoch: 126, iters: 200, time: 0.163, data: 0.002) G_GAN: 2.102 G_L1: 6.346 D_real: 0.349 D_fake: 0.335 \n",
      "(epoch: 126, iters: 300, time: 0.367, data: 0.002) G_GAN: 1.503 G_L1: 6.524 D_real: 0.448 D_fake: 0.268 \n",
      "(epoch: 126, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.240 G_L1: 4.504 D_real: 0.643 D_fake: 0.540 \n",
      "(epoch: 126, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.584 G_L1: 6.444 D_real: 0.258 D_fake: 0.385 \n",
      "End of epoch 126 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 100, time: 0.163, data: 0.149) G_GAN: 1.057 G_L1: 7.038 D_real: 0.430 D_fake: 0.463 \n",
      "(epoch: 127, iters: 200, time: 0.385, data: 0.002) G_GAN: 1.066 G_L1: 7.866 D_real: 0.670 D_fake: 0.115 \n",
      "(epoch: 127, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.763 G_L1: 4.638 D_real: 0.346 D_fake: 0.456 \n",
      "(epoch: 127, iters: 400, time: 0.163, data: 0.002) G_GAN: 2.645 G_L1: 7.378 D_real: 0.285 D_fake: 0.358 \n",
      "(epoch: 127, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.605 G_L1: 7.058 D_real: 0.629 D_fake: 0.287 \n",
      "End of epoch 127 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 100, time: 0.369, data: 0.171) G_GAN: 1.367 G_L1: 3.728 D_real: 0.322 D_fake: 0.661 \n",
      "(epoch: 128, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.190 G_L1: 5.789 D_real: 0.654 D_fake: 0.154 \n",
      "(epoch: 128, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.837 G_L1: 6.320 D_real: 0.645 D_fake: 0.104 \n",
      "(epoch: 128, iters: 400, time: 0.163, data: 0.003) G_GAN: 1.572 G_L1: 7.985 D_real: 0.530 D_fake: 0.238 \n",
      "(epoch: 128, iters: 500, time: 0.364, data: 0.002) G_GAN: 1.536 G_L1: 5.826 D_real: 0.431 D_fake: 0.311 \n",
      "End of epoch 128 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 100, time: 0.163, data: 0.152) G_GAN: 1.378 G_L1: 6.563 D_real: 0.714 D_fake: 0.294 \n",
      "(epoch: 129, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.413 G_L1: 4.229 D_real: 0.727 D_fake: 0.369 \n",
      "(epoch: 129, iters: 300, time: 0.163, data: 0.003) G_GAN: 1.690 G_L1: 7.169 D_real: 0.403 D_fake: 0.503 \n",
      "(epoch: 129, iters: 400, time: 0.373, data: 0.002) G_GAN: 1.522 G_L1: 6.474 D_real: 0.262 D_fake: 0.437 \n",
      "(epoch: 129, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.788 G_L1: 7.069 D_real: 0.176 D_fake: 0.640 \n",
      "End of epoch 129 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 100, time: 0.164, data: 0.154) G_GAN: 1.667 G_L1: 3.612 D_real: 0.613 D_fake: 0.419 \n",
      "(epoch: 130, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.376 G_L1: 4.524 D_real: 0.476 D_fake: 0.564 \n",
      "(epoch: 130, iters: 300, time: 0.366, data: 0.002) G_GAN: 1.440 G_L1: 5.974 D_real: 0.539 D_fake: 0.178 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 130, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.563 G_L1: 6.092 D_real: 0.595 D_fake: 0.153 \n",
      "(epoch: 130, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.436 G_L1: 6.277 D_real: 0.468 D_fake: 0.902 \n",
      "saving the latest model (epoch 130, total_iters 65000)\n",
      "saving the model at the end of epoch 130, iters 65000\n",
      "End of epoch 130 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 100, time: 0.164, data: 0.179) G_GAN: 1.639 G_L1: 5.376 D_real: 0.422 D_fake: 0.597 \n",
      "(epoch: 131, iters: 200, time: 0.377, data: 0.002) G_GAN: 1.772 G_L1: 6.266 D_real: 0.327 D_fake: 0.297 \n",
      "(epoch: 131, iters: 300, time: 0.163, data: 0.002) G_GAN: 0.602 G_L1: 6.806 D_real: 0.958 D_fake: 0.134 \n",
      "(epoch: 131, iters: 400, time: 0.163, data: 0.003) G_GAN: 1.158 G_L1: 6.824 D_real: 0.733 D_fake: 0.329 \n",
      "(epoch: 131, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.728 G_L1: 5.349 D_real: 0.628 D_fake: 0.181 \n",
      "End of epoch 131 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 100, time: 0.361, data: 0.156) G_GAN: 2.008 G_L1: 7.130 D_real: 0.165 D_fake: 0.276 \n",
      "(epoch: 132, iters: 200, time: 0.164, data: 0.002) G_GAN: 0.939 G_L1: 5.628 D_real: 0.923 D_fake: 0.207 \n",
      "(epoch: 132, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.046 G_L1: 5.277 D_real: 0.682 D_fake: 0.360 \n",
      "(epoch: 132, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.060 G_L1: 3.806 D_real: 0.723 D_fake: 0.556 \n",
      "(epoch: 132, iters: 500, time: 0.381, data: 0.002) G_GAN: 2.161 G_L1: 7.908 D_real: 0.210 D_fake: 0.595 \n",
      "End of epoch 132 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 100, time: 0.163, data: 0.157) G_GAN: 1.310 G_L1: 5.451 D_real: 0.492 D_fake: 0.343 \n",
      "(epoch: 133, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.239 G_L1: 6.339 D_real: 0.397 D_fake: 0.506 \n",
      "(epoch: 133, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.126 G_L1: 4.822 D_real: 0.541 D_fake: 0.368 \n",
      "(epoch: 133, iters: 400, time: 0.376, data: 0.002) G_GAN: 1.695 G_L1: 6.307 D_real: 0.229 D_fake: 1.051 \n",
      "(epoch: 133, iters: 500, time: 0.164, data: 0.002) G_GAN: 2.115 G_L1: 7.579 D_real: 0.204 D_fake: 0.612 \n",
      "End of epoch 133 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 100, time: 0.164, data: 0.145) G_GAN: 1.780 G_L1: 5.783 D_real: 0.309 D_fake: 0.342 \n",
      "(epoch: 134, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.544 G_L1: 6.217 D_real: 0.552 D_fake: 0.295 \n",
      "(epoch: 134, iters: 300, time: 0.387, data: 0.002) G_GAN: 1.496 G_L1: 7.473 D_real: 0.728 D_fake: 0.126 \n",
      "(epoch: 134, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.195 G_L1: 3.286 D_real: 0.518 D_fake: 0.627 \n",
      "(epoch: 134, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.313 G_L1: 7.140 D_real: 0.396 D_fake: 0.384 \n",
      "End of epoch 134 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 100, time: 0.163, data: 0.155) G_GAN: 1.738 G_L1: 7.358 D_real: 0.283 D_fake: 0.541 \n",
      "(epoch: 135, iters: 200, time: 0.377, data: 0.002) G_GAN: 1.183 G_L1: 6.534 D_real: 1.014 D_fake: 0.475 \n",
      "(epoch: 135, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.739 G_L1: 6.215 D_real: 0.535 D_fake: 0.173 \n",
      "(epoch: 135, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.308 G_L1: 4.601 D_real: 0.923 D_fake: 0.231 \n",
      "(epoch: 135, iters: 500, time: 0.163, data: 0.003) G_GAN: 1.387 G_L1: 6.271 D_real: 0.335 D_fake: 0.555 \n",
      "saving the model at the end of epoch 135, iters 67500\n",
      "End of epoch 135 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 100, time: 0.376, data: 0.152) G_GAN: 2.293 G_L1: 5.622 D_real: 0.127 D_fake: 0.535 \n",
      "(epoch: 136, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.796 G_L1: 6.219 D_real: 0.281 D_fake: 0.422 \n",
      "(epoch: 136, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.407 G_L1: 4.774 D_real: 0.540 D_fake: 0.594 \n",
      "(epoch: 136, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.415 G_L1: 5.601 D_real: 0.494 D_fake: 0.957 \n",
      "(epoch: 136, iters: 500, time: 0.377, data: 0.002) G_GAN: 1.404 G_L1: 5.895 D_real: 0.393 D_fake: 0.587 \n",
      "End of epoch 136 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 100, time: 0.163, data: 0.165) G_GAN: 0.910 G_L1: 5.369 D_real: 0.784 D_fake: 0.306 \n",
      "(epoch: 137, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.542 G_L1: 7.794 D_real: 0.258 D_fake: 0.394 \n",
      "(epoch: 137, iters: 300, time: 0.164, data: 0.002) G_GAN: 0.961 G_L1: 5.813 D_real: 0.613 D_fake: 0.325 \n",
      "(epoch: 137, iters: 400, time: 0.379, data: 0.002) G_GAN: 1.714 G_L1: 6.531 D_real: 0.286 D_fake: 0.699 \n",
      "(epoch: 137, iters: 500, time: 0.163, data: 0.002) G_GAN: 1.935 G_L1: 6.970 D_real: 0.497 D_fake: 0.401 \n",
      "End of epoch 137 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 100, time: 0.163, data: 0.156) G_GAN: 1.676 G_L1: 6.794 D_real: 0.384 D_fake: 0.540 \n",
      "(epoch: 138, iters: 200, time: 0.164, data: 0.003) G_GAN: 1.218 G_L1: 6.926 D_real: 1.156 D_fake: 0.156 \n",
      "(epoch: 138, iters: 300, time: 0.386, data: 0.002) G_GAN: 2.447 G_L1: 6.616 D_real: 0.122 D_fake: 1.026 \n",
      "(epoch: 138, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.787 G_L1: 5.887 D_real: 0.686 D_fake: 0.262 \n",
      "(epoch: 138, iters: 500, time: 0.164, data: 0.002) G_GAN: 2.169 G_L1: 5.631 D_real: 0.262 D_fake: 0.191 \n",
      "End of epoch 138 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 100, time: 0.163, data: 0.146) G_GAN: 1.888 G_L1: 6.124 D_real: 0.277 D_fake: 0.400 \n",
      "(epoch: 139, iters: 200, time: 0.389, data: 0.002) G_GAN: 2.236 G_L1: 6.543 D_real: 0.307 D_fake: 0.296 \n",
      "(epoch: 139, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.868 G_L1: 6.122 D_real: 0.263 D_fake: 0.391 \n",
      "(epoch: 139, iters: 400, time: 0.163, data: 0.002) G_GAN: 2.332 G_L1: 5.229 D_real: 0.349 D_fake: 0.226 \n",
      "(epoch: 139, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.718 G_L1: 5.658 D_real: 0.390 D_fake: 0.238 \n",
      "End of epoch 139 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 100, time: 0.381, data: 0.188) G_GAN: 1.564 G_L1: 4.059 D_real: 0.323 D_fake: 0.692 \n",
      "(epoch: 140, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.594 G_L1: 6.419 D_real: 0.333 D_fake: 0.798 \n",
      "(epoch: 140, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.856 G_L1: 6.088 D_real: 0.130 D_fake: 0.364 \n",
      "(epoch: 140, iters: 400, time: 0.163, data: 0.003) G_GAN: 1.802 G_L1: 6.278 D_real: 0.537 D_fake: 0.418 \n",
      "(epoch: 140, iters: 500, time: 0.401, data: 0.002) G_GAN: 1.726 G_L1: 6.138 D_real: 0.327 D_fake: 0.517 \n",
      "saving the latest model (epoch 140, total_iters 70000)\n",
      "saving the model at the end of epoch 140, iters 70000\n",
      "End of epoch 140 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 100, time: 0.166, data: 0.151) G_GAN: 2.147 G_L1: 5.453 D_real: 0.216 D_fake: 0.745 \n",
      "(epoch: 141, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.529 G_L1: 4.160 D_real: 0.720 D_fake: 0.265 \n",
      "(epoch: 141, iters: 300, time: 0.164, data: 0.003) G_GAN: 1.720 G_L1: 7.120 D_real: 0.161 D_fake: 0.484 \n",
      "(epoch: 141, iters: 400, time: 0.445, data: 0.002) G_GAN: 2.269 G_L1: 7.347 D_real: 0.958 D_fake: 0.144 \n",
      "(epoch: 141, iters: 500, time: 0.164, data: 0.002) G_GAN: 0.958 G_L1: 5.583 D_real: 1.182 D_fake: 0.191 \n",
      "End of epoch 141 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 100, time: 0.164, data: 0.155) G_GAN: 1.032 G_L1: 5.607 D_real: 0.725 D_fake: 0.172 \n",
      "(epoch: 142, iters: 200, time: 0.164, data: 0.003) G_GAN: 1.719 G_L1: 5.999 D_real: 0.592 D_fake: 0.223 \n",
      "(epoch: 142, iters: 300, time: 0.386, data: 0.002) G_GAN: 0.673 G_L1: 5.121 D_real: 0.534 D_fake: 0.486 \n",
      "(epoch: 142, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.397 G_L1: 8.619 D_real: 0.472 D_fake: 0.182 \n",
      "(epoch: 142, iters: 500, time: 0.170, data: 0.002) G_GAN: 1.800 G_L1: 6.201 D_real: 0.201 D_fake: 0.368 \n",
      "End of epoch 142 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 100, time: 0.165, data: 0.170) G_GAN: 1.569 G_L1: 7.066 D_real: 0.385 D_fake: 0.150 \n",
      "(epoch: 143, iters: 200, time: 0.391, data: 0.003) G_GAN: 2.137 G_L1: 5.964 D_real: 0.247 D_fake: 0.144 \n",
      "(epoch: 143, iters: 300, time: 0.164, data: 0.002) G_GAN: 2.372 G_L1: 7.330 D_real: 0.242 D_fake: 0.585 \n",
      "(epoch: 143, iters: 400, time: 0.163, data: 0.002) G_GAN: 1.964 G_L1: 6.510 D_real: 0.239 D_fake: 0.417 \n",
      "(epoch: 143, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.352 G_L1: 4.435 D_real: 0.848 D_fake: 0.361 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 143 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 100, time: 0.400, data: 0.155) G_GAN: 1.576 G_L1: 5.569 D_real: 0.367 D_fake: 0.301 \n",
      "(epoch: 144, iters: 200, time: 0.165, data: 0.002) G_GAN: 0.846 G_L1: 3.773 D_real: 0.416 D_fake: 0.702 \n",
      "(epoch: 144, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.699 G_L1: 5.702 D_real: 0.554 D_fake: 0.841 \n",
      "(epoch: 144, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.347 G_L1: 6.503 D_real: 0.266 D_fake: 0.889 \n",
      "(epoch: 144, iters: 500, time: 0.378, data: 0.002) G_GAN: 1.016 G_L1: 5.486 D_real: 0.589 D_fake: 0.421 \n",
      "End of epoch 144 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 100, time: 0.166, data: 0.144) G_GAN: 1.077 G_L1: 3.948 D_real: 0.610 D_fake: 0.261 \n",
      "(epoch: 145, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.029 G_L1: 4.539 D_real: 0.491 D_fake: 0.676 \n",
      "(epoch: 145, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.456 G_L1: 4.394 D_real: 0.839 D_fake: 0.284 \n",
      "(epoch: 145, iters: 400, time: 0.399, data: 0.002) G_GAN: 1.935 G_L1: 6.148 D_real: 0.742 D_fake: 0.120 \n",
      "(epoch: 145, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.533 G_L1: 5.888 D_real: 0.281 D_fake: 0.712 \n",
      "saving the model at the end of epoch 145, iters 72500\n",
      "End of epoch 145 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 100, time: 0.165, data: 0.157) G_GAN: 1.614 G_L1: 6.238 D_real: 0.422 D_fake: 0.198 \n",
      "(epoch: 146, iters: 200, time: 0.166, data: 0.002) G_GAN: 1.664 G_L1: 7.285 D_real: 0.345 D_fake: 0.334 \n",
      "(epoch: 146, iters: 300, time: 0.409, data: 0.002) G_GAN: 1.024 G_L1: 4.327 D_real: 0.682 D_fake: 0.429 \n",
      "(epoch: 146, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.043 G_L1: 6.739 D_real: 0.559 D_fake: 0.764 \n",
      "(epoch: 146, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.673 G_L1: 5.475 D_real: 0.737 D_fake: 0.272 \n",
      "End of epoch 146 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 100, time: 0.166, data: 0.174) G_GAN: 1.255 G_L1: 6.024 D_real: 0.637 D_fake: 0.310 \n",
      "(epoch: 147, iters: 200, time: 0.393, data: 0.002) G_GAN: 1.211 G_L1: 7.660 D_real: 0.261 D_fake: 0.495 \n",
      "(epoch: 147, iters: 300, time: 0.164, data: 0.002) G_GAN: 2.101 G_L1: 6.448 D_real: 0.259 D_fake: 0.128 \n",
      "(epoch: 147, iters: 400, time: 0.170, data: 0.002) G_GAN: 1.496 G_L1: 9.072 D_real: 0.592 D_fake: 0.464 \n",
      "(epoch: 147, iters: 500, time: 0.168, data: 0.002) G_GAN: 0.989 G_L1: 6.203 D_real: 0.790 D_fake: 0.232 \n",
      "End of epoch 147 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 100, time: 0.402, data: 0.176) G_GAN: 1.666 G_L1: 8.557 D_real: 0.470 D_fake: 0.380 \n",
      "(epoch: 148, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.018 G_L1: 7.491 D_real: 0.662 D_fake: 0.546 \n",
      "(epoch: 148, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.578 G_L1: 6.532 D_real: 0.281 D_fake: 0.458 \n",
      "(epoch: 148, iters: 400, time: 0.164, data: 0.003) G_GAN: 1.883 G_L1: 5.728 D_real: 0.272 D_fake: 0.250 \n",
      "(epoch: 148, iters: 500, time: 0.392, data: 0.002) G_GAN: 1.251 G_L1: 6.003 D_real: 0.626 D_fake: 0.276 \n",
      "End of epoch 148 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 100, time: 0.163, data: 0.180) G_GAN: 3.223 G_L1: 5.839 D_real: 0.147 D_fake: 0.641 \n",
      "(epoch: 149, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.570 G_L1: 6.204 D_real: 0.427 D_fake: 0.425 \n",
      "(epoch: 149, iters: 300, time: 0.165, data: 0.002) G_GAN: 2.513 G_L1: 6.874 D_real: 0.192 D_fake: 0.268 \n",
      "(epoch: 149, iters: 400, time: 0.398, data: 0.003) G_GAN: 1.284 G_L1: 7.630 D_real: 0.421 D_fake: 0.581 \n",
      "(epoch: 149, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.750 G_L1: 7.109 D_real: 0.313 D_fake: 0.344 \n",
      "End of epoch 149 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 100, time: 0.164, data: 0.147) G_GAN: 1.547 G_L1: 4.726 D_real: 0.418 D_fake: 0.352 \n",
      "(epoch: 150, iters: 200, time: 0.165, data: 0.002) G_GAN: 2.311 G_L1: 8.224 D_real: 0.505 D_fake: 0.137 \n",
      "(epoch: 150, iters: 300, time: 0.394, data: 0.002) G_GAN: 1.356 G_L1: 4.835 D_real: 0.575 D_fake: 0.537 \n",
      "(epoch: 150, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.604 G_L1: 5.366 D_real: 0.585 D_fake: 0.550 \n",
      "(epoch: 150, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.396 G_L1: 7.096 D_real: 0.717 D_fake: 0.279 \n",
      "saving the latest model (epoch 150, total_iters 75000)\n",
      "saving the model at the end of epoch 150, iters 75000\n",
      "End of epoch 150 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 100, time: 0.165, data: 0.166) G_GAN: 1.918 G_L1: 6.383 D_real: 0.222 D_fake: 0.761 \n",
      "(epoch: 151, iters: 200, time: 0.395, data: 0.002) G_GAN: 1.416 G_L1: 7.231 D_real: 0.239 D_fake: 0.293 \n",
      "(epoch: 151, iters: 300, time: 0.164, data: 0.002) G_GAN: 2.568 G_L1: 8.050 D_real: 0.372 D_fake: 0.291 \n",
      "(epoch: 151, iters: 400, time: 0.166, data: 0.002) G_GAN: 1.057 G_L1: 4.369 D_real: 0.706 D_fake: 0.497 \n",
      "(epoch: 151, iters: 500, time: 0.165, data: 0.002) G_GAN: 2.175 G_L1: 7.263 D_real: 0.137 D_fake: 0.981 \n",
      "End of epoch 151 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 100, time: 0.397, data: 0.145) G_GAN: 2.224 G_L1: 6.927 D_real: 0.253 D_fake: 0.441 \n",
      "(epoch: 152, iters: 200, time: 0.163, data: 0.002) G_GAN: 1.700 G_L1: 7.023 D_real: 0.402 D_fake: 0.201 \n",
      "(epoch: 152, iters: 300, time: 0.164, data: 0.002) G_GAN: 2.145 G_L1: 7.272 D_real: 0.302 D_fake: 0.099 \n",
      "(epoch: 152, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.569 G_L1: 5.153 D_real: 0.383 D_fake: 0.410 \n",
      "(epoch: 152, iters: 500, time: 0.388, data: 0.002) G_GAN: 1.616 G_L1: 7.431 D_real: 0.396 D_fake: 0.424 \n",
      "End of epoch 152 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 100, time: 0.164, data: 0.149) G_GAN: 1.508 G_L1: 4.716 D_real: 0.334 D_fake: 0.771 \n",
      "(epoch: 153, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.157 G_L1: 5.171 D_real: 0.521 D_fake: 0.597 \n",
      "(epoch: 153, iters: 300, time: 0.165, data: 0.002) G_GAN: 2.255 G_L1: 6.304 D_real: 0.249 D_fake: 0.285 \n",
      "(epoch: 153, iters: 400, time: 0.396, data: 0.002) G_GAN: 0.872 G_L1: 6.993 D_real: 1.460 D_fake: 0.256 \n",
      "(epoch: 153, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.946 G_L1: 3.779 D_real: 0.176 D_fake: 0.825 \n",
      "End of epoch 153 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 100, time: 0.164, data: 0.146) G_GAN: 1.344 G_L1: 6.029 D_real: 0.387 D_fake: 0.613 \n",
      "(epoch: 154, iters: 200, time: 0.165, data: 0.002) G_GAN: 2.519 G_L1: 6.540 D_real: 0.243 D_fake: 0.392 \n",
      "(epoch: 154, iters: 300, time: 0.407, data: 0.002) G_GAN: 1.272 G_L1: 6.330 D_real: 0.444 D_fake: 0.566 \n",
      "(epoch: 154, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.569 G_L1: 5.795 D_real: 0.511 D_fake: 0.547 \n",
      "(epoch: 154, iters: 500, time: 0.166, data: 0.003) G_GAN: 1.193 G_L1: 5.895 D_real: 1.227 D_fake: 0.121 \n",
      "End of epoch 154 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 100, time: 0.165, data: 0.155) G_GAN: 2.087 G_L1: 6.195 D_real: 0.141 D_fake: 0.718 \n",
      "(epoch: 155, iters: 200, time: 0.405, data: 0.003) G_GAN: 1.346 G_L1: 6.464 D_real: 0.337 D_fake: 0.734 \n",
      "(epoch: 155, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.707 G_L1: 7.266 D_real: 0.279 D_fake: 0.256 \n",
      "(epoch: 155, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.578 G_L1: 4.389 D_real: 0.501 D_fake: 0.350 \n",
      "(epoch: 155, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.624 G_L1: 4.525 D_real: 0.576 D_fake: 0.407 \n",
      "saving the model at the end of epoch 155, iters 77500\n",
      "End of epoch 155 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 100, time: 0.408, data: 0.169) G_GAN: 1.959 G_L1: 6.133 D_real: 0.301 D_fake: 0.260 \n",
      "(epoch: 156, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.581 G_L1: 5.413 D_real: 0.246 D_fake: 0.270 \n",
      "(epoch: 156, iters: 300, time: 0.163, data: 0.002) G_GAN: 1.235 G_L1: 5.548 D_real: 1.091 D_fake: 0.179 \n",
      "(epoch: 156, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.695 G_L1: 6.095 D_real: 0.109 D_fake: 0.683 \n",
      "(epoch: 156, iters: 500, time: 0.408, data: 0.002) G_GAN: 2.768 G_L1: 6.940 D_real: 0.272 D_fake: 0.091 \n",
      "End of epoch 156 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 100, time: 0.167, data: 0.150) G_GAN: 1.210 G_L1: 5.228 D_real: 0.556 D_fake: 0.409 \n",
      "(epoch: 157, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.161 G_L1: 4.040 D_real: 0.704 D_fake: 0.420 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 157, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.213 G_L1: 6.240 D_real: 0.796 D_fake: 0.258 \n",
      "(epoch: 157, iters: 400, time: 0.420, data: 0.002) G_GAN: 0.859 G_L1: 5.361 D_real: 0.465 D_fake: 0.328 \n",
      "(epoch: 157, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.022 G_L1: 4.630 D_real: 1.141 D_fake: 0.236 \n",
      "End of epoch 157 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 100, time: 0.167, data: 0.147) G_GAN: 1.352 G_L1: 4.940 D_real: 0.588 D_fake: 0.451 \n",
      "(epoch: 158, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.520 G_L1: 8.546 D_real: 0.193 D_fake: 0.563 \n",
      "(epoch: 158, iters: 300, time: 0.395, data: 0.002) G_GAN: 1.877 G_L1: 5.568 D_real: 0.733 D_fake: 0.353 \n",
      "(epoch: 158, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.029 G_L1: 6.397 D_real: 1.433 D_fake: 0.126 \n",
      "(epoch: 158, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.549 G_L1: 4.760 D_real: 0.381 D_fake: 0.524 \n",
      "End of epoch 158 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 100, time: 0.165, data: 0.181) G_GAN: 1.813 G_L1: 6.517 D_real: 0.830 D_fake: 0.089 \n",
      "(epoch: 159, iters: 200, time: 0.410, data: 0.003) G_GAN: 0.960 G_L1: 5.050 D_real: 0.746 D_fake: 0.233 \n",
      "(epoch: 159, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.644 G_L1: 6.980 D_real: 0.301 D_fake: 0.445 \n",
      "(epoch: 159, iters: 400, time: 0.166, data: 0.002) G_GAN: 1.764 G_L1: 5.565 D_real: 0.243 D_fake: 0.492 \n",
      "(epoch: 159, iters: 500, time: 0.164, data: 0.002) G_GAN: 2.066 G_L1: 4.847 D_real: 0.297 D_fake: 0.329 \n",
      "End of epoch 159 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 100, time: 0.417, data: 0.173) G_GAN: 1.504 G_L1: 4.638 D_real: 0.459 D_fake: 0.367 \n",
      "(epoch: 160, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.521 G_L1: 5.311 D_real: 0.840 D_fake: 0.197 \n",
      "(epoch: 160, iters: 300, time: 0.165, data: 0.002) G_GAN: 2.046 G_L1: 7.413 D_real: 0.214 D_fake: 0.274 \n",
      "(epoch: 160, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.628 G_L1: 6.035 D_real: 0.331 D_fake: 0.354 \n",
      "(epoch: 160, iters: 500, time: 0.415, data: 0.002) G_GAN: 1.895 G_L1: 6.683 D_real: 0.213 D_fake: 0.554 \n",
      "saving the latest model (epoch 160, total_iters 80000)\n",
      "saving the model at the end of epoch 160, iters 80000\n",
      "End of epoch 160 / 200 \t Time Taken: 55 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 100, time: 0.163, data: 0.169) G_GAN: 1.750 G_L1: 6.925 D_real: 0.223 D_fake: 0.582 \n",
      "(epoch: 161, iters: 200, time: 0.164, data: 0.003) G_GAN: 2.125 G_L1: 5.227 D_real: 0.473 D_fake: 0.281 \n",
      "(epoch: 161, iters: 300, time: 0.167, data: 0.002) G_GAN: 1.467 G_L1: 5.047 D_real: 0.275 D_fake: 0.343 \n",
      "(epoch: 161, iters: 400, time: 0.391, data: 0.002) G_GAN: 1.421 G_L1: 5.677 D_real: 0.234 D_fake: 0.413 \n",
      "(epoch: 161, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.643 G_L1: 4.090 D_real: 0.556 D_fake: 0.289 \n",
      "End of epoch 161 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 100, time: 0.166, data: 0.148) G_GAN: 1.812 G_L1: 7.247 D_real: 0.225 D_fake: 0.619 \n",
      "(epoch: 162, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.704 G_L1: 7.381 D_real: 0.110 D_fake: 0.369 \n",
      "(epoch: 162, iters: 300, time: 0.410, data: 0.002) G_GAN: 1.512 G_L1: 5.201 D_real: 0.254 D_fake: 0.571 \n",
      "(epoch: 162, iters: 400, time: 0.164, data: 0.002) G_GAN: 2.075 G_L1: 8.261 D_real: 0.180 D_fake: 0.392 \n",
      "(epoch: 162, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.476 G_L1: 4.645 D_real: 0.534 D_fake: 0.320 \n",
      "End of epoch 162 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 100, time: 0.168, data: 0.157) G_GAN: 1.245 G_L1: 5.728 D_real: 0.585 D_fake: 0.401 \n",
      "(epoch: 163, iters: 200, time: 0.413, data: 0.002) G_GAN: 1.812 G_L1: 8.248 D_real: 0.351 D_fake: 0.222 \n",
      "(epoch: 163, iters: 300, time: 0.165, data: 0.002) G_GAN: 2.429 G_L1: 7.021 D_real: 0.291 D_fake: 0.413 \n",
      "(epoch: 163, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.318 G_L1: 5.053 D_real: 0.543 D_fake: 0.335 \n",
      "(epoch: 163, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.305 G_L1: 5.812 D_real: 0.280 D_fake: 0.453 \n",
      "End of epoch 163 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 100, time: 0.414, data: 0.178) G_GAN: 1.763 G_L1: 7.217 D_real: 0.177 D_fake: 0.897 \n",
      "(epoch: 164, iters: 200, time: 0.166, data: 0.002) G_GAN: 1.193 G_L1: 4.227 D_real: 0.881 D_fake: 0.345 \n",
      "(epoch: 164, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.410 G_L1: 4.330 D_real: 0.593 D_fake: 0.335 \n",
      "(epoch: 164, iters: 400, time: 0.165, data: 0.003) G_GAN: 1.264 G_L1: 5.696 D_real: 0.495 D_fake: 0.439 \n",
      "(epoch: 164, iters: 500, time: 0.410, data: 0.002) G_GAN: 1.799 G_L1: 6.875 D_real: 0.330 D_fake: 0.443 \n",
      "End of epoch 164 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 100, time: 0.164, data: 0.144) G_GAN: 1.392 G_L1: 6.425 D_real: 0.424 D_fake: 0.474 \n",
      "(epoch: 165, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.158 G_L1: 7.499 D_real: 0.714 D_fake: 0.361 \n",
      "(epoch: 165, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.812 G_L1: 6.912 D_real: 0.228 D_fake: 0.496 \n",
      "(epoch: 165, iters: 400, time: 0.404, data: 0.002) G_GAN: 1.399 G_L1: 6.561 D_real: 0.343 D_fake: 0.442 \n",
      "(epoch: 165, iters: 500, time: 0.165, data: 0.002) G_GAN: 2.342 G_L1: 6.855 D_real: 0.224 D_fake: 0.224 \n",
      "saving the model at the end of epoch 165, iters 82500\n",
      "End of epoch 165 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 100, time: 0.164, data: 0.142) G_GAN: 1.261 G_L1: 4.294 D_real: 0.483 D_fake: 0.388 \n",
      "(epoch: 166, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.698 G_L1: 6.793 D_real: 0.150 D_fake: 0.602 \n",
      "(epoch: 166, iters: 300, time: 0.412, data: 0.002) G_GAN: 1.584 G_L1: 5.188 D_real: 0.276 D_fake: 0.488 \n",
      "(epoch: 166, iters: 400, time: 0.165, data: 0.003) G_GAN: 1.915 G_L1: 6.356 D_real: 0.147 D_fake: 0.351 \n",
      "(epoch: 166, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.694 G_L1: 7.703 D_real: 0.344 D_fake: 0.513 \n",
      "End of epoch 166 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 100, time: 0.164, data: 0.159) G_GAN: 1.479 G_L1: 5.413 D_real: 0.390 D_fake: 0.245 \n",
      "(epoch: 167, iters: 200, time: 0.411, data: 0.002) G_GAN: 1.335 G_L1: 4.422 D_real: 0.462 D_fake: 0.460 \n",
      "(epoch: 167, iters: 300, time: 0.164, data: 0.002) G_GAN: 2.143 G_L1: 8.411 D_real: 0.090 D_fake: 0.549 \n",
      "(epoch: 167, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.353 G_L1: 5.121 D_real: 0.681 D_fake: 0.223 \n",
      "(epoch: 167, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.342 G_L1: 4.357 D_real: 0.408 D_fake: 0.501 \n",
      "End of epoch 167 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 100, time: 0.418, data: 0.170) G_GAN: 1.678 G_L1: 5.361 D_real: 0.271 D_fake: 0.481 \n",
      "(epoch: 168, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.499 G_L1: 6.012 D_real: 0.653 D_fake: 0.212 \n",
      "(epoch: 168, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.880 G_L1: 5.853 D_real: 0.209 D_fake: 0.632 \n",
      "(epoch: 168, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.481 G_L1: 6.898 D_real: 0.480 D_fake: 0.235 \n",
      "(epoch: 168, iters: 500, time: 0.412, data: 0.002) G_GAN: 1.262 G_L1: 5.703 D_real: 0.342 D_fake: 0.485 \n",
      "End of epoch 168 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 100, time: 0.165, data: 0.163) G_GAN: 1.930 G_L1: 7.508 D_real: 0.284 D_fake: 0.268 \n",
      "(epoch: 169, iters: 200, time: 0.164, data: 0.002) G_GAN: 2.247 G_L1: 6.324 D_real: 0.187 D_fake: 0.146 \n",
      "(epoch: 169, iters: 300, time: 0.165, data: 0.003) G_GAN: 1.328 G_L1: 5.996 D_real: 0.374 D_fake: 0.605 \n",
      "(epoch: 169, iters: 400, time: 0.430, data: 0.002) G_GAN: 1.955 G_L1: 6.978 D_real: 0.242 D_fake: 0.456 \n",
      "(epoch: 169, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.238 G_L1: 5.937 D_real: 0.510 D_fake: 0.439 \n",
      "End of epoch 169 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 100, time: 0.165, data: 0.157) G_GAN: 1.631 G_L1: 6.503 D_real: 0.318 D_fake: 0.417 \n",
      "(epoch: 170, iters: 200, time: 0.166, data: 0.003) G_GAN: 1.610 G_L1: 5.259 D_real: 0.375 D_fake: 0.425 \n",
      "(epoch: 170, iters: 300, time: 0.422, data: 0.002) G_GAN: 1.124 G_L1: 4.719 D_real: 0.480 D_fake: 0.456 \n",
      "(epoch: 170, iters: 400, time: 0.164, data: 0.002) G_GAN: 2.276 G_L1: 7.821 D_real: 0.073 D_fake: 0.631 \n",
      "(epoch: 170, iters: 500, time: 0.165, data: 0.004) G_GAN: 1.283 G_L1: 4.400 D_real: 0.481 D_fake: 0.576 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the latest model (epoch 170, total_iters 85000)\n",
      "saving the model at the end of epoch 170, iters 85000\n",
      "End of epoch 170 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 100, time: 0.165, data: 0.174) G_GAN: 1.689 G_L1: 5.102 D_real: 0.220 D_fake: 0.722 \n",
      "(epoch: 171, iters: 200, time: 0.409, data: 0.002) G_GAN: 1.839 G_L1: 5.780 D_real: 0.577 D_fake: 0.200 \n",
      "(epoch: 171, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.989 G_L1: 7.685 D_real: 0.364 D_fake: 0.242 \n",
      "(epoch: 171, iters: 400, time: 0.164, data: 0.003) G_GAN: 1.695 G_L1: 5.044 D_real: 0.441 D_fake: 0.301 \n",
      "(epoch: 171, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.610 G_L1: 6.919 D_real: 0.259 D_fake: 0.624 \n",
      "End of epoch 171 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 100, time: 0.425, data: 0.146) G_GAN: 1.682 G_L1: 5.620 D_real: 0.217 D_fake: 0.670 \n",
      "(epoch: 172, iters: 200, time: 0.165, data: 0.003) G_GAN: 1.481 G_L1: 5.530 D_real: 0.445 D_fake: 0.349 \n",
      "(epoch: 172, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.615 G_L1: 6.742 D_real: 0.315 D_fake: 0.576 \n",
      "(epoch: 172, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.884 G_L1: 7.318 D_real: 0.344 D_fake: 0.302 \n",
      "(epoch: 172, iters: 500, time: 0.407, data: 0.002) G_GAN: 1.310 G_L1: 5.539 D_real: 0.403 D_fake: 0.270 \n",
      "End of epoch 172 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 100, time: 0.164, data: 0.175) G_GAN: 1.213 G_L1: 5.554 D_real: 0.434 D_fake: 0.501 \n",
      "(epoch: 173, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.618 G_L1: 8.380 D_real: 0.277 D_fake: 0.346 \n",
      "(epoch: 173, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.503 G_L1: 6.794 D_real: 0.519 D_fake: 0.288 \n",
      "(epoch: 173, iters: 400, time: 0.411, data: 0.003) G_GAN: 1.201 G_L1: 4.846 D_real: 0.466 D_fake: 0.505 \n",
      "(epoch: 173, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.261 G_L1: 4.801 D_real: 0.423 D_fake: 0.504 \n",
      "End of epoch 173 / 200 \t Time Taken: 52 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 100, time: 0.164, data: 0.153) G_GAN: 1.565 G_L1: 6.929 D_real: 0.429 D_fake: 0.359 \n",
      "(epoch: 174, iters: 200, time: 0.165, data: 0.002) G_GAN: 2.832 G_L1: 6.656 D_real: 0.272 D_fake: 0.207 \n",
      "(epoch: 174, iters: 300, time: 0.424, data: 0.002) G_GAN: 1.573 G_L1: 7.073 D_real: 0.295 D_fake: 0.289 \n",
      "(epoch: 174, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.250 G_L1: 4.610 D_real: 0.627 D_fake: 0.217 \n",
      "(epoch: 174, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.533 G_L1: 4.695 D_real: 0.703 D_fake: 0.231 \n",
      "End of epoch 174 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 100, time: 0.165, data: 0.153) G_GAN: 1.753 G_L1: 6.661 D_real: 0.363 D_fake: 0.194 \n",
      "(epoch: 175, iters: 200, time: 0.412, data: 0.002) G_GAN: 1.808 G_L1: 5.117 D_real: 0.400 D_fake: 0.536 \n",
      "(epoch: 175, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.571 G_L1: 5.700 D_real: 0.136 D_fake: 0.724 \n",
      "(epoch: 175, iters: 400, time: 0.165, data: 0.003) G_GAN: 1.220 G_L1: 6.456 D_real: 0.490 D_fake: 0.440 \n",
      "(epoch: 175, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.931 G_L1: 7.709 D_real: 0.139 D_fake: 0.588 \n",
      "saving the model at the end of epoch 175, iters 87500\n",
      "End of epoch 175 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 100, time: 0.437, data: 0.145) G_GAN: 1.576 G_L1: 4.031 D_real: 0.418 D_fake: 0.328 \n",
      "(epoch: 176, iters: 200, time: 0.165, data: 0.003) G_GAN: 1.066 G_L1: 6.605 D_real: 0.990 D_fake: 0.208 \n",
      "(epoch: 176, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.724 G_L1: 6.890 D_real: 0.470 D_fake: 0.170 \n",
      "(epoch: 176, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.117 G_L1: 5.131 D_real: 0.517 D_fake: 0.257 \n",
      "(epoch: 176, iters: 500, time: 0.431, data: 0.002) G_GAN: 1.456 G_L1: 6.238 D_real: 0.475 D_fake: 0.353 \n",
      "End of epoch 176 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 100, time: 0.164, data: 0.154) G_GAN: 1.375 G_L1: 6.876 D_real: 0.332 D_fake: 0.798 \n",
      "(epoch: 177, iters: 200, time: 0.164, data: 0.002) G_GAN: 2.000 G_L1: 6.892 D_real: 0.316 D_fake: 0.144 \n",
      "(epoch: 177, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.331 G_L1: 6.711 D_real: 0.423 D_fake: 0.685 \n",
      "(epoch: 177, iters: 400, time: 0.432, data: 0.003) G_GAN: 1.766 G_L1: 5.791 D_real: 0.644 D_fake: 0.128 \n",
      "(epoch: 177, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.864 G_L1: 10.107 D_real: 0.166 D_fake: 0.278 \n",
      "End of epoch 177 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 100, time: 0.165, data: 0.160) G_GAN: 1.348 G_L1: 5.780 D_real: 0.338 D_fake: 0.609 \n",
      "(epoch: 178, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.453 G_L1: 5.110 D_real: 0.605 D_fake: 0.234 \n",
      "(epoch: 178, iters: 300, time: 0.423, data: 0.002) G_GAN: 1.792 G_L1: 4.947 D_real: 0.386 D_fake: 0.376 \n",
      "(epoch: 178, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.409 G_L1: 5.702 D_real: 0.475 D_fake: 0.399 \n",
      "(epoch: 178, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.526 G_L1: 7.154 D_real: 0.269 D_fake: 0.395 \n",
      "End of epoch 178 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 100, time: 0.164, data: 0.188) G_GAN: 1.782 G_L1: 5.522 D_real: 0.403 D_fake: 0.312 \n",
      "(epoch: 179, iters: 200, time: 0.426, data: 0.003) G_GAN: 1.406 G_L1: 4.969 D_real: 0.241 D_fake: 0.659 \n",
      "(epoch: 179, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.724 G_L1: 8.107 D_real: 0.257 D_fake: 0.385 \n",
      "(epoch: 179, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.865 G_L1: 7.775 D_real: 0.292 D_fake: 0.238 \n",
      "(epoch: 179, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.583 G_L1: 6.408 D_real: 0.218 D_fake: 0.368 \n",
      "End of epoch 179 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000416\n",
      "(epoch: 180, iters: 100, time: 0.445, data: 0.176) G_GAN: 1.289 G_L1: 5.233 D_real: 0.685 D_fake: 0.306 \n",
      "(epoch: 180, iters: 200, time: 0.166, data: 0.002) G_GAN: 1.332 G_L1: 6.420 D_real: 0.440 D_fake: 0.419 \n",
      "(epoch: 180, iters: 300, time: 0.164, data: 0.003) G_GAN: 1.614 G_L1: 6.424 D_real: 0.247 D_fake: 0.731 \n",
      "(epoch: 180, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.136 G_L1: 7.607 D_real: 0.186 D_fake: 0.953 \n",
      "(epoch: 180, iters: 500, time: 0.461, data: 0.003) G_GAN: 1.533 G_L1: 5.088 D_real: 0.395 D_fake: 0.292 \n",
      "saving the latest model (epoch 180, total_iters 90000)\n",
      "saving the model at the end of epoch 180, iters 90000\n",
      "End of epoch 180 / 200 \t Time Taken: 56 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 100, time: 0.166, data: 0.153) G_GAN: 1.003 G_L1: 3.372 D_real: 0.590 D_fake: 0.634 \n",
      "(epoch: 181, iters: 200, time: 0.164, data: 0.003) G_GAN: 1.833 G_L1: 6.105 D_real: 0.181 D_fake: 0.305 \n",
      "(epoch: 181, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.765 G_L1: 6.589 D_real: 0.421 D_fake: 0.218 \n",
      "(epoch: 181, iters: 400, time: 0.423, data: 0.003) G_GAN: 1.585 G_L1: 6.388 D_real: 0.376 D_fake: 0.366 \n",
      "(epoch: 181, iters: 500, time: 0.170, data: 0.002) G_GAN: 1.545 G_L1: 4.823 D_real: 0.405 D_fake: 0.350 \n",
      "End of epoch 181 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 100, time: 0.165, data: 0.173) G_GAN: 2.048 G_L1: 6.586 D_real: 0.288 D_fake: 0.222 \n",
      "(epoch: 182, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.929 G_L1: 7.298 D_real: 0.149 D_fake: 0.346 \n",
      "(epoch: 182, iters: 300, time: 0.421, data: 0.002) G_GAN: 1.623 G_L1: 7.292 D_real: 0.387 D_fake: 0.217 \n",
      "(epoch: 182, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.656 G_L1: 7.592 D_real: 0.365 D_fake: 0.263 \n",
      "(epoch: 182, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.245 G_L1: 4.686 D_real: 0.628 D_fake: 0.347 \n",
      "End of epoch 182 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 100, time: 0.164, data: 0.158) G_GAN: 0.908 G_L1: 6.288 D_real: 0.515 D_fake: 0.502 \n",
      "(epoch: 183, iters: 200, time: 0.425, data: 0.002) G_GAN: 1.356 G_L1: 5.977 D_real: 0.325 D_fake: 0.423 \n",
      "(epoch: 183, iters: 300, time: 0.164, data: 0.002) G_GAN: 2.172 G_L1: 7.297 D_real: 0.239 D_fake: 0.246 \n",
      "(epoch: 183, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.682 G_L1: 4.240 D_real: 0.229 D_fake: 0.670 \n",
      "(epoch: 183, iters: 500, time: 0.166, data: 0.003) G_GAN: 1.430 G_L1: 8.131 D_real: 0.303 D_fake: 0.448 \n",
      "End of epoch 183 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 100, time: 0.439, data: 0.155) G_GAN: 1.073 G_L1: 5.332 D_real: 0.596 D_fake: 0.472 \n",
      "(epoch: 184, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.144 G_L1: 5.787 D_real: 0.556 D_fake: 0.392 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 184, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.872 G_L1: 7.215 D_real: 0.178 D_fake: 0.348 \n",
      "(epoch: 184, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.679 G_L1: 6.132 D_real: 0.293 D_fake: 0.400 \n",
      "(epoch: 184, iters: 500, time: 0.424, data: 0.002) G_GAN: 1.206 G_L1: 6.127 D_real: 0.464 D_fake: 0.338 \n",
      "End of epoch 184 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 100, time: 0.165, data: 0.166) G_GAN: 1.685 G_L1: 6.760 D_real: 0.353 D_fake: 0.323 \n",
      "(epoch: 185, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.178 G_L1: 4.170 D_real: 0.514 D_fake: 0.406 \n",
      "(epoch: 185, iters: 300, time: 0.165, data: 0.002) G_GAN: 1.492 G_L1: 4.667 D_real: 0.348 D_fake: 0.295 \n",
      "(epoch: 185, iters: 400, time: 0.424, data: 0.002) G_GAN: 1.508 G_L1: 7.569 D_real: 0.182 D_fake: 0.400 \n",
      "(epoch: 185, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.428 G_L1: 4.522 D_real: 0.360 D_fake: 0.456 \n",
      "saving the model at the end of epoch 185, iters 92500\n",
      "End of epoch 185 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 100, time: 0.164, data: 0.145) G_GAN: 1.544 G_L1: 5.165 D_real: 0.617 D_fake: 0.231 \n",
      "(epoch: 186, iters: 200, time: 0.164, data: 0.003) G_GAN: 1.482 G_L1: 6.414 D_real: 0.398 D_fake: 0.394 \n",
      "(epoch: 186, iters: 300, time: 0.438, data: 0.002) G_GAN: 1.343 G_L1: 5.341 D_real: 0.542 D_fake: 0.779 \n",
      "(epoch: 186, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.795 G_L1: 6.934 D_real: 0.184 D_fake: 0.303 \n",
      "(epoch: 186, iters: 500, time: 0.165, data: 0.002) G_GAN: 1.419 G_L1: 5.980 D_real: 0.464 D_fake: 0.245 \n",
      "End of epoch 186 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 100, time: 0.165, data: 0.145) G_GAN: 1.671 G_L1: 6.400 D_real: 0.335 D_fake: 0.360 \n",
      "(epoch: 187, iters: 200, time: 0.434, data: 0.002) G_GAN: 1.206 G_L1: 4.785 D_real: 0.436 D_fake: 0.447 \n",
      "(epoch: 187, iters: 300, time: 0.164, data: 0.002) G_GAN: 1.579 G_L1: 6.651 D_real: 0.352 D_fake: 0.314 \n",
      "(epoch: 187, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.379 G_L1: 6.681 D_real: 0.290 D_fake: 0.380 \n",
      "(epoch: 187, iters: 500, time: 0.164, data: 0.002) G_GAN: 2.096 G_L1: 7.345 D_real: 0.165 D_fake: 0.281 \n",
      "End of epoch 187 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 100, time: 0.434, data: 0.171) G_GAN: 1.802 G_L1: 7.929 D_real: 0.137 D_fake: 0.335 \n",
      "(epoch: 188, iters: 200, time: 0.169, data: 0.002) G_GAN: 1.078 G_L1: 5.222 D_real: 0.599 D_fake: 0.371 \n",
      "(epoch: 188, iters: 300, time: 0.165, data: 0.003) G_GAN: 1.337 G_L1: 4.065 D_real: 0.636 D_fake: 0.124 \n",
      "(epoch: 188, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.179 G_L1: 5.021 D_real: 0.644 D_fake: 0.307 \n",
      "(epoch: 188, iters: 500, time: 0.441, data: 0.002) G_GAN: 1.288 G_L1: 6.311 D_real: 0.577 D_fake: 0.301 \n",
      "End of epoch 188 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 100, time: 0.164, data: 0.170) G_GAN: 1.295 G_L1: 7.226 D_real: 0.262 D_fake: 0.490 \n",
      "(epoch: 189, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.488 G_L1: 4.112 D_real: 0.561 D_fake: 0.422 \n",
      "(epoch: 189, iters: 300, time: 0.166, data: 0.003) G_GAN: 1.517 G_L1: 5.278 D_real: 0.210 D_fake: 0.564 \n",
      "(epoch: 189, iters: 400, time: 0.435, data: 0.002) G_GAN: 1.404 G_L1: 5.561 D_real: 0.267 D_fake: 0.403 \n",
      "(epoch: 189, iters: 500, time: 0.167, data: 0.002) G_GAN: 2.194 G_L1: 6.716 D_real: 0.146 D_fake: 0.182 \n",
      "End of epoch 189 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 100, time: 0.164, data: 0.164) G_GAN: 1.545 G_L1: 7.602 D_real: 0.301 D_fake: 0.348 \n",
      "(epoch: 190, iters: 200, time: 0.167, data: 0.002) G_GAN: 1.628 G_L1: 6.834 D_real: 0.295 D_fake: 0.303 \n",
      "(epoch: 190, iters: 300, time: 0.476, data: 0.003) G_GAN: 1.635 G_L1: 7.273 D_real: 0.186 D_fake: 0.477 \n",
      "(epoch: 190, iters: 400, time: 0.168, data: 0.002) G_GAN: 1.845 G_L1: 6.579 D_real: 0.227 D_fake: 0.256 \n",
      "(epoch: 190, iters: 500, time: 0.166, data: 0.002) G_GAN: 2.107 G_L1: 8.703 D_real: 0.206 D_fake: 0.245 \n",
      "saving the latest model (epoch 190, total_iters 95000)\n",
      "saving the model at the end of epoch 190, iters 95000\n",
      "End of epoch 190 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 100, time: 0.164, data: 0.171) G_GAN: 1.295 G_L1: 7.134 D_real: 0.449 D_fake: 0.359 \n",
      "(epoch: 191, iters: 200, time: 0.464, data: 0.002) G_GAN: 1.457 G_L1: 6.996 D_real: 0.491 D_fake: 0.276 \n",
      "(epoch: 191, iters: 300, time: 0.169, data: 0.002) G_GAN: 1.420 G_L1: 4.544 D_real: 0.332 D_fake: 0.421 \n",
      "(epoch: 191, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.965 G_L1: 6.296 D_real: 0.234 D_fake: 0.188 \n",
      "(epoch: 191, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.841 G_L1: 6.428 D_real: 0.296 D_fake: 0.286 \n",
      "End of epoch 191 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 100, time: 0.450, data: 0.155) G_GAN: 1.158 G_L1: 4.356 D_real: 0.413 D_fake: 0.469 \n",
      "(epoch: 192, iters: 200, time: 0.166, data: 0.002) G_GAN: 1.246 G_L1: 5.241 D_real: 0.409 D_fake: 0.374 \n",
      "(epoch: 192, iters: 300, time: 0.176, data: 0.002) G_GAN: 1.521 G_L1: 6.021 D_real: 0.263 D_fake: 0.416 \n",
      "(epoch: 192, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.700 G_L1: 2.580 D_real: 0.430 D_fake: 0.365 \n",
      "(epoch: 192, iters: 500, time: 0.444, data: 0.003) G_GAN: 1.669 G_L1: 7.505 D_real: 0.338 D_fake: 0.298 \n",
      "End of epoch 192 / 200 \t Time Taken: 55 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 100, time: 0.166, data: 0.151) G_GAN: 1.901 G_L1: 4.935 D_real: 0.379 D_fake: 0.267 \n",
      "(epoch: 193, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.337 G_L1: 7.148 D_real: 0.416 D_fake: 0.371 \n",
      "(epoch: 193, iters: 300, time: 0.164, data: 0.003) G_GAN: 1.145 G_L1: 4.625 D_real: 0.447 D_fake: 0.474 \n",
      "(epoch: 193, iters: 400, time: 0.456, data: 0.003) G_GAN: 1.429 G_L1: 5.503 D_real: 0.173 D_fake: 0.517 \n",
      "(epoch: 193, iters: 500, time: 0.166, data: 0.003) G_GAN: 1.840 G_L1: 7.502 D_real: 0.144 D_fake: 0.276 \n",
      "End of epoch 193 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 100, time: 0.165, data: 0.187) G_GAN: 1.615 G_L1: 6.512 D_real: 0.338 D_fake: 0.279 \n",
      "(epoch: 194, iters: 200, time: 0.166, data: 0.002) G_GAN: 2.286 G_L1: 8.181 D_real: 0.238 D_fake: 0.158 \n",
      "(epoch: 194, iters: 300, time: 0.450, data: 0.003) G_GAN: 1.471 G_L1: 4.845 D_real: 0.538 D_fake: 0.349 \n",
      "(epoch: 194, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.316 G_L1: 4.348 D_real: 0.337 D_fake: 0.336 \n",
      "(epoch: 194, iters: 500, time: 0.166, data: 0.003) G_GAN: 1.468 G_L1: 5.366 D_real: 0.398 D_fake: 0.321 \n",
      "End of epoch 194 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 100, time: 0.164, data: 0.154) G_GAN: 1.908 G_L1: 6.362 D_real: 0.465 D_fake: 0.221 \n",
      "(epoch: 195, iters: 200, time: 0.457, data: 0.003) G_GAN: 1.562 G_L1: 6.090 D_real: 0.414 D_fake: 0.320 \n",
      "(epoch: 195, iters: 300, time: 0.164, data: 0.003) G_GAN: 1.693 G_L1: 6.757 D_real: 0.374 D_fake: 0.259 \n",
      "(epoch: 195, iters: 400, time: 0.166, data: 0.002) G_GAN: 1.273 G_L1: 6.658 D_real: 0.324 D_fake: 0.426 \n",
      "(epoch: 195, iters: 500, time: 0.164, data: 0.003) G_GAN: 1.547 G_L1: 5.107 D_real: 0.424 D_fake: 0.302 \n",
      "saving the model at the end of epoch 195, iters 97500\n",
      "End of epoch 195 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 100, time: 0.453, data: 0.170) G_GAN: 2.546 G_L1: 5.756 D_real: 0.211 D_fake: 0.102 \n",
      "(epoch: 196, iters: 200, time: 0.164, data: 0.002) G_GAN: 1.422 G_L1: 8.063 D_real: 0.283 D_fake: 0.447 \n",
      "(epoch: 196, iters: 300, time: 0.178, data: 0.002) G_GAN: 1.242 G_L1: 6.204 D_real: 0.495 D_fake: 0.468 \n",
      "(epoch: 196, iters: 400, time: 0.168, data: 0.003) G_GAN: 1.694 G_L1: 4.312 D_real: 0.586 D_fake: 0.321 \n",
      "(epoch: 196, iters: 500, time: 0.448, data: 0.003) G_GAN: 1.588 G_L1: 8.503 D_real: 0.328 D_fake: 0.277 \n",
      "End of epoch 196 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 100, time: 0.165, data: 0.155) G_GAN: 1.463 G_L1: 6.135 D_real: 0.255 D_fake: 0.357 \n",
      "(epoch: 197, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.221 G_L1: 6.138 D_real: 0.451 D_fake: 0.432 \n",
      "(epoch: 197, iters: 300, time: 0.171, data: 0.002) G_GAN: 0.966 G_L1: 6.637 D_real: 0.422 D_fake: 0.587 \n",
      "(epoch: 197, iters: 400, time: 0.498, data: 0.002) G_GAN: 1.527 G_L1: 5.841 D_real: 0.358 D_fake: 0.293 \n",
      "(epoch: 197, iters: 500, time: 0.164, data: 0.002) G_GAN: 1.440 G_L1: 5.913 D_real: 0.382 D_fake: 0.395 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 197 / 200 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 100, time: 0.167, data: 0.144) G_GAN: 1.559 G_L1: 4.995 D_real: 0.264 D_fake: 0.334 \n",
      "(epoch: 198, iters: 200, time: 0.165, data: 0.002) G_GAN: 1.457 G_L1: 4.562 D_real: 0.442 D_fake: 0.296 \n",
      "(epoch: 198, iters: 300, time: 0.444, data: 0.002) G_GAN: 2.010 G_L1: 7.059 D_real: 0.284 D_fake: 0.202 \n",
      "(epoch: 198, iters: 400, time: 0.164, data: 0.002) G_GAN: 1.902 G_L1: 5.360 D_real: 0.281 D_fake: 0.208 \n",
      "(epoch: 198, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.350 G_L1: 5.636 D_real: 0.427 D_fake: 0.385 \n",
      "End of epoch 198 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 100, time: 0.164, data: 0.178) G_GAN: 1.285 G_L1: 3.461 D_real: 0.567 D_fake: 0.410 \n",
      "(epoch: 199, iters: 200, time: 0.468, data: 0.003) G_GAN: 1.343 G_L1: 4.325 D_real: 0.412 D_fake: 0.383 \n",
      "(epoch: 199, iters: 300, time: 0.164, data: 0.003) G_GAN: 1.776 G_L1: 6.628 D_real: 0.170 D_fake: 0.263 \n",
      "(epoch: 199, iters: 400, time: 0.165, data: 0.002) G_GAN: 1.240 G_L1: 5.704 D_real: 0.505 D_fake: 0.430 \n",
      "(epoch: 199, iters: 500, time: 0.165, data: 0.003) G_GAN: 1.253 G_L1: 5.710 D_real: 0.439 D_fake: 0.442 \n",
      "End of epoch 199 / 200 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 100, time: 0.482, data: 0.161) G_GAN: 1.428 G_L1: 5.595 D_real: 0.499 D_fake: 0.340 \n",
      "(epoch: 200, iters: 200, time: 0.166, data: 0.002) G_GAN: 1.839 G_L1: 6.280 D_real: 0.289 D_fake: 0.248 \n",
      "(epoch: 200, iters: 300, time: 0.166, data: 0.002) G_GAN: 1.740 G_L1: 7.260 D_real: 0.143 D_fake: 0.255 \n",
      "(epoch: 200, iters: 400, time: 0.169, data: 0.003) G_GAN: 1.508 G_L1: 4.210 D_real: 0.615 D_fake: 0.316 \n",
      "(epoch: 200, iters: 500, time: 0.472, data: 0.002) G_GAN: 2.140 G_L1: 5.509 D_real: 0.448 D_fake: 0.166 \n",
      "saving the latest model (epoch 200, total_iters 100000)\n",
      "saving the model at the end of epoch 200, iters 100000\n",
      "End of epoch 200 / 200 \t Time Taken: 56 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot extrarealsyncolor/AB --model pix2pix --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 4  --netG resnet_9blocks --preprocess none --name realsyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 4                             \t[default: 1]\n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: testimg                       \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: realsyn                       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_apr17_e_realsyn       \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from Apr17/realsyn/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.366 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['testimg/001.jpg']\n",
      "processing (0005)-th image... ['testimg/006.jpg']\n",
      "processing (0010)-th image... ['testimg/011.jpg']\n",
      "processing (0015)-th image... ['testimg/016.jpg']\n",
      "processing (0020)-th image... ['testimg/021.jpg']\n",
      "processing (0025)-th image... ['testimg/026.jpg']\n",
      "processing (0030)-th image... ['testimg/031.jpg']\n",
      "processing (0035)-th image... ['testimg/036.jpg']\n",
      "processing (0040)-th image... ['testimg/041.jpg']\n",
      "processing (0045)-th image... ['testimg/046.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot testimg --model test --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 4 --netG resnet_9blocks --preprocess none --name realsyn --results_dir results_apr17_e_realsyn  --dataset_mode single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 4                             \t[default: 1]\n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "                crop_size: 256                           \n",
      "                 dataroot: testimages                    \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: realsyn                       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: none                          \t[default: resize_and_crop]\n",
      "              results_dir: results_apr17_t_realsyn       \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from Apr17/realsyn/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.366 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['testimages/0054-160-m3h--5-h-ksb-etanorm-g-100-200-g11.jpg']\n",
      "The image size needs to be a multiple of 4. The loaded image size was (1801, 1169), so it was adjusted to (1800, 1168). This adjustment will be done to all images whose sizes are not multiples of 4\n",
      "processing (0005)-th image... ['testimages/17J-SG02_17J-SG02 nameplate.jpeg']\n",
      "processing (0010)-th image... ['testimages/2968_3.jpeg']\n",
      "processing (0015)-th image... ['testimages/4.jpg']\n",
      "processing (0020)-th image... ['testimages/7506_3.jpeg']\n",
      "processing (0025)-th image... ['testimages/NamePlate110.jpeg']\n",
      "processing (0030)-th image... ['testimages/image_185.jpg']\n",
      "processing (0035)-th image... ['testimages/image_765.jpg']\n",
      "processing (0040)-th image... ['testimages/s-l640.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot testimages --model test --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 4 --netG resnet_9blocks --preprocess none --name realsyn --results_dir results_apr17_t_realsyn  --dataset_mode single  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 2                             \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: Apr17                         \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 300                           \t[default: 256]\n",
      "                 dataroot: cycleGAN/                     \t[default: None]\n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0,1                           \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: True                          \t[default: None]\n",
      "                 lambda_A: 10.0                          \n",
      "                 lambda_B: 10.0                          \n",
      "          lambda_identity: 0.5                           \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 400                           \t[default: 286]\n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \n",
      "               n_layers_D: 3                             \n",
      "                     name: cycle_gan                     \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: True                          \n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [UnalignedDataset] was created\n",
      "The number of training images = 480\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [CycleGANModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G_A] Total number of parameters : 11.366 M\n",
      "[Network G_B] Total number of parameters : 11.366 M\n",
      "[Network D_A] Total number of parameters : 2.763 M\n",
      "[Network D_B] Total number of parameters : 2.763 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory Apr17/cycle_gan/web...\n",
      "(epoch: 1, iters: 100, time: 0.230, data: 0.165) D_A: 0.648 G_A: 0.904 cycle_A: 2.428 idt_A: 0.527 D_B: 0.428 G_B: 0.493 cycle_B: 1.144 idt_B: 1.053 \n",
      "(epoch: 1, iters: 200, time: 0.228, data: 0.001) D_A: 0.213 G_A: 0.457 cycle_A: 3.393 idt_A: 0.629 D_B: 0.452 G_B: 0.601 cycle_B: 1.338 idt_B: 1.568 \n",
      "(epoch: 1, iters: 300, time: 0.231, data: 0.001) D_A: 0.359 G_A: 0.499 cycle_A: 2.998 idt_A: 0.402 D_B: 0.265 G_B: 0.324 cycle_B: 0.994 idt_B: 1.175 \n",
      "(epoch: 1, iters: 400, time: 0.391, data: 0.002) D_A: 0.263 G_A: 0.380 cycle_A: 2.459 idt_A: 0.317 D_B: 0.317 G_B: 0.327 cycle_B: 0.664 idt_B: 1.261 \n",
      "End of epoch 1 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 20, time: 0.232, data: 0.001) D_A: 0.441 G_A: 0.710 cycle_A: 3.417 idt_A: 0.364 D_B: 0.375 G_B: 0.514 cycle_B: 0.823 idt_B: 1.671 \n",
      "(epoch: 2, iters: 120, time: 0.236, data: 0.001) D_A: 0.299 G_A: 0.368 cycle_A: 2.460 idt_A: 0.322 D_B: 0.266 G_B: 0.472 cycle_B: 0.671 idt_B: 1.123 \n",
      "(epoch: 2, iters: 220, time: 0.232, data: 0.002) D_A: 0.330 G_A: 0.494 cycle_A: 4.712 idt_A: 0.556 D_B: 0.272 G_B: 0.331 cycle_B: 1.122 idt_B: 2.239 \n",
      "(epoch: 2, iters: 320, time: 0.391, data: 0.002) D_A: 0.197 G_A: 0.335 cycle_A: 2.035 idt_A: 0.222 D_B: 0.240 G_B: 0.391 cycle_B: 0.494 idt_B: 0.649 \n",
      "(epoch: 2, iters: 420, time: 0.231, data: 0.001) D_A: 0.239 G_A: 0.523 cycle_A: 2.272 idt_A: 0.286 D_B: 0.221 G_B: 0.340 cycle_B: 0.738 idt_B: 1.140 \n",
      "End of epoch 2 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 40, time: 0.231, data: 0.001) D_A: 0.207 G_A: 0.226 cycle_A: 3.722 idt_A: 0.251 D_B: 0.358 G_B: 0.299 cycle_B: 0.654 idt_B: 1.579 \n",
      "(epoch: 3, iters: 140, time: 0.238, data: 0.001) D_A: 0.235 G_A: 0.523 cycle_A: 2.688 idt_A: 0.324 D_B: 0.189 G_B: 0.429 cycle_B: 0.705 idt_B: 1.300 \n",
      "(epoch: 3, iters: 240, time: 0.383, data: 0.001) D_A: 0.268 G_A: 0.706 cycle_A: 3.998 idt_A: 0.396 D_B: 0.284 G_B: 0.350 cycle_B: 0.849 idt_B: 1.857 \n",
      "(epoch: 3, iters: 340, time: 0.251, data: 0.001) D_A: 0.144 G_A: 0.418 cycle_A: 3.225 idt_A: 0.341 D_B: 0.173 G_B: 0.464 cycle_B: 0.734 idt_B: 1.545 \n",
      "(epoch: 3, iters: 440, time: 0.232, data: 0.001) D_A: 0.231 G_A: 0.291 cycle_A: 2.511 idt_A: 0.240 D_B: 0.280 G_B: 0.393 cycle_B: 0.493 idt_B: 0.803 \n",
      "End of epoch 3 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 60, time: 0.235, data: 0.001) D_A: 0.174 G_A: 0.408 cycle_A: 1.915 idt_A: 0.293 D_B: 0.283 G_B: 0.351 cycle_B: 0.699 idt_B: 0.844 \n",
      "(epoch: 4, iters: 160, time: 0.402, data: 0.001) D_A: 0.160 G_A: 0.237 cycle_A: 1.892 idt_A: 0.211 D_B: 0.252 G_B: 0.319 cycle_B: 0.444 idt_B: 0.667 \n",
      "(epoch: 4, iters: 260, time: 0.233, data: 0.001) D_A: 0.309 G_A: 1.072 cycle_A: 1.760 idt_A: 0.186 D_B: 0.411 G_B: 0.498 cycle_B: 0.663 idt_B: 0.604 \n",
      "(epoch: 4, iters: 360, time: 0.231, data: 0.004) D_A: 0.211 G_A: 0.536 cycle_A: 3.046 idt_A: 0.243 D_B: 0.269 G_B: 0.303 cycle_B: 0.590 idt_B: 0.945 \n",
      "(epoch: 4, iters: 460, time: 0.229, data: 0.002) D_A: 0.166 G_A: 0.729 cycle_A: 2.609 idt_A: 0.206 D_B: 0.235 G_B: 0.272 cycle_B: 0.482 idt_B: 1.241 \n",
      "End of epoch 4 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 80, time: 0.380, data: 0.001) D_A: 0.211 G_A: 0.481 cycle_A: 2.793 idt_A: 0.234 D_B: 0.263 G_B: 0.271 cycle_B: 0.532 idt_B: 0.996 \n",
      "(epoch: 5, iters: 180, time: 0.226, data: 0.001) D_A: 2.045 G_A: 0.691 cycle_A: 2.083 idt_A: 0.492 D_B: 0.249 G_B: 0.223 cycle_B: 0.987 idt_B: 0.782 \n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot cycleGAN/ --model cycle_gan --input_nc 1 --output_nc 1 --norm instance --checkpoints_dir Apr17 --gpu_ids 0,1 --batch_size 2  --netG resnet_9blocks --preprocess resize_and_crop --load_size 400 --no_flip --crop_size 300 --name cycle_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pix2pix.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
